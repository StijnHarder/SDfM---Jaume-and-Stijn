{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # to make jupyter print all outputs, not just the last one\n",
    "from IPython.core.display import HTML # to pretty print pandas df and be able to copy them over (e.g. to ppt slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_parquet('cleaned/netflix_parquet')\n",
    "movielens_df = pd.read_parquet('cleaned/movielens_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix_df = netflix_df[netflix_df['review_data'].apply(lambda x: len(x) if x is not None else 0) > 500]\n",
    "netflix_df = netflix_df[netflix_df['review_data'].apply(lambda x: 30 <= len(x) <= 350 if x is not None else False)]\n",
    "movielens_df = movielens_df[movielens_df['review_data'].apply(lambda x: 30 <= len(x) <= 350 if x is not None else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>review_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>649</td>\n",
       "      <td>[{'date': 2002-01-09, 'rating': 1.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>[{'date': 2005-07-11, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>927</td>\n",
       "      <td>[{'date': 2005-12-05, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>735</td>\n",
       "      <td>[{'date': 2005-07-06, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1337</td>\n",
       "      <td>[{'date': 2005-06-08, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1090</td>\n",
       "      <td>[{'date': 2005-05-11, 'rating': 2.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1281</td>\n",
       "      <td>[{'date': 2005-04-11, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>[{'date': 2004-11-29, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>182</td>\n",
       "      <td>[{'date': 2002-02-20, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>[{'date': 2004-11-30, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                        review_data\n",
       "648       649  [{'date': 2002-01-09, 'rating': 1.0, 'userId':...\n",
       "84         85  [{'date': 2005-07-11, 'rating': 4.0, 'userId':...\n",
       "926       927  [{'date': 2005-12-05, 'rating': 3.0, 'userId':...\n",
       "734       735  [{'date': 2005-07-06, 'rating': 4.0, 'userId':...\n",
       "1336     1337  [{'date': 2005-06-08, 'rating': 3.0, 'userId':...\n",
       "...       ...                                                ...\n",
       "1089     1090  [{'date': 2005-05-11, 'rating': 2.0, 'userId':...\n",
       "1280     1281  [{'date': 2005-04-11, 'rating': 3.0, 'userId':...\n",
       "248       249  [{'date': 2004-11-29, 'rating': 4.0, 'userId':...\n",
       "181       182  [{'date': 2002-02-20, 'rating': 4.0, 'userId':...\n",
       "104       105  [{'date': 2004-11-30, 'rating': 3.0, 'userId':...\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>review_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>2029</td>\n",
       "      <td>[{'date': 2000-01-18, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>89305</td>\n",
       "      <td>[{'date': 2011-12-19, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18076</th>\n",
       "      <td>101088</td>\n",
       "      <td>[{'date': 2020-05-10, 'rating': 2.5, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>64285</td>\n",
       "      <td>[{'date': 2009-01-29, 'rating': 4.5, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>554</td>\n",
       "      <td>[{'date': 2000-03-20, 'rating': 1.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23007</th>\n",
       "      <td>127096</td>\n",
       "      <td>[{'date': 2015-05-23, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47772</th>\n",
       "      <td>253620</td>\n",
       "      <td>[{'date': 2022-04-12, 'rating': 4.5, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12158</th>\n",
       "      <td>59985</td>\n",
       "      <td>[{'date': 2021-11-14, 'rating': 3.5, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5374</th>\n",
       "      <td>5506</td>\n",
       "      <td>[{'date': 2023-01-08, 'rating': 2.5, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>5968</td>\n",
       "      <td>[{'date': 2015-04-19, 'rating': 1.5, 'userId':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                        review_data\n",
       "1932      2029  [{'date': 2000-01-18, 'rating': 4.0, 'userId':...\n",
       "16102    89305  [{'date': 2011-12-19, 'rating': 4.0, 'userId':...\n",
       "18076   101088  [{'date': 2020-05-10, 'rating': 2.5, 'userId':...\n",
       "12563    64285  [{'date': 2009-01-29, 'rating': 4.5, 'userId':...\n",
       "546        554  [{'date': 2000-03-20, 'rating': 1.0, 'userId':...\n",
       "...        ...                                                ...\n",
       "23007   127096  [{'date': 2015-05-23, 'rating': 3.0, 'userId':...\n",
       "47772   253620  [{'date': 2022-04-12, 'rating': 4.5, 'userId':...\n",
       "12158    59985  [{'date': 2021-11-14, 'rating': 3.5, 'userId':...\n",
       "5374      5506  [{'date': 2023-01-08, 'rating': 2.5, 'userId':...\n",
       "5825      5968  [{'date': 2015-04-19, 'rating': 1.5, 'userId':...\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (netflix_df.sample(n=n_rows,random_state=42))[['movieId','review_data']]\n",
    "df\n",
    "df2 = (movielens_df.sample(n=n_rows,random_state=42))[['movieId','review_data']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43956"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "27828"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = df['review_data'].values\n",
    "user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(df['movieId'], review_data)])\n",
    "len(user_ids)\n",
    "len(np.unique(movieIds))\n",
    "\n",
    "review_data2 = df2['review_data'].values\n",
    "user_ids2 = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data2])\n",
    "ratings2 = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data2])\n",
    "movieIds2 = np.concatenate([[movieId] * len(row) for movieId, row in zip(df['movieId'], review_data2)])\n",
    "len(user_ids2)\n",
    "len(np.unique(movieIds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up user-item matrix\n",
    "First we will create a user-item matrix which records all the user-item interactions.\n",
    "\n",
    "\n",
    "### `create_user_item_matrix` Function Explanation\n",
    "\n",
    "### Steps:\n",
    "1. **Extract Review Data**:\n",
    "   - Extract the review data from the provided DataFrame, which contains user IDs, ratings, and movie IDs.\n",
    "\n",
    "2. **Create User and Movie IDs Arrays**:\n",
    "   - Extract user IDs, ratings, and movie IDs from the review data and concatenate them into separate arrays.\n",
    "   - Generate dictionaries to map user IDs and movie IDs to unique indices in the user-item matrix.\n",
    "\n",
    "3. **Initialize User-Item Matrix**:\n",
    "   - Determine the dimensions of the user-item matrix based on the number of unique users and movies.\n",
    "   - Initialize an empty user-item matrix filled with NaN values.\n",
    "\n",
    "4. **Populate User-Item Matrix**:\n",
    "   - Iterate through the review data and populate the user-item matrix with ratings.\n",
    "   - Map user and movie IDs to their corresponding indices in the matrix and insert the ratings.\n",
    "\n",
    "5. **Return Results**:\n",
    "   - Return the user-item matrix along with dictionaries mapping user and movie IDs to indices, and arrays containing user and movie IDs.\n",
    "  \n",
    "### Functions Used and Purpose:\n",
    "\n",
    "- **`np.concatenate()`**: Used to concatenate arrays containing user IDs, ratings, and movie IDs extracted from the review data.\n",
    "- **`enumerate()`**: Used to iterate over the unique user IDs and movie IDs and generate indices for mapping.\n",
    "- **`np.unique()`**: Used to find the unique user IDs and movie IDs in the review data.\n",
    "- **`np.full()`**: Used to initialize an empty user-item matrix filled with NaN values.\n",
    "- **`zip()`**: Used to iterate over multiple iterables simultaneously (user IDs, movie IDs, ratings).\n",
    "- **`enumerate()`**: Used to iterate over the indices and elements of an iterable (user IDs, movie IDs) simultaneously.\n",
    "- **Indexing and Slicing**: Used to access and modify elements in arrays and matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(train_test_val_set):\n",
    "    \"\"\"\n",
    "    Creates a user-item matrix from the provided dataset containing review data.\n",
    "\n",
    "    Parameters:\n",
    "    train_test_val_set (DataFrame): DataFrame containing review data with columns 'review_data',\n",
    "                                    which is a list of dictionaries with keys 'userId', 'rating',\n",
    "                                    and 'movieId'.\n",
    "\n",
    "    Returns:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies), the matrix is an NumPy array which contains lists of user-item interactions, meaning a user and their corresponding ratings to the movieIds.    \n",
    "    \n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    \n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    \n",
    "    user_ids (numpy.ndarray): Array containing user IDs corresponding to each rating in the matrix.\n",
    "    \n",
    "    movie_ids (numpy.ndarray): Array containing movie IDs corresponding to each rating in the matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    review_data = train_test_val_set['review_data'].values\n",
    "    user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "    ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "    movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(train_test_val_set['movieId'], review_data)])\n",
    "\n",
    "    # create dictionaries to map user IDs and movie IDs to unique indices to map over\n",
    "    user_id_dict = {user_id: index for index, user_id in enumerate(np.unique(user_ids))}\n",
    "    movie_id_dict = {movie_id: index for index, movie_id in enumerate(np.unique(movieIds))}\n",
    "\n",
    "    # initialize an empty user-item matrix\n",
    "    user_count = len(user_id_dict)\n",
    "    movie_count = len(movie_id_dict)\n",
    "    user_item_matrix = np.full((user_count, movie_count), np.nan)\n",
    "\n",
    "    # populate the user-item matrix with ratings from the dataset\n",
    "    for i, (user_id, movie_id, rating) in enumerate(zip(user_ids, movieIds, ratings)):\n",
    "        user_index = user_id_dict[user_id]\n",
    "        movie_index = movie_id_dict[movie_id]\n",
    "        user_item_matrix[user_index, movie_index] = rating\n",
    "\n",
    "    return user_item_matrix, user_id_dict, movie_id_dict, user_ids, movieIds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of ratings in user-item matrix:\n",
    "We might suggest filling the empty values with 0s, but that can create issues with recommendation engines. \n",
    "\n",
    "If we were to fill this NaN with a 0, we would be incorrectly implying they greatly disliked! We are going to center each user’s ratings around 0 by deducting the row average and then fill in the missing values with 0. This means the missing data is replaced with neutral scores.\n",
    "\n",
    "### `computing_neutral_scores` Function Explanation\n",
    "\n",
    "### Functions Used and Purpose:\n",
    "- **`np.nanmean()`**: Used to calculate the average rating for each user while handling NaN (missing) values.\n",
    "  - **`axis=1`**: Specifies that the calculation is done along the rows (i.e., for each user).\n",
    "- **`np.nan_to_num()`**: Used to fill in missing data (NaN) with zeros while preserving non-NaN values.\n",
    "- **`np.reshape(-1, 1)`**: Used to reshape the array to ensure proper broadcasting during subtraction.\n",
    "- **Indexing and Slicing**: Used to access elements in arrays and matrices.\n",
    "\n",
    "### Steps:\n",
    "1. **Calculate Average Ratings**:\n",
    "   - Use `np.nanmean()` to compute the average rating for each user along the rows of the user-item matrix. This handles missing ratings (NaN) gracefully, computing the mean while ignoring NaN values.\n",
    "\n",
    "2. **Center Ratings Around 0**:\n",
    "   - Subtract the average ratings from each user's ratings in the user-item matrix. This centers each user's ratings around 0, effectively removing the user bias from the ratings.\n",
    "\n",
    "3. **Fill Missing Data with Zeros**:\n",
    "   - Use `np.nan_to_num()` to replace missing data (NaN) with zeros while preserving the existing non-NaN values. This ensures that missing ratings are treated neutrally (i.e., as if the user has not rated the item).\n",
    "\n",
    "4. **Return Normalized User Ratings**:\n",
    "   - Return the resulting normalized user ratings matrix, where missing ratings have been replaced with zeros and each user's ratings are centered around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_neutral_scores(user_item_matrix):\n",
    "    \"\"\"\n",
    "    Compute neutral scores for user-item interactions in a user-item matrix.\n",
    "\n",
    "    Parameters:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "\n",
    "    Returns:\n",
    "    user_ratings_matrix_normed (numpy.ndarray): Matrix representing users' ratings normalized with neutral scores.\n",
    "    \"\"\"\n",
    "    # Calculate the average rating for each user\n",
    "    avg_ratings = np.nanmean(user_item_matrix, axis=1)\n",
    "\n",
    "    # Center each user's ratings around 0\n",
    "    user_ratings_matrix_centered = user_item_matrix - avg_ratings.reshape(-1, 1)\n",
    "\n",
    "    # Fill in the missing data with 0s\n",
    "    user_ratings_matrix_normed = np.nan_to_num(user_ratings_matrix_centered, nan=0)\n",
    "\n",
    "    return user_ratings_matrix_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute similarity:\n",
    "Regularly, cosine similarity is often used to measure the similarity between users based on their preferences or ratings for items (in this case, movies). Cosine similarity ranges from -1 to 1, where:\n",
    "\n",
    "- 1 indicates perfect similarity,\n",
    "- 0 indicates no similarity, and\n",
    "- -1 indicates perfect dissimilarity.\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Positive Cosine Similarity**: Users are similar in their preferences or ratings for movies.\n",
    "- **Zero Cosine Similarity**: Users have no similarity in their preferences.\n",
    "- **Negative Cosine Similarity**: Users are dissimilar in their preferences, tending towards opposite ratings for movies.\n",
    "\n",
    "### Practical Implication:\n",
    "\n",
    "If one user likes certain types of movies, the other user tends to dislike them, or vice versa. In other words, users with negative cosine similarities have contrasting preferences, making them less suitable for recommending movies to each other.\n",
    "\n",
    "___\n",
    "\n",
    "To see how similar users are we will compute the similarity between them. I will use cosine similarity as distance measure. The manhatten norm will be used to decrease computational weight instead of euclidian norm.\n",
    "\n",
    "### Explanation `calculate_user_similarity_manhattan` Function\n",
    "\n",
    "This function calculates the cosine similarity matrix between users based on their ratings using the Manhattan norm.\n",
    "\n",
    "1. **Thresholding**: First, the function applies thresholding to the user ratings matrix. Ratings below the threshold are set to 0, ensuring that only significant ratings are considered.\n",
    "\n",
    "2. **Dot Product Calculation**: It then computes the dot product of each pair of row vectors (users) in the thresholded matrix. This represents the similarity between users based on their common rated items.\n",
    "\n",
    "3. **Norm Calculation**: Next, it calculates the norms (magnitude) of each row vector, considering only values above the threshold. This step prepares for the normalization process.\n",
    "\n",
    "4. **Normalization**: The dot products are divided by the norms of the corresponding row vectors, effectively normalizing the similarity values. This step ensures that users with a large number of ratings are not favored over users with fewer ratings.\n",
    "\n",
    "5. **Setting Diagonal to 0**: Finally, the diagonal elements of the similarity matrix are set to 0 to avoid self-similarity, as a user's rating should not be compared to itself.\n",
    "\n",
    "### Explanation of NumPy Functions\n",
    "\n",
    "- **np.dot**: Computes the dot product of arrays. Here, it calculates the dot product of the thresholded user ratings matrix with its transpose, resulting in the similarity matrix.\n",
    "  \n",
    "- **np.where**: Returns indices where a condition is true. It's used here to apply thresholding to the user ratings matrix.\n",
    "  \n",
    "- **np.sum**: Computes the sum of array elements. It calculates the norms of each row vector after thresholding, which are then used for normalization.\n",
    "  \n",
    "- **np.abs**: Computes the absolute value element-wise. Used to ensure positive values for norms calculation.\n",
    "  \n",
    "- **np.fill_diagonal**: Fills the diagonal of an array with a specified value. It's used to set diagonal elements of the similarity matrix to 0 to avoid self-similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_similarity_manhattan(user_ratings_matrix, threshold):\n",
    "    \"\"\"\n",
    "    Calculate user similarity using Manhattan distance-based similarity measure.\n",
    "\n",
    "    Parameters:\n",
    "    user_ratings_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    threshold (float): Threshold value for considering ratings in the similarity calculation.\n",
    "\n",
    "    Returns:\n",
    "    similarity_matrix (numpy.ndarray): Matrix representing similarity between users based on the Manhattan distance.\n",
    "\n",
    "    The Manhattan distance-based similarity measure is calculated as follows:\n",
    "    1. Compute the dot product of each pair of row vectors in the user_ratings_matrix, considering only values above the threshold.\n",
    "    2. Calculate the norms of each row vector, considering only values above the threshold.\n",
    "    3. Replace zero norms with a small value to avoid division by zero.\n",
    "    4. Calculate the similarity matrix using broadcasting, where the similarity between users i and j is given by the dot product\n",
    "       divided by the product of their norms.\n",
    "    5. Set diagonal elements to 0 to avoid self-similarity.\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate dot product of each pair of row vectors, considering only values above the threshold\n",
    "    dot_products = np.dot(np.where(user_ratings_matrix >= threshold, user_ratings_matrix, 0), user_ratings_matrix.T)\n",
    "    \n",
    "    # Calculate norms of each row vector, considering only values above the threshold\n",
    "    norms = np.sum(np.abs(np.where(user_ratings_matrix >= threshold, user_ratings_matrix, 0)), axis=1)\n",
    "    \n",
    "    # Replace zero norms with a small value to avoid division by zero\n",
    "    norms[norms == 0] = 1e-8\n",
    "    \n",
    "    # Calculate similarity matrix using broadcasting\n",
    "    similarity_matrix = dot_products / (norms[:, None] * norms)\n",
    "    \n",
    "    # Set diagonal elements to 0 to avoid self-similarity\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform User-Based KNN\n",
    "\n",
    "The top 5 recommendations represent the movies that are most highly rated by users who are most similar to the target user, based on the user-based k-nearest neighbors (KNN) collaborative filtering algorithm.\n",
    "\n",
    "### Explanation `generate_user_knn_regressor` function:\n",
    "**Recommendations Calculation Process**\n",
    "1. **Neighbour selection:** based on the cosine similarity number, the top k similar users are selected. This would be positive cosine similarity scores, as they indicate similarity. \n",
    "2. **Aggregation of Ratings:**:For each movie that the nearest neighbours have rated that the target user has not, the ratings are aggregated.\n",
    "\n",
    "3. **Average Ratings Calculation:** the aggregated ratings are divided by the number of neighbors who rated each movie to calculate the average rating for each movie.\n",
    "\n",
    "4. **Top Recommendations:** Finally, the top 5 movies with the highest average ratings are selected as the recommendations for the target user. These are the movies that are predicted to be most preferred by the target user based on the ratings of their nearest neighbors.\n",
    "\n",
    "**Explanation of NumPy Functions**\n",
    "\n",
    "1. **np.argsort**: Returns the indices that would sort an array. Used to find indices of the k most similar users in descending order.\n",
    "  \n",
    "2. **np.where**: Returns indices of elements satisfying a condition. Used to find movies rated by similar users (not NaN).\n",
    "\n",
    "3. **np.sum**: Computes sum of array elements. Used to aggregate ratings and counts for each movie across similar users.\n",
    "\n",
    "4. **np.divide**: Performs element-wise division. Used to calculate average ratings for each movie by dividing aggregated ratings by the number of similar users who rated each movie. Handles division by zero errors.\n",
    "\n",
    "5. **np.argsort (again)**: Finds indices that would sort movies by average ratings in descending order. Used to select top 5 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_knn_regressor(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations for a given user using user-based k-nearest neighbors (KNN) collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    recommendations (list): List of tuples containing recommended movie IDs and their predicted or expected ratings for the given user.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # Find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # Get similarity scores of the user with other users and sort indices\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # Find movies rated by similar users\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # Calculate average ratings for each movie\n",
    "    movie_ratings = np.zeros_like(user_item_matrix[0])\n",
    "    movie_counts = np.zeros_like(user_item_matrix[0], dtype=int)\n",
    "    \n",
    "    # Aggregate ratings and counts for each movie\n",
    "    for movie in rated_movies:\n",
    "        movie_ratings[movie] += np.sum(user_item_matrix[similar_users_indices, movie])\n",
    "        movie_counts[movie] += np.sum(~np.isnan(user_item_matrix[similar_users_indices, movie]))\n",
    "    \n",
    "    # Calculate average ratings\n",
    "    average_ratings = np.divide(movie_ratings, movie_counts, out=np.zeros_like(movie_ratings), where=movie_counts!=0)\n",
    "\n",
    "    # Sort movies by average ratings in descending order\n",
    "    sorted_indices = np.argsort(average_ratings)[::-1]\n",
    "\n",
    "    # Convert movie indices back to movie IDs and return top 5 recommendations\n",
    "    top_recommendations = [(list(movie_id_dict.keys())[list(movie_id_dict.values()).index(movie_index)], average_ratings[movie_index])\n",
    "                           for movie_index in sorted_indices[:5]]\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UserKNN classifier:\n",
    "In contrast to userKNN regressor, we will now recommend items based on majority voting. Which will consist of the following:\n",
    "\n",
    "Based on the cosine similarity, the nearest neighbours will be selected, just like in the KNN regressor. Afterwards, instead of computing the avg rating and then computing the items which have the highest avg. ratings, KNN classifier counts the items which have the same rating and recommends the item to the user which has the highest count of the same ratings, in other words: **majority vote**.\n",
    "\n",
    "Alternatively, **weighted average** could be used as a approach in userKNN classifier. The ratings of the nearest neighbours are assigned weights based on their similarity to the target user. More similar neighbors might have a greater influence on the prediction.\n",
    "\n",
    "Because of the preprocessing of the data, the ratings are generally not exactly the same. **Therefore, weighted average will be used**. \n",
    "\n",
    "### `generate_user_knn_recommendations_classifier` Function Explanation\n",
    "\n",
    "### Steps:\n",
    "1. **Input Validation**:\n",
    "   - Check if the provided user ID exists in the user ID dictionary. If not found, print a message and return an empty list.\n",
    "\n",
    "2. **Find Similar Users**:\n",
    "   - Get the similarity scores of the target user with other users from the similarity matrix.\n",
    "   - Sort the indices of similar users based on their similarity scores in descending order.\n",
    "   - Select the top `k` similar users for consideration.\n",
    "\n",
    "3. **Calculate Weighted Average Ratings**:\n",
    "   - For each movie rated by the selected similar users:\n",
    "     - Calculate the weighted sum of ratings, where the weights are the similarity scores between the target user and the similar users.\n",
    "     - Accumulate the sum of similarities for normalization.\n",
    "     - Compute the weighted average rating for each movie.\n",
    "\n",
    "4. **Sort Recommendations**:\n",
    "   - Sort the movies by their weighted average ratings in descending order.\n",
    "\n",
    "5. **Convert Indices to Movie IDs**:\n",
    "   - Convert the indices of the top recommended movies back to their corresponding movie IDs using the `movie_id_dict`.\n",
    "\n",
    "6. **Return Recommendations**:\n",
    "   - Return a list of tuples containing the movie IDs and their predicted ratings, limited to the top 5 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_knn_recommendations_classifier(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations for a given user using user-based k-nearest neighbors (KNN) collaborative filtering with weighted average.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    recommendations (list): List of tuples containing recommended movie IDs and their predicted ratings for the given user.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # Find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # Get similarity scores of the user with other users and sort indices\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # Find movies rated by similar users\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # Calculate weighted average ratings for each movie\n",
    "    weighted_avg_ratings = np.zeros_like(user_item_matrix[0])\n",
    "    similarity_sum = 0\n",
    "    \n",
    "    for movie in rated_movies:\n",
    "        # Calculate weighted sum of ratings and sum of similarities\n",
    "        weighted_sum = np.sum(user_item_matrix[similar_users_indices, movie] * user_similarity_matrix[user_index, similar_users_indices])\n",
    "        similarity_sum += np.sum(user_similarity_matrix[user_index, similar_users_indices])\n",
    "        weighted_avg_ratings[movie] = weighted_sum / similarity_sum if similarity_sum != 0 else 0\n",
    "\n",
    "    # Sort movies by weighted average ratings in descending order\n",
    "    sorted_indices = np.argsort(weighted_avg_ratings)[::-1]\n",
    "\n",
    "    # Convert movie indices back to movie IDs and return recommendations\n",
    "    recommendations_classifier = [(list(movie_id_dict.keys())[list(movie_id_dict.values()).index(movie_index)], weighted_avg_ratings[movie_index])\n",
    "                       for movie_index in sorted_indices[:5]]\n",
    "    return recommendations_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See a first batch of recommendations:\n",
    "\n",
    "By using the functions above to recommend movies above the following results are generated for each dataset:\n",
    "\n",
    "`Netflix dataset:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix, user_id_dict, movie_id_dict, user_ids, movieIds = create_user_item_matrix(df)\n",
    "user_ratings_matrix_normed = computing_neutral_scores(user_item_matrix)\n",
    "user_similarity_matrix_manhattan = calculate_user_similarity_manhattan(user_ratings_matrix_normed, threshold=0.5) # still explain why treshold on 0.5!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN regressor Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 2012897:\n",
      "Movie ID: 928, Predicted Rating: 3.0\n",
      "Movie ID: 1106, Predicted Rating: 3.0\n",
      "Movie ID: 1131, Predicted Rating: 2.0\n",
      "Movie ID: 736, Predicted Rating: 0.0\n",
      "Movie ID: 726, Predicted Rating: 0.0\n"
     ]
    }
   ],
   "source": [
    "user_id = user_ids[1]\n",
    "user_knn_recommendations = generate_user_knn_regressor(user_id, user_item_matrix, user_similarity_matrix_manhattan, user_id_dict, movie_id_dict, k=1)\n",
    "print(f\"UserKNN regressor Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id}:\")\n",
    "for movie_id, rating in user_knn_recommendations:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN classifier Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 2012897:\n",
      "Movie ID: 928, Predicted Rating: 3.0\n",
      "Movie ID: 1106, Predicted Rating: 1.5\n",
      "Movie ID: 1131, Predicted Rating: 0.6666666666666666\n",
      "Movie ID: 736, Predicted Rating: 0.0\n",
      "Movie ID: 726, Predicted Rating: 0.0\n"
     ]
    }
   ],
   "source": [
    "user_id = user_ids[1]\n",
    "recommendations_knn_classifier = generate_user_knn_recommendations_classifier(user_id, user_item_matrix, user_similarity_matrix_manhattan, user_id_dict, movie_id_dict, k=1)\n",
    "print(f\"UserKNN classifier Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id}:\")\n",
    "for movie_id, rating in recommendations_knn_classifier:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MovieLens dataset:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix2, user_id_dict2, movie_id_dict2, user_ids2, movieIds2 = create_user_item_matrix(df2)\n",
    "user_ratings_matrix_normed2 = computing_neutral_scores(user_item_matrix2)\n",
    "user_similarity_matrix_manhattan2 = calculate_user_similarity_manhattan(user_ratings_matrix_normed2, threshold=0.5) # still explain why treshold on 0.5!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN regressor Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 144354:\n",
      "Movie ID: 1564, Predicted Rating: 5.0\n",
      "Movie ID: 2575, Predicted Rating: 5.0\n",
      "Movie ID: 80, Predicted Rating: 4.0\n",
      "Movie ID: 4920, Predicted Rating: 0.0\n",
      "Movie ID: 4618, Predicted Rating: 0.0\n"
     ]
    }
   ],
   "source": [
    "user_id2 = user_ids2[1]\n",
    "user_knn_recommendations2 = generate_user_knn_regressor(user_id2, user_item_matrix2, user_similarity_matrix_manhattan2, user_id_dict2, movie_id_dict2, k=1)\n",
    "print(f\"UserKNN regressor Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id2}:\")\n",
    "for movie_id, rating in user_knn_recommendations2:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN classifier Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 144354:\n",
      "Movie ID: 80, Predicted Rating: 4.0\n",
      "Movie ID: 1564, Predicted Rating: 2.5\n",
      "Movie ID: 2575, Predicted Rating: 1.6666666666666665\n",
      "Movie ID: 4920, Predicted Rating: 0.0\n",
      "Movie ID: 4618, Predicted Rating: 0.0\n"
     ]
    }
   ],
   "source": [
    "user_id2 = user_ids2[1]\n",
    "recommendations_knn_classifier2 = generate_user_knn_recommendations_classifier(user_id2, user_item_matrix2, user_similarity_matrix_manhattan2, user_id_dict2, movie_id_dict2, k=1)\n",
    "print(f\"UserKNN classifier Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id2}:\")\n",
    "for movie_id, rating in recommendations_knn_classifier2:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the movieIds which are recommended are the same, the predicted rating differs somewhat, already indicating a difference between the two userKNN models.\n",
    "\n",
    "## Baseline performance\n",
    "\n",
    "To assess performance, we are going to assess the comparison between the original user-item interactions and the predicted user-item interactions. In order to do so, we will generate a complete matrix with predicted raitings to compare with the original one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28675, 250)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.7826087 , -1.7826087 , -1.7826087 , -1.73469388, -1.71428571,\n",
       "       -1.71428571, -1.7       , -1.7       , -1.6       , -1.6       ,\n",
       "       -1.6       , -1.6       , -1.6       , -1.57142857, -1.57142857,\n",
       "       -1.57142857, -1.57142857, -1.57142857, -1.55555556, -1.5       ,\n",
       "       -1.        , -0.875     , -0.83333333, -0.83333333, -0.8       ,\n",
       "       -0.7826087 , -0.75      , -0.73469388, -0.71428571, -0.7       ,\n",
       "       -0.7       , -0.66666667, -0.66666667, -0.66666667, -0.66666667,\n",
       "       -0.62650602, -0.6       , -0.6       , -0.58333333, -0.57142857,\n",
       "       -0.57142857, -0.57142857, -0.55555556, -0.5       , -0.33333333,\n",
       "        0.        ,  0.125     ,  0.16666667,  0.16666667,  0.2       ,\n",
       "        0.2       ,  0.2173913 ,  0.2173913 ,  0.25      ,  0.26530612,\n",
       "        0.28571429,  0.3       ,  0.3       ,  0.3       ,  0.33333333,\n",
       "        0.33333333,  0.33333333,  0.33333333,  0.33333333,  0.37349398,\n",
       "        0.4       ,  0.4       ,  0.4       ,  0.4       ,  0.4       ,\n",
       "        0.4       ,  0.41666667,  0.41666667,  0.41666667,  0.42857143,\n",
       "        0.42857143,  0.42857143,  0.42857143,  0.42857143,  0.44444444,\n",
       "        0.44444444,  0.44444444,  0.5       ,  0.66666667,  1.        ,\n",
       "        1.16666667,  1.26530612,  1.37349398,  1.4       ,  1.5       ,\n",
       "        2.37349398])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: -1.782608695652174, Count: 6\n",
      "Value: -1.7826086956521738, Count: 8\n",
      "Value: -1.7826086956521736, Count: 10\n",
      "Value: -1.7346938775510203, Count: 5\n",
      "Value: -1.7142857142857144, Count: 13\n",
      "Value: -1.7142857142857142, Count: 1\n",
      "Value: -1.7000000000000002, Count: 2\n",
      "Value: -1.7, Count: 7\n",
      "Value: -1.6000000000000003, Count: 10\n",
      "Value: -1.6, Count: 309\n",
      "Value: -1.5999999999999999, Count: 1\n",
      "Value: -1.5999999999999996, Count: 187\n",
      "Value: -1.5999999999999994, Count: 1\n",
      "Value: -1.5714285714285718, Count: 1\n",
      "Value: -1.5714285714285716, Count: 80\n",
      "Value: -1.5714285714285714, Count: 57\n",
      "Value: -1.5714285714285712, Count: 6\n",
      "Value: -1.571428571428571, Count: 2\n",
      "Value: -1.5555555555555554, Count: 124\n",
      "Value: -1.5, Count: 1\n",
      "Value: -1.0, Count: 30\n",
      "Value: -0.875, Count: 3\n",
      "Value: -0.8333333333333335, Count: 4\n",
      "Value: -0.8333333333333333, Count: 7\n",
      "Value: -0.7999999999999998, Count: 17\n",
      "Value: -0.7826086956521738, Count: 12\n",
      "Value: -0.75, Count: 172\n",
      "Value: -0.7346938775510203, Count: 6\n",
      "Value: -0.7142857142857144, Count: 22\n",
      "Value: -0.7000000000000002, Count: 9\n",
      "Value: -0.7, Count: 18\n",
      "Value: -0.666666666666667, Count: 147\n",
      "Value: -0.6666666666666667, Count: 103\n",
      "Value: -0.6666666666666666, Count: 2\n",
      "Value: -0.6666666666666665, Count: 1853\n",
      "Value: -0.6265060240963856, Count: 128\n",
      "Value: -0.6000000000000002, Count: 4\n",
      "Value: -0.6000000000000001, Count: 1117\n",
      "Value: -0.5833333333333333, Count: 690\n",
      "Value: -0.5714285714285716, Count: 1220\n",
      "Value: -0.5714285714285712, Count: 62\n",
      "Value: -0.5714285714285711, Count: 1\n",
      "Value: -0.5555555555555554, Count: 824\n",
      "Value: -0.5, Count: 41\n",
      "Value: -0.3333333333333335, Count: 2\n",
      "Value: 0.0, Count: 7147454\n",
      "Value: 0.125, Count: 21\n",
      "Value: 0.16666666666666652, Count: 13\n",
      "Value: 0.16666666666666674, Count: 35\n",
      "Value: 0.20000000000000018, Count: 64\n",
      "Value: 0.2000000000000002, Count: 4\n",
      "Value: 0.21739130434782614, Count: 60\n",
      "Value: 0.21739130434782616, Count: 180\n",
      "Value: 0.25, Count: 516\n",
      "Value: 0.26530612244897966, Count: 35\n",
      "Value: 0.2857142857142856, Count: 139\n",
      "Value: 0.2999999999999998, Count: 64\n",
      "Value: 0.2999999999999999, Count: 8\n",
      "Value: 0.30000000000000004, Count: 42\n",
      "Value: 0.333333333333333, Count: 6\n",
      "Value: 0.33333333333333304, Count: 288\n",
      "Value: 0.33333333333333326, Count: 206\n",
      "Value: 0.3333333333333334, Count: 4\n",
      "Value: 0.3333333333333335, Count: 3706\n",
      "Value: 0.37349397590361444, Count: 87\n",
      "Value: 0.39999999999999986, Count: 21\n",
      "Value: 0.3999999999999999, Count: 2924\n",
      "Value: 0.39999999999999997, Count: 6\n",
      "Value: 0.4000000000000003, Count: 16\n",
      "Value: 0.40000000000000036, Count: 732\n",
      "Value: 0.4000000000000004, Count: 4\n",
      "Value: 0.4166666666666667, Count: 7\n",
      "Value: 0.41666666666666674, Count: 952\n",
      "Value: 0.4166666666666668, Count: 7\n",
      "Value: 0.4285714285714283, Count: 129\n",
      "Value: 0.4285714285714284, Count: 159\n",
      "Value: 0.42857142857142844, Count: 1643\n",
      "Value: 0.4285714285714288, Count: 305\n",
      "Value: 0.4285714285714289, Count: 10\n",
      "Value: 0.4444444444444446, Count: 32\n",
      "Value: 0.44444444444444464, Count: 1422\n",
      "Value: 0.4444444444444447, Count: 10\n",
      "Value: 0.5, Count: 41\n",
      "Value: 0.6666666666666665, Count: 1\n",
      "Value: 1.0, Count: 30\n",
      "Value: 1.1666666666666665, Count: 1\n",
      "Value: 1.2653061224489797, Count: 3\n",
      "Value: 1.3734939759036144, Count: 33\n",
      "Value: 1.4, Count: 3\n",
      "Value: 1.5, Count: 1\n",
      "Value: 2.3734939759036147, Count: 1\n"
     ]
    }
   ],
   "source": [
    "def generate_complete_pred_matrix_classifier(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations for a given user using user-based k-nearest neighbors (KNN) collaborative filtering with weighted average.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    ratings (numpy.ndarray): Array containing predicted ratings for the given user.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # Find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # Get similarity scores of the user with other users and sort indices\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # Find movies rated by similar users\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # Calculate weighted average ratings for each movie\n",
    "    weighted_sum = np.dot(user_similarity_matrix[user_index, similar_users_indices], user_item_matrix[similar_users_indices][:, rated_movies])\n",
    "    similarity_sum = np.sum(user_similarity_matrix[user_index, similar_users_indices])\n",
    "\n",
    "    # Calculate predicted ratings\n",
    "    ratings = weighted_sum / similarity_sum if similarity_sum != 0 else np.zeros_like(user_item_matrix[user_index])\n",
    "    return ratings\n",
    "\n",
    "def generate_predicted_ratings_array(user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates an array of predicted ratings for all users using user-based k-nearest neighbors (KNN) collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    predicted_ratings_array (numpy.ndarray): Array of predicted ratings for all users.\n",
    "    \"\"\"\n",
    "    num_users = user_item_matrix.shape[0]\n",
    "    predicted_ratings_array = np.zeros((num_users, user_item_matrix.shape[1]))\n",
    "\n",
    "    for user_id in user_id_dict:\n",
    "        user_index = user_id_dict[user_id]\n",
    "        predicted_ratings_array[user_index] = generate_complete_pred_matrix_classifier(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k)\n",
    "\n",
    "    return predicted_ratings_array\n",
    "\n",
    "# Example usage\n",
    "generate_predicted_ratings_array(user_ratings_matrix_normed, user_similarity_matrix_manhattan, user_id_dict, movie_id_dict, k=1)\n",
    "generate_predicted_ratings_array(user_ratings_matrix_normed, user_similarity_matrix_manhattan, user_id_dict, movie_id_dict, k=1).shape\n",
    "np.unique(generate_predicted_ratings_array(user_ratings_matrix_normed, user_similarity_matrix_manhattan, user_id_dict, movie_id_dict, k=1))\n",
    "# Get unique values and their counts\n",
    "unique_values, value_counts = np.unique(generate_predicted_ratings_array(user_ratings_matrix_normed, user_similarity_matrix_manhattan, user_id_dict, movie_id_dict, k=1), return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for value, count in zip(unique_values, value_counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_ddb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
