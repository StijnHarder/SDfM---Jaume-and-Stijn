{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we are going to proceed with the building in the models. Machine learning models to build recommender systems. The models that are going to be built are Collaborative filtering using Item-based rating prediction (ItemKNN) and Item-based classification (ItemKNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is a technique used in recommendation systems to predict or classify items based on the preferences or behavior of similar users or items. Item-based Collaborative Filtering (CF) focuses on the similarity between items rather than users. There are two main approaches within item-based CF: rating prediction and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # to make jupyter print all outputs, not just the last one\n",
    "from IPython.core.display import HTML # to pretty print pandas df and be able to copy them over (e.g. to ppt slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaume\\Documents\\MDDB\\SDM\\SDfM---Jaume-and-Stijn 2\\SDfM---Jaume-and-Stijn\n"
     ]
    }
   ],
   "source": [
    "# We print the directory where the file is located\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_sample30_parquet',\n",
       " 'final_sample50_parquet',\n",
       " 'final_sample5_parquet',\n",
       " 'movielens_parquet',\n",
       " 'netflix_parquet',\n",
       " 'sample_tenth_netflix',\n",
       " 'unpacked_reviews_df_100k.parquet']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set the directory to the cleaned folder\n",
    "os.listdir(os.path.join('.', 'cleaned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the final_sample file and store it in a dataframe\n",
    "df = pd.read_parquet('cleaned/final_sample50_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102657, 27)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Western</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>(no genres listed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1996-11-08</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2005-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2011-05-18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId       title  year  userId  rating       date  month  Adventure  \\\n",
       "0        1  Toy Story   1995       1     4.0 2000-07-30      7          1   \n",
       "1        1  Toy Story   1995       5     4.0 1996-11-08     11          1   \n",
       "2        1  Toy Story   1995       7     4.5 2005-01-25      1          1   \n",
       "3        1  Toy Story   1995      15     2.5 2017-11-13     11          1   \n",
       "4        1  Toy Story   1995      17     4.5 2011-05-18      5          1   \n",
       "\n",
       "   Animation  Children  ...  Horror  Mystery  Sci-Fi  War  Musical  \\\n",
       "0          1         1  ...       0        0       0    0        0   \n",
       "1          1         1  ...       0        0       0    0        0   \n",
       "2          1         1  ...       0        0       0    0        0   \n",
       "3          1         1  ...       0        0       0    0        0   \n",
       "4          1         1  ...       0        0       0    0        0   \n",
       "\n",
       "   Documentary  IMAX  Western  Film-Noir  (no genres listed)  \n",
       "0            0     0        0          0                   0  \n",
       "1            0     0        0          0                   0  \n",
       "2            0     0        0          0                   0  \n",
       "3            0     0        0          0                   0  \n",
       "4            0     0        0          0                   0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'title', 'year', 'userId', 'rating', 'date', 'month',\n",
       "       'Adventure', 'Animation', 'Children', 'Comedy', 'Fantasy', 'Romance',\n",
       "       'Drama', 'Action', 'Crime', 'Thriller', 'Horror', 'Mystery', 'Sci-Fi',\n",
       "       'War', 'Musical', 'Documentary', 'IMAX', 'Western', 'Film-Noir',\n",
       "       '(no genres listed)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the columns of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n",
      "9711\n"
     ]
    }
   ],
   "source": [
    "# We print the number of unique users and movies\n",
    "print(df['userId'].nunique())\n",
    "print(df['movieId'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\n",
      "599    2795\n",
      "414    2697\n",
      "474    2373\n",
      "448    1863\n",
      "274    1346\n",
      "       ... \n",
      "257      20\n",
      "406      20\n",
      "278      20\n",
      "595      20\n",
      "147      20\n",
      "Name: count, Length: 610, dtype: int64\n",
      "movieId\n",
      "296       484\n",
      "356       335\n",
      "318       319\n",
      "593       283\n",
      "2571      280\n",
      "         ... \n",
      "101360      1\n",
      "128592      1\n",
      "128542      1\n",
      "128991      1\n",
      "193609      1\n",
      "Name: count, Length: 9711, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are userIDs that haven't rated movies at all\n",
    "print(df['userId'].value_counts().sort_values(ascending=False))\n",
    "\n",
    "# Check if there are movieIDs that haven't been rated at all\n",
    "print(df['movieId'].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>War</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Western</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>(no genres listed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65623</th>\n",
       "      <td>4966</td>\n",
       "      <td>Incredible Shrinking Man, The</td>\n",
       "      <td>1957</td>\n",
       "      <td>288</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2002-07-10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                           title  year  userId  rating  \\\n",
       "65623     4966  Incredible Shrinking Man, The   1957     288     3.0   \n",
       "\n",
       "            date  month  Adventure  Animation  Children  ...  Horror  Mystery  \\\n",
       "65623 2002-07-10      7          0          0         0  ...       0        0   \n",
       "\n",
       "       Sci-Fi  War  Musical  Documentary  IMAX  Western  Film-Noir  \\\n",
       "65623       1    0        0            0     0        0          0   \n",
       "\n",
       "       (no genres listed)  \n",
       "65623                   0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the rating for movieID 4966\n",
    "df[df['movieId'] == 4966]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are NaN values in the rating column\n",
    "df['rating'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "Number of unique movies: 9711\n"
     ]
    }
   ],
   "source": [
    "# Print the number of unique users\n",
    "print(\"Number of unique users:\", df['userId'].nunique())\n",
    "\n",
    "# Print the number of unique movies\n",
    "print(\"Number of unique movies:\", df['movieId'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId                        int64\n",
       "title                         object\n",
       "year                          object\n",
       "userId                         int64\n",
       "rating                       float64\n",
       "date                  datetime64[ns]\n",
       "month                          int32\n",
       "Adventure                      int64\n",
       "Animation                      int64\n",
       "Children                       int64\n",
       "Comedy                         int64\n",
       "Fantasy                        int64\n",
       "Romance                        int64\n",
       "Drama                          int64\n",
       "Action                         int64\n",
       "Crime                          int64\n",
       "Thriller                       int64\n",
       "Horror                         int64\n",
       "Mystery                        int64\n",
       "Sci-Fi                         int64\n",
       "War                            int64\n",
       "Musical                        int64\n",
       "Documentary                    int64\n",
       "IMAX                           int64\n",
       "Western                        int64\n",
       "Film-Noir                      int64\n",
       "(no genres listed)             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the data types of the DF\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select the columns that are not genres\n",
    "columns_not_genres = ['movieId', 'title', 'year', 'userId', 'rating', 'date', '(no genres listed)']\n",
    "for column in df.columns:\n",
    "    if column not in columns_not_genres :\n",
    "        df.rename(columns={column: 'genre_' + column}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'title', 'year', 'userId', 'rating', 'date', 'genre_month',\n",
       "       'genre_Adventure', 'genre_Animation', 'genre_Children', 'genre_Comedy',\n",
       "       'genre_Fantasy', 'genre_Romance', 'genre_Drama', 'genre_Action',\n",
       "       'genre_Crime', 'genre_Thriller', 'genre_Horror', 'genre_Mystery',\n",
       "       'genre_Sci-Fi', 'genre_War', 'genre_Musical', 'genre_Documentary',\n",
       "       'genre_IMAX', 'genre_Western', 'genre_Film-Noir', '(no genres listed)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the columns of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Rating Prediction (ItemKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: User-Item matrix construction\n",
    "The first thing we have to do is build the user-item matrix:\n",
    "\n",
    "- Choose a similarity metric to calculate the similarity between items. Common metrics include cosine similarity, Pearson correlation coefficient, and Jaccard similarity.\n",
    "- Calculate the similarity between each pair of items based on the ratings provided by users. This will result in an item-item similarity matrix.\n",
    "\n",
    "##### Libraries Used\n",
    "- **pandas**: A powerful data manipulation library in Python.\n",
    "- **numpy**: A library for numerical computing in Python.\n",
    "- **sklearn.metrics.pairwise.cosine_similarity**: A function from scikit-learn used to compute the cosine similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert userId column to integer type if needed\n",
    "if df['userId'].dtype != int:\n",
    "    df['userId'] = df['userId'].astype(int)\n",
    "\n",
    "# Get all unique user IDs and movie IDs\n",
    "all_user_ids = np.unique(df['userId'])\n",
    "all_movie_ids = np.unique(df['movieId'])\n",
    "\n",
    "# Determine the number of unique users and movies\n",
    "num_users = len(all_user_ids)\n",
    "num_movies = len(all_movie_ids)\n",
    "\n",
    "# Create a dictionary to store ratings for each user\n",
    "user_ratings = {}\n",
    "\n",
    "# Iterate through the DataFrame and populate the user_ratings dictionary\n",
    "for _, row in df.iterrows():\n",
    "    user_id = row['userId']\n",
    "    movie_id = row['movieId']\n",
    "    rating = row['rating']\n",
    "    \n",
    "    # Initialize the user's ratings list if not already present\n",
    "    if user_id not in user_ratings:\n",
    "        user_ratings[user_id] = np.zeros(num_movies)\n",
    "    \n",
    "    # Assign the rating to the corresponding movie index\n",
    "    user_ratings[user_id][np.where(all_movie_ids == movie_id)[0][0]] = rating\n",
    "\n",
    "# Create user-item matrix from the dictionary\n",
    "item_user_matrix = pd.DataFrame(user_ratings.values(), index=user_ratings.keys(), columns=all_movie_ids)\n",
    "\n",
    "# Convert user-item matrix to NumPy array for faster computation\n",
    "item_user_array = item_user_matrix.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1       2       3       4       5       6       7       8       9       \\\n",
       "1      4.0     0.0     4.0     0.0     0.0     4.0     0.0     0.0     0.0   \n",
       "5      4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7      4.5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "15     2.5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "17     4.5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "    10      ...  193565  193567  193571  193573  193579  193581  193583  \\\n",
       "1      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "7      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "15     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "17     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "    193585  193587  193609  \n",
       "1      0.0     0.0     0.0  \n",
       "5      0.0     0.0     0.0  \n",
       "7      0.0     0.0     0.0  \n",
       "15     0.0     0.0     0.0  \n",
       "17     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 9711 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4. , 0. , 4. , ..., 0. , 0. , 0. ],\n",
       "       [4. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [4.5, 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 3.5, 3.5, 0. ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "The train-val-test split is a technique used in machine learning to evaluate the performance of a model. It involves dividing the dataset into three subsets: the training set, the validation set, and the test set.\n",
    "\n",
    "The training set is used to train the model and optimize its parameters.\n",
    "The validation set is used to fine-tune the model and select the best hyperparameters.\n",
    "The test set is used to evaluate the final performance of the model on unseen data.\n",
    "By using a train-val-test split, we can assess the model's performance on unseen data and ensure that it generalizes well to new examples. It helps prevent overfitting and provides a more reliable estimate of the model's performance in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (390, 9711)\n",
      "Validation set shape: (98, 9711)\n",
      "Test set shape: (122, 9711)\n",
      " \n",
      "Training set matrix shape: (390, 9711)\n",
      "Validation set matrix shape: (98, 9711)\n",
      "Test set matrix shape: (122, 9711)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and test sets\n",
    "train_val, test = train_test_split(item_user_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "train, val = train_test_split(train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", train.shape)\n",
    "print(\"Validation set shape:\", val.shape)\n",
    "print(\"Test set shape:\", test.shape)\n",
    "\n",
    "# We are also going to do the split for the matrix df\n",
    "# Split the user-item matrix into training and test sets\n",
    "train_val_matrix, test_matrix = train_test_split(item_user_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training set matrix into training and validation sets\n",
    "train_matrix, val_matrix = train_test_split(train_val_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# We print a ' ' to give some space inbetween lines\n",
    "print(' ')\n",
    "\n",
    "# Print the shapes of the matrix datasets\n",
    "print(\"Training set matrix shape:\", train_matrix.shape)\n",
    "print(\"Validation set matrix shape:\", val_matrix.shape)\n",
    "print(\"Test set matrix shape:\", test_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 9711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1       2       3       4       5       6       7       8       9       \\\n",
       "8       0.0     4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "74      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "263     4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "167     3.5     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "26      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "75      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "440     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "508     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "92      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "496     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     10      ...  193565  193567  193571  193573  193579  193581  193583  \\\n",
       "8       2.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "74      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "263     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "167     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "26      3.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "75      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "440     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "508     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "92      0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "496     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     193585  193587  193609  \n",
       "8       0.0     0.0     0.0  \n",
       "74      0.0     0.0     0.0  \n",
       "263     0.0     0.0     0.0  \n",
       "167     0.0     0.0     0.0  \n",
       "26      0.0     0.0     0.0  \n",
       "..      ...     ...     ...  \n",
       "75      0.0     0.0     0.0  \n",
       "440     0.0     0.0     0.0  \n",
       "508     0.0     0.0     0.0  \n",
       "92      0.0     0.0     0.0  \n",
       "496     0.0     0.0     0.0  \n",
       "\n",
       "[390 rows x 9711 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 4., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between items using NumPy functions\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "# Calculate item-item similarity matrix for train data\n",
    "#item_similarity_matrix_train = np.zeros((train.shape[1], train.shape[1]))\n",
    "\n",
    "#for i in range(train.shape[1]):\n",
    " #   for j in range(i, train.shape[1]):\n",
    "  #      item_similarity_matrix_train[i, j] = cosine_similarity(train[:, i], train[:, j])\n",
    "   #     item_similarity_matrix_train[j, i] = item_similarity_matrix_train[i, j]\n",
    "\n",
    "# Adjusting the mapping to start indexing from 0\n",
    "user_id_to_index = {user_id: i for i, user_id in enumerate(item_user_matrix.index)}\n",
    "index_to_user_id = {i: user_id for i, user_id in enumerate(item_user_matrix.index)}\n",
    "\n",
    "# Create a mapping from movie IDs to indices\n",
    "movie_id_to_index = {movie_id: i for i, movie_id in enumerate(item_user_matrix.columns)}\n",
    "index_to_movie_id = {i: movie_id for i, movie_id in enumerate(item_user_matrix.columns)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Calculation utilizing Genres:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We create item-genre matrix\n",
    "def create_item_genre_matrix(df, train):\n",
    "    # Extract genre columns from the dataframe\n",
    "    genre_columns = [col for col in df.columns if col.startswith('genre_')]\n",
    "    \n",
    "    # Initialize item-genre matrix with zeros\n",
    "    item_genre_matrix = pd.DataFrame(0, index=genre_columns, columns=train.columns)\n",
    "    \n",
    "    # Fill the matrix with genre information\n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        item_id = row['movieId']  # Assuming 'movieId' is the column containing item IDs\n",
    "        genres = row[genre_columns].values\n",
    "        item_genre_matrix[item_id] = genres\n",
    "    \n",
    "    return item_genre_matrix\n",
    "\n",
    "# We create the item_genre matrix with the train set and the original df\n",
    "item_genre_matrix = create_item_genre_matrix(df, train_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>genre_month</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Adventure</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Animation</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Children</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Comedy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Fantasy</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Romance</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Drama</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Action</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Crime</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Thriller</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Horror</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Mystery</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Sci-Fi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_War</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Musical</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Documentary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_IMAX</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Western</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre_Film-Noir</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 9711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1      2      3      4      5      6      7      8       \\\n",
       "genre_month           11      5      5      3      5      5      2     10   \n",
       "genre_Adventure        1      1      0      0      0      0      0      1   \n",
       "genre_Animation        1      0      0      0      0      0      0      0   \n",
       "genre_Children         1      1      0      0      0      0      0      1   \n",
       "genre_Comedy           1      0      1      1      1      0      1      0   \n",
       "genre_Fantasy          1      1      0      0      0      0      0      0   \n",
       "genre_Romance          0      0      1      1      0      0      1      0   \n",
       "genre_Drama            0      0      0      1      0      0      0      0   \n",
       "genre_Action           0      0      0      0      0      1      0      0   \n",
       "genre_Crime            0      0      0      0      0      1      0      0   \n",
       "genre_Thriller         0      0      0      0      0      1      0      0   \n",
       "genre_Horror           0      0      0      0      0      0      0      0   \n",
       "genre_Mystery          0      0      0      0      0      0      0      0   \n",
       "genre_Sci-Fi           0      0      0      0      0      0      0      0   \n",
       "genre_War              0      0      0      0      0      0      0      0   \n",
       "genre_Musical          0      0      0      0      0      0      0      0   \n",
       "genre_Documentary      0      0      0      0      0      0      0      0   \n",
       "genre_IMAX             0      0      0      0      0      0      0      0   \n",
       "genre_Western          0      0      0      0      0      0      0      0   \n",
       "genre_Film-Noir        0      0      0      0      0      0      0      0   \n",
       "\n",
       "                  9      10      ... 193565 193567 193571 193573 193579  \\\n",
       "genre_month            6     11  ...      9      9      9      9      9   \n",
       "genre_Adventure        0      1  ...      0      0      0      0      0   \n",
       "genre_Animation        0      0  ...      1      1      0      1      0   \n",
       "genre_Children         0      0  ...      0      0      0      0      0   \n",
       "genre_Comedy           0      0  ...      1      0      1      0      0   \n",
       "genre_Fantasy          0      0  ...      0      0      0      0      0   \n",
       "genre_Romance          0      0  ...      0      0      0      0      0   \n",
       "genre_Drama            0      0  ...      0      1      1      0      0   \n",
       "genre_Action           1      1  ...      1      0      0      0      0   \n",
       "genre_Crime            0      0  ...      0      0      0      0      0   \n",
       "genre_Thriller         0      1  ...      0      0      0      0      0   \n",
       "genre_Horror           0      0  ...      0      0      0      0      0   \n",
       "genre_Mystery          0      0  ...      0      0      0      0      0   \n",
       "genre_Sci-Fi           0      0  ...      1      0      0      0      0   \n",
       "genre_War              0      0  ...      0      0      0      0      0   \n",
       "genre_Musical          0      0  ...      0      0      0      0      0   \n",
       "genre_Documentary      0      0  ...      0      0      0      0      1   \n",
       "genre_IMAX             0      0  ...      0      0      0      0      0   \n",
       "genre_Western          0      0  ...      0      0      0      0      0   \n",
       "genre_Film-Noir        0      0  ...      0      0      0      0      0   \n",
       "\n",
       "                  193581 193583 193585 193587 193609  \n",
       "genre_month            9      9      9      9      9  \n",
       "genre_Adventure        0      0      0      0      0  \n",
       "genre_Animation        1      1      0      1      0  \n",
       "genre_Children         0      0      0      0      0  \n",
       "genre_Comedy           1      1      0      0      1  \n",
       "genre_Fantasy          1      1      0      0      0  \n",
       "genre_Romance          0      0      0      0      0  \n",
       "genre_Drama            0      0      1      0      0  \n",
       "genre_Action           1      0      0      1      0  \n",
       "genre_Crime            0      0      0      0      0  \n",
       "genre_Thriller         0      0      0      0      0  \n",
       "genre_Horror           0      0      0      0      0  \n",
       "genre_Mystery          0      0      0      0      0  \n",
       "genre_Sci-Fi           0      0      0      0      0  \n",
       "genre_War              0      0      0      0      0  \n",
       "genre_Musical          0      0      0      0      0  \n",
       "genre_Documentary      0      0      0      0      0  \n",
       "genre_IMAX             0      0      0      0      0  \n",
       "genre_Western          0      0      0      0      0  \n",
       "genre_Film-Noir        0      0      0      0      0  \n",
       "\n",
       "[20 rows x 9711 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 9711)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_genre_matrix\n",
    "\n",
    "item_genre_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collaborative Filtering with Cosine Similarity\n",
    "\n",
    "This code snippet demonstrates how to perform item-based collaborative filtering using cosine similarity. Collaborative filtering is a technique commonly used in recommendation systems to predict a user's preferences for items based on the preferences of similar users/items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.44712915 0.32065335 ... 0.         0.         0.        ]\n",
      " [0.44712915 1.         0.28478259 ... 0.         0.         0.        ]\n",
      " [0.32065335 0.28478259 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         1.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_item_similarity_matrix(data):\n",
    "    # Calculate cosine similarity between items\n",
    "    item_similarity_matrix = cosine_similarity(data.T)\n",
    "    np.fill_diagonal(item_similarity_matrix, 1)  # Set diagonal values to 1\n",
    "    return item_similarity_matrix\n",
    "\n",
    "# We calculate the item similarity using the train user-item matrix data\n",
    "item_similarity_matrix_train = calculate_item_similarity_matrix(train)\n",
    "print(item_similarity_matrix_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 719. MiB for an array with shape (9711, 9711) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item_similarity_matrix\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Assuming item_genre_matrix is the item-genre matrix\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m item_similarity_genres_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_item_similarity_genres\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_genre_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(item_similarity_genres_matrix)\n",
      "Cell \u001b[1;32mIn[52], line 7\u001b[0m, in \u001b[0;36mcalculate_item_similarity_genres\u001b[1;34m(item_genre_matrix)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_item_similarity_genres\u001b[39m(item_genre_matrix):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Calculate cosine similarity between items\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     num_items \u001b[38;5;241m=\u001b[39m item_genre_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     item_similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Iterate over pairs of columns to calculate cosine similarity\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_items):\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 719. MiB for an array with shape (9711, 9711) and data type float64"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_item_similarity_genres(item_genre_matrix):\n",
    "    # Calculate cosine similarity between items\n",
    "    item_similarity_matrix = cosine_similarity(item_genre_matrix.T)\n",
    "    np.fill_diagonal(item_similarity_matrix, 1)  # Set diagonal values to 1\n",
    "    return item_similarity_matrix\n",
    "\n",
    "# Example usage:\n",
    "# Assuming item_genre_matrix is the item-genre matrix\n",
    "item_similarity_genres_matrix = calculate_item_similarity_genres(item_genre_matrix)\n",
    "print(item_similarity_genres_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2923, 2923)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_genres_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 4: 1,\n",
       " 9: 2,\n",
       " 11: 3,\n",
       " 13: 4,\n",
       " 15: 5,\n",
       " 18: 6,\n",
       " 20: 7,\n",
       " 24: 8,\n",
       " 30: 9,\n",
       " 31: 10,\n",
       " 32: 11,\n",
       " 36: 12,\n",
       " 40: 13,\n",
       " 41: 14,\n",
       " 43: 15,\n",
       " 45: 16,\n",
       " 50: 17,\n",
       " 52: 18,\n",
       " 53: 19,\n",
       " 55: 20,\n",
       " 63: 21,\n",
       " 65: 22,\n",
       " 66: 23,\n",
       " 69: 24,\n",
       " 73: 25,\n",
       " 76: 26,\n",
       " 77: 27,\n",
       " 78: 28,\n",
       " 81: 29,\n",
       " 85: 30,\n",
       " 88: 31,\n",
       " 89: 32,\n",
       " 92: 33,\n",
       " 99: 34,\n",
       " 100: 35,\n",
       " 103: 36,\n",
       " 104: 37,\n",
       " 105: 38,\n",
       " 107: 39,\n",
       " 108: 40,\n",
       " 112: 41,\n",
       " 116: 42,\n",
       " 117: 43,\n",
       " 118: 44,\n",
       " 119: 45,\n",
       " 122: 46,\n",
       " 123: 47,\n",
       " 125: 48,\n",
       " 129: 49,\n",
       " 145: 50,\n",
       " 146: 51,\n",
       " 149: 52,\n",
       " 158: 53,\n",
       " 159: 54,\n",
       " 162: 55,\n",
       " 172: 56,\n",
       " 177: 57,\n",
       " 186: 58,\n",
       " 194: 59,\n",
       " 199: 60,\n",
       " 201: 61,\n",
       " 204: 62,\n",
       " 208: 63,\n",
       " 209: 64,\n",
       " 211: 65,\n",
       " 212: 66,\n",
       " 213: 67,\n",
       " 217: 68,\n",
       " 230: 69,\n",
       " 233: 70,\n",
       " 243: 71,\n",
       " 246: 72,\n",
       " 247: 73,\n",
       " 248: 74,\n",
       " 250: 75,\n",
       " 253: 76,\n",
       " 254: 77,\n",
       " 257: 78,\n",
       " 258: 79,\n",
       " 266: 80,\n",
       " 267: 81,\n",
       " 271: 82,\n",
       " 277: 83,\n",
       " 283: 84,\n",
       " 285: 85,\n",
       " 287: 86,\n",
       " 290: 87,\n",
       " 291: 88,\n",
       " 296: 89,\n",
       " 303: 90,\n",
       " 305: 91,\n",
       " 307: 92,\n",
       " 315: 93,\n",
       " 328: 94,\n",
       " 330: 95,\n",
       " 333: 96,\n",
       " 334: 97,\n",
       " 342: 98,\n",
       " 346: 99,\n",
       " 350: 100,\n",
       " 353: 101,\n",
       " 357: 102,\n",
       " 358: 103,\n",
       " 360: 104,\n",
       " 361: 105,\n",
       " 363: 106,\n",
       " 365: 107,\n",
       " 370: 108,\n",
       " 372: 109,\n",
       " 374: 110,\n",
       " 376: 111,\n",
       " 377: 112,\n",
       " 378: 113,\n",
       " 380: 114,\n",
       " 389: 115,\n",
       " 393: 116,\n",
       " 405: 117,\n",
       " 408: 118,\n",
       " 409: 119,\n",
       " 416: 120,\n",
       " 423: 121,\n",
       " 435: 122,\n",
       " 437: 123,\n",
       " 442: 124,\n",
       " 446: 125,\n",
       " 452: 126,\n",
       " 453: 127,\n",
       " 459: 128,\n",
       " 460: 129,\n",
       " 461: 130,\n",
       " 464: 131,\n",
       " 470: 132,\n",
       " 471: 133,\n",
       " 472: 134,\n",
       " 473: 135,\n",
       " 477: 136,\n",
       " 478: 137,\n",
       " 490: 138,\n",
       " 492: 139,\n",
       " 496: 140,\n",
       " 499: 141,\n",
       " 504: 142,\n",
       " 510: 143,\n",
       " 512: 144,\n",
       " 514: 145,\n",
       " 518: 146,\n",
       " 520: 147,\n",
       " 522: 148,\n",
       " 527: 149,\n",
       " 528: 150,\n",
       " 532: 151,\n",
       " 535: 152,\n",
       " 539: 153,\n",
       " 540: 154,\n",
       " 541: 155,\n",
       " 543: 156,\n",
       " 544: 157,\n",
       " 551: 158,\n",
       " 553: 159,\n",
       " 555: 160,\n",
       " 556: 161,\n",
       " 574: 162,\n",
       " 580: 163,\n",
       " 585: 164,\n",
       " 592: 165,\n",
       " 593: 166,\n",
       " 594: 167,\n",
       " 596: 168,\n",
       " 605: 169,\n",
       " 612: 170,\n",
       " 617: 171,\n",
       " 627: 172,\n",
       " 628: 173,\n",
       " 635: 174,\n",
       " 637: 175,\n",
       " 640: 176,\n",
       " 645: 177,\n",
       " 656: 178,\n",
       " 661: 179,\n",
       " 665: 180,\n",
       " 667: 181,\n",
       " 680: 182,\n",
       " 685: 183,\n",
       " 692: 184,\n",
       " 694: 185,\n",
       " 707: 186,\n",
       " 708: 187,\n",
       " 715: 188,\n",
       " 722: 189,\n",
       " 728: 190,\n",
       " 731: 191,\n",
       " 733: 192,\n",
       " 736: 193,\n",
       " 748: 194,\n",
       " 757: 195,\n",
       " 759: 196,\n",
       " 760: 197,\n",
       " 773: 198,\n",
       " 778: 199,\n",
       " 782: 200,\n",
       " 783: 201,\n",
       " 785: 202,\n",
       " 790: 203,\n",
       " 791: 204,\n",
       " 795: 205,\n",
       " 805: 206,\n",
       " 810: 207,\n",
       " 824: 208,\n",
       " 828: 209,\n",
       " 835: 210,\n",
       " 841: 211,\n",
       " 842: 212,\n",
       " 848: 213,\n",
       " 870: 214,\n",
       " 875: 215,\n",
       " 880: 216,\n",
       " 888: 217,\n",
       " 891: 218,\n",
       " 892: 219,\n",
       " 896: 220,\n",
       " 900: 221,\n",
       " 901: 222,\n",
       " 911: 223,\n",
       " 914: 224,\n",
       " 918: 225,\n",
       " 923: 226,\n",
       " 924: 227,\n",
       " 927: 228,\n",
       " 929: 229,\n",
       " 930: 230,\n",
       " 931: 231,\n",
       " 932: 232,\n",
       " 934: 233,\n",
       " 937: 234,\n",
       " 944: 235,\n",
       " 950: 236,\n",
       " 953: 237,\n",
       " 956: 238,\n",
       " 959: 239,\n",
       " 961: 240,\n",
       " 965: 241,\n",
       " 969: 242,\n",
       " 970: 243,\n",
       " 971: 244,\n",
       " 973: 245,\n",
       " 979: 246,\n",
       " 981: 247,\n",
       " 982: 248,\n",
       " 986: 249,\n",
       " 988: 250,\n",
       " 990: 251,\n",
       " 996: 252,\n",
       " 998: 253,\n",
       " 1003: 254,\n",
       " 1005: 255,\n",
       " 1006: 256,\n",
       " 1007: 257,\n",
       " 1008: 258,\n",
       " 1015: 259,\n",
       " 1016: 260,\n",
       " 1021: 261,\n",
       " 1024: 262,\n",
       " 1029: 263,\n",
       " 1032: 264,\n",
       " 1037: 265,\n",
       " 1040: 266,\n",
       " 1046: 267,\n",
       " 1047: 268,\n",
       " 1059: 269,\n",
       " 1060: 270,\n",
       " 1061: 271,\n",
       " 1073: 272,\n",
       " 1089: 273,\n",
       " 1092: 274,\n",
       " 1094: 275,\n",
       " 1095: 276,\n",
       " 1096: 277,\n",
       " 1099: 278,\n",
       " 1104: 279,\n",
       " 1123: 280,\n",
       " 1127: 281,\n",
       " 1129: 282,\n",
       " 1135: 283,\n",
       " 1144: 284,\n",
       " 1148: 285,\n",
       " 1156: 286,\n",
       " 1161: 287,\n",
       " 1171: 288,\n",
       " 1173: 289,\n",
       " 1176: 290,\n",
       " 1178: 291,\n",
       " 1204: 292,\n",
       " 1207: 293,\n",
       " 1213: 294,\n",
       " 1220: 295,\n",
       " 1226: 296,\n",
       " 1232: 297,\n",
       " 1234: 298,\n",
       " 1241: 299,\n",
       " 1248: 300,\n",
       " 1253: 301,\n",
       " 1258: 302,\n",
       " 1259: 303,\n",
       " 1261: 304,\n",
       " 1265: 305,\n",
       " 1266: 306,\n",
       " 1268: 307,\n",
       " 1271: 308,\n",
       " 1272: 309,\n",
       " 1283: 310,\n",
       " 1296: 311,\n",
       " 1299: 312,\n",
       " 1304: 313,\n",
       " 1307: 314,\n",
       " 1320: 315,\n",
       " 1321: 316,\n",
       " 1328: 317,\n",
       " 1329: 318,\n",
       " 1331: 319,\n",
       " 1333: 320,\n",
       " 1336: 321,\n",
       " 1339: 322,\n",
       " 1346: 323,\n",
       " 1350: 324,\n",
       " 1354: 325,\n",
       " 1356: 326,\n",
       " 1358: 327,\n",
       " 1367: 328,\n",
       " 1370: 329,\n",
       " 1372: 330,\n",
       " 1373: 331,\n",
       " 1374: 332,\n",
       " 1378: 333,\n",
       " 1388: 334,\n",
       " 1391: 335,\n",
       " 1394: 336,\n",
       " 1395: 337,\n",
       " 1396: 338,\n",
       " 1398: 339,\n",
       " 1408: 340,\n",
       " 1412: 341,\n",
       " 1415: 342,\n",
       " 1423: 343,\n",
       " 1430: 344,\n",
       " 1432: 345,\n",
       " 1440: 346,\n",
       " 1441: 347,\n",
       " 1442: 348,\n",
       " 1446: 349,\n",
       " 1447: 350,\n",
       " 1454: 351,\n",
       " 1465: 352,\n",
       " 1473: 353,\n",
       " 1474: 354,\n",
       " 1490: 355,\n",
       " 1496: 356,\n",
       " 1498: 357,\n",
       " 1499: 358,\n",
       " 1502: 359,\n",
       " 1507: 360,\n",
       " 1515: 361,\n",
       " 1516: 362,\n",
       " 1518: 363,\n",
       " 1519: 364,\n",
       " 1526: 365,\n",
       " 1541: 366,\n",
       " 1542: 367,\n",
       " 1546: 368,\n",
       " 1549: 369,\n",
       " 1554: 370,\n",
       " 1564: 371,\n",
       " 1565: 372,\n",
       " 1572: 373,\n",
       " 1580: 374,\n",
       " 1585: 375,\n",
       " 1590: 376,\n",
       " 1591: 377,\n",
       " 1592: 378,\n",
       " 1594: 379,\n",
       " 1597: 380,\n",
       " 1599: 381,\n",
       " 1602: 382,\n",
       " 1609: 383,\n",
       " 1616: 384,\n",
       " 1619: 385,\n",
       " 1620: 386,\n",
       " 1623: 387,\n",
       " 1625: 388,\n",
       " 1627: 389,\n",
       " 1642: 390,\n",
       " 1654: 391,\n",
       " 1655: 392,\n",
       " 1658: 393,\n",
       " 1661: 394,\n",
       " 1665: 395,\n",
       " 1667: 396,\n",
       " 1676: 397,\n",
       " 1678: 398,\n",
       " 1694: 399,\n",
       " 1695: 400,\n",
       " 1699: 401,\n",
       " 1701: 402,\n",
       " 1702: 403,\n",
       " 1707: 404,\n",
       " 1713: 405,\n",
       " 1729: 406,\n",
       " 1731: 407,\n",
       " 1732: 408,\n",
       " 1757: 409,\n",
       " 1762: 410,\n",
       " 1767: 411,\n",
       " 1769: 412,\n",
       " 1772: 413,\n",
       " 1779: 414,\n",
       " 1784: 415,\n",
       " 1785: 416,\n",
       " 1797: 417,\n",
       " 1798: 418,\n",
       " 1799: 419,\n",
       " 1806: 420,\n",
       " 1816: 421,\n",
       " 1829: 422,\n",
       " 1831: 423,\n",
       " 1835: 424,\n",
       " 1841: 425,\n",
       " 1844: 426,\n",
       " 1856: 427,\n",
       " 1857: 428,\n",
       " 1873: 429,\n",
       " 1881: 430,\n",
       " 1882: 431,\n",
       " 1883: 432,\n",
       " 1889: 433,\n",
       " 1894: 434,\n",
       " 1897: 435,\n",
       " 1910: 436,\n",
       " 1911: 437,\n",
       " 1914: 438,\n",
       " 1919: 439,\n",
       " 1921: 440,\n",
       " 1924: 441,\n",
       " 1926: 442,\n",
       " 1934: 443,\n",
       " 1936: 444,\n",
       " 1938: 445,\n",
       " 1939: 446,\n",
       " 1940: 447,\n",
       " 1942: 448,\n",
       " 1944: 449,\n",
       " 1949: 450,\n",
       " 1952: 451,\n",
       " 1953: 452,\n",
       " 1955: 453,\n",
       " 1960: 454,\n",
       " 1961: 455,\n",
       " 1964: 456,\n",
       " 1966: 457,\n",
       " 1969: 458,\n",
       " 1975: 459,\n",
       " 1976: 460,\n",
       " 1979: 461,\n",
       " 1981: 462,\n",
       " 1992: 463,\n",
       " 1993: 464,\n",
       " 1995: 465,\n",
       " 1997: 466,\n",
       " 2002: 467,\n",
       " 2004: 468,\n",
       " 2005: 469,\n",
       " 2007: 470,\n",
       " 2008: 471,\n",
       " 2013: 472,\n",
       " 2016: 473,\n",
       " 2021: 474,\n",
       " 2023: 475,\n",
       " 2026: 476,\n",
       " 2027: 477,\n",
       " 2037: 478,\n",
       " 2041: 479,\n",
       " 2042: 480,\n",
       " 2046: 481,\n",
       " 2059: 482,\n",
       " 2065: 483,\n",
       " 2067: 484,\n",
       " 2068: 485,\n",
       " 2070: 486,\n",
       " 2071: 487,\n",
       " 2078: 488,\n",
       " 2080: 489,\n",
       " 2081: 490,\n",
       " 2087: 491,\n",
       " 2094: 492,\n",
       " 2095: 493,\n",
       " 2096: 494,\n",
       " 2098: 495,\n",
       " 2099: 496,\n",
       " 2106: 497,\n",
       " 2107: 498,\n",
       " 2108: 499,\n",
       " 2114: 500,\n",
       " 2115: 501,\n",
       " 2117: 502,\n",
       " 2125: 503,\n",
       " 2135: 504,\n",
       " 2137: 505,\n",
       " 2139: 506,\n",
       " 2140: 507,\n",
       " 2141: 508,\n",
       " 2142: 509,\n",
       " 2145: 510,\n",
       " 2148: 511,\n",
       " 2150: 512,\n",
       " 2156: 513,\n",
       " 2159: 514,\n",
       " 2160: 515,\n",
       " 2161: 516,\n",
       " 2162: 517,\n",
       " 2167: 518,\n",
       " 2171: 519,\n",
       " 2177: 520,\n",
       " 2188: 521,\n",
       " 2190: 522,\n",
       " 2202: 523,\n",
       " 2203: 524,\n",
       " 2210: 525,\n",
       " 2226: 526,\n",
       " 2232: 527,\n",
       " 2240: 528,\n",
       " 2247: 529,\n",
       " 2248: 530,\n",
       " 2249: 531,\n",
       " 2261: 532,\n",
       " 2264: 533,\n",
       " 2265: 534,\n",
       " 2269: 535,\n",
       " 2273: 536,\n",
       " 2286: 537,\n",
       " 2288: 538,\n",
       " 2302: 539,\n",
       " 2310: 540,\n",
       " 2312: 541,\n",
       " 2313: 542,\n",
       " 2320: 543,\n",
       " 2322: 544,\n",
       " 2323: 545,\n",
       " 2324: 546,\n",
       " 2325: 547,\n",
       " 2327: 548,\n",
       " 2332: 549,\n",
       " 2334: 550,\n",
       " 2335: 551,\n",
       " 2336: 552,\n",
       " 2338: 553,\n",
       " 2340: 554,\n",
       " 2342: 555,\n",
       " 2344: 556,\n",
       " 2356: 557,\n",
       " 2358: 558,\n",
       " 2363: 559,\n",
       " 2366: 560,\n",
       " 2368: 561,\n",
       " 2373: 562,\n",
       " 2375: 563,\n",
       " 2378: 564,\n",
       " 2381: 565,\n",
       " 2383: 566,\n",
       " 2389: 567,\n",
       " 2390: 568,\n",
       " 2392: 569,\n",
       " 2393: 570,\n",
       " 2394: 571,\n",
       " 2396: 572,\n",
       " 2403: 573,\n",
       " 2405: 574,\n",
       " 2407: 575,\n",
       " 2417: 576,\n",
       " 2425: 577,\n",
       " 2433: 578,\n",
       " 2435: 579,\n",
       " 2439: 580,\n",
       " 2446: 581,\n",
       " 2447: 582,\n",
       " 2453: 583,\n",
       " 2460: 584,\n",
       " 2472: 585,\n",
       " 2474: 586,\n",
       " 2476: 587,\n",
       " 2495: 588,\n",
       " 2498: 589,\n",
       " 2511: 590,\n",
       " 2514: 591,\n",
       " 2521: 592,\n",
       " 2540: 593,\n",
       " 2544: 594,\n",
       " 2546: 595,\n",
       " 2549: 596,\n",
       " 2550: 597,\n",
       " 2557: 598,\n",
       " 2565: 599,\n",
       " 2568: 600,\n",
       " 2573: 601,\n",
       " 2579: 602,\n",
       " 2587: 603,\n",
       " 2590: 604,\n",
       " 2596: 605,\n",
       " 2605: 606,\n",
       " 2606: 607,\n",
       " 2609: 608,\n",
       " 2616: 609,\n",
       " 2625: 610,\n",
       " 2630: 611,\n",
       " 2632: 612,\n",
       " 2643: 613,\n",
       " 2651: 614,\n",
       " 2655: 615,\n",
       " 2664: 616,\n",
       " 2668: 617,\n",
       " 2670: 618,\n",
       " 2672: 619,\n",
       " 2681: 620,\n",
       " 2682: 621,\n",
       " 2690: 622,\n",
       " 2694: 623,\n",
       " 2697: 624,\n",
       " 2701: 625,\n",
       " 2709: 626,\n",
       " 2712: 627,\n",
       " 2724: 628,\n",
       " 2734: 629,\n",
       " 2736: 630,\n",
       " 2737: 631,\n",
       " 2742: 632,\n",
       " 2746: 633,\n",
       " 2751: 634,\n",
       " 2757: 635,\n",
       " 2769: 636,\n",
       " 2770: 637,\n",
       " 2774: 638,\n",
       " 2775: 639,\n",
       " 2779: 640,\n",
       " 2788: 641,\n",
       " 2792: 642,\n",
       " 2801: 643,\n",
       " 2802: 644,\n",
       " 2803: 645,\n",
       " 2804: 646,\n",
       " 2805: 647,\n",
       " 2808: 648,\n",
       " 2810: 649,\n",
       " 2816: 650,\n",
       " 2819: 651,\n",
       " 2822: 652,\n",
       " 2827: 653,\n",
       " 2828: 654,\n",
       " 2829: 655,\n",
       " 2836: 656,\n",
       " 2837: 657,\n",
       " 2839: 658,\n",
       " 2840: 659,\n",
       " 2846: 660,\n",
       " 2852: 661,\n",
       " 2858: 662,\n",
       " 2860: 663,\n",
       " 2862: 664,\n",
       " 2863: 665,\n",
       " 2866: 666,\n",
       " 2872: 667,\n",
       " 2880: 668,\n",
       " 2881: 669,\n",
       " 2882: 670,\n",
       " 2883: 671,\n",
       " 2884: 672,\n",
       " 2891: 673,\n",
       " 2893: 674,\n",
       " 2894: 675,\n",
       " 2900: 676,\n",
       " 2907: 677,\n",
       " 2912: 678,\n",
       " 2924: 679,\n",
       " 2937: 680,\n",
       " 2941: 681,\n",
       " 2942: 682,\n",
       " 2943: 683,\n",
       " 2950: 684,\n",
       " 2956: 685,\n",
       " 2961: 686,\n",
       " 2962: 687,\n",
       " 2966: 688,\n",
       " 2967: 689,\n",
       " 2968: 690,\n",
       " 2974: 691,\n",
       " 2982: 692,\n",
       " 2983: 693,\n",
       " 2985: 694,\n",
       " 2986: 695,\n",
       " 2988: 696,\n",
       " 2989: 697,\n",
       " 2991: 698,\n",
       " 3000: 699,\n",
       " 3010: 700,\n",
       " 3013: 701,\n",
       " 3015: 702,\n",
       " 3016: 703,\n",
       " 3018: 704,\n",
       " 3033: 705,\n",
       " 3034: 706,\n",
       " 3035: 707,\n",
       " 3038: 708,\n",
       " 3046: 709,\n",
       " 3051: 710,\n",
       " 3052: 711,\n",
       " 3053: 712,\n",
       " 3054: 713,\n",
       " 3062: 714,\n",
       " 3070: 715,\n",
       " 3073: 716,\n",
       " 3083: 717,\n",
       " 3093: 718,\n",
       " 3095: 719,\n",
       " 3098: 720,\n",
       " 3102: 721,\n",
       " 3106: 722,\n",
       " 3109: 723,\n",
       " 3113: 724,\n",
       " 3120: 725,\n",
       " 3130: 726,\n",
       " 3148: 727,\n",
       " 3152: 728,\n",
       " 3155: 729,\n",
       " 3168: 730,\n",
       " 3169: 731,\n",
       " 3174: 732,\n",
       " 3182: 733,\n",
       " 3190: 734,\n",
       " 3196: 735,\n",
       " 3203: 736,\n",
       " 3204: 737,\n",
       " 3211: 738,\n",
       " 3217: 739,\n",
       " 3223: 740,\n",
       " 3249: 741,\n",
       " 3252: 742,\n",
       " 3254: 743,\n",
       " 3259: 744,\n",
       " 3260: 745,\n",
       " 3266: 746,\n",
       " 3268: 747,\n",
       " 3269: 748,\n",
       " 3271: 749,\n",
       " 3280: 750,\n",
       " 3281: 751,\n",
       " 3287: 752,\n",
       " 3289: 753,\n",
       " 3295: 754,\n",
       " 3301: 755,\n",
       " 3308: 756,\n",
       " 3310: 757,\n",
       " 3313: 758,\n",
       " 3315: 759,\n",
       " 3316: 760,\n",
       " 3326: 761,\n",
       " 3334: 762,\n",
       " 3358: 763,\n",
       " 3361: 764,\n",
       " 3363: 765,\n",
       " 3364: 766,\n",
       " 3365: 767,\n",
       " 3370: 768,\n",
       " 3378: 769,\n",
       " 3379: 770,\n",
       " 3386: 771,\n",
       " 3391: 772,\n",
       " 3393: 773,\n",
       " 3394: 774,\n",
       " 3401: 775,\n",
       " 3403: 776,\n",
       " 3404: 777,\n",
       " 3420: 778,\n",
       " 3436: 779,\n",
       " 3439: 780,\n",
       " 3442: 781,\n",
       " 3445: 782,\n",
       " 3455: 783,\n",
       " 3459: 784,\n",
       " 3467: 785,\n",
       " 3478: 786,\n",
       " 3479: 787,\n",
       " 3481: 788,\n",
       " 3492: 789,\n",
       " 3496: 790,\n",
       " 3499: 791,\n",
       " 3500: 792,\n",
       " 3504: 793,\n",
       " 3505: 794,\n",
       " 3511: 795,\n",
       " 3513: 796,\n",
       " 3514: 797,\n",
       " 3529: 798,\n",
       " 3545: 799,\n",
       " 3548: 800,\n",
       " 3549: 801,\n",
       " 3565: 802,\n",
       " 3566: 803,\n",
       " 3577: 804,\n",
       " 3586: 805,\n",
       " 3590: 806,\n",
       " 3592: 807,\n",
       " 3593: 808,\n",
       " 3594: 809,\n",
       " 3596: 810,\n",
       " 3599: 811,\n",
       " 3604: 812,\n",
       " 3608: 813,\n",
       " 3609: 814,\n",
       " 3618: 815,\n",
       " 3619: 816,\n",
       " 3624: 817,\n",
       " 3632: 818,\n",
       " 3641: 819,\n",
       " 3648: 820,\n",
       " 3658: 821,\n",
       " 3661: 822,\n",
       " 3664: 823,\n",
       " 3669: 824,\n",
       " 3675: 825,\n",
       " 3680: 826,\n",
       " 3686: 827,\n",
       " 3688: 828,\n",
       " 3689: 829,\n",
       " 3691: 830,\n",
       " 3692: 831,\n",
       " 3693: 832,\n",
       " 3696: 833,\n",
       " 3697: 834,\n",
       " 3698: 835,\n",
       " 3704: 836,\n",
       " 3707: 837,\n",
       " 3708: 838,\n",
       " 3709: 839,\n",
       " 3715: 840,\n",
       " 3736: 841,\n",
       " 3744: 842,\n",
       " 3752: 843,\n",
       " 3764: 844,\n",
       " 3766: 845,\n",
       " 3768: 846,\n",
       " 3774: 847,\n",
       " 3783: 848,\n",
       " 3790: 849,\n",
       " 3792: 850,\n",
       " 3798: 851,\n",
       " 3808: 852,\n",
       " 3810: 853,\n",
       " 3821: 854,\n",
       " 3824: 855,\n",
       " 3825: 856,\n",
       " 3830: 857,\n",
       " 3832: 858,\n",
       " 3835: 859,\n",
       " 3836: 860,\n",
       " 3838: 861,\n",
       " 3843: 862,\n",
       " 3845: 863,\n",
       " 3851: 864,\n",
       " 3855: 865,\n",
       " 3858: 866,\n",
       " 3859: 867,\n",
       " 3861: 868,\n",
       " 3871: 869,\n",
       " 3893: 870,\n",
       " 3895: 871,\n",
       " 3896: 872,\n",
       " 3897: 873,\n",
       " 3898: 874,\n",
       " 3900: 875,\n",
       " 3908: 876,\n",
       " 3918: 877,\n",
       " 3925: 878,\n",
       " 3926: 879,\n",
       " 3929: 880,\n",
       " 3932: 881,\n",
       " 3938: 882,\n",
       " 3947: 883,\n",
       " 3949: 884,\n",
       " 3952: 885,\n",
       " 3962: 886,\n",
       " 3963: 887,\n",
       " 3964: 888,\n",
       " 3965: 889,\n",
       " 3968: 890,\n",
       " 3972: 891,\n",
       " 3979: 892,\n",
       " 3981: 893,\n",
       " 3985: 894,\n",
       " 3994: 895,\n",
       " 4006: 896,\n",
       " 4010: 897,\n",
       " 4012: 898,\n",
       " 4016: 899,\n",
       " 4017: 900,\n",
       " 4018: 901,\n",
       " 4022: 902,\n",
       " 4023: 903,\n",
       " 4029: 904,\n",
       " 4035: 905,\n",
       " 4036: 906,\n",
       " 4037: 907,\n",
       " 4040: 908,\n",
       " 4042: 909,\n",
       " 4043: 910,\n",
       " 4046: 911,\n",
       " 4047: 912,\n",
       " 4051: 913,\n",
       " 4055: 914,\n",
       " 4056: 915,\n",
       " 4061: 916,\n",
       " 4062: 917,\n",
       " 4065: 918,\n",
       " 4066: 919,\n",
       " 4077: 920,\n",
       " 4078: 921,\n",
       " 4079: 922,\n",
       " 4081: 923,\n",
       " 4084: 924,\n",
       " 4089: 925,\n",
       " 4091: 926,\n",
       " 4093: 927,\n",
       " 4102: 928,\n",
       " 4103: 929,\n",
       " 4104: 930,\n",
       " 4110: 931,\n",
       " 4111: 932,\n",
       " 4113: 933,\n",
       " 4123: 934,\n",
       " 4124: 935,\n",
       " 4130: 936,\n",
       " 4131: 937,\n",
       " 4132: 938,\n",
       " 4138: 939,\n",
       " 4142: 940,\n",
       " 4148: 941,\n",
       " 4149: 942,\n",
       " 4154: 943,\n",
       " 4155: 944,\n",
       " 4160: 945,\n",
       " 4161: 946,\n",
       " 4168: 947,\n",
       " 4174: 948,\n",
       " 4181: 949,\n",
       " 4189: 950,\n",
       " 4194: 951,\n",
       " 4202: 952,\n",
       " 4204: 953,\n",
       " 4207: 954,\n",
       " 4210: 955,\n",
       " 4212: 956,\n",
       " 4214: 957,\n",
       " 4215: 958,\n",
       " 4217: 959,\n",
       " 4228: 960,\n",
       " 4229: 961,\n",
       " 4232: 962,\n",
       " 4233: 963,\n",
       " 4235: 964,\n",
       " 4236: 965,\n",
       " 4238: 966,\n",
       " 4241: 967,\n",
       " 4251: 968,\n",
       " 4270: 969,\n",
       " 4289: 970,\n",
       " 4292: 971,\n",
       " 4293: 972,\n",
       " 4296: 973,\n",
       " 4306: 974,\n",
       " 4321: 975,\n",
       " 4323: 976,\n",
       " 4325: 977,\n",
       " 4327: 978,\n",
       " 4329: 979,\n",
       " 4333: 980,\n",
       " 4367: 981,\n",
       " 4369: 982,\n",
       " 4374: 983,\n",
       " 4386: 984,\n",
       " 4387: 985,\n",
       " 4394: 986,\n",
       " 4403: 987,\n",
       " 4410: 988,\n",
       " 4419: 989,\n",
       " 4429: 990,\n",
       " 4439: 991,\n",
       " 4441: 992,\n",
       " 4442: 993,\n",
       " 4443: 994,\n",
       " 4444: 995,\n",
       " 4450: 996,\n",
       " 4458: 997,\n",
       " 4462: 998,\n",
       " 4463: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_id_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60, 60: 61, 61: 62, 62: 63, 63: 64, 64: 65, 65: 66, 66: 67, 67: 68, 68: 69, 69: 70, 70: 71, 71: 72, 72: 73, 73: 74, 74: 75, 75: 76, 76: 77, 77: 78, 78: 79, 79: 80, 80: 81, 81: 82, 82: 83, 83: 84, 84: 85, 85: 86, 86: 87, 87: 88, 88: 89, 89: 90, 90: 91, 91: 92, 92: 93, 93: 94, 94: 95, 95: 96, 96: 97, 97: 98, 98: 99, 99: 100, 100: 101, 101: 102, 102: 103, 103: 104, 104: 105, 105: 106, 106: 107, 107: 108, 108: 109, 109: 110, 110: 111, 111: 112, 112: 113, 113: 114, 114: 115, 115: 116, 116: 117, 117: 118, 118: 119, 119: 120, 120: 121, 121: 122, 122: 123, 123: 124, 124: 125, 125: 126, 126: 128, 127: 129, 128: 130, 129: 131, 130: 132, 131: 133, 132: 134, 133: 135, 134: 136, 135: 137, 136: 138, 137: 139, 138: 140, 139: 141, 140: 142, 141: 143, 142: 144, 143: 145, 144: 146, 145: 147, 146: 148, 147: 149, 148: 150, 149: 151, 150: 152, 151: 153, 152: 154, 153: 155, 154: 156, 155: 157, 156: 158, 157: 159, 158: 160, 159: 161, 160: 162, 161: 163, 162: 164, 163: 165, 164: 166, 165: 167, 166: 168, 167: 169, 168: 170, 169: 171, 170: 172, 171: 173, 172: 174, 173: 175, 174: 176, 175: 177, 176: 178, 177: 179, 178: 180, 179: 181, 180: 182, 181: 183, 182: 184, 183: 185, 184: 186, 185: 187, 186: 188, 187: 189, 188: 190, 189: 191, 190: 192, 191: 193, 192: 194, 193: 195, 194: 196, 195: 197, 196: 198, 197: 199, 198: 200, 199: 201, 200: 202, 201: 203, 202: 204, 203: 205, 204: 206, 205: 207, 206: 208, 207: 209, 208: 210, 209: 211, 210: 212, 211: 213, 212: 214, 213: 215, 214: 216, 215: 217, 216: 218, 217: 219, 218: 220, 219: 221, 220: 222, 221: 223, 222: 224, 223: 225, 224: 226, 225: 227, 226: 228, 227: 229, 228: 230, 229: 231, 230: 232, 231: 233, 232: 234, 233: 235, 234: 236, 235: 237, 236: 238, 237: 239, 238: 240, 239: 241, 240: 242, 241: 243, 242: 244, 243: 245, 244: 246, 245: 247, 246: 248, 247: 249, 248: 250, 249: 251, 250: 252, 251: 253, 252: 254, 253: 255, 254: 256, 255: 257, 256: 258, 257: 259, 258: 260, 259: 261, 260: 262, 261: 263, 262: 264, 263: 265, 264: 266, 265: 267, 266: 268, 267: 269, 268: 270, 269: 271, 270: 272, 271: 273, 272: 274, 273: 275, 274: 276, 275: 277, 276: 278, 277: 279, 278: 280, 279: 281, 280: 282, 281: 283, 282: 284, 283: 285, 284: 286, 285: 287, 286: 288, 287: 289, 288: 290, 289: 291, 290: 292, 291: 293, 292: 294, 293: 295, 294: 296, 295: 297, 296: 298, 297: 299, 298: 300, 299: 301, 300: 302, 301: 303, 302: 304, 303: 305, 304: 306, 305: 307, 306: 308, 307: 309, 308: 310, 309: 311, 310: 312, 311: 313, 312: 314, 313: 315, 314: 316, 315: 317, 316: 318, 317: 319, 318: 320, 319: 321, 320: 322, 321: 323, 322: 324, 323: 325, 324: 326, 325: 327, 326: 328, 327: 329, 328: 330, 329: 331, 330: 332, 331: 333, 332: 334, 333: 335, 334: 336, 335: 337, 336: 338, 337: 339, 338: 340, 339: 341, 340: 342, 341: 343, 342: 344, 343: 345, 344: 346, 345: 347, 346: 348, 347: 349, 348: 350, 349: 351, 350: 352, 351: 353, 352: 354, 353: 355, 354: 356, 355: 357, 356: 358, 357: 359, 358: 360, 359: 361, 360: 362, 361: 363, 362: 364, 363: 365, 364: 366, 365: 367, 366: 368, 367: 369, 368: 370, 369: 371, 370: 372, 371: 373, 372: 374, 373: 375, 374: 376, 375: 377, 376: 378, 377: 379, 378: 380, 379: 381, 380: 382, 381: 383, 382: 384, 383: 385, 384: 386, 385: 387, 386: 388, 387: 389, 388: 390, 389: 391, 390: 392, 391: 393, 392: 394, 393: 395, 394: 396, 395: 397, 396: 398, 397: 399, 398: 400, 399: 401, 400: 402, 401: 403, 402: 404, 403: 405, 404: 406, 405: 407, 406: 408, 407: 409, 408: 410, 409: 411, 410: 412, 411: 413, 412: 414, 413: 415, 414: 416, 415: 417, 416: 418, 417: 419, 418: 420, 419: 421, 420: 422, 421: 423, 422: 424, 423: 425, 424: 426, 425: 427, 426: 428, 427: 429, 428: 430, 429: 431, 430: 432, 431: 433, 432: 434, 433: 435, 434: 436, 435: 437, 436: 438, 437: 439, 438: 440, 439: 441, 440: 442, 441: 443, 442: 444, 443: 445, 444: 446, 445: 447, 446: 448, 447: 449, 448: 450, 449: 451, 450: 452, 451: 453, 452: 454, 453: 455, 454: 456, 455: 457, 456: 458, 457: 459, 458: 460, 459: 461, 460: 462, 461: 463, 462: 464, 463: 465, 464: 466, 465: 467, 466: 468, 467: 469, 468: 470, 469: 471, 470: 472, 471: 473, 472: 474, 473: 475, 474: 476, 475: 477, 476: 478, 477: 479, 478: 480, 479: 481, 480: 482, 481: 483, 482: 484, 483: 485, 484: 486, 485: 487, 486: 488, 487: 489, 488: 490, 489: 491, 490: 492, 491: 493, 492: 494, 493: 495, 494: 496, 495: 497, 496: 498, 497: 499, 498: 500, 499: 501, 500: 502, 501: 503, 502: 504, 503: 505, 504: 506, 505: 507, 506: 508, 507: 509, 508: 510, 509: 511, 510: 512, 511: 513, 512: 514, 513: 515, 514: 516, 515: 517, 516: 518, 517: 519, 518: 520, 519: 521, 520: 522, 521: 523, 522: 524, 523: 525, 524: 526, 525: 527, 526: 528, 527: 529, 528: 530, 529: 531, 530: 532, 531: 533, 532: 534, 533: 535, 534: 536, 535: 537, 536: 538, 537: 539, 538: 540, 539: 541, 540: 542, 541: 543, 542: 544, 543: 545, 544: 546, 545: 547, 546: 548, 547: 549, 548: 550, 549: 551, 550: 552, 551: 553, 552: 554, 553: 555, 554: 556, 555: 557, 556: 558, 557: 559, 558: 560, 559: 561, 560: 562, 561: 563, 562: 564, 563: 565, 564: 566, 565: 567, 566: 568, 567: 569, 568: 570, 569: 571, 570: 572, 571: 573, 572: 574, 573: 575, 574: 576, 575: 577, 576: 578, 577: 579, 578: 580, 579: 581, 580: 582, 581: 583, 582: 584, 583: 585, 584: 586, 585: 587, 586: 588, 587: 589, 588: 590, 589: 591, 590: 592, 591: 593, 592: 594, 593: 595, 594: 596, 595: 597, 596: 598, 597: 599, 598: 600, 599: 601, 600: 602, 601: 603, 602: 604, 603: 605, 604: 606, 605: 607, 606: 608, 607: 609, 608: 610}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 128: 126, 129: 127, 130: 128, 131: 129, 132: 130, 133: 131, 134: 132, 135: 133, 136: 134, 137: 135, 138: 136, 139: 137, 140: 138, 141: 139, 142: 140, 143: 141, 144: 142, 145: 143, 146: 144, 147: 145, 148: 146, 149: 147, 150: 148, 151: 149, 152: 150, 153: 151, 154: 152, 155: 153, 156: 154, 157: 155, 158: 156, 159: 157, 160: 158, 161: 159, 162: 160, 163: 161, 164: 162, 165: 163, 166: 164, 167: 165, 168: 166, 169: 167, 170: 168, 171: 169, 172: 170, 173: 171, 174: 172, 175: 173, 176: 174, 177: 175, 178: 176, 179: 177, 180: 178, 181: 179, 182: 180, 183: 181, 184: 182, 185: 183, 186: 184, 187: 185, 188: 186, 189: 187, 190: 188, 191: 189, 192: 190, 193: 191, 194: 192, 195: 193, 196: 194, 197: 195, 198: 196, 199: 197, 200: 198, 201: 199, 202: 200, 203: 201, 204: 202, 205: 203, 206: 204, 207: 205, 208: 206, 209: 207, 210: 208, 211: 209, 212: 210, 213: 211, 214: 212, 215: 213, 216: 214, 217: 215, 218: 216, 219: 217, 220: 218, 221: 219, 222: 220, 223: 221, 224: 222, 225: 223, 226: 224, 227: 225, 228: 226, 229: 227, 230: 228, 231: 229, 232: 230, 233: 231, 234: 232, 235: 233, 236: 234, 237: 235, 238: 236, 239: 237, 240: 238, 241: 239, 242: 240, 243: 241, 244: 242, 245: 243, 246: 244, 247: 245, 248: 246, 249: 247, 250: 248, 251: 249, 252: 250, 253: 251, 254: 252, 255: 253, 256: 254, 257: 255, 258: 256, 259: 257, 260: 258, 261: 259, 262: 260, 263: 261, 264: 262, 265: 263, 266: 264, 267: 265, 268: 266, 269: 267, 270: 268, 271: 269, 272: 270, 273: 271, 274: 272, 275: 273, 276: 274, 277: 275, 278: 276, 279: 277, 280: 278, 281: 279, 282: 280, 283: 281, 284: 282, 285: 283, 286: 284, 287: 285, 288: 286, 289: 287, 290: 288, 291: 289, 292: 290, 293: 291, 294: 292, 295: 293, 296: 294, 297: 295, 298: 296, 299: 297, 300: 298, 301: 299, 302: 300, 303: 301, 304: 302, 305: 303, 306: 304, 307: 305, 308: 306, 309: 307, 310: 308, 311: 309, 312: 310, 313: 311, 314: 312, 315: 313, 316: 314, 317: 315, 318: 316, 319: 317, 320: 318, 321: 319, 322: 320, 323: 321, 324: 322, 325: 323, 326: 324, 327: 325, 328: 326, 329: 327, 330: 328, 331: 329, 332: 330, 333: 331, 334: 332, 335: 333, 336: 334, 337: 335, 338: 336, 339: 337, 340: 338, 341: 339, 342: 340, 343: 341, 344: 342, 345: 343, 346: 344, 347: 345, 348: 346, 349: 347, 350: 348, 351: 349, 352: 350, 353: 351, 354: 352, 355: 353, 356: 354, 357: 355, 358: 356, 359: 357, 360: 358, 361: 359, 362: 360, 363: 361, 364: 362, 365: 363, 366: 364, 367: 365, 368: 366, 369: 367, 370: 368, 371: 369, 372: 370, 373: 371, 374: 372, 375: 373, 376: 374, 377: 375, 378: 376, 379: 377, 380: 378, 381: 379, 382: 380, 383: 381, 384: 382, 385: 383, 386: 384, 387: 385, 388: 386, 389: 387, 390: 388, 391: 389, 392: 390, 393: 391, 394: 392, 395: 393, 396: 394, 397: 395, 398: 396, 399: 397, 400: 398, 401: 399, 402: 400, 403: 401, 404: 402, 405: 403, 406: 404, 407: 405, 408: 406, 409: 407, 410: 408, 411: 409, 412: 410, 413: 411, 414: 412, 415: 413, 416: 414, 417: 415, 418: 416, 419: 417, 420: 418, 421: 419, 422: 420, 423: 421, 424: 422, 425: 423, 426: 424, 427: 425, 428: 426, 429: 427, 430: 428, 431: 429, 432: 430, 433: 431, 434: 432, 435: 433, 436: 434, 437: 435, 438: 436, 439: 437, 440: 438, 441: 439, 442: 440, 443: 441, 444: 442, 445: 443, 446: 444, 447: 445, 448: 446, 449: 447, 450: 448, 451: 449, 452: 450, 453: 451, 454: 452, 455: 453, 456: 454, 457: 455, 458: 456, 459: 457, 460: 458, 461: 459, 462: 460, 463: 461, 464: 462, 465: 463, 466: 464, 467: 465, 468: 466, 469: 467, 470: 468, 471: 469, 472: 470, 473: 471, 474: 472, 475: 473, 476: 474, 477: 475, 478: 476, 479: 477, 480: 478, 481: 479, 482: 480, 483: 481, 484: 482, 485: 483, 486: 484, 487: 485, 488: 486, 489: 487, 490: 488, 491: 489, 492: 490, 493: 491, 494: 492, 495: 493, 496: 494, 497: 495, 498: 496, 499: 497, 500: 498, 501: 499, 502: 500, 503: 501, 504: 502, 505: 503, 506: 504, 507: 505, 508: 506, 509: 507, 510: 508, 511: 509, 512: 510, 513: 511, 514: 512, 515: 513, 516: 514, 517: 515, 518: 516, 519: 517, 520: 518, 521: 519, 522: 520, 523: 521, 524: 522, 525: 523, 526: 524, 527: 525, 528: 526, 529: 527, 530: 528, 531: 529, 532: 530, 533: 531, 534: 532, 535: 533, 536: 534, 537: 535, 538: 536, 539: 537, 540: 538, 541: 539, 542: 540, 543: 541, 544: 542, 545: 543, 546: 544, 547: 545, 548: 546, 549: 547, 550: 548, 551: 549, 552: 550, 553: 551, 554: 552, 555: 553, 556: 554, 557: 555, 558: 556, 559: 557, 560: 558, 561: 559, 562: 560, 563: 561, 564: 562, 565: 563, 566: 564, 567: 565, 568: 566, 569: 567, 570: 568, 571: 569, 572: 570, 573: 571, 574: 572, 575: 573, 576: 574, 577: 575, 578: 576, 579: 577, 580: 578, 581: 579, 582: 580, 583: 581, 584: 582, 585: 583, 586: 584, 587: 585, 588: 586, 589: 587, 590: 588, 591: 589, 592: 590, 593: 591, 594: 592, 595: 593, 596: 594, 597: 595, 598: 596, 599: 597, 600: 598, 601: 599, 602: 600, 603: 601, 604: 602, 605: 603, 606: 604, 607: 605, 608: 606, 609: 607, 610: 608}\n"
     ]
    }
   ],
   "source": [
    "print(user_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 2923)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 2923)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2923, 2923)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_matrix_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices Summation:\n",
    "\n",
    "Once we have both similarity matrices (the one from the ratings and the one from the genres) we can add them with a weighted sumation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Similarity Matrix:\n",
      " [[1.         0.09451459 0.16637116 ... 0.13416408 0.232379   0.09486833]\n",
      " [0.09451459 1.         0.         ... 0.         0.1        0.        ]\n",
      " [0.16637116 0.         1.         ... 0.         0.         0.21213203]\n",
      " ...\n",
      " [0.13416408 0.         0.         ... 1.         0.17320508 0.21213203]\n",
      " [0.232379   0.1        0.         ... 0.17320508 1.         0.12247449]\n",
      " [0.09486833 0.         0.21213203 ... 0.21213203 0.12247449 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def combine_similarity_matrices(similarity_matrix1, similarity_matrix2, weight1 = 0.7, weight2 = 0.3):\n",
    "    # Check if the matrices have the same shape\n",
    "    if similarity_matrix1.shape != similarity_matrix2.shape:\n",
    "        raise ValueError(\"Matrices must have the same shape.\")\n",
    "\n",
    "    # Combine matrices using weighted summation\n",
    "    combined_similarity_matrix = (weight1 * similarity_matrix1) + (weight2 * similarity_matrix2)\n",
    "    return combined_similarity_matrix\n",
    "\n",
    "# Define weights for each matrix\n",
    "weight_ratings = 0.7\n",
    "weight_genres = 0.3\n",
    "\n",
    "# Combine the similarity matrices\n",
    "item_similarity_matrix_train = combine_similarity_matrices(item_similarity_matrix_train, item_similarity_genres_matrix, weight_ratings, weight_genres)\n",
    "\n",
    "# Print or use the combined similarity matrix as needed\n",
    "print(\"Combined Similarity Matrix:\\n\", item_similarity_matrix_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Neighborhood Selection\n",
    "- Determine the neighborhood size, i.e., the number of most similar items to consider when predicting ratings for a target item.\n",
    "- Select the most similar items for each item in the dataset based on their calculated similarities. This forms the neighborhood for each item.\n",
    "\n",
    "#### Item-Based Neighborhoods and Ratings Aggregation\n",
    "\n",
    "This code following snippet enhances the previous item-based collaborative filtering approach by considering ratings aggregation within the item neighborhoods.\n",
    "\n",
    "##### Steps:\n",
    "\n",
    "1. **Defining Neighborhood Size**:\n",
    "   - The variable `neighborhood_size` determines the number of most similar items to consider in the neighborhood.\n",
    "\n",
    "2. **Initializing Data Structure**:\n",
    "   - An empty dictionary `item_neighborhoods` is initialized to store the neighborhoods for each item.\n",
    "\n",
    "3. **Iterating Over Items**:\n",
    "   - For each movie in the dataset:\n",
    "     - All ratings for the current movie are extracted from the DataFrame (`df`).\n",
    "     - Ratings aggregation is performed. In this example, the average rating for the movie is computed, but other aggregation methods can be used.\n",
    "     - The similarity scores for the current movie are retrieved from the precomputed `item_similarity_matrix`.\n",
    "     - Similarity scores are sorted in descending order, and the indices of the most similar items (excluding itself) are obtained.\n",
    "     - These indices are converted back to movie IDs, forming the neighborhood for the current item.\n",
    "     - The neighborhood for the current item is stored in the `item_neighborhoods` dictionary.\n",
    "\n",
    "4. **Output**:\n",
    "   - `item_neighborhoods`: A dictionary where keys are movie IDs, and values are lists of movie IDs representing the neighborhood of each item. Each movie's neighborhood includes movies with similar ratings and content.\n",
    "\n",
    "##### Note:\n",
    "- This approach considers both similarity in ratings and content (as captured by cosine similarity) when building item neighborhoods.\n",
    "- Aggregating ratings within item neighborhoods helps in providing more personalized recommendations.\n",
    "- The choice of rating aggregation method (e.g., mean, median) can impact the quality of recommendations and may need to be adjusted based on the characteristics of the dataset and user preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [4306, 1073, 5218, 1265, 1367], 4: [25905, 32291, 5076, 6509, 6100], 9: [694, 692, 1599, 667, 990], 11: [539, 1307, 357, 2396, 105], 13: [2141, 4154, 2137, 2037, 126142], 15: [2822, 736, 258, 380, 442], 18: [3858, 1546, 5427, 3979, 7367], 20: [7007, 114818, 1432, 3268, 99728], 24: [3478, 2862, 790, 2846, 4012], 30: [4695, 4766, 2008, 149, 1415], 31: [277, 211, 6918, 37736, 3252], 32: [541, 50, 1089, 1356, 296], 36: [290, 247, 43, 2310, 81], 40: [694, 715, 1059, 5992, 1047], 41: [4723, 4888, 2106, 8337, 1507], 43: [25999, 8451, 7479, 8920, 4484], 45: [4029, 2177, 3310, 100, 2203], 50: [1089, 296, 593, 32, 592], 52: [892, 85, 3310, 496, 2697], 53: [2435, 1519, 645, 2609, 835], 55: [7299, 6768, 50923, 2546, 971], 63: [7103, 212, 6625, 2514, 5113], 65: [88, 785, 637, 656, 104], 66: [667, 76, 891, 692, 103], 69: [514, 785, 7103, 3313, 470], 73: [277, 527, 944, 26326, 41], 76: [66, 692, 103, 748, 64231], 77: [108, 759, 363, 1856, 99], 78: [627, 996, 100, 211, 694], 81: [290, 707, 36, 152284, 7354], 85: [2544, 1549, 3586, 617, 3792], 88: [65, 785, 5307, 3691, 2007], 89: [1432, 1599, 117895, 3268, 2816], 92: [4077, 3420, 7883, 6810, 7560], 99: [77, 108, 759, 1856, 363], 100: [6335, 6971, 627, 4888, 4723], 103: [692, 891, 76, 782, 66], 104: [333, 2694, 3254, 6188, 637], 105: [62344, 7034, 4836, 3155, 11], 107: [2709, 3034, 2087, 1367, 1806], 108: [108, 759, 363, 1856, 99], 112: [2880, 65, 464, 785, 733], 116: [1144, 791, 7171, 6948, 6269], 117: [52375, 6796, 247, 2332, 290], 118: [2836, 3692, 2037, 3370, 2446], 119: [25752, 1546, 34312, 612, 90890], 122: [4132, 437, 3120, 267, 91628], 123: [48638, 147002, 26317, 87660, 5202], 125: [3851, 1585, 151311, 2390, 937], 129: [2937, 1446, 1699, 2988, 3217], 145: [2985, 4369, 296, 80489, 99728], 146: [2775, 6386, 2590, 6279, 4836], 149: [2540, 4695, 1415, 4766, 2008], 158: [107, 2161, 828, 986, 442], 159: [78836, 7459, 188675, 148424, 116799], 162: [3182, 556, 99, 759, 27912], 172: [1320, 1037, 442, 8371, 3697], 177: [4403, 33896, 1329, 3838, 7650], 186: [3394, 539, 357, 333, 708], 194: [3925, 1173, 6978, 574, 41712], 199: [2171, 4419, 4589, 8502, 1549], 201: [69951, 137517, 95839, 6270, 164280], 204: [315, 442, 172, 7310, 1599], 208: [442, 380, 8644, 736, 1676], 209: [7299, 6768, 981, 50923, 2546], 211: [26812, 62799, 61628, 1268, 60046], 212: [6625, 7103, 2514, 888, 1655], 213: [496, 283, 85, 307, 99], 217: [271, 277, 981, 350, 100], 230: [100, 4077, 3420, 6810, 4625], 233: [30, 835, 2630, 2435, 2609], 243: [170837, 810, 6936, 1702, 27075], 246: [556, 99, 162, 2323, 1123], 247: [6335, 4723, 290, 4888, 36], 248: [267, 437, 333, 637, 435], 250: [460, 437, 374, 258, 248], 253: [266, 4720, 2160, 3499, 350], 254: [7299, 6768, 981, 50923, 2546], 257: [350, 490, 36276, 1661, 8771], 258: [2037, 44399, 118, 31223, 250], 266: [11, 539, 253, 105, 380], 267: [248, 637, 333, 59429, 520], 271: [217, 277, 452, 358, 828], 277: [271, 31, 981, 217, 350], 283: [5272, 5258, 4061, 213, 5723], 285: [4036, 83601, 7742, 7492, 8405], 287: [5470, 1307, 5135, 7121, 5151], 290: [211, 4695, 36, 81, 149], 291: [3370, 2446, 2453, 3692, 2037], 296: [593, 50, 1213, 778, 1089], 303: [6595, 2989, 4866, 3764, 72591], 305: [728, 471, 2681, 2390, 518], 307: [2310, 4723, 4888, 1695, 2336], 315: [204, 350, 7017, 592, 8268], 328: [163937, 70208, 138610, 142366, 97188], 330: [3692, 2446, 2453, 118, 2037], 333: [104, 585, 248, 637, 267], 334: [4810, 645, 2609, 334, 2630], 342: [3851, 2390, 357, 84553, 8695], 346: [4713, 4488, 835, 2630, 4810], 350: [257, 315, 277, 539, 217], 353: [592, 2167, 2985, 555, 105585], 357: [539, 1307, 708, 1265, 11], 358: [233, 580, 3952, 574, 277], 360: [3120, 459, 1599, 4516, 6425], 361: [51884, 47970, 4487, 55112, 25795], 363: [108, 3680, 77, 759, 32314], 365: [7299, 121035, 50923, 2546, 971], 370: [1391, 2027, 1665, 104, 520], 372: [1542, 1883, 4529, 3046, 2145], 374: [810, 77206, 250, 6559, 1702], 376: [736, 805, 733, 9, 2334], 377: [380, 736, 592, 539, 1370], 378: [54796, 78174, 118, 84553, 2836], 380: [377, 592, 736, 208, 733], 389: [41, 2324, 2390, 527, 1944], 393: [69805, 106491, 7017, 6994, 60937], 405: [5040, 95149, 108795, 163056, 5463], 408: [408, 459, 4516, 4541, 4293], 409: [52375, 168266, 2332, 290, 1213], 416: [470, 998, 3313, 2098, 122], 423: [2540, 2956, 3744, 2334, 4640], 435: [248, 333, 437, 2407, 520], 437: [460, 870, 250, 2381, 248], 442: [208, 1831, 172, 204, 1676], 446: [2943, 199, 4419, 25841, 1549], 452: [1841, 2943, 2310, 1446, 715], 453: [131656, 117887, 378, 4155, 18], 459: [1667, 4482, 408, 3120, 4207], 460: [250, 437, 248, 585, 471], 461: [1176, 2544, 3586, 1549, 3792], 464: [27480, 58826, 61818, 52831, 73741], 470: [470, 2098, 2736, 998, 3774], 471: [305, 1394, 728, 2247, 1135], 472: [6425, 3548, 504, 2265, 1016], 473: [7103, 2514, 6625, 212, 4215], 477: [6791, 8714, 2310, 3310, 8502], 478: [1910, 61323, 7102, 6724, 3130], 490: [540, 2210, 257, 92, 7348], 492: [2247, 1966, 125, 1701, 3851], 496: [213, 85, 283, 52, 99], 499: [1440, 2007, 3691, 3051, 3693], 504: [1762, 1599, 2816, 472, 6425], 510: [6768, 981, 50923, 2546, 971], 512: [2900, 3693, 2363, 3661, 3664], 514: [1440, 3691, 2007, 69, 785], 518: [6425, 2381, 2265, 1731, 870], 520: [3254, 104, 585, 3968, 2335], 522: [4723, 4888, 1432, 5646, 110882], 527: [5995, 2324, 296, 50068, 1299], 528: [155659, 98836, 106883, 84950, 119068], 532: [2514, 2159, 1732, 7103, 5075], 535: [3038, 2866, 2240, 3260, 2439], 539: [11, 357, 2396, 1307, 2145], 540: [490, 459, 257, 350, 1061], 541: [1676, 1882, 1127, 924, 3697], 543: [3394, 1934, 7826, 708, 3254], 544: [1599, 2816, 1762, 504, 2381], 551: [596, 594, 1073, 2087, 661], 553: [1266, 277, 1283, 1304, 266], 555: [1089, 1729, 296, 592, 50], 556: [108, 2323, 77, 1123, 759], 574: [580, 461, 988, 2417, 1173], 580: [574, 715, 461, 3985, 1395], 585: [333, 6944, 3688, 104, 49220], 592: [380, 353, 296, 377, 2985], 593: [296, 50, 1089, 592, 1258], 594: [596, 551, 2087, 1032, 2081], 596: [594, 551, 1032, 2087, 661], 605: [1767, 199, 4419, 2171, 1678], 612: [1585, 4079, 7647, 2261, 2417], 617: [685, 896, 85, 791, 1144], 627: [5893, 78, 100, 3370, 291], 628: [805, 36, 78, 68347, 3403], 635: [61628, 26812, 62799, 4251, 2358], 637: [65, 104, 267, 248, 333], 640: [2320, 944, 707, 981, 291], 645: [4810, 645, 2609, 334, 2630], 656: [65, 842, 6425, 1474, 637], 661: [596, 551, 2087, 1073, 1032], 665: [78142, 3035, 74342, 6542, 26158], 667: [66, 891, 692, 9, 76], 680: [6023, 4624, 5828, 8800, 26810], 685: [685, 617, 791, 1144, 85], 692: [103, 76, 891, 990, 66], 694: [9, 996, 78, 504, 40], 707: [81, 290, 640, 6279, 5563], 708: [357, 1307, 3394, 6254, 372], 715: [2943, 580, 452, 461, 1841], 722: [7171, 4217, 363, 6453, 3680], 728: [2177, 574, 1585, 305, 2390], 731: [1161, 592, 139717, 137345, 6322], 733: [736, 1356, 380, 1370, 2115], 736: [377, 733, 380, 376, 1356], 748: [76, 692, 66, 1882, 880], 757: [7299, 50923, 2546, 971, 961], 759: [108, 77, 363, 99, 1856], 760: [92243, 115969, 141749, 126430, 6285], 773: [87660, 111817, 773, 3845, 26059], 778: [296, 1732, 1213, 7323, 6003], 782: [103, 805, 891, 1061, 692], 783: [2081, 594, 661, 551, 1029], 785: [2335, 65, 69, 514, 3254], 790: [790, 3051, 4043, 3577, 3442], 791: [1144, 685, 896, 116, 617], 795: [7299, 121035, 50923, 2546, 971], 805: [782, 628, 376, 40583, 100], 810: [374, 637, 1367, 1073, 1474], 824: [61011, 69118, 6234, 135288, 108981], 828: [158, 661, 271, 217, 1367], 835: [4810, 645, 2609, 334, 2630], 841: [1329, 3838, 4403, 33896, 7650], 842: [891, 656, 65, 103, 3692], 848: [2775, 6246, 2590, 7089, 8571], 870: [2381, 4660, 157270, 31000, 118512], 875: [27705, 95624, 72591, 8677, 55112], 880: [748, 103, 5544, 76, 692], 888: [6625, 212, 1655, 7103, 2514], 891: [842, 103, 66, 692, 667], 892: [52, 3774, 1883, 1046, 2396], 896: [685, 617, 791, 1144, 85], 900: [199, 918, 605, 8502, 6912], 901: [2863, 3548, 5427, 3858, 1546], 911: [3632, 5021, 7121, 2579, 931], 914: [2565, 7080, 2690, 5991, 2145], 918: [2565, 7080, 900, 1926, 3963], 923: [1354, 5013, 3152, 1283, 1358], 924: [3994, 541, 1204, 1253, 1127], 927: [5231, 25752, 4204, 927, 4860], 929: [36276, 25927, 6273, 4077, 3420], 930: [3334, 931, 1248, 2203, 3203], 931: [2171, 2177, 2203, 3203, 199], 932: [1897, 1829, 123545, 25856, 50685], 934: [6702, 4929, 2792, 7375, 6944], 937: [3851, 1046, 125, 2390, 892], 944: [45635, 8650, 52967, 4292, 8463], 950: [5602, 6724, 1914, 8044, 8645], 953: [6936, 1961, 1952, 1265, 5971], 956: [50274, 6031, 1496, 8921, 4296], 959: [4292, 2757, 7479, 8057, 4189], 961: [7299, 6768, 981, 50923, 2546], 965: [48142, 2550, 6852, 36276, 4546], 969: [2067, 3035, 4795, 3608, 2941], 970: [8341, 2697, 6837, 8302, 25795], 971: [1096, 1949, 1938, 3271, 3095], 973: [6376, 8232, 5685, 43460, 4600], 979: [2106, 50068, 68872, 160422, 58876], 981: [100, 277, 217, 477, 31], 982: [4292, 2757, 7479, 8057, 4189], 986: [146, 1016, 1015, 4795, 1592], 988: [2417, 1816, 2435, 334, 1585], 990: [7017, 692, 8268, 6994, 1499], 996: [64231, 78, 100, 694, 782], 998: [470, 2098, 3313, 3764, 2373], 1003: [4632, 47952, 116887, 46865, 109846], 1005: [6625, 4214, 1021, 7103, 4822], 1006: [3641, 8338, 31260, 8462, 4046], 1007: [2016, 473, 6559, 6625, 4081], 1008: [4327, 26142, 4323, 26750, 4329], 1015: [2161, 986, 6297, 146, 26999], 1016: [2095, 2016, 3393, 3548, 2037], 1021: [1005, 2709, 1592, 4822, 1474], 1024: [4241, 2099, 43869, 134019, 2495], 1029: [2096, 2078, 3034, 2087, 1032], 1032: [2087, 3034, 596, 2096, 594], 1037: [1591, 172, 1882, 1320, 1590], 1040: [121035, 50923, 2546, 971, 961], 1046: [937, 896, 685, 45361, 892], 1047: [2802, 2403, 996, 1616, 692], 1059: [1678, 2943, 51884, 932, 25856], 1060: [617, 4029, 1173, 1883, 140816], 1061: [782, 100, 89, 692, 3169], 1073: [551, 1, 661, 596, 6936], 1089: [50, 296, 1213, 1729, 593], 1092: [1089, 4238, 3505, 50, 1620], 1094: [2067, 2802, 2858, 1897, 3403], 1095: [211, 3260, 5272, 5258, 452], 1096: [2336, 971, 3260, 2188, 80454], 1099: [6232, 8482, 7052, 7062, 8463], 1104: [7234, 1695, 25841, 1938, 4723], 1123: [2323, 6692, 556, 4061, 5258], 1127: [1129, 1374, 2094, 2989, 1356], 1129: [3704, 1127, 2985, 1374, 2403], 1135: [2779, 2736, 2247, 1171, 1440], 1144: [1144, 685, 896, 116, 617], 1148: [2081, 2709, 1234, 2080, 5218], 1156: [7299, 6768, 981, 50923, 2546], 1161: [7938, 1572, 44657, 7939, 5531], 1171: [2247, 2779, 1135, 49220, 1966], 1173: [574, 1695, 988, 2417, 461], 1176: [461, 3586, 2544, 1549, 1415], 1178: [92243, 115969, 106441, 145418, 50068], 1204: [1272, 2202, 924, 1299, 2067], 1207: [3897, 3152, 4439, 7234, 64620], 1213: [296, 1089, 1729, 778, 64614], 1220: [1391, 6863, 1394, 1265, 1580], 1226: [1498, 3479, 5984, 1678, 461], 1232: [145418, 7748, 160565, 106441, 44719], 1234: [6957, 1396, 1171, 1732, 2779], 1241: [7657, 3018, 5909, 27778, 51498], 1248: [3334, 2159, 2511, 2912, 930], 1253: [40583, 60037, 2664, 924, 27408], 1258: [1997, 1333, 593, 2288, 83134], 1259: [1961, 924, 2858, 3897, 1204], 1261: [3018, 52950, 7657, 6755, 1241], 1265: [1307, 1394, 357, 4018, 1784], 1266: [1283, 3098, 3871, 553, 1952], 1268: [211, 3500, 2681, 3774, 52], 1271: [5991, 4641, 2145, 6724, 61323], 1272: [1178, 1204, 2202, 3985, 1939], 1283: [3365, 1266, 3095, 3871, 2866], 1296: [461, 4419, 199, 1176, 2171], 1299: [1944, 3152, 2067, 1204, 1272], 1304: [1283, 1266, 7027, 3836, 1953], 1307: [1265, 5299, 357, 2724, 4823], 1320: [3697, 172, 1590, 2167, 8371], 1321: [1333, 40617, 8967, 6695, 2746], 1328: [841, 3908, 3709, 42723, 8225], 1329: [1329, 33896, 4403, 7650, 8405], 1331: [841, 3908, 3709, 42723, 8225], 1333: [3499, 1321, 2664, 1258, 2160], 1336: [3661, 3664, 2460, 1995, 2900], 1339: [1350, 1333, 2327, 3697, 2159], 1346: [3459, 2068, 2802, 2609, 4810], 1350: [48142, 7646, 7116, 1333, 1997], 1354: [6791, 4589, 3223, 3310, 3152], 1356: [1374, 1127, 733, 2094, 541], 1358: [535, 3260, 3271, 2240, 1952], 1367: [1, 107, 1073, 1806, 3034], 1370: [2989, 1127, 5349, 380, 2403], 1372: [1374, 1373, 1356, 2393, 1396], 1373: [2393, 1374, 1372, 2322, 2643], 1374: [1356, 1129, 1127, 1372, 1373], 1378: [4040, 2261, 2016, 4084, 2802], 1388: [4124, 40617, 33164, 6695, 32743], 1391: [1676, 1580, 2701, 1220, 2407], 1394: [2247, 1265, 785, 4641, 1171], 1395: [2736, 151311, 8848, 179813, 162414], 1396: [2985, 1234, 1580, 1372, 2381], 1398: [6434, 6178, 4495, 7212, 4296], 1408: [4035, 1378, 7162, 8730, 7137], 1412: [89580, 27822, 4093, 90943, 37240], 1415: [1415, 1549, 2544, 3586, 4695], 1423: [4292, 2757, 7479, 8057, 4189], 1430: [31049, 95690, 91688, 1565, 84696], 1432: [5628, 114818, 2769, 3895, 6971], 1440: [2007, 3691, 499, 3051, 4081], 1441: [499, 4621, 1307, 3394, 2248], 1442: [3073, 1642, 896, 685, 3565], 1446: [452, 1841, 1519, 2943, 129], 1447: [3947, 3895, 5628, 4699, 4911], 1454: [2417, 988, 3051, 1816, 41712], 1465: [6246, 2590, 2775, 5563, 4836], 1473: [1024, 2596, 1226, 3053, 2099], 1474: [1016, 1592, 656, 842, 2095], 1490: [1490, 6533, 26171, 2356, 4289], 1496: [50274, 6031, 8921, 4296, 2801], 1498: [3586, 2544, 1549, 4766, 1415], 1499: [990, 692, 2989, 5264, 736], 1502: [4296, 2801, 1678, 25833, 25856], 1507: [8337, 8461, 7560, 8057, 7052], 1515: [72489, 27705, 72591, 32743, 875], 1516: [1911, 2880, 3618, 333, 3287], 1518: [1616, 7017, 990, 8268, 1370], 1519: [53, 1694, 1446, 1207, 1358], 1526: [5231, 25752, 4204, 927, 4860], 1541: [2261, 499, 3691, 2007, 4149], 1542: [7354, 372, 7264, 3925, 3051], 1546: [1546, 5427, 7264, 7354, 5628], 1549: [2544, 3586, 4766, 3792, 1415], 1554: [1549, 2544, 3586, 3792, 4766], 1564: [1897, 1829, 4062, 2681, 932], 1565: [31049, 95690, 91688, 1430, 84696], 1572: [44657, 5531, 7938, 7939, 1572], 1580: [1391, 1676, 2701, 3033, 45499], 1585: [2417, 988, 1816, 1699, 2891], 1590: [1320, 2232, 3697, 1037, 1779], 1591: [1037, 1129, 2986, 4553, 3704], 1592: [6425, 1713, 2265, 1474, 518], 1594: [4529, 3046, 988, 2417, 5272], 1597: [2712, 4160, 2605, 4699, 4487], 1599: [2816, 504, 1762, 6425, 2265], 1602: [6425, 6559, 25905, 518, 870], 1609: [49822, 805, 5387, 60735, 3513], 1616: [1518, 7017, 1370, 1047, 990], 1619: [5995, 70451, 50068, 1894, 2966], 1620: [118354, 105755, 124859, 157407, 127132], 1623: [841, 3908, 3709, 42723, 8225], 1625: [3386, 1089, 4720, 2712, 104879], 1627: [1695, 4056, 4695, 4640, 4811], 1642: [4929, 1934, 5307, 6376, 8232], 1654: [26528, 74282, 65359, 47384, 27036], 1655: [2514, 3843, 888, 212, 7103], 1658: [291, 3370, 118, 2446, 4228], 1661: [5563, 6279, 6246, 4836, 146], 1665: [2335, 4233, 3821, 3254, 1731], 1667: [459, 504, 4482, 8650, 4055], 1676: [1391, 3698, 1580, 541, 2985], 1678: [2943, 3259, 1059, 605, 2310], 1694: [1519, 3590, 790, 5258, 5272], 1695: [4811, 2435, 3514, 4810, 645], 1699: [2439, 2417, 988, 2988, 1816], 1701: [988, 2417, 1816, 1699, 2065], 1702: [1806, 77206, 65577, 6794, 374], 1707: [6559, 6994, 4374, 6793, 5076], 1713: [31223, 8946, 4649, 6425, 1592], 1729: [1089, 1213, 27831, 296, 555], 1731: [8967, 6794, 165639, 3511, 72601], 1732: [778, 296, 6957, 1089, 2378], 1757: [45382, 5986, 8848, 162414, 179813], 1762: [504, 1599, 2816, 6425, 2265], 1767: [605, 6031, 1496, 7092, 8921], 1769: [4640, 7802, 2956, 7048, 3895], 1772: [2325, 77667, 1220, 3268, 2837], 1779: [1882, 3981, 1590, 1591, 2672], 1784: [3481, 2396, 2858, 1307, 8949], 1785: [3895, 60647, 5628, 6335, 6588], 1797: [6289, 7171, 3609, 8938, 6269], 1798: [5387, 2568, 5065, 5312, 291], 1799: [5508, 90528, 31049, 6003, 71211], 1806: [1731, 6794, 2709, 2042, 72601], 1816: [2417, 988, 2435, 2630, 1585], 1829: [1897, 1564, 4062, 932, 3217], 1831: [2094, 1882, 442, 2989, 95875], 1835: [4155, 48696, 3824, 2340, 4487], 1841: [452, 2943, 2310, 1446, 715], 1844: [152284, 159415, 2544, 1549, 3586], 1856: [77, 108, 86593, 759, 99], 1857: [1585, 90890, 130970, 1516, 5896], 1873: [48696, 7162, 51884, 68347, 3707], 1881: [71160, 62970, 65359, 1654, 47384], 1882: [3697, 2701, 49278, 541, 95875], 1883: [372, 2396, 1784, 4029, 3046], 1889: [64231, 32743, 6220, 6250, 162598], 1894: [54004, 90576, 3120, 4018, 2340], 1897: [1829, 1564, 4062, 932, 3217], 1910: [4695, 988, 2417, 149, 2008], 1911: [1665, 2860, 2694, 3979, 6188], 1914: [4029, 25841, 2390, 4641, 950], 1919: [2709, 4846, 8571, 7089, 3492], 1921: [2672, 4235, 1729, 1253, 24], 1924: [40597, 78174, 2188, 62344, 54796], 1926: [1926, 8714, 8502, 6912, 4589], 1934: [4929, 1642, 4495, 6407, 7033], 1936: [4111, 1938, 5365, 25856, 5651], 1938: [25856, 46974, 7234, 45635, 2757], 1939: [1096, 2202, 1938, 3035, 1936], 1940: [4292, 2757, 7479, 8057, 4189], 1942: [6452, 1423, 8920, 45635, 8451], 1944: [2067, 1299, 3095, 3217, 7215], 1949: [6452, 3095, 971, 2988, 3217], 1952: [3271, 535, 3038, 7069, 2336], 1953: [4855, 129937, 3764, 541, 4640], 1955: [1938, 46974, 30850, 7234, 25856], 1960: [3152, 2988, 2439, 3271, 1695], 1961: [3949, 4022, 3098, 8970, 47099], 1964: [2988, 2439, 1699, 3169, 2682], 1966: [2247, 3046, 2779, 8571, 7089], 1969: [1976, 3918, 3938, 136958, 167538], 1975: [2327, 167538, 5649, 4541, 3938], 1976: [3918, 1969, 2460, 1336, 3016], 1979: [160565, 145418, 106441, 112818, 94018], 1981: [841, 3832, 169670, 5588, 4715], 1992: [2446, 26116, 1333, 67186, 52644], 1993: [1910, 3566, 543, 4161, 2108], 1995: [1336, 3708, 3664, 3661, 7646], 1997: [1258, 1350, 1333, 4720, 2232], 2002: [1396, 3130, 4084, 2985, 1234], 2004: [8967, 3511, 144734, 3689, 89305], 2005: [2161, 2115, 2804, 1032, 6539], 2007: [3691, 1440, 3051, 3715, 4081], 2008: [4695, 4766, 149, 1415, 334], 2013: [168456, 85025, 110826, 91273, 105121], 2016: [1016, 4081, 4012, 3715, 2261], 2021: [3070, 1591, 3704, 6294, 924], 2023: [1089, 4855, 27831, 1092, 4238], 2026: [2446, 3370, 291, 3692, 2107], 2027: [4233, 3618, 2383, 100326, 6314], 2037: [2836, 118, 3692, 2041, 291], 2041: [2037, 7000, 3401, 52730, 6814], 2042: [6794, 6559, 1806, 5307, 1731], 2046: [4006, 2094, 3401, 1127, 986], 2059: [74154, 2080, 1707, 34336, 115667], 2065: [1701, 6100, 6509, 4419, 1498], 2067: [1944, 969, 2202, 1299, 1094], 2068: [645, 2609, 4810, 334, 3514], 2070: [4035, 3365, 199, 2171, 4419], 2071: [44657, 5531, 7938, 7939, 1572], 2078: [3034, 2081, 2096, 1029, 2080], 2080: [2081, 2078, 2087, 2059, 1029], 2081: [2078, 2080, 2087, 3034, 2096], 2087: [2096, 1032, 596, 2081, 594], 2094: [1127, 1831, 1356, 1374, 1129], 2095: [42740, 8275, 8331, 1526, 5231], 2096: [2087, 2078, 1029, 1032, 3034], 2098: [3313, 470, 998, 2736, 3774], 2099: [1024, 2137, 3034, 6232, 1032], 2106: [3196, 4888, 4723, 1642, 6041], 2107: [2026, 841, 6559, 5076, 25905], 2108: [4621, 1307, 3358, 2396, 2080], 2114: [3109, 3478, 2866, 31260, 4484], 2115: [45722, 6539, 2005, 7153, 5349], 2117: [2363, 3994, 1695, 5646, 522], 2125: [50685, 58347, 932, 54276, 4621], 2135: [5076, 346, 6559, 2141, 2162], 2137: [2099, 2141, 1029, 1032, 2096], 2139: [3034, 2137, 1029, 1032, 2142], 2140: [2968, 5463, 2161, 2005, 4896], 2141: [3034, 2137, 1032, 13, 2139], 2142: [2139, 1032, 5076, 2141, 37211], 2145: [2248, 3825, 372, 2942, 4823], 2148: [3693, 3313, 470, 2098, 2792], 2150: [3608, 3070, 2390, 2108, 2265], 2156: [103027, 66203, 6765, 7137, 1784], 2159: [30, 4786, 1248, 3918, 149], 2160: [53953, 1333, 3499, 2550, 2967], 2161: [2005, 1032, 1015, 4896, 2140], 2162: [5076, 6559, 51698, 25905, 2161], 2167: [2985, 1320, 5219, 6615, 55232], 2171: [199, 6837, 25795, 8302, 2697], 2177: [2171, 7826, 5007, 5581, 2210], 2188: [80454, 62344, 40597, 78174, 54796], 2190: [7299, 51174, 981, 50923, 2546], 2202: [31116, 6791, 1507, 8461, 8337], 2203: [149, 2171, 2540, 4695, 2177], 2210: [7772, 3420, 4077, 6163, 6810], 2226: [85334, 65350, 7255, 55052, 605], 2232: [93840, 52281, 7022, 45081, 1590], 2240: [2988, 2439, 3260, 535, 5272], 2247: [1966, 2779, 1135, 1171, 4066], 2248: [2145, 2396, 3481, 50685, 1307], 2249: [47970, 90576, 31049, 55112, 2335], 2261: [7647, 4079, 4040, 4081, 1541], 2264: [6314, 100326, 5636, 4662, 3715], 2265: [6425, 3548, 472, 518, 870], 2269: [7101, 6665, 4374, 7742, 6765], 2273: [4369, 130634, 4270, 104241, 3744], 2286: [25752, 1585, 90890, 130970, 1516], 2288: [541, 37380, 93840, 2985, 1127], 2302: [2694, 3254, 785, 2335, 1135], 2310: [4723, 2943, 4888, 6041, 7299], 2312: [2967, 3098, 790, 2862, 1955], 2313: [6918, 37736, 7234, 3217, 7301], 2320: [6971, 7449, 6285, 5628, 4699], 2322: [2549, 3766, 1373, 2393, 2816], 2323: [1123, 5723, 5272, 4061, 5258], 2324: [92259, 2858, 2396, 527, 1784], 2325: [2027, 1772, 4233, 2837, 6559], 2327: [1975, 1339, 1321, 2004, 1333], 2332: [36931, 26159, 7108, 73876, 8840], 2334: [2344, 4640, 423, 2177, 72591], 2335: [1665, 785, 2694, 2249, 3254], 2336: [1096, 3260, 3152, 4723, 1695], 2338: [56339, 8947, 4124, 70159, 31049], 2340: [4823, 5151, 6192, 4018, 1894], 2342: [3481, 2912, 1394, 1396, 92259], 2344: [2802, 2956, 2334, 4640, 461], 2356: [5780, 1490, 6533, 26171, 4289], 2358: [60046, 52042, 26812, 62799, 61628], 2363: [512, 2117, 5544, 3708, 4006], 2366: [2991, 108795, 5700, 53453, 163056], 2368: [5700, 53453, 8447, 161918, 85025], 2373: [499, 1440, 998, 3442, 2148], 2375: [1665, 2335, 1135, 3254, 4081], 2378: [2381, 2383, 5900, 2264, 1135], 2381: [870, 6425, 2383, 518, 100326], 2383: [5636, 4662, 100326, 6314, 43558], 2389: [32213, 184253, 4450, 2159, 87413], 2390: [3851, 1914, 728, 2770, 125], 2392: [6794, 84601, 162598, 8967, 99910], 2393: [1373, 5944, 1374, 1882, 2322], 2394: [2087, 2096, 2081, 918, 551], 2396: [1784, 1307, 2858, 2248, 1883], 2403: [6664, 2985, 1129, 2989, 1127], 2405: [2989, 2265, 2822, 3608, 25962], 2407: [3033, 4545, 2375, 3070, 2335], 2417: [988, 1816, 2435, 334, 1585], 2425: [30, 4927, 4717, 5075, 3015], 2433: [944, 1938, 408, 61406, 4482], 2435: [4810, 645, 2609, 334, 2630], 2439: [2988, 1699, 2682, 2630, 2435], 2446: [3692, 291, 3370, 2026, 330], 2447: [2961, 1395, 3861, 2736, 3313], 2453: [291, 3370, 2037, 3692, 118], 2460: [1336, 3664, 3661, 2900, 1995], 2472: [155812, 6249, 2472, 4660, 118512], 2474: [1695, 138210, 2769, 80126, 4811], 2476: [2816, 2373, 2802, 3836, 1378], 2495: [128991, 134019, 84187, 145080, 136024], 2498: [165639, 7845, 4492, 8967, 182639], 2511: [2425, 1248, 7089, 8571, 3492], 2514: [7103, 1655, 212, 6625, 3843], 2521: [97470, 2521, 157407, 93242, 127132], 2540: [149, 4695, 4766, 2008, 1415], 2544: [3586, 1549, 4766, 3792, 1415], 2546: [2961, 2447, 2881, 1299, 4078], 2549: [2322, 1882, 3661, 3664, 3442], 2550: [92, 26303, 6744, 7646, 5853], 2557: [49822, 805, 5387, 60735, 3513], 2565: [7080, 918, 8502, 1767, 914], 2568: [4207, 459, 4062, 1798, 3764], 2573: [2882, 2829, 2860, 477, 8714], 2579: [8771, 5021, 4754, 48142, 36276], 2587: [528, 6314, 119068, 100326, 155659], 2590: [6246, 2590, 4836, 5563, 6279], 2596: [5074, 140928, 34164, 4500, 5650], 2605: [4776, 4369, 555, 53322, 1729], 2606: [3692, 2836, 2026, 118, 2446], 2609: [4810, 645, 2609, 334, 2630], 2616: [1953, 6157, 1599, 1473, 544], 2625: [5349, 2986, 1591, 8644, 1374], 2630: [4810, 645, 2609, 334, 2630], 2632: [8195, 2071, 7938, 5531, 44657], 2643: [3401, 504, 1762, 131714, 8743], 2651: [841, 3908, 3709, 42723, 8225], 2655: [841, 3908, 3709, 42723, 8225], 2664: [1333, 4553, 60037, 5853, 53953], 2668: [3692, 2446, 2900, 330, 2672], 2670: [6434, 3073, 1507, 8337, 8461], 2672: [2320, 1921, 6971, 6041, 3269], 2681: [3774, 3500, 1564, 3632, 1268], 2682: [2988, 2439, 1699, 6246, 645], 2690: [25905, 2837, 80584, 4419, 6100], 2694: [3254, 2335, 104, 785, 1665], 2697: [25795, 2697, 6837, 6407, 4495], 2701: [1882, 1391, 1580, 1676, 6541], 2709: [1919, 3511, 1806, 2041, 2098], 2712: [4056, 4235, 4720, 46723, 104879], 2724: [1307, 4018, 59725, 4639, 31685], 2734: [2988, 2439, 1699, 3223, 3152], 2736: [34528, 470, 151311, 3313, 1135], 2737: [1515, 27705, 61073, 5782, 132796], 2742: [66511, 5461, 1060, 3174, 67267], 2746: [2081, 2375, 1321, 2096, 2078], 2751: [66511, 5461, 1060, 3174, 67267], 2757: [4292, 2757, 7479, 8057, 4189], 2769: [124859, 99005, 105755, 110826, 113416], 2770: [2390, 4233, 2694, 49220, 785], 2774: [5470, 162590, 5135, 7121, 5151], 2775: [6246, 2590, 4836, 5563, 6279], 2779: [1135, 2247, 3130, 1171, 1966], 2788: [8910, 3511, 2937, 1394, 2375], 2792: [6702, 6944, 5401, 2148, 470], 2801: [50274, 6031, 1496, 8921, 4296], 2802: [2956, 3505, 2344, 461, 1346], 2803: [47950, 5553, 4487, 7137, 7102], 2804: [2005, 2081, 6936, 2080, 104], 2805: [4149, 4132, 3326, 4018, 5299], 2808: [6996, 8677, 7017, 6994, 990], 2810: [7616, 26303, 47261, 5853, 3838], 2816: [1599, 504, 1762, 6425, 2265], 2819: [461, 3505, 3169, 3073, 4061], 2822: [4795, 62344, 4035, 6527, 2803], 2827: [8800, 5828, 6583, 4541, 1590], 2828: [2829, 950, 2883, 1914, 2770], 2829: [2883, 1585, 2860, 2247, 2828], 2836: [118, 3692, 2037, 2453, 291], 2837: [80584, 94833, 6238, 7375, 7034], 2839: [3790, 1627, 3326, 3513, 5267], 2840: [68347, 48696, 27705, 72489, 46723], 2846: [3051, 5076, 2907, 3608, 2007], 2852: [6768, 981, 50923, 2546, 971], 2858: [2396, 1784, 3481, 1213, 296], 2860: [3511, 870, 158022, 109317, 3596], 2862: [790, 3051, 4043, 3577, 3442], 2863: [42002, 901, 2265, 8695, 7048], 2866: [199, 34528, 6235, 535, 2609], 2872: [3479, 2966, 2115, 2161, 2140], 2880: [113345, 104925, 73676, 146309, 6095], 2881: [157407, 6862, 72489, 8968, 124859], 2882: [2573, 4022, 6787, 46723, 3897], 2883: [1816, 2829, 528, 2417, 98836], 2884: [5470, 7082, 5135, 7121, 5151], 2891: [5773, 4831, 1585, 5651, 4410], 2893: [105954, 116887, 94780, 55247, 6721], 2894: [4500, 4625, 4464, 5646, 4717], 2900: [512, 3664, 3661, 2460, 1336], 2907: [2007, 3691, 1440, 3051, 4081], 2912: [30, 149, 2203, 2540, 4695], 2924: [3972, 104925, 73676, 8578, 141400], 2937: [6254, 25752, 8331, 4860, 42740], 2941: [199, 1398, 2565, 969, 3549], 2942: [7080, 4936, 7318, 2145, 3109], 2943: [2310, 452, 1841, 1678, 446], 2950: [55112, 3109, 48696, 95624, 2405], 2956: [2802, 2540, 2344, 423, 1769], 2961: [3774, 2546, 470, 3313, 2447], 2962: [5470, 1307, 94503, 5135, 7121], 2966: [1695, 7069, 4723, 4888, 2344], 2967: [2312, 3420, 4077, 2177, 1995], 2968: [2140, 3052, 924, 3608, 3070], 2974: [2446, 26116, 1333, 67186, 52644], 2982: [2446, 26116, 1333, 67186, 52644], 2983: [3505, 3445, 580, 2344, 2802], 2985: [2986, 1129, 2403, 2167, 1676], 2986: [2985, 94018, 105585, 1591, 132796], 2988: [2439, 1699, 2682, 2435, 4810], 2989: [2991, 2403, 1127, 1370, 2344], 2991: [2989, 2344, 7802, 423, 8501], 3000: [5618, 5971, 7153, 6350, 6857], 3010: [7299, 6768, 981, 50923, 2546], 3013: [66427, 51498, 2514, 3692, 842], 3015: [4927, 4625, 5075, 2894, 2425], 3016: [7202, 140267, 48150, 55492, 142598], 3018: [6755, 27584, 1241, 7845, 8578], 3033: [3254, 2407, 4545, 2375, 1580], 3034: [2078, 1032, 2081, 2096, 1029], 3035: [1699, 1816, 1939, 2988, 2171], 3038: [535, 4546, 5238, 6918, 37736], 3046: [5723, 1966, 6254, 1594, 4061], 3051: [2862, 790, 3691, 2007, 4012], 3052: [6539, 2115, 2968, 2005, 1265], 3053: [6285, 760, 3062, 4888, 2106], 3054: [83803, 43869, 2495, 71129, 4241], 3062: [3836, 4047, 3985, 7980, 3053], 3070: [2407, 2891, 3704, 3401, 2021], 3073: [1442, 3169, 3093, 1964, 2819], 3083: [5258, 5272, 55069, 535, 4419], 3093: [3073, 4035, 2070, 2775, 6246], 3095: [25841, 3217, 1949, 3152, 25753], 3098: [2312, 3271, 1961, 3252, 1955], 3102: [6163, 4488, 2177, 2203, 7826], 3106: [3252, 3196, 8667, 125916, 127108], 3109: [4012, 3478, 7479, 6454, 8650], 3113: [45081, 65682, 40617, 6695, 95149], 3120: [4516, 4293, 6425, 459, 360], 3130: [2779, 7089, 8571, 3403, 3467], 3148: [1695, 4888, 4723, 971, 4017], 3152: [25841, 6791, 1354, 3095, 2988], 3155: [4836, 2590, 2775, 6246, 52668], 3168: [2734, 2866, 2682, 535, 1960], 3169: [149, 2540, 3073, 4695, 60647], 3174: [6881, 6867, 148424, 4641, 6978], 3182: [3859, 89090, 55156, 7786, 4236], 3190: [3316, 1969, 1976, 3918, 3401], 3196: [2106, 31116, 4723, 4888, 4439], 3203: [2177, 2203, 4786, 2210, 931], 3204: [3445, 7616, 3386, 2956, 2550], 3211: [6810, 25999, 982, 4292, 45635], 3217: [8650, 25753, 8451, 31260, 2757], 3223: [645, 2630, 3514, 334, 4810], 3249: [47950, 127132, 93242, 97470, 101884], 3252: [7069, 3098, 408, 4482, 4487], 3254: [5481, 2694, 1665, 2335, 4233], 3259: [1678, 4487, 4621, 605, 51884], 3260: [2240, 535, 1096, 2336, 2988], 3266: [127298, 59604, 179815, 48997, 5028], 3268: [77667, 103655, 114818, 59429, 26686], 3269: [2672, 1784, 2407, 2145, 372], 3271: [1952, 7009, 5632, 4888, 4723], 3280: [841, 3832, 169670, 5588, 4715], 3281: [6400, 3281, 8938, 6042, 7141], 3287: [4142, 6702, 7080, 6345, 3594], 3289: [6768, 981, 50923, 2546, 971], 3295: [7299, 6768, 981, 50923, 2546], 3301: [4718, 2027, 4018, 5481, 3968], 3308: [4410, 5773, 4831, 5365, 4111], 3310: [6791, 5685, 6376, 43460, 4600], 3313: [470, 2098, 2736, 998, 3774], 3315: [3315, 73042, 104875, 167772, 103602], 3316: [3190, 1976, 2320, 5628, 423], 3326: [4233, 3861, 3790, 2839, 2027], 3334: [1248, 6852, 8044, 930, 3152], 3358: [3436, 118, 2453, 2108, 3496], 3361: [372, 3363, 2396, 1307, 1883], 3363: [3361, 6881, 1173, 36535, 372], 3364: [6603, 7121, 1938, 6412, 25856], 3365: [1283, 2070, 3871, 2203, 3792], 3370: [291, 2446, 2453, 3692, 2037], 3378: [7299, 51174, 981, 50923, 2546], 3379: [7299, 6768, 981, 50923, 2546], 3386: [965, 47950, 3204, 1625, 36276], 3391: [585, 612, 90890, 130970, 1516], 3393: [25870, 5279, 4462, 4495, 7212], 3394: [1934, 118, 2016, 3693, 4929], 3401: [2643, 2041, 2368, 5700, 53453], 3403: [3436, 3130, 1096, 3467, 3445], 3404: [504, 1599, 2816, 3403, 1667], 3420: [4077, 6810, 25927, 36276, 7560], 3436: [3496, 3403, 3358, 3361, 3130], 3439: [2005, 1005, 5069, 2115, 2099], 3442: [4043, 790, 2862, 3051, 3577], 3445: [4786, 3505, 149, 2068, 1176], 3455: [5465, 7587, 5531, 44657, 7938], 3459: [645, 2609, 4810, 3514, 2630], 3467: [6791, 3310, 34528, 6235, 2866], 3478: [4012, 8463, 4113, 7052, 2757], 3479: [1226, 2872, 2094, 2115, 2150], 3481: [1784, 3897, 2248, 8949, 2858], 3492: [8571, 7089, 1966, 6509, 2511], 3496: [3436, 3358, 1554, 2248, 3361], 3499: [1333, 2160, 7022, 53953, 52281], 3500: [3051, 2681, 4012, 3774, 1268], 3504: [3038, 6724, 4029, 5013, 34528], 3505: [2802, 2819, 3445, 2344, 2983], 3511: [4492, 151317, 31000, 109317, 3596], 3513: [3952, 4077, 3420, 6810, 36276], 3514: [4810, 645, 2609, 334, 2630], 3529: [30818, 6306, 8044, 7056, 6852], 3545: [8714, 8502, 4589, 4189, 4292], 3548: [5685, 6376, 8232, 4600, 43460], 3549: [1934, 6912, 4929, 7033, 7212], 3565: [5307, 1642, 54276, 61406, 4929], 3566: [4600, 5685, 6376, 8232, 43460], 3577: [790, 2862, 3051, 4043, 3442], 3586: [2544, 1549, 4766, 3792, 1415], 3590: [1694, 3835, 3504, 3363, 2779], 3592: [2495, 182639, 140541, 104780, 162982], 3593: [31660, 68945, 5944, 69524, 131656], 3594: [4936, 7080, 4142, 6345, 7318], 3596: [155812, 6249, 2472, 4660, 118512], 3599: [6912, 8331, 4204, 7026, 128089], 3604: [3315, 73042, 104875, 167772, 103602], 3608: [2846, 2937, 4081, 2247, 2150], 3609: [6400, 3281, 8938, 6042, 7141], 3618: [2027, 4233, 100326, 6314, 5636], 3619: [25752, 585, 612, 90890, 130970], 3624: [6156, 66785, 2273, 4232, 2701], 3632: [5602, 7102, 6744, 4204, 7026], 3641: [4292, 2757, 7479, 8057, 4189], 3648: [512, 3932, 1924, 149146, 26409], 3658: [3932, 1924, 149146, 3648, 26409], 3661: [3664, 1336, 2460, 2900, 1995], 3664: [3664, 1336, 2460, 2900, 1995], 3669: [25752, 585, 612, 90890, 130970], 3675: [6912, 7212, 5279, 7033, 4796], 3680: [32314, 363, 7616, 1572, 8196], 3686: [92, 32213, 184253, 3932, 2446], 3688: [3689, 3596, 112497, 109317, 4660], 3689: [157270, 4660, 155812, 6249, 31000], 3691: [3691, 1440, 3051, 3715, 4081], 3692: [2836, 118, 2446, 2037, 330], 3693: [1440, 499, 2900, 512, 2007], 3696: [54910, 97988, 61692, 8578, 6734], 3697: [1882, 1320, 3704, 8861, 3698], 3698: [1676, 3697, 3704, 541, 2985], 3704: [1129, 3697, 1127, 2989, 3698], 3707: [48696, 5365, 3577, 1873, 68347], 3708: [1995, 512, 92, 1336, 7646], 3709: [841, 7564, 42723, 8225, 140267], 3715: [4081, 3691, 2007, 4012, 4043], 3736: [87660, 111817, 773, 3845, 26059], 3744: [4640, 423, 3618, 1432, 1627], 3752: [4686, 89305, 3821, 4718, 2694], 3764: [157407, 156706, 157432, 139717, 2383], 3766: [2322, 186587, 8894, 187031, 3196], 3768: [2816, 2476, 4594, 3766, 6808], 3774: [2961, 2681, 3313, 470, 518], 3783: [4043, 1695, 2240, 4047, 3442], 3790: [3790, 1627, 3326, 3513, 5267], 3792: [2544, 1549, 3586, 4766, 1415], 3798: [3897, 56339, 155064, 6250, 3513], 3808: [1507, 115969, 68872, 160422, 58876], 3810: [5111, 6971, 5387, 60735, 3513], 3821: [4233, 1665, 3979, 3511, 3968], 3824: [4062, 4155, 2269, 6665, 7742], 3825: [4018, 2145, 52973, 3481, 2248], 3830: [113252, 54910, 71500, 1321, 1993], 3832: [841, 7564, 3709, 42723, 8225], 3835: [3590, 2210, 92, 2446, 291], 3836: [3062, 7980, 2476, 4795, 6808], 3838: [1329, 33896, 4403, 7650, 8405], 3843: [2514, 136958, 167538, 3938, 1655], 3845: [87660, 111817, 773, 3845, 26059], 3851: [937, 125, 2390, 1914, 342], 3855: [4296, 152284, 8981, 1678, 25833], 3858: [1546, 5427, 7264, 7354, 5628], 3859: [7171, 7141, 6667, 6400, 6327], 3861: [4233, 3254, 3326, 3968, 2335], 3871: [31116, 3365, 6454, 52967, 6768], 3893: [3952, 6254, 6003, 4529, 5135], 3895: [5628, 6588, 6971, 6335, 7449], 3896: [27480, 118082, 58826, 112727, 113862], 3897: [4022, 3481, 1961, 3949, 1358], 3898: [77667, 60126, 5247, 3268, 4717], 3900: [66511, 7089, 1060, 3174, 67267], 3908: [140267, 110591, 48150, 142598, 7202], 3918: [1976, 1969, 2159, 3838, 2460], 3925: [6978, 41712, 73676, 149011, 7354], 3926: [2021, 2368, 166526, 135133, 3401], 3929: [5116, 5581, 25752, 1526, 4204], 3932: [5649, 4138, 5604, 7883, 7646], 3938: [167538, 136958, 40478, 7891, 8894], 3947: [7587, 5465, 4065, 7820, 3455], 3949: [5810, 1961, 4022, 47099, 3897], 3952: [4077, 3420, 6810, 3513, 25927], 3962: [66427, 51498, 2514, 3692, 842], 3963: [1926, 8714, 8502, 6912, 4589], 3964: [54276, 61406, 123545, 7302, 6559], 3965: [25927, 6603, 982, 4113, 52967], 3968: [3979, 3861, 8910, 3821, 3254], 3972: [2924, 2880, 73676, 104925, 7657], 3979: [3821, 3968, 3511, 5942, 4728], 3981: [1779, 1882, 57368, 76, 95875], 3985: [2775, 2590, 6246, 3062, 580], 3994: [924, 2117, 5349, 6934, 48774], 4006: [2046, 2363, 2099, 42422, 31660], 4010: [109317, 4660, 3596, 118512, 31000], 4012: [4081, 3051, 3715, 3691, 2007], 4016: [6297, 3034, 53121, 6936, 5218], 4017: [1695, 4888, 5632, 4723, 6285], 4018: [31685, 4823, 3825, 5299, 2724], 4022: [1961, 3897, 3949, 47099, 72641], 4023: [47725, 5723, 4061, 62155, 6218], 4029: [3310, 1914, 4641, 6881, 6724], 4035: [4795, 5440, 2070, 6178, 8921], 4036: [48142, 6220, 32743, 37736, 6918], 4037: [3895, 3529, 6552, 8044, 5628], 4040: [2261, 4010, 2264, 103819, 155812], 4042: [2775, 6386, 2590, 6246, 34536], 4043: [3442, 2862, 790, 3051, 3577], 4046: [4292, 2757, 7479, 8057, 4189], 4047: [4042, 34536, 31116, 3062, 43396], 4051: [8137, 26409, 8136, 133377, 161918], 4055: [4292, 2757, 7479, 8057, 4189], 4056: [1627, 82378, 4640, 1661, 149], 4061: [5272, 5258, 5723, 2323, 3046], 4062: [1897, 1829, 1564, 3824, 4482], 4065: [7820, 7587, 41617, 5465, 5531], 4066: [2247, 5339, 5723, 6814, 1490], 4077: [3420, 6810, 25927, 36276, 7560], 4078: [7299, 121035, 50923, 2546, 971], 4079: [7647, 2261, 8158, 612, 8024], 4081: [4012, 3715, 2007, 3691, 1440], 4084: [7325, 114818, 3764, 5803, 110297], 4089: [1546, 34312, 612, 90890, 130970], 4091: [113207, 6978, 3481, 118, 4149], 4093: [27822, 74750, 89580, 90943, 1412], 4102: [4516, 4293, 3120, 4482, 4541], 4103: [8730, 126430, 116529, 92243, 115969], 4104: [112497, 155812, 118512, 103819, 3596], 4110: [490, 3203, 152077, 166568, 2210], 4111: [5365, 4410, 5651, 1936, 4831], 4113: [4292, 2757, 7479, 8057, 4189], 4123: [25752, 1546, 612, 90890, 130970], 4124: [31049, 72591, 27705, 1388, 8947], 4130: [8610, 4462, 25870, 8275, 5231], 4131: [7033, 7082, 4796, 7212, 5279], 4132: [4686, 118814, 144262, 139915, 116413], 4138: [4204, 5581, 7026, 5116, 4860], 4142: [6702, 7080, 3287, 3594, 4936], 4148: [71252, 5630, 35957, 33164, 39446], 4149: [4079, 8024, 7264, 7048, 7647], 4154: [132660, 115667, 74688, 77414, 139747], 4155: [3824, 2269, 7742, 4374, 6665], 4160: [4723, 4888, 6031, 6178, 4296], 4161: [4233, 3861, 4846, 5247, 4066], 4168: [98908, 139915, 111680, 118814, 116413], 4174: [7299, 121035, 50923, 2546, 971], 4181: [25752, 1546, 612, 90890, 130970], 4189: [4292, 2757, 7479, 8057, 4189], 4194: [6886, 1944, 2067, 7162, 74688], 4202: [7891, 8894, 187031, 185473, 40478], 4204: [5231, 25752, 4204, 927, 4860], 4207: [459, 4516, 4541, 408, 4482], 4210: [6868, 2664, 100306, 27317, 37736], 4212: [118354, 6424, 139717, 4662, 156706], 4214: [7103, 4215, 1005, 2514, 5650], 4215: [7103, 2514, 188797, 185473, 6625], 4217: [58309, 7171, 6667, 3609, 6042], 4228: [113159, 118082, 104925, 5909, 58870], 4229: [116413, 144262, 111680, 98908, 118814], 4232: [6297, 8526, 6156, 4367, 4016], 4233: [2027, 6249, 155812, 103819, 109317], 4235: [4699, 1695, 6971, 1627, 1921], 4236: [89090, 55156, 7786, 4236, 6935], 4238: [4855, 4957, 1092, 4945, 118354], 4241: [43869, 134019, 2495, 145080, 128991], 4251: [60735, 52042, 60647, 61628, 26812], 4270: [45186, 4367, 60126, 60072, 41569], 4289: [5780, 1572, 2071, 44657, 7939], 4292: [4292, 2757, 7479, 8057, 4189], 4293: [4516, 3120, 4686, 4541, 4482], 4296: [50274, 6031, 1496, 8921, 2801], 4306: [5218, 6539, 4896, 1, 7153], 4321: [5308, 3254, 4677, 3861, 4686], 4323: [26142, 63853, 4327, 1008, 7379], 4325: [7299, 6768, 981, 50923, 2546], 4327: [26750, 6386, 4035, 41863, 4795], 4329: [4957, 4945, 4238, 1266, 6386], 4333: [5602, 49220, 7102, 4678, 4860], 4367: [4270, 45722, 6934, 45186, 2115], 4369: [45186, 2273, 4855, 4776, 67923], 4374: [6665, 6994, 7101, 8869, 4517], 4386: [31223, 6794, 32017, 6013, 5109], 4387: [52950, 6095, 141400, 26399, 135803], 4394: [3599, 901, 42002, 7706, 91873], 4403: [1329, 33896, 4403, 7650, 8405], 4410: [5773, 5365, 4831, 4111, 5651], 4419: [199, 2171, 3586, 2544, 1549], 4429: [1572, 5531, 2071, 7939, 7938], 4439: [6285, 177763, 4202, 145418, 4888], 4441: [4444, 4065, 3947, 8501, 4066], 4442: [100306, 7340, 6868, 4621, 4545], 4443: [3697, 6574, 3981, 76, 122920], 4444: [4441, 104141, 130634, 95004, 64231], 4450: [149, 2540, 4695, 4766, 1415], 4458: [1797, 6289, 7171, 7932, 7786], 4462: [8610, 25870, 25752, 927, 5231], 4463: [2106, 1507, 68872, 160422, 58876], 4464: [2894, 4500, 5075, 25795, 2697], 4473: [2106, 50068, 68872, 160422, 58876], 4477: [6625, 4686, 32314, 5497, 1490], 4482: [408, 459, 4516, 4541, 4293], 4484: [4292, 2757, 7479, 8057, 4189], 4487: [51884, 55112, 48696, 408, 95624], 4488: [2540, 346, 4695, 4713, 2891], 4492: [3511, 4952, 60161, 165639, 4660], 4495: [7033, 5279, 4796, 7082, 7212], 4500: [5075, 4717, 2894, 4625, 4464], 4505: [4296, 152284, 1678, 25833, 25856], 4506: [50, 8771, 5630, 1092, 1661], 4516: [4293, 3120, 408, 4482, 4541], 4517: [4715, 4827, 7017, 7742, 6665], 4529: [1594, 3046, 5258, 5272, 988], 4541: [4516, 4482, 408, 4293, 4207], 4545: [3033, 7340, 2407, 4621, 8633], 4546: [6301, 37736, 6918, 7234, 3038], 4553: [5026, 92420, 72424, 160341, 60471], 4589: [8714, 7835, 8502, 36276, 7062], 4594: [2816, 2476, 3768, 3766, 6808], 4595: [7299, 121035, 50923, 2546, 971], 4599: [7299, 6768, 50923, 2546, 971], 4600: [8232, 5685, 6376, 43460, 6837], 4602: [6424, 4662, 98908, 100326, 116413], 4615: [7299, 6768, 981, 50923, 2546], 4616: [7069, 3871, 31116, 4055, 4189], 4621: [4132, 7340, 3259, 90576, 2108], 4622: [25752, 585, 90890, 130970, 1516], 4624: [6023, 680, 26810, 7299, 1241], 4625: [3015, 4500, 2894, 4927, 5075], 4632: [47952, 1003, 131714, 116887, 109846], 4639: [4823, 5299, 7375, 6944, 5151], 4640: [2540, 149, 1695, 4786, 4695], 4641: [4029, 1914, 6724, 6881, 8366], 4642: [6881, 5992, 34164, 8949, 5508], 4649: [8946, 30883, 31223, 32009, 6013], 4660: [155812, 6249, 2472, 4660, 118512], 4662: [6314, 5636, 100326, 2587, 4602], 4671: [7299, 121035, 50923, 2546, 971], 4672: [7033, 5279, 4796, 7082, 7212], 4677: [5553, 4844, 5308, 8387, 7367], 4678: [49220, 4333, 5470, 25752, 8275], 4686: [4132, 4293, 7000, 157270, 3596], 4695: [1415, 2008, 149, 4766, 645], 4699: [6588, 6971, 7449, 7354, 3947], 4703: [6385, 6246, 2590, 2775, 2682], 4713: [346, 4488, 2630, 835, 2609], 4715: [4827, 7742, 6665, 4517, 6994], 4717: [5075, 4500, 3015, 4927, 2425], 4718: [69784, 5481, 6188, 104, 3979], 4719: [33158, 45208, 7379, 4632, 1003], 4720: [53953, 2712, 81591, 48394, 2160], 4722: [45106, 27685, 6944, 50802, 5139], 4723: [4888, 6041, 7299, 6335, 5632], 4728: [6156, 3979, 3511, 8814, 1966], 4733: [25752, 585, 612, 90890, 130970], 4734: [4104, 8376, 3979, 3254, 8807], 4750: [79224, 26828, 3439, 74580, 104141], 4754: [7116, 2579, 37736, 6918, 4546], 4766: [1415, 1549, 2544, 3586, 4695], 4776: [80489, 4369, 52458, 2985, 5630], 4785: [3871, 3093, 3365, 1283, 1266], 4786: [3459, 149, 2540, 2630, 4810], 4795: [4035, 7162, 146, 4836, 7212], 4796: [7033, 5279, 7082, 7212, 4495], 4810: [4810, 645, 2609, 334, 2630], 4811: [1695, 6285, 6971, 7354, 7449], 4821: [5476, 40723, 27584, 71252, 8526], 4822: [31700, 44399, 31223, 146, 4649], 4823: [4639, 5299, 4018, 5151, 1307], 4827: [4827, 7742, 6665, 4517, 6994], 4828: [5470, 162590, 5135, 7121, 5151], 4831: [5773, 4410, 5651, 2891, 4111], 4836: [6246, 2775, 2590, 5563, 6279], 4844: [5553, 4836, 5563, 6279, 1661], 4845: [3715, 6957, 6314, 63, 173619], 4846: [1919, 6345, 2709, 4154, 3565], 4847: [7299, 6768, 50923, 2546, 971], 4855: [4238, 4369, 1953, 2334, 2985], 4860: [5231, 25752, 4204, 927, 4860], 4866: [126420, 129937, 6095, 26399, 135803], 4888: [4723, 6041, 6285, 7299, 6335], 4896: [54001, 4306, 45722, 81834, 69844], 4900: [25752, 1546, 34312, 612, 90890], 4901: [129937, 5630, 1729, 4776, 73741], 4911: [5497, 32314, 3947, 4699, 3858], 4926: [26422, 4642, 6345, 5508, 33725], 4927: [3015, 4625, 4500, 2894, 4717], 4929: [1642, 1934, 5307, 4104, 1526], 4936: [3594, 2942, 7080, 4142, 6345], 4945: [4957, 4329, 4238, 4855, 4901], 4952: [4660, 8447, 155812, 157270, 6249], 4957: [4945, 4329, 4238, 4855, 1092], 4964: [5524, 5499, 26085, 51314, 3259], 4965: [1515, 61073, 5782, 132796, 315], 4966: [5544, 112868, 1779, 179053, 880], 4994: [6765, 7080, 54276, 6702, 5051], 5007: [7826, 5231, 927, 4204, 2210], 5010: [50068, 57528, 59369, 5995, 34536], 5011: [5051, 6049, 7354, 6192, 6285], 5013: [4029, 3504, 5505, 5991, 923], 5015: [51884, 4160, 5791, 4723, 4888], 5021: [7700, 2579, 7748, 7102, 26422], 5026: [4553, 72424, 160341, 59738, 77364], 5028: [104337, 5028, 113705, 135288, 179815], 5034: [5391, 6031, 4296, 7092, 956], 5039: [5040, 5463, 2363, 405, 4207], 5040: [5463, 163056, 108795, 405, 71129], 5048: [126921, 132584, 26183, 111146, 5480], 5051: [6049, 5391, 5011, 5034, 4994], 5065: [5476, 52644, 5081, 27584, 52950], 5069: [31660, 42422, 68945, 8126, 70687], 5074: [34164, 7419, 48744, 6370, 2596], 5075: [4717, 4500, 4464, 3015, 4625], 5076: [6559, 25905, 32291, 26326, 2162], 5080: [25752, 1546, 612, 90890, 130970], 5081: [6347, 6078, 5065, 3824, 5015], 5092: [8978, 132584, 5480, 8814, 136355], 5102: [5879, 4677, 4822, 26198, 4844], 5108: [51931, 70301, 5267, 27821, 61705], 5109: [4386, 3981, 4367, 4270, 172585], 5111: [49822, 81591, 5387, 60735, 3513], 5112: [51174, 981, 50923, 2546, 971], 5113: [1490, 5780, 6533, 26171, 2356], 5116: [5231, 25752, 4204, 927, 4860], 5135: [6254, 5470, 5723, 5034, 5279], 5139: [58870, 5909, 41712, 51498, 71732], 5146: [27778, 97988, 61692, 105801, 130840], 5151: [7101, 5308, 4374, 4823, 6944], 5165: [841, 177, 169670, 5588, 4715], 5202: [87660, 111817, 773, 3845, 26059], 5212: [179813, 6935, 8848, 5288, 7786], 5218: [4306, 53121, 4016, 4896, 1], 5219: [55232, 8861, 95875, 86835, 71254], 5231: [5231, 25752, 4204, 927, 4860], 5238: [3845, 7052, 2757, 4292, 6454], 5247: [3688, 6814, 4215, 4229, 7000], 5258: [5272, 4061, 283, 2240, 5723], 5264: [169982, 7376, 8860, 32017, 84414], 5267: [37739, 8982, 43396, 31700, 2590], 5269: [7299, 51174, 981, 50923, 2546], 5272: [5272, 4061, 283, 2240, 5723], 5279: [7033, 4796, 7082, 7212, 4495], 5284: [5470, 1307, 5135, 7121, 5151], 5288: [6612, 55156, 7786, 6935, 4236], 5292: [635, 67534, 34536, 61011, 60735], 5296: [6344, 7375, 2837, 4018, 4823], 5299: [4823, 4018, 1307, 4639, 31685], 5307: [4929, 4104, 1642, 3565, 1934], 5308: [7101, 5151, 4104, 3254, 4321], 5312: [5387, 3895, 1798, 6335, 555], 5322: [7299, 6768, 50923, 2546, 971], 5339: [32291, 5258, 5272, 84950, 136778], 5345: [7299, 6768, 50923, 2546, 971], 5349: [45499, 6934, 8644, 2115, 41569], 5365: [4111, 4410, 5651, 4831, 5773], 5387: [1798, 61406, 123545, 54276, 5312], 5391: [6049, 5034, 5051, 5011, 8920], 5401: [2792, 118512, 112497, 109317, 151317], 5417: [201, 137517, 95839, 6270, 164280], 5424: [58803, 6885, 3893, 2803, 7044], 5427: [1546, 5427, 7264, 7354, 5628], 5440: [4035, 7171, 1423, 6336, 6327], 5442: [104241, 162478, 103372, 93510, 104925], 5444: [4016, 33004, 5218, 4306, 6297], 5451: [5890, 4131, 5893, 25795, 8302], 5460: [5651, 5773, 4831, 4410, 2891], 5461: [7323, 1060, 3174, 67267, 2596], 5463: [5040, 55995, 6615, 49649, 40851], 5465: [5465, 7820, 3455, 4065, 41617], 5470: [4495, 7082, 6407, 7212, 5279], 5476: [40723, 71252, 40617, 27584, 52950], 5480: [132584, 136353, 170837, 136359, 136355], 5481: [3254, 8376, 6287, 4718, 6188], 5485: [4061, 5723, 5505, 5272, 5258], 5497: [32314, 5780, 6533, 26124, 1490], 5499: [5524, 26085, 51314, 3259, 2950], 5501: [34336, 4649, 8946, 31223, 30883], 5505: [3310, 43460, 4600, 8232, 6376], 5508: [66511, 140816, 91784, 26158, 87660], 5524: [77414, 50802, 82152, 74688, 139747], 5530: [2769, 7354, 1546, 3858, 6285], 5531: [44657, 5531, 7938, 7939, 1572], 5544: [4625, 3015, 4927, 2363, 2117], 5550: [37211, 3963, 3315, 3604, 918], 5553: [4844, 2803, 4677, 1661, 4602], 5556: [593, 112727, 2159, 2389, 40723], 5563: [6279, 2590, 6246, 2775, 4836], 5573: [5942, 6862, 100326, 6314, 5636], 5581: [5231, 25752, 4204, 927, 4860], 5588: [841, 7564, 3709, 42723, 8225], 5602: [4860, 5231, 4204, 927, 5863], 5604: [25752, 5231, 4860, 5581, 4204], 5618: [3000, 5971, 6350, 4306, 4896], 5628: [6971, 3895, 7449, 7354, 1546], 5630: [4148, 1089, 4776, 52604, 53322], 5632: [4723, 4888, 6041, 7299, 2310], 5635: [7299, 6768, 981, 50923, 2546], 5636: [4662, 6314, 100326, 2587, 4602], 5646: [2894, 7354, 6285, 6192, 4699], 5649: [4138, 3932, 7883, 7646, 8482], 5650: [7103, 4214, 37384, 2514, 4215], 5651: [5773, 4831, 4111, 4410, 5460], 5664: [139747, 2340, 6192, 7486, 900], 5669: [8622, 27912, 93721, 44788, 162], 5685: [8232, 4600, 6376, 43460, 6837], 5688: [6768, 981, 50923, 2546, 971], 5700: [5700, 161918, 2368, 168456, 91273], 5706: [7323, 1060, 3174, 67267, 2596], 5723: [4061, 3046, 6254, 2323, 5258], 5736: [7171, 65188, 1331, 1329, 1328], 5749: [4036, 83601, 7742, 7492, 8405], 5773: [4831, 4410, 5651, 2891, 3308], 5780: [1490, 6533, 26171, 2356, 4289], 5782: [27705, 60735, 4251, 2840, 72591], 5791: [5992, 5015, 4160, 4723, 4888], 5803: [114818, 110297, 103655, 3268, 77667], 5810: [3949, 7299, 6041, 72641, 8970], 5817: [2106, 1507, 68872, 160422, 58876], 5828: [8844, 8236, 6989, 6692, 6583], 5853: [26303, 3838, 1329, 26124, 4403], 5863: [5231, 25752, 4204, 927, 4860], 5874: [25752, 1546, 34312, 612, 90890], 5875: [4292, 2757, 7479, 8057, 4189], 5879: [6279, 4836, 1661, 6246, 5563], 5890: [5451, 5893, 6044, 627, 4131], 5891: [66090, 26303, 6885, 5853, 4403], 5893: [5890, 6044, 5451, 627, 1095], 5896: [25752, 1546, 34312, 612, 90890], 5900: [2378, 4662, 6314, 100326, 5636], 5909: [6063, 149011, 52644, 6872, 51498], 5919: [161044, 158388, 176371, 27074, 26124], 5942: [5573, 4649, 8946, 49220, 31223], 5944: [3593, 45499, 2393, 64231, 122920], 5954: [2769, 6852, 8645, 2332, 8044], 5955: [7009, 2866, 34528, 6235, 51884], 5969: [103027, 3774, 7137, 1784, 5485], 5971: [6350, 3000, 5618, 48394, 26776], 5984: [8195, 41617, 7939, 2071, 1572], 5986: [8848, 179813, 162414, 45382, 6064], 5991: [5013, 1271, 6218, 6345, 914], 5992: [5791, 4160, 6881, 4888, 4723], 5995: [50068, 527, 3949, 47099, 1619], 6003: [6881, 6724, 8366, 6335, 55280], 6013: [8946, 4649, 7376, 30883, 31223], 6023: [4624, 680, 26810, 7044, 7299], 6031: [50274, 1496, 8921, 4296, 2801], 6033: [1546, 34312, 612, 90890, 130970], 6041: [4723, 4888, 7299, 5632, 2310], 6042: [6400, 3281, 8938, 6042, 7141], 6044: [5893, 5890, 5451, 627, 5891], 6049: [5391, 5051, 5011, 5034, 848], 6057: [70301, 50923, 49793, 43932, 27837], 6063: [5909, 52644, 6872, 149011, 105801], 6064: [162414, 179813, 5986, 8848, 45382], 6078: [6347, 5081, 5040, 5312, 5219], 6095: [6095, 26399, 141400, 135815, 26401], 6100: [25905, 6533, 5780, 1490, 26171], 6119: [148238, 6119, 59026, 142558, 73681], 6141: [25752, 1546, 612, 90890, 130970], 6145: [6787, 40617, 2974, 74370, 66090], 6153: [435, 4545, 3326, 2498, 4079], 6156: [4728, 3624, 149406, 63859, 51575], 6157: [8666, 8860, 6595, 72489, 7163], 6158: [63239, 104245, 53121, 5218, 163072], 6163: [7826, 2210, 7772, 4796, 8921], 6178: [50274, 6031, 1496, 8921, 4296], 6182: [25752, 1546, 612, 90890, 130970], 6184: [3577, 2862, 2609, 835, 645], 6188: [37384, 5481, 69784, 4718, 104], 6192: [6588, 7264, 7354, 4699, 5646], 6203: [585, 612, 90890, 130970, 1516], 6204: [25752, 585, 612, 90890, 130970], 6218: [5299, 7137, 2396, 5991, 3481], 6220: [32743, 40617, 6695, 162598, 8967], 6232: [8684, 1099, 8341, 982, 25753], 6234: [61011, 69118, 135288, 108981, 169958], 6235: [34528, 162414, 179813, 5986, 8848], 6238: [80584, 54796, 78174, 8302, 2697], 6246: [6246, 2590, 4836, 5563, 6279], 6249: [155812, 6249, 2472, 4660, 118512], 6250: [86835, 86295, 6615, 5476, 60037], 6254: [5723, 4495, 4672, 7212, 6407], 6269: [6400, 3281, 8938, 6042, 7141], 6270: [2071, 7938, 5531, 44657, 7939], 6273: [929, 4296, 2801, 6178, 1496], 6279: [5563, 2590, 6246, 2775, 4836], 6280: [72489, 2540, 3947, 7040, 64231], 6285: [6971, 4888, 7354, 7449, 4723], 6287: [5481, 5307, 3254, 5308, 4718], 6288: [6603, 8341, 8645, 6370, 6454], 6289: [7171, 8938, 3281, 3609, 6042], 6294: [6583, 5264, 8861, 7376, 169982], 6297: [4016, 4232, 50685, 5218, 32017], 6301: [4546, 3455, 7587, 5465, 7939], 6306: [27912, 30818, 27846, 3529, 8044], 6310: [6992, 1060, 3174, 67267, 2596], 6314: [4662, 5636, 100326, 2587, 4602], 6316: [107, 1073, 44399, 65577, 258], 6322: [2605, 156706, 1785, 53322, 3895], 6327: [6400, 3281, 8938, 6042, 7141], 6332: [56176, 6687, 7255, 73319, 52279], 6335: [4888, 4723, 3895, 6971, 5628], 6336: [4292, 2757, 7479, 8057, 4189], 6344: [44943, 7208, 5296, 27815, 62644], 6345: [6702, 4846, 3594, 4936, 4142], 6347: [5081, 6078, 5015, 5065, 5108], 6350: [5971, 26776, 5618, 71129, 3000], 6368: [7932, 58425, 90630, 118784, 117531], 6370: [34164, 5074, 48744, 6288, 6881], 6376: [8232, 5685, 4600, 43460, 6837], 6385: [4703, 1938, 8970, 4723, 4888], 6386: [4042, 4836, 146, 6246, 6279], 6400: [6400, 3281, 8938, 6042, 7141], 6407: [7033, 5279, 4796, 7082, 7212], 6408: [43708, 103602, 136471, 4102, 98083], 6410: [151317, 4660, 112497, 109317, 3596], 6412: [8695, 7121, 25856, 3364, 1938], 6424: [4602, 4212, 116413, 5636, 144262], 6425: [2265, 518, 870, 472, 2381], 6434: [1507, 8461, 8337, 1398, 7560], 6449: [7299, 6768, 50923, 2546, 971], 6452: [1949, 1942, 973, 2202, 971], 6453: [7171, 6692, 363, 3680, 7932], 6454: [4292, 2757, 7479, 8057, 4189], 6476: [148709, 118354, 113186, 93242, 69118], 6493: [103027, 3774, 7137, 1784, 5485], 6509: [7089, 25905, 8571, 3492, 5076], 6510: [152284, 8981, 1678, 25833, 25856], 6516: [7299, 51174, 981, 50923, 2546], 6517: [7299, 6768, 981, 50923, 2546], 6527: [25962, 970, 7092, 956, 7082], 6533: [1490, 6533, 26171, 2356, 4289], 6535: [74450, 50685, 7380, 7375, 8695], 6539: [45722, 7153, 4306, 2115, 3052], 6541: [8666, 45722, 111360, 78105, 5264], 6542: [78142, 3035, 74342, 665, 26158], 6552: [6335, 6852, 3947, 6724, 4699], 6554: [3599, 4394, 901, 42002, 7706], 6559: [5076, 25905, 32291, 1707, 6100], 6560: [77667, 31878, 5247, 3268, 4717], 6574: [3697, 3981, 4443, 76, 122920], 6583: [8800, 8236, 5828, 8844, 6692], 6588: [6192, 4699, 6971, 7264, 3895], 6591: [4189, 45635, 8338, 8920, 8057], 6595: [52458, 8861, 95875, 55232, 92420], 6597: [2808, 3698, 1373, 8677, 64997], 6603: [3965, 8341, 25927, 5875, 2757], 6612: [89090, 55156, 7786, 4236, 6935], 6615: [71252, 86835, 8861, 52950, 5476], 6625: [212, 888, 7103, 2514, 4477], 6638: [5470, 1307, 94503, 5135, 7121], 6664: [7310, 169982, 95473, 108795, 163056], 6665: [4715, 4827, 4374, 7742, 4517], 6666: [7089, 8571, 6270, 4289, 153408], 6667: [6400, 3281, 8938, 6042, 7141], 6668: [4296, 2801, 1678, 25833, 25856], 6679: [1546, 7354, 3858, 6285, 5427], 6687: [46865, 52279, 109846, 47952, 4632], 6692: [1123, 8844, 8236, 8800, 6583], 6695: [40617, 32743, 6220, 5476, 8967], 6699: [7299, 6768, 50923, 2546, 971], 6702: [4142, 6345, 934, 6944, 2792], 6709: [105585, 7439, 91485, 27801, 4821], 6720: [104241, 162478, 103372, 93510, 104925], 6721: [95473, 169982, 163056, 162598, 84414], 6724: [6852, 8044, 7102, 25841, 37736], 6732: [115667, 132660, 139747, 77414, 74154], 6734: [3696, 54910, 118082, 61692, 130840], 6744: [4138, 5116, 5581, 5649, 8331], 6755: [27584, 5909, 8967, 51498, 6063], 6765: [4994, 4374, 2269, 4155, 8643], 6768: [4292, 2757, 7479, 8057, 4189], 6770: [8730, 6178, 2801, 4296, 956], 6775: [89090, 55156, 7786, 4236, 6935], 6782: [3599, 4394, 901, 42002, 7706], 6787: [40583, 6810, 4546, 6989, 3513], 6791: [3310, 2757, 4484, 6336, 7052], 6793: [6794, 1707, 6994, 7742, 4374], 6794: [8967, 165639, 44020, 104141, 72601], 6796: [60753, 5954, 6852, 8044, 6552], 6804: [3715, 1234, 6314, 63, 173619], 6808: [106441, 160565, 146, 34536, 4042], 6810: [4077, 3420, 36276, 25927, 7560], 6814: [106542, 7000, 43558, 155812, 112497], 6816: [25752, 4040, 34312, 612, 90890], 6827: [25752, 4040, 34312, 612, 90890], 6837: [25795, 2697, 6837, 6407, 4495], 6849: [69951, 8535, 2453, 6270, 30818], 6852: [6724, 8044, 25841, 6918, 37736], 6853: [25752, 1546, 34312, 612, 90890], 6857: [5069, 5146, 3000, 68945, 31660], 6860: [101525, 247, 2332, 290, 1213], 6862: [5573, 124859, 70301, 105755, 157407], 6863: [5481, 42002, 8376, 3254, 1220], 6867: [148424, 78836, 5238, 30850, 43460], 6868: [27317, 5465, 7587, 3455, 7616], 6872: [63826, 34323, 80162, 6095, 26399], 6881: [4723, 4888, 6376, 4600, 43460], 6885: [5465, 7587, 41617, 8195, 3455], 6886: [1944, 4194, 2067, 7162, 74688], 6888: [58156, 4718, 94478, 6958, 8947], 6902: [6971, 78218, 95690, 5628, 7449], 6912: [4796, 7212, 4495, 5279, 4672], 6918: [37736, 7234, 7301, 7052, 8463], 6934: [8644, 45499, 5349, 53996, 56174], 6935: [89090, 55156, 7786, 4236, 6935], 6936: [4016, 6188, 1073, 2804, 2087], 6944: [27685, 6702, 2249, 2792, 5151], 6948: [6400, 3281, 8938, 6042, 7141], 6957: [7367, 3979, 116799, 1732, 4677], 6958: [7380, 170837, 8978, 5480, 121781], 6963: [6400, 3281, 8938, 6042, 7141], 6971: [7449, 6285, 5628, 4699, 6588], 6978: [3925, 41712, 73676, 149011, 8840], 6989: [5828, 4202, 8894, 8844, 187031], 6992: [7323, 1060, 3174, 67267, 2596], 6994: [7017, 4374, 6665, 7742, 4517], 6996: [7017, 6994, 2808, 8268, 4374], 6997: [60647, 26812, 62799, 61628, 635], 6998: [7299, 6768, 981, 50923, 2546], 7000: [6814, 106542, 168456, 43558, 126420], 7005: [25752, 4040, 34312, 612, 90890], 7007: [129937, 20, 114818, 80126, 34450], 7009: [27408, 4055, 4292, 31260, 2757], 7017: [6994, 8268, 4517, 990, 4374], 7020: [103027, 3774, 7137, 1784, 5485], 7022: [5219, 27801, 93840, 52281, 74750], 7024: [7301, 2071, 7938, 7939, 113705], 7026: [5231, 25752, 4204, 927, 4860], 7027: [6386, 4042, 7766, 34536, 1465], 7030: [7299, 6768, 981, 50923, 2546], 7033: [5279, 4796, 7082, 7212, 4495], 7034: [80584, 6238, 147002, 48638, 26317], 7040: [72489, 2540, 3947, 64231, 67508], 7041: [3715, 6957, 6314, 63, 173619], 7044: [48142, 8501, 32743, 6220, 162598], 7048: [7647, 6335, 5628, 4149, 6881], 7052: [4292, 2757, 7479, 8057, 4189], 7056: [30818, 8044, 6852, 25841, 3529], 7062: [4292, 2757, 7479, 8057, 4189], 7069: [45635, 1940, 52967, 4189, 7052], 7080: [25856, 2565, 4994, 1938, 8502], 7082: [7033, 5279, 4796, 7212, 4495], 7089: [8571, 3492, 3310, 6666, 1966], 7092: [50274, 6031, 1496, 8921, 4296], 7101: [4374, 4168, 144262, 116413, 98908], 7102: [37736, 6918, 47950, 6724, 3632], 7103: [2514, 6625, 212, 4215, 473], 7104: [158022, 3596, 155812, 2472, 4660], 7108: [36931, 7108, 26159, 73741, 34450], 7116: [4754, 7646, 2579, 6744, 26303], 7121: [8695, 6412, 25856, 7212, 4495], 7132: [7706, 4132, 118814, 4168, 139915], 7137: [3310, 51884, 47970, 134021, 6370], 7141: [6400, 3281, 8938, 6042, 7141], 7153: [6539, 45722, 41569, 2115, 54001], 7154: [95449, 97024, 74450, 109853, 123545], 7162: [4795, 1873, 7215, 4035, 4836], 7163: [5264, 8371, 37380, 105585, 71254], 7171: [6400, 3281, 8938, 6042, 7141], 7176: [7299, 121035, 50923, 2546, 971], 7179: [4296, 26317, 8981, 1678, 25833], 7191: [25752, 1546, 34312, 612, 90890], 7202: [142598, 140267, 48150, 55492, 110591], 7206: [8748, 6533, 68444, 1490, 5780], 7208: [7883, 8482, 7062, 1940, 45635], 7212: [7033, 5279, 4796, 7082, 4495], 7215: [25841, 8044, 25856, 6852, 7162], 7234: [37736, 6918, 1938, 7301, 25856], 7236: [1320, 158388, 8447, 176371, 161044], 7238: [8484, 32906, 26158, 3736, 773], 7254: [8371, 71530, 8644, 45499, 3994], 7255: [85334, 6332, 65350, 2226, 73319], 7264: [7354, 1546, 5427, 6192, 3858], 7282: [113252, 54910, 71500, 1321, 1993], 7299: [4723, 4888, 6041, 5632, 6335], 7301: [7024, 37736, 6918, 7234, 2071], 7302: [123545, 61406, 54276, 49389, 8695], 7307: [88327, 135815, 26401, 77364, 113345], 7310: [6664, 95004, 7376, 95149, 95473], 7318: [4055, 4046, 6768, 4113, 4189], 7323: [6881, 7460, 4641, 48744, 34164], 7324: [4719, 7379, 45208, 37739, 8982], 7325: [4084, 114818, 6595, 8968, 58156], 7340: [4860, 8275, 8331, 7026, 5863], 7347: [82378, 45361, 6297, 31804, 48142], 7348: [2210, 113862, 156726, 160341, 89582], 7354: [7264, 5427, 6285, 6192, 3858], 7360: [27317, 52458, 42723, 27705, 4776], 7367: [116799, 103810, 76173, 6957, 148424], 7375: [74450, 8869, 6702, 6535, 109853], 7376: [6013, 95004, 5264, 40851, 95473], 7377: [101525, 247, 2332, 290, 1213], 7379: [4719, 58876, 7324, 37739, 31700], 7380: [58347, 72737, 74154, 6535, 6958], 7411: [66427, 51498, 2514, 3692, 842], 7419: [5074, 118082, 54910, 6734, 151311], 7439: [105585, 27801, 67923, 99910, 89840], 7443: [7171, 8264, 6453, 3680, 7932], 7449: [6971, 6285, 5628, 6588, 3895], 7459: [188675, 106648, 92637, 90528, 65037], 7460: [148424, 143859, 78836, 5909, 73681], 7479: [4292, 2757, 7479, 8057, 4189], 7486: [152284, 8981, 1678, 25833, 25856], 7492: [4036, 83601, 7742, 8405, 100306], 7560: [8337, 8461, 4077, 1507, 3420], 7561: [45081, 85788, 2327, 65682, 52950], 7564: [6288, 4529, 6370, 3182, 4827], 7587: [5465, 7820, 3455, 4065, 41617], 7616: [47261, 26303, 3455, 8195, 7587], 7646: [36276, 8771, 5649, 2210, 929], 7647: [2261, 42740, 5231, 25752, 4204], 7650: [1329, 3838, 33896, 4403, 26303], 7657: [8578, 27778, 51498, 80162, 113159], 7700: [5021, 37736, 6918, 4546, 7766], 7706: [91873, 34018, 37211, 158022, 2472], 7742: [4827, 4715, 6665, 4517, 7017], 7748: [134515, 172013, 46862, 44719, 27513], 7756: [27869, 7980, 77201, 8730, 26681], 7762: [4077, 3420, 6810, 7560, 25927], 7766: [37736, 7069, 6918, 4546, 7700], 7772: [25927, 929, 2210, 4077, 6163], 7786: [89090, 55156, 7786, 4236, 6935], 7802: [72601, 95473, 169982, 163056, 108795], 7811: [3994, 6184, 24, 2117, 112804], 7820: [5465, 7587, 41617, 4065, 7938], 7826: [7082, 4672, 4796, 5279, 6163], 7835: [970, 8302, 25795, 6837, 6912], 7845: [8967, 165639, 40617, 182639, 6794], 7883: [8482, 8338, 4189, 8451, 31260], 7891: [40478, 4202, 8894, 136958, 167538], 7926: [3334, 130482, 6552, 6862, 6989], 7932: [6368, 7171, 6400, 118784, 117531], 7938: [44657, 5531, 7938, 7939, 1572], 7939: [44657, 5531, 7938, 7939, 1572], 7976: [7299, 121035, 50923, 2546, 971], 7979: [118784, 90630, 91860, 86279, 179135], 7980: [8730, 31116, 3871, 3062, 6770], 7993: [8196, 3838, 33896, 1490, 6533], 8024: [4079, 8158, 4149, 87413, 7069], 8033: [4602, 79333, 4844, 4228, 6023], 8044: [25841, 6852, 6603, 6724, 7215], 8057: [4292, 2757, 7479, 8057, 4189], 8126: [31660, 42422, 5069, 70687, 53574], 8136: [8137, 26409, 4051, 133377, 8447], 8137: [26409, 4051, 8136, 133377, 161918], 8142: [34323, 7108, 26159, 104925, 73876], 8158: [7069, 4079, 8024, 4616, 7048], 8189: [122246, 148881, 117877, 166526, 113705], 8195: [5984, 2632, 41617, 7938, 7939], 8196: [7993, 3838, 33896, 1490, 6533], 8197: [6886, 1944, 4194, 2067, 7162], 8225: [841, 7564, 3709, 42723, 140267], 8232: [5685, 4600, 6376, 43460, 6837], 8236: [8844, 5828, 8800, 6692, 6583], 8264: [146682, 120807, 163653, 159849, 93721], 8268: [7017, 6994, 4517, 990, 6996], 8275: [5231, 25752, 4204, 927, 4860], 8302: [25795, 2697, 6837, 6407, 4495], 8331: [5231, 25752, 4204, 927, 4860], 8337: [1507, 8461, 7560, 8057, 7052], 8338: [4292, 2757, 7479, 8057, 4189], 8341: [8684, 970, 6232, 6603, 7062], 8366: [36535, 8910, 55280, 6881, 34164], 8371: [95875, 71530, 71254, 8644, 45186], 8376: [5481, 48385, 8910, 8807, 104], 8387: [6314, 4662, 5636, 100326, 4602], 8405: [2071, 5531, 1572, 1329, 7939], 8447: [142424, 4051, 26409, 2368, 8137], 8451: [4292, 2757, 7479, 8057, 4189], 8461: [1507, 8337, 7560, 8057, 7052], 8462: [4292, 2757, 7479, 8057, 4189], 8463: [4292, 2757, 7479, 8057, 4189], 8477: [166526, 81681, 64993, 108689, 99917], 8482: [7883, 1099, 1423, 7479, 2757], 8484: [7238, 32906, 26158, 3736, 773], 8500: [128542, 1762, 37380, 160565, 161918], 8501: [72601, 33164, 48142, 95004, 40617], 8502: [956, 6031, 8921, 8714, 50274], 8506: [257, 7616, 7347, 6476, 78349], 8511: [25752, 1546, 34312, 612, 90890], 8526: [4821, 27584, 6794, 3511, 40723], 8530: [34271, 2801, 6031, 6178, 956], 8531: [6013, 6057, 125916, 4649, 8946], 8533: [66203, 95449, 71823, 7154, 72641], 8535: [52579, 2573, 65810, 346, 6347], 8571: [7089, 3492, 3310, 6666, 1966], 8577: [7171, 6327, 363, 6453, 3680], 8578: [3696, 7657, 51498, 60471, 97988], 8601: [66511, 7089, 1060, 3174, 67267], 8604: [54617, 59026, 148238, 142558, 6119], 8610: [4462, 25870, 25752, 927, 5231], 8622: [5669, 44788, 3859, 7932, 6368], 8626: [512, 3932, 1924, 149146, 3648], 8633: [26750, 32291, 64997, 4545, 7000], 8640: [91485, 45186, 94780, 67923, 79224], 8643: [4374, 8869, 74154, 6765, 7101], 8644: [45186, 6934, 45499, 8371, 56174], 8645: [6852, 8044, 6288, 25841, 5954], 8650: [4292, 2757, 7479, 8057, 4189], 8666: [40851, 6157, 57326, 6057, 71160], 8667: [4296, 152284, 1678, 25833, 25856], 8677: [72591, 875, 27705, 64997, 55112], 8684: [6232, 8341, 959, 8057, 7052], 8695: [6412, 7121, 54276, 42002, 25856], 8714: [8502, 8451, 52967, 8338, 4484], 8730: [6770, 7980, 8844, 6583, 5828], 8743: [62970, 8782, 65359, 71160, 47384], 8748: [68444, 66511, 140816, 76173, 127204], 8755: [7171, 4217, 363, 6453, 3680], 8771: [7646, 36276, 929, 2210, 7835], 8782: [62970, 71160, 27036, 65359, 47384], 8795: [7307, 4103, 126430, 8640, 71810], 8800: [6583, 5828, 8236, 6692, 8844], 8804: [7299, 6768, 981, 50923, 2546], 8807: [59022, 84772, 138036, 8376, 106918], 8814: [8978, 51575, 26645, 172321, 169912], 8840: [8840, 63179, 41712, 26401, 89582], 8844: [5828, 8236, 8730, 6770, 6583], 8848: [8848, 179813, 162414, 45382, 6064], 8860: [5264, 6615, 35957, 71252, 40723], 8861: [6615, 55232, 86835, 95875, 37380], 8869: [4374, 74450, 7375, 109853, 8643], 8894: [187031, 40478, 7891, 167538, 136958], 8910: [48385, 8366, 8376, 2788, 143859], 8920: [4292, 2757, 7479, 8057, 4189], 8921: [50274, 6031, 1496, 4296, 2801], 8933: [66511, 5461, 3174, 67267, 2596], 8937: [6057, 62792, 49793, 50923, 8982], 8938: [6400, 3281, 8938, 6042, 7141], 8946: [8946, 30883, 31223, 32009, 6013], 8947: [8861, 35957, 6595, 43679, 39446], 8948: [54276, 123545, 61406, 25856, 7121], 8949: [1784, 4641, 3481, 7137, 6370], 8952: [7299, 6768, 50923, 2546, 971], 8957: [39446, 43679, 33164, 42723, 6615], 8967: [7845, 40617, 6794, 165639, 32743], 8968: [31049, 72591, 72489, 27705, 875], 8970: [6385, 72641, 37739, 8982, 27815], 8978: [8814, 5092, 51575, 132584, 31223], 8981: [48696, 26308, 7154, 8533, 55112], 8982: [37739, 5267, 62792, 31700, 34536], 8998: [7171, 6327, 363, 6453, 3680], 9005: [94799, 113350, 1232, 60760, 6184], 25752: [5231, 25752, 4204, 927, 4860], 25753: [4292, 2757, 7479, 8057, 4189], 25771: [108689, 7302, 49389, 5028, 71438], 25795: [25795, 2697, 6837, 6407, 4495], 25833: [4296, 8921, 1678, 25856, 2858], 25841: [8044, 6852, 7215, 8920, 959], 25855: [707, 70301, 54274, 4450, 5465], 25856: [1938, 7121, 123545, 54276, 46974], 25870: [4462, 4495, 8610, 6407, 7033], 25887: [79684, 94661, 130452, 102378, 143031], 25905: [6559, 5076, 6100, 32291, 6509], 25927: [929, 3965, 4077, 7772, 3420], 25962: [6527, 970, 6178, 6163, 50274], 25999: [4292, 2757, 7479, 8057, 4189], 26059: [87660, 111817, 773, 3845, 26059], 26085: [5524, 5499, 51314, 3259, 2950], 26116: [7646, 5649, 2210, 92, 1995], 26124: [5853, 5497, 2632, 33896, 44657], 26131: [6301, 6235, 8848, 179813, 5986], 26142: [4323, 63853, 4327, 1008, 7379], 26150: [2106, 50068, 68872, 160422, 58876], 26158: [32906, 8484, 66511, 140816, 7238], 26159: [36931, 7108, 26159, 73741, 34450], 26171: [5780, 1490, 6533, 2356, 8196], 26183: [111146, 126921, 130518, 136355, 136353], 26198: [141994, 188797, 185473, 52435, 5102], 26303: [5853, 33896, 3838, 1329, 4403], 26308: [55444, 52579, 73681, 37495, 136018], 26317: [48638, 147002, 87660, 26059, 65037], 26326: [27513, 172013, 44719, 46862, 5076], 26347: [103027, 3481, 6765, 7137, 1784], 26350: [7299, 50923, 2546, 971, 961], 26391: [63179, 8840, 26498, 26401, 89582], 26394: [8921, 1678, 25833, 25856, 2858], 26399: [6095, 26399, 141400, 135815, 26401], 26401: [135815, 36931, 73876, 88327, 73676], 26409: [8137, 4051, 8136, 133377, 161918], 26422: [43460, 8232, 5685, 4600, 6376], 26498: [8840, 63179, 41712, 26401, 89582], 26504: [464, 7802, 4238, 6709, 2625], 26510: [113345, 61818, 60471, 27778, 97988], 26528: [1654, 74282, 35347, 65359, 47384], 26562: [7299, 6768, 50923, 2546, 971], 26564: [52579, 8535, 65810, 346, 6347], 26567: [25752, 1546, 612, 90890, 130970], 26587: [41617, 63082, 1415, 81, 4766], 26645: [131826, 26645, 49735, 172321, 167854], 26681: [88327, 7307, 26401, 135815, 36931], 26686: [59429, 103655, 77667, 3268, 106540], 26696: [26399, 6095, 204, 7376, 7310], 26701: [130482, 27904, 2985, 85414, 74510], 26732: [98083, 81831, 101531, 104303, 58156], 26736: [105585, 592, 2956, 99910, 94405], 26743: [64993, 71438, 104337, 5028, 113705], 26750: [33558, 26812, 62799, 61628, 61986], 26776: [6350, 26999, 5971, 5069, 5618], 26792: [4232, 2041, 63859, 152081, 2005], 26797: [7171, 6327, 363, 6453, 3680], 26810: [6023, 7299, 680, 4624, 37731], 26812: [62799, 26812, 60735, 61011, 60046], 26828: [74580, 26792, 4232, 67295, 5460], 26854: [34323, 330, 52831, 157432, 8142], 26887: [43932, 5065, 31804, 70159, 184253], 26913: [193587, 99813, 95004, 136297, 136024], 26940: [25752, 585, 612, 90890, 130970], 26999: [91266, 95473, 126142, 104141, 84414], 27036: [71160, 65359, 47384, 8782, 62970], 27074: [161044, 5919, 158388, 176371, 26124], 27075: [83601, 59604, 67295, 3266, 71264], 27105: [42556, 83374, 175197, 25771, 135143], 27124: [49822, 5111, 5387, 60735, 3513], 27155: [6350, 3054, 177285, 71129, 130520], 27178: [5470, 1307, 94503, 5135, 7121], 27255: [7299, 6768, 981, 50923, 2546], 27266: [7460, 6270, 5984, 26308, 8195], 27317: [6868, 52644, 5909, 6063, 80846], 27370: [25752, 585, 90890, 130970, 1516], 27408: [3420, 4077, 6810, 36276, 25927], 27480: [27480, 73741, 52831, 8142, 160341], 27513: [44719, 172013, 46862, 164280, 134515], 27584: [40723, 52950, 5476, 71252, 86295], 27618: [48774, 117529, 187031, 7700, 5349], 27619: [126921, 26183, 111146, 136359, 136355], 27685: [4722, 45106, 6249, 118512, 157270], 27692: [77201, 3836, 4442, 5010, 105121], 27705: [72591, 875, 95624, 31049, 8677], 27773: [70286, 965, 8957, 7616, 1089], 27778: [105801, 48150, 7202, 140267, 55492], 27784: [114707, 1997, 145080, 80846, 8947], 27790: [34271, 1099, 8530, 34450, 2332], 27801: [7439, 86835, 89840, 117895, 6615], 27815: [5238, 25841, 7208, 8970, 6454], 27821: [37739, 31700, 8982, 2775, 2590], 27822: [4093, 89580, 1412, 74750, 32743], 27829: [6692, 363, 6453, 3680, 7932], 27831: [44665, 52604, 1729, 96432, 60753], 27837: [57326, 50445, 6057, 6013, 43932], 27846: [27912, 3859, 6306, 6775, 7786], 27869: [7980, 77201, 8730, 26681, 88327], 27904: [60760, 116799, 53953, 57368, 4754], 27912: [27846, 3859, 6306, 6775, 7786], 30818: [25841, 6306, 8044, 7056, 6852], 30850: [8650, 4055, 25753, 31260, 6454], 30883: [8946, 4649, 31223, 57326, 32009], 30890: [7299, 6768, 981, 50923, 2546], 30892: [7171, 62662, 58425, 58309, 55156], 31000: [155812, 6249, 2472, 4660, 118512], 31049: [90576, 72591, 27705, 55112, 47970], 31116: [3871, 8337, 8461, 1507, 2202], 31223: [4649, 8946, 30883, 32009, 70334], 31260: [4292, 2757, 7479, 8057, 4189], 31617: [126430, 8795, 7307, 71810, 8640], 31660: [42422, 68945, 5069, 8126, 70687], 31685: [4018, 59725, 58998, 5299, 52973], 31700: [4822, 44399, 37739, 8982, 31223], 31804: [45361, 52950, 53326, 27584, 60471], 31878: [104241, 81229, 60126, 95875, 7419], 31923: [2880, 138036, 6156, 7000, 65588], 32009: [70334, 4649, 50923, 8946, 49793], 32017: [6013, 5264, 7376, 8860, 60161], 32031: [126921, 121781, 8978, 51575, 72701], 32116: [25752, 1546, 612, 90890, 130970], 32160: [25752, 1546, 612, 90890, 130970], 32179: [707, 27831, 54274, 4450, 5465], 32213: [184253, 143365, 78349, 26686, 77667], 32243: [142550, 93022, 131104, 167854, 172321], 32291: [5339, 5076, 25905, 6559, 528], 32314: [5497, 6533, 5780, 3680, 1490], 32387: [91976, 26401, 1465, 1667, 102735], 32649: [2106, 1507, 68872, 160422, 58876], 32728: [171917, 104879, 36276, 350, 3505], 32743: [32743, 40617, 6695, 162598, 8967], 32898: [108689, 166526, 105250, 74791, 127298], 32906: [7238, 8484, 26158, 3736, 773], 33004: [84772, 8644, 68358, 5444, 3033], 33124: [2106, 3808, 68872, 160422, 58876], 33126: [4321, 148652, 6412, 111743, 2016], 33158: [4719, 4632, 57526, 130634, 50445], 33164: [39446, 40617, 71252, 6695, 6615], 33421: [7299, 51174, 981, 50923, 2546], 33558: [26812, 62799, 61628, 60735, 4251], 33639: [3859, 3182, 27912, 7171, 6775], 33669: [112580, 42732, 67267, 2125, 89305], 33677: [7171, 6327, 363, 6453, 3680], 33725: [26422, 4642, 6345, 5508, 4926], 33838: [556, 363, 6453, 3680, 7932], 33896: [1329, 33896, 4403, 7650, 8405], 34018: [91873, 37211, 155812, 151317, 3596], 34148: [7299, 6768, 981, 50923, 2546], 34164: [5074, 48744, 6370, 55280, 6881], 34271: [8530, 6057, 8341, 70301, 6603], 34312: [131826, 26645, 49735, 172321, 167854], 34323: [52831, 8142, 27480, 80162, 63826], 34336: [32009, 5501, 8946, 70334, 4649], 34450: [104925, 73676, 7108, 26159, 73876], 34528: [6235, 4600, 5685, 43460, 6376], 34530: [25752, 1546, 612, 90890, 130970], 34536: [37739, 8982, 2775, 2590, 6246], 34540: [66511, 5461, 3174, 67267, 2596], 34800: [25752, 1546, 612, 90890, 130970], 35347: [26528, 1654, 74282, 65359, 47384], 35957: [71252, 5476, 8860, 6615, 33164], 36276: [929, 4077, 3420, 6810, 8771], 36477: [103027, 3774, 7137, 1784, 5485], 36535: [8366, 6881, 100843, 34164, 8232], 36931: [36931, 7108, 26159, 73741, 34450], 37211: [34018, 91873, 2472, 151317, 118512], 37240: [90943, 89580, 1412, 4093, 6692], 37380: [86835, 8861, 6615, 160565, 45081], 37384: [63479, 8814, 6188, 50942, 34164], 37495: [26308, 142558, 55444, 148238, 6119], 37731: [90057, 99910, 6023, 680, 7044], 37736: [6918, 7234, 7301, 4546, 959], 37739: [8982, 5267, 31700, 6246, 2590], 38095: [36931, 73876, 26159, 7108, 34450], 38798: [40597, 78174, 54796, 2188, 80454], 38992: [7299, 6768, 50923, 2546, 971], 39435: [27837, 57326, 6057, 129229, 50923], 39446: [43679, 33164, 42723, 6615, 71252], 40478: [7891, 136958, 3938, 8894, 167538], 40581: [63479, 73319, 109372, 50942, 94323], 40583: [27408, 1253, 41863, 7009, 6787], 40597: [54796, 78174, 2188, 84553, 80454], 40617: [6695, 32743, 6220, 5476, 8967], 40723: [5476, 71252, 27584, 52950, 4821], 40826: [70334, 32009, 50685, 34336, 50923], 40851: [7376, 8666, 108795, 163056, 71129], 40870: [7299, 121035, 50923, 2546, 971], 41285: [25856, 8981, 7154, 7234, 51884], 41569: [45722, 51662, 45186, 7153, 8644], 41617: [5984, 7820, 7587, 4065, 8195], 41627: [91976, 26401, 1465, 1667, 102735], 41712: [73676, 149011, 34450, 63179, 26498], 41828: [122092, 74342, 78142, 184791, 131826], 41863: [5238, 6997, 33558, 8341, 27408], 42002: [8695, 7121, 6412, 6912, 49220], 42422: [31660, 68945, 8126, 5069, 70687], 42556: [27105, 168218, 47261, 83374, 140737], 42723: [39446, 43679, 110591, 55492, 7202], 42732: [4649, 8946, 132660, 115667, 31223], 42734: [163653, 159849, 120807, 91266, 80834], 42738: [65682, 55232, 8861, 122890, 6615], 42740: [5231, 25752, 4204, 927, 4860], 43396: [8982, 37739, 5267, 34536, 26812], 43460: [8232, 5685, 4600, 6376, 6837], 43558: [6814, 6314, 100326, 157432, 5636], 43677: [50068, 68872, 160422, 58876, 979], 43679: [39446, 86295, 8957, 6615, 71252], 43684: [60753, 5015, 8910, 3481, 6796], 43708: [136471, 4102, 6408, 98083, 103602], 43869: [4241, 128991, 134019, 155774, 69746], 43928: [71254, 60937, 95875, 128542, 101962], 43932: [50445, 61705, 67186, 6057, 70301], 44020: [84414, 104141, 182639, 95004, 71129], 44238: [2148, 1241, 44241, 53450, 44243], 44241: [44238, 2148, 1241, 53450, 44243], 44243: [144734, 44241, 7845, 165639, 2148], 44301: [52375, 55036, 2332, 290, 1213], 44399: [4822, 31700, 30883, 31223, 57326], 44657: [44657, 5531, 7938, 7939, 1572], 44665: [27831, 1213, 4776, 64614, 1089], 44719: [44719, 172013, 46862, 164280, 134515], 44773: [99122, 142444, 131826, 49735, 119714], 44788: [7932, 6368, 52767, 7171, 6327], 44849: [26701, 92420, 122920, 1882, 692], 44943: [6344, 7208, 8622, 5296, 27815], 44974: [78218, 27317, 89582, 6868, 110330], 45081: [37380, 5476, 52950, 52281, 39446], 45106: [4722, 27685, 50802, 5524, 6944], 45183: [4084, 103810, 2273, 7325, 20], 45186: [8644, 91630, 8371, 4270, 41569], 45208: [31223, 8946, 4649, 44399, 51575], 45361: [53326, 31804, 51698, 1046, 7347], 45382: [1757, 5986, 8848, 162414, 179813], 45499: [53996, 8644, 6934, 5349, 8371], 45635: [4292, 2757, 7479, 8057, 4189], 45648: [66511, 6992, 3174, 67267, 2596], 45666: [49220, 127204, 8275, 8331, 8748], 45722: [6539, 41569, 2115, 7153, 4367], 46367: [2605, 3896, 1785, 53322, 3895], 46723: [8970, 81591, 27408, 3949, 2712], 46862: [44719, 172013, 46862, 164280, 134515], 46865: [52279, 6687, 109846, 56176, 47952], 46974: [1938, 25856, 7234, 7052, 5875], 47099: [4022, 72641, 3949, 1961, 1178], 47261: [7616, 6270, 3455, 26303, 5465], 47384: [65359, 27036, 71160, 62970, 1654], 47725: [153408, 128594, 143031, 106594, 25887], 47950: [36276, 8771, 929, 118354, 4077], 47952: [4632, 1003, 131714, 116887, 46865], 47970: [55112, 51884, 95624, 31049, 90576], 48142: [7044, 8501, 2579, 965, 4036], 48150: [142598, 140267, 48150, 55492, 110591], 48385: [69784, 8910, 8376, 143859, 4718], 48394: [5971, 41569, 81591, 7153, 3949], 48416: [3715, 6957, 6314, 63, 173619], 48638: [26317, 147002, 87660, 26059, 65037], 48649: [74342, 78142, 72624, 122092, 41828], 48696: [55112, 95624, 90576, 1873, 3707], 48741: [6400, 3281, 8938, 6042, 7141], 48744: [34164, 73681, 26308, 5074, 6370], 48774: [8644, 41569, 45499, 6934, 5349], 48783: [50068, 49822, 46974, 58876, 105121], 48997: [90528, 3266, 59604, 67508, 188675], 49110: [5604, 435, 4545, 3326, 2498], 49220: [927, 42740, 4204, 5581, 1526], 49278: [57368, 5264, 55232, 8861, 71530], 49389: [123545, 54276, 61406, 7302, 6412], 49649: [78105, 40851, 71160, 76175, 45722], 49688: [105121, 113416, 2521, 110826, 91273], 49735: [131826, 26645, 49735, 172321, 167854], 49793: [49793, 58876, 61705, 70301, 32009], 49822: [48783, 6862, 50068, 93242, 4251], 50068: [48783, 5010, 5995, 31116, 1178], 50147: [50445, 144522, 63826, 112818, 47952], 50274: [6031, 1496, 8921, 4296, 2801], 50445: [67186, 43932, 27837, 61705, 57526], 50601: [51698, 40851, 126142, 44399, 57326], 50610: [25752, 585, 90890, 130970, 1516], 50613: [50613, 44773, 99122, 142444, 115111], 50685: [67267, 47970, 51884, 7121, 25856], 50802: [84847, 74154, 5524, 89678, 65193], 50923: [49793, 58876, 61705, 70301, 32009], 50942: [94323, 109372, 63479, 40581, 73319], 50999: [157775, 167772, 136353, 136355, 136359], 51174: [87660, 111817, 773, 3845, 26059], 51255: [61024, 31878, 104241, 93510, 57368], 51314: [5524, 5499, 26085, 3259, 2950], 51498: [149011, 54910, 113159, 71732, 110591], 51575: [8814, 8978, 8946, 4649, 31223], 51662: [41569, 45722, 53996, 6934, 68358], 51698: [50601, 53326, 45361, 2162, 27837], 51884: [2801, 50274, 8921, 1496, 7092], 51931: [82767, 50923, 49793, 61705, 58876], 52042: [4251, 60046, 60735, 2358, 60647], 52279: [52279, 6687, 109846, 56176, 47952], 52281: [57528, 37380, 45081, 86835, 7439], 52328: [64497, 57368, 152077, 27821, 48774], 52375: [101525, 247, 2332, 290, 1213], 52435: [26198, 188797, 185473, 141994, 2078], 52458: [6595, 67267, 27705, 39446, 43679], 52579: [55444, 73681, 26308, 136018, 54617], 52604: [185135, 8860, 74228, 27831, 3896], 52644: [26303, 5909, 6872, 6063, 5853], 52668: [68269, 71823, 3155, 5092, 72407], 52730: [118512, 31000, 103819, 2472, 158022], 52767: [44788, 7171, 6667, 48741, 6042], 52784: [7171, 6327, 363, 6453, 3680], 52831: [58826, 34323, 27480, 80162, 63826], 52950: [40723, 27584, 80162, 63826, 5476], 52967: [4292, 2757, 7479, 8057, 4189], 52973: [58998, 62434, 4018, 3825, 31685], 53121: [5218, 4016, 4306, 4896, 50601], 53123: [59018, 8502, 7009, 27408, 61628], 53140: [69805, 27036, 71160, 8782, 47384], 53322: [5630, 80489, 97304, 58803, 1089], 53326: [45361, 31804, 51698, 2162, 1046], 53355: [149566, 133712, 134004, 108078, 84246], 53450: [44238, 2148, 1241, 44241, 44243], 53453: [5700, 161918, 2368, 168456, 91273], 53460: [43869, 136353, 136359, 136355, 4241], 53574: [66511, 140816, 91784, 26158, 148424], 53953: [2160, 4754, 6063, 60037, 2664], 53996: [45499, 6934, 8371, 95875, 8644], 54001: [81834, 69844, 4896, 74789, 7153], 54004: [62155, 87192, 62434, 58998, 1894], 54274: [707, 70301, 4450, 5465, 88593], 54276: [123545, 61406, 8948, 25856, 8695], 54617: [148238, 6119, 59026, 142558, 73681], 54768: [2804, 1713, 31223, 374, 77206], 54796: [78174, 62344, 40597, 2188, 80454], 54910: [3696, 138610, 163937, 89028, 97188], 54934: [585, 612, 90890, 130970, 1516], 54962: [61011, 55094, 62799, 61628, 26812], 55036: [101525, 247, 2332, 290, 1213], 55052: [2226, 123545, 8533, 80584, 95449], 55069: [66371, 58309, 446, 3083, 4217], 55094: [61011, 54962, 62799, 61628, 26812], 55112: [90576, 95624, 47970, 31049, 48696], 55156: [89090, 55156, 7786, 4236, 6935], 55205: [7299, 121035, 50923, 2546, 971], 55232: [8861, 5219, 6615, 86835, 71254], 55241: [25752, 585, 612, 90890, 130970], 55247: [106100, 91976, 3949, 117529, 105954], 55272: [52375, 101525, 247, 2332, 290], 55280: [34164, 71464, 5909, 8366, 5074], 55444: [73681, 52579, 26308, 136018, 148238], 55492: [142598, 140267, 48150, 55492, 110591], 55721: [67508, 64614, 97304, 105585, 103810], 55805: [707, 70301, 54274, 4450, 5465], 55844: [103027, 3481, 6765, 7137, 1784], 55995: [5463, 146309, 103655, 31804, 69526], 56022: [4713, 3994, 6184, 24, 2117], 56174: [8644, 8371, 6934, 68358, 77561], 56176: [52279, 46865, 6332, 6687, 8695], 56339: [8947, 100306, 2338, 61406, 67267], 57326: [27837, 43932, 30883, 50445, 6057], 57368: [49278, 70286, 8644, 55232, 95875], 57526: [70301, 67186, 61705, 6057, 50445], 57528: [86835, 52281, 6615, 99910, 95875], 58156: [5942, 26732, 5573, 45666, 103819], 58162: [8748, 68444, 90576, 62434, 140816], 58287: [49822, 81591, 5387, 60735, 3513], 58293: [69524, 8807, 8968, 3825, 48696], 58306: [50068, 68872, 160422, 58876, 979], 58309: [4217, 55069, 66371, 446, 6775], 58347: [7380, 47384, 27036, 54276, 90576], 58376: [117364, 117531, 91860, 58425, 102823], 58425: [134796, 90630, 91860, 58425, 102823], 58803: [80489, 6862, 68554, 53322, 49822], 58826: [27480, 73741, 52831, 8142, 160341], 58870: [51498, 41712, 73676, 118082, 113159], 58876: [49793, 50923, 61705, 70301, 32009], 58972: [65577, 77206, 90890, 69140, 74580], 58998: [52973, 62434, 86833, 31685, 54004], 59016: [707, 70301, 54274, 4450, 5465], 59018: [26812, 61628, 62799, 61011, 33558], 59022: [8807, 138036, 84772, 63479, 88785], 59026: [148238, 6119, 59026, 142558, 73681], 59118: [30850, 6867, 62113, 1955, 8949], 59369: [72489, 52458, 91535, 8860, 52281], 59429: [26686, 77667, 103655, 106540, 3268], 59549: [4296, 152284, 8981, 1678, 25833], 59604: [83601, 27075, 3266, 48997, 58803], 59667: [25752, 4040, 34312, 612, 90890], 59725: [31685, 6687, 4018, 2724, 90576], 59738: [74580, 5026, 67534, 3386, 58972], 59810: [7299, 6768, 981, 50923, 2546], 59947: [20, 5628, 145, 7007, 1432], 60037: [60760, 6250, 8126, 42422, 145418], 60046: [2358, 52042, 26812, 62799, 61628], 60072: [71254, 92420, 117895, 6595, 89840], 60126: [104241, 31878, 87192, 97913, 95875], 60161: [4492, 3511, 32017, 44020, 84414], 60471: [97988, 80162, 113345, 63826, 61692], 60538: [2446, 26116, 1333, 67186, 52644], 60647: [4251, 6997, 60735, 52042, 61628], 60735: [4251, 52042, 60647, 61628, 26812], 60753: [6997, 43684, 60647, 61628, 62799], 60760: [60037, 94799, 6250, 42422, 68945], 60904: [5530, 4012, 34528, 3900, 3925], 60937: [69805, 53140, 76175, 130634, 40851], 60950: [159415, 152284, 50685, 92259, 148956], 61011: [54962, 55094, 62799, 61628, 26812], 61024: [93510, 51255, 88812, 103810, 131013], 61073: [1515, 4965, 5782, 132796, 315], 61240: [105801, 27317, 100306, 27778, 113159], 61246: [25752, 585, 612, 90890, 130970], 61255: [25752, 585, 612, 90890, 130970], 61323: [71464, 55280, 116799, 7367, 52973], 61350: [62376, 64997, 33558, 4251, 60735], 61406: [123545, 54276, 1938, 25856, 7302], 61628: [62799, 26812, 60735, 61011, 60046], 61692: [97988, 3696, 113313, 138610, 163937], 61697: [3386, 1089, 4506, 1661, 2579], 61705: [70301, 50923, 49793, 43932, 57526], 61818: [72424, 160341, 60471, 77364, 27480], 61986: [26750, 52042, 54962, 2358, 635], 62008: [115111, 167772, 50999, 157775, 99122], 62113: [112580, 135885, 8748, 68444, 144734], 62155: [32009, 8814, 70334, 128594, 106594], 62344: [54796, 78174, 2188, 80454, 40597], 62376: [62970, 61350, 8782, 1881, 26528], 62434: [52973, 58998, 152091, 101415, 84772], 62644: [145418, 90809, 27815, 47099, 179709], 62662: [7171, 7786, 6453, 3680, 7932], 62792: [6057, 70301, 50923, 49793, 8982], 62799: [62799, 26812, 60735, 61011, 60046], 62970: [8782, 71160, 65359, 47384, 8743], 63082: [64614, 2858, 72641, 106100, 80463], 63179: [8840, 63179, 41712, 26401, 89582], 63239: [6158, 104245, 53121, 8869, 4306], 63479: [40581, 4649, 8946, 50942, 37384], 63515: [61011, 69118, 6234, 135288, 108981], 63826: [80162, 52831, 142366, 113313, 163937], 63853: [65359, 47384, 27036, 3053, 35347], 63859: [130520, 87222, 152081, 60126, 97913], 64231: [1889, 32743, 6220, 104141, 162598], 64497: [97752, 49278, 49822, 52328, 143365], 64614: [63082, 1213, 80463, 59369, 55721], 64620: [89804, 1955, 70159, 145418, 61406], 64993: [26743, 81681, 113705, 5028, 104337], 64997: [8677, 61350, 61011, 52042, 61628], 65037: [87660, 111817, 773, 3845, 26059], 65188: [52767, 44788, 93721, 90576, 72591], 65193: [89678, 84847, 90809, 94799, 91266], 65350: [2226, 85334, 7255, 52328, 55052], 65359: [47384, 27036, 71160, 1654, 62970], 65577: [77206, 58972, 69140, 90890, 91653], 65588: [142550, 26183, 111146, 130518, 182297], 65601: [2446, 26116, 1333, 67186, 52644], 65682: [42738, 6615, 8861, 37380, 45081], 65740: [5470, 7101, 94503, 5135, 7121], 65810: [90057, 143365, 103624, 59429, 32213], 66090: [68347, 5891, 81417, 6885, 1590], 66203: [32009, 8533, 70334, 109853, 62155], 66371: [145418, 55069, 106441, 72720, 4439], 66427: [51498, 2514, 3692, 842, 8967], 66511: [140816, 26158, 91784, 8748, 65037], 66544: [2106, 1507, 68872, 160422, 58876], 66785: [89305, 7000, 106491, 6814, 93766], 67186: [50445, 43932, 57526, 61705, 70301], 67193: [3102, 5553, 5424, 58803, 156706], 67267: [50685, 34336, 54276, 32009, 5501], 67295: [27075, 59604, 83601, 3266, 87222], 67508: [90528, 7459, 188675, 136024, 92637], 67534: [5292, 635, 74580, 59018, 26812], 67923: [130634, 104241, 7439, 112818, 71254], 68073: [166015, 158972, 66511, 140816, 92094], 68269: [52668, 71823, 3155, 72407, 8533], 68347: [66090, 5891, 1873, 6885, 48696], 68358: [69526, 112852, 122886, 111759, 56174], 68444: [68444, 66511, 140816, 76173, 127204], 68552: [121035, 50923, 2546, 971, 961], 68554: [108729, 58803, 85414, 53322, 4776], 68848: [74228, 118082, 113159, 104925, 34450], 68872: [2106, 50068, 160422, 58876, 979], 68945: [31660, 42422, 5069, 8126, 70687], 69118: [113350, 97870, 140237, 129659, 165075], 69131: [2540, 3947, 7040, 64231, 67508], 69140: [77206, 65577, 81819, 58972, 91653], 69524: [72591, 27705, 31049, 8677, 875], 69526: [101864, 68358, 95510, 71530, 55995], 69606: [115667, 132660, 82152, 139747, 6732], 69746: [145080, 136024, 43869, 155774, 84187], 69784: [48385, 71464, 4718, 127204, 143859], 69805: [53140, 71160, 60937, 8782, 27036], 69844: [81834, 54001, 4896, 118696, 78105], 69951: [41569, 71745, 97752, 76175, 137517], 70159: [1979, 145418, 105585, 64620, 89804], 70208: [138610, 89028, 74370, 113313, 97188], 70286: [57368, 68358, 56174, 122920, 8644], 70301: [57526, 61705, 6057, 49793, 50923], 70334: [32009, 4649, 50923, 49793, 8946], 70451: [6591, 1619, 43396, 70159, 50068], 70637: [4296, 8921, 1678, 25833, 25856], 70663: [162590, 5135, 7121, 5151, 8869], 70687: [42422, 8126, 31660, 5069, 53574], 71106: [114678, 59429, 176371, 87192, 111360], 71129: [108795, 84414, 163056, 95473, 95149], 71160: [8782, 27036, 65359, 62970, 47384], 71211: [127204, 90528, 67508, 105254, 140816], 71252: [5476, 6615, 40723, 27584, 52950], 71254: [92420, 94018, 71530, 89840, 60072], 71264: [87222, 130520, 93272, 83349, 93766], 71438: [104337, 5028, 113705, 135288, 179815], 71464: [148424, 69784, 55280, 78836, 41712], 71500: [113252, 54910, 1321, 1993, 7282], 71520: [152091, 91690, 166492, 107630, 162478], 71530: [71254, 8371, 101864, 67923, 103253], 71550: [112421, 5013, 2417, 130452, 59118], 71619: [121035, 50923, 2546, 971, 961], 71732: [51498, 54910, 149011, 113159, 7202], 71745: [78836, 148424, 106766, 69951, 127298], 71810: [7307, 4103, 126430, 8640, 8795], 71823: [52668, 68269, 32009, 50923, 70334], 71999: [187031, 27618, 117529, 41569, 48774], 72407: [98203, 78772, 52668, 97024, 82152], 72424: [160341, 58826, 27480, 63826, 80162], 72489: [8861, 875, 27705, 7376, 8860], 72591: [27705, 31049, 8677, 875, 69524], 72601: [95473, 84414, 108795, 95004, 71129], 72624: [94661, 25887, 130452, 48649, 79684], 72641: [88810, 106100, 8970, 47099, 5810], 72692: [72692, 121781, 157775, 167772, 50999], 72694: [97870, 148482, 129659, 101895, 140237], 72701: [5480, 126921, 94503, 130518, 26183], 72720: [87660, 65037, 145418, 773, 3845], 72737: [7380, 78772, 74450, 58347, 4016], 73042: [136359, 136353, 136355, 121781, 126921], 73266: [106330, 109372, 71211, 127204, 140816], 73290: [136562, 127098, 146656, 98154, 100383], 73319: [40581, 109372, 50942, 94323, 106330], 73323: [74510, 159, 105585, 99728, 157432], 73676: [34450, 26401, 41712, 135815, 7108], 73681: [59026, 142558, 6119, 54617, 55444], 73741: [73876, 7108, 26159, 27480, 36931], 73808: [707, 70301, 54274, 4450, 5465], 73876: [36931, 7108, 26159, 73741, 34450], 74154: [115667, 132660, 139747, 50802, 6732], 74228: [80846, 107997, 89028, 74370, 163937], 74275: [103027, 3774, 7137, 1784, 5485], 74282: [26528, 1654, 27036, 35347, 65359], 74342: [78142, 130452, 94661, 25887, 79684], 74370: [138610, 70208, 89028, 113313, 97188], 74450: [54276, 8869, 7375, 6535, 109853], 74510: [73323, 106839, 132796, 89840, 105585], 74545: [127136, 7044, 162414, 179813, 5986], 74553: [5069, 42422, 31660, 68945, 8126], 74580: [59738, 67534, 58972, 20, 7007], 74647: [25752, 1546, 612, 90890, 130970], 74688: [77414, 82152, 139747, 115667, 132660], 74750: [5476, 71252, 40723, 27822, 43679], 74789: [86880, 81834, 54001, 97938, 135143], 74791: [134019, 2495, 4241, 128991, 145080], 74868: [37380, 6220, 94799, 32743, 77414], 75341: [4296, 152284, 1678, 25833, 25856], 75416: [6294, 122922, 208, 130842, 2094], 75805: [110771, 91628, 132660, 115667, 109895], 76077: [84772, 152091, 83349, 62434, 111743], 76173: [68444, 8748, 140816, 188675, 66511], 76175: [93766, 69805, 91485, 94780, 60937], 77177: [92243, 115969, 126430, 141749, 82378], 77201: [27869, 7980, 8730, 26681, 88327], 77206: [65577, 90890, 69140, 58972, 91653], 77364: [7307, 61818, 73741, 26401, 72424], 77414: [74688, 82152, 139747, 132660, 115667], 77561: [87232, 112852, 95510, 101864, 45499], 77667: [59429, 3268, 103655, 26686, 87192], 77931: [6734, 8578, 58870, 3696, 41712], 78105: [49649, 86880, 76175, 6541, 60937], 78142: [78142, 130452, 94661, 25887, 79684], 78174: [78174, 62344, 40597, 2188, 80454], 78209: [127098, 45666, 86833, 69784, 6119], 78218: [161966, 110330, 108727, 152284, 95690], 78349: [32213, 184253, 110882, 162478, 143365], 78772: [74450, 98203, 72737, 72407, 58347], 78836: [148424, 87304, 63179, 51174, 65037], 79006: [7171, 7786, 6453, 3680, 7932], 79224: [94780, 87192, 93766, 8640, 6057], 79242: [136778, 106883, 528, 155659, 98836], 79333: [4602, 8033, 4844, 4228, 6023], 79357: [78836, 114678, 68848, 128512, 148424], 79684: [25887, 94661, 130452, 102378, 143031], 79798: [87413, 3545, 8024, 4450, 3095], 79895: [49649, 57326, 140737, 2115, 2373], 80126: [129937, 89582, 138210, 63179, 26498], 80162: [80162, 52831, 142366, 113313, 163937], 80454: [80454, 62344, 40597, 78174, 54796], 80463: [102407, 106100, 72641, 3949, 89804], 80489: [97304, 4776, 7007, 100383, 99728], 80584: [2837, 7034, 6238, 94833, 93805], 80727: [102378, 130452, 94661, 131104, 79684], 80834: [126142, 101962, 91266, 129229, 90809], 80846: [97188, 138610, 74370, 142366, 114707], 80969: [3269, 27266, 2393, 42422, 79357], 81156: [91653, 5942, 6814, 77177, 5573], 81229: [104241, 31878, 93510, 60126, 103810], 81417: [74750, 97701, 66090, 48150, 142598], 81591: [52458, 48394, 3949, 97304, 106100], 81681: [64993, 71438, 104337, 113705, 5028], 81819: [69140, 91653, 65577, 77206, 106766], 81831: [26732, 101531, 104303, 98083, 99145], 81834: [69844, 54001, 74789, 4896, 86880], 82152: [77414, 74688, 139747, 115667, 132660], 82242: [31660, 68945, 5069, 70687, 84553], 82378: [141749, 92243, 115969, 126430, 105954], 82767: [51931, 112804, 79242, 101525, 146656], 83134: [93840, 6755, 37380, 86295, 91485], 83177: [52730, 155812, 6249, 151317, 31000], 83349: [104241, 95441, 93766, 67923, 152091], 83374: [91273, 126420, 5700, 53453, 157432], 83601: [59604, 27075, 3266, 48997, 2313], 83613: [95875, 86835, 91630, 130634, 6615], 83803: [3054, 4241, 44020, 104141, 43869], 84187: [2495, 128991, 136024, 51174, 87304], 84246: [53355, 149566, 133712, 134004, 108078], 84414: [71129, 169982, 95473, 108795, 44020], 84553: [40597, 54796, 78174, 38798, 2188], 84601: [99910, 32743, 6220, 162598, 86295], 84696: [91688, 151317, 103819, 155812, 6249], 84772: [76077, 138036, 8807, 95875, 152091], 84844: [52375, 168266, 2332, 290, 1213], 84847: [65193, 89678, 91266, 90809, 94799], 84950: [155659, 98836, 528, 106883, 119068], 85025: [168456, 101884, 97870, 148482, 165075], 85056: [117895, 114818, 103655, 69606, 143365], 85316: [3287, 163072, 6158, 4241, 4154], 85334: [7255, 2226, 65350, 66203, 55052], 85414: [71254, 104879, 57368, 114180, 97752], 85788: [156726, 89028, 113313, 97188, 74370], 85881: [102378, 80727, 79684, 25887, 130452], 86279: [134796, 90630, 91860, 58425, 102823], 86295: [27584, 86835, 109578, 6615, 43679], 86593: [85025, 2368, 168456, 7000, 101884], 86817: [103027, 3481, 6765, 7137, 1784], 86833: [88785, 58998, 97921, 109895, 69784], 86835: [6615, 86295, 8861, 6250, 99910], 86864: [62970, 8743, 163056, 26510, 5700], 86880: [74789, 78105, 106002, 118696, 77561], 86892: [130634, 60937, 67923, 64231, 7802], 87192: [77667, 59429, 3268, 103655, 93766], 87222: [87876, 95510, 138036, 63859, 149406], 87232: [77561, 112852, 95875, 45499, 101864], 87304: [87660, 111817, 773, 3845, 26059], 87413: [79798, 8024, 3545, 4450, 4641], 87485: [135861, 143969, 152091, 155820, 84553], 87522: [103027, 52, 6765, 7137, 1784], 87660: [87660, 111817, 773, 3845, 26059], 87834: [25887, 167772, 79684, 94661, 130452], 87867: [90890, 111617, 94405, 2335, 2694], 87876: [100611, 136556, 87222, 149406, 27619], 87960: [7171, 4217, 363, 6453, 3680], 88267: [136359, 164200, 136355, 53460, 42734], 88327: [7307, 135815, 26401, 26681, 7108], 88593: [707, 70301, 54274, 4450, 5465], 88785: [110771, 94323, 111617, 50942, 106540], 88810: [72641, 80463, 95624, 106100, 102407], 88812: [131013, 93510, 114818, 113453, 89840], 89028: [138610, 70208, 74370, 113313, 97188], 89090: [89090, 55156, 7786, 4236, 6935], 89305: [66785, 7000, 3596, 103819, 158022], 89580: [89580, 27822, 4093, 90943, 37240], 89582: [63179, 113862, 26498, 73741, 8840], 89586: [13, 172825, 172585, 5109, 5218], 89678: [65193, 84847, 90809, 94799, 91266], 89804: [55444, 106100, 90057, 64620, 46974], 89840: [117895, 94018, 92420, 105585, 27801], 89864: [40597, 97921, 109374, 41712, 38798], 89904: [54276, 143969, 100843, 123545, 134021], 90057: [65810, 143365, 103624, 110882, 77667], 90243: [26401, 1465, 1667, 102735, 91470], 90353: [7299, 6768, 981, 50923, 2546], 90405: [97304, 104841, 97752, 53322, 143365], 90439: [97304, 166568, 82378, 80489, 93242], 90528: [67508, 7459, 188675, 92637, 106648], 90576: [55112, 31049, 47970, 48696, 27705], 90630: [134796, 90630, 91860, 58425, 102823], 90809: [65193, 89678, 84847, 94799, 129229], 90863: [7171, 27829, 363, 6453, 3680], 90890: [87867, 91653, 77206, 65577, 2335], 90943: [37240, 1412, 4093, 89580, 27822], 91266: [84847, 65193, 89678, 126142, 94799], 91273: [137517, 105121, 97470, 99005, 113416], 91414: [156553, 6793, 31700, 175475, 53460], 91470: [108727, 110330, 78218, 152284, 167790], 91485: [76175, 6664, 67923, 106491, 37380], 91535: [96079, 77561, 152077, 97938, 59369], 91628: [109895, 132660, 115667, 139747, 74154], 91630: [45186, 83613, 96079, 95510, 77561], 91653: [119068, 98836, 84950, 136778, 155659], 91688: [84696, 151317, 103819, 155812, 6249], 91690: [107630, 166492, 71520, 162478, 152091], 91784: [140816, 66511, 92637, 26158, 68444], 91860: [134796, 90630, 91860, 58425, 102823], 91873: [34018, 37211, 155812, 151317, 3596], 91976: [51174, 87304, 87660, 3845, 111817], 92094: [166015, 106839, 68073, 96432, 155168], 92192: [2827, 2664, 97988, 3661, 3664], 92243: [115969, 141749, 126430, 760, 82378], 92259: [109374, 60950, 2324, 127202, 112183], 92420: [89840, 117895, 71254, 95875, 86835], 92637: [188675, 7459, 91784, 90528, 106648], 93022: [131104, 32243, 34312, 117109, 128089], 93040: [117364, 5288, 58376, 37240, 96606], 93242: [127132, 157130, 149612, 97470, 124859], 93272: [136556, 100611, 122890, 87876, 87222], 93502: [49822, 805, 5387, 60735, 3513], 93510: [88812, 131013, 61024, 113453, 104241], 93721: [8264, 146682, 44788, 65188, 134796], 93723: [5470, 1307, 5135, 7121, 5151], 93766: [101025, 94780, 106491, 87192, 116529], 93790: [7299, 51174, 981, 50923, 2546], 93805: [160565, 94018, 143969, 2837, 80584], 93840: [83134, 2232, 37380, 8861, 86835], 94018: [132796, 160565, 112818, 89840, 106491], 94323: [109372, 50942, 106330, 63479, 135861], 94405: [64231, 104141, 7802, 72601, 99910], 94478: [8695, 54276, 89904, 6888, 98175], 94503: [134004, 133712, 149566, 84246, 108078], 94661: [25887, 79684, 130452, 102378, 143031], 94780: [93766, 101025, 87192, 79224, 76175], 94799: [90809, 65193, 89678, 84847, 80834], 94810: [79357, 27266, 5530, 4713, 6184], 94833: [52730, 7000, 156553, 2837, 83177], 95004: [95473, 95149, 104141, 84414, 44020], 95149: [108795, 95004, 71129, 95473, 44020], 95170: [2087, 596, 551, 661, 1881], 95207: [7007, 86835, 109578, 103655, 95875], 95441: [152091, 83349, 104241, 71520, 84772], 95449: [97024, 7154, 109853, 55112, 98203], 95473: [84414, 108795, 95004, 72601, 71129], 95499: [149406, 96004, 95780, 146309, 95473], 95510: [77561, 122922, 122886, 95875, 112852], 95519: [6857, 108795, 177285, 3000, 55995], 95543: [164200, 106540, 126921, 50999, 167772], 95624: [875, 27705, 55112, 47970, 48696], 95633: [50613, 44773, 99122, 142444, 115111], 95690: [107630, 166492, 161966, 78218, 91690], 95780: [95499, 149406, 96004, 146309, 95473], 95839: [69951, 201, 137517, 6270, 164280], 95875: [83613, 86835, 8861, 92420, 8371], 96004: [95499, 149406, 95780, 146309, 95473], 96079: [91630, 77561, 91535, 122886, 117529], 96283: [56176, 31223, 374, 77206, 1919], 96432: [162598, 92094, 166015, 6220, 32743], 96520: [61011, 69118, 6234, 135288, 108981], 96606: [96606, 115203, 105250, 175743, 44719], 96821: [106642, 128512, 77414, 90057, 127108], 97024: [109853, 98203, 95449, 7154, 74450], 97188: [138610, 70208, 89028, 74370, 113313], 97230: [7171, 6327, 363, 6453, 3680], 97304: [90439, 80489, 102407, 106100, 105504], 97470: [97470, 2521, 157407, 93242, 127132], 97701: [7202, 55492, 110591, 140267, 142598], 97752: [103253, 111759, 64497, 85414, 69951], 97870: [97870, 148482, 129659, 101895, 140237], 97913: [60126, 83134, 71520, 63859, 138036], 97921: [86833, 109374, 106100, 106918, 112183], 97938: [74789, 105504, 91535, 97752, 101864], 97950: [136020, 7048, 6709, 112, 7802], 97988: [97988, 3696, 113313, 138610, 163937], 98083: [26732, 81831, 104303, 101531, 58156], 98154: [136562, 73290, 61406, 97304, 105121], 98175: [139915, 98908, 118814, 144262, 111680], 98203: [97024, 109853, 95449, 74450, 7154], 98361: [48394, 143367, 4235, 81591, 46723], 98604: [64993, 42422, 3824, 45382, 4296], 98607: [149146, 133217, 139855, 91470, 166492], 98836: [155659, 528, 106883, 84950, 119068], 98908: [116413, 139915, 111680, 118814, 4168], 99005: [99005, 110826, 157407, 157432, 97470], 99122: [44773, 142444, 131826, 49735, 119714], 99145: [101531, 104303, 81831, 90809, 89678], 99728: [114818, 106839, 5803, 103655, 110297], 99813: [95004, 95149, 95473, 104141, 108795], 99910: [86835, 84601, 6615, 7439, 117895], 99917: [8477, 136602, 6734, 61692, 130840], 100083: [166492, 107630, 91690, 95690, 167790], 100194: [25752, 585, 612, 90890, 130970], 100306: [4442, 27317, 6868, 7340, 56339], 100326: [4662, 6314, 5636, 2587, 4602], 100383: [106100, 38095, 73290, 80489, 8860], 100507: [155820, 34312, 184791, 52279, 169912], 100611: [136556, 27619, 87876, 130520, 93272], 100843: [152270, 179709, 36535, 143969, 89904], 101025: [93766, 94780, 106491, 89305, 76175], 101074: [2746, 4624, 5879, 62008, 2078], 101415: [155820, 134021, 139915, 84950, 155659], 101525: [2332, 36931, 26159, 73876, 7108], 101531: [104303, 81831, 99145, 98083, 26732], 101765: [1894, 3492, 2405, 68848, 969], 101864: [106002, 77561, 111759, 69526, 135133], 101884: [127132, 85025, 93242, 124859, 157130], 101895: [97870, 148482, 129659, 101895, 140237], 101962: [80834, 60937, 43928, 144734, 112580], 102378: [130452, 25887, 79684, 94661, 80727], 102407: [136562, 80463, 127108, 106100, 97304], 102590: [7171, 8577, 6948, 6963, 7141], 102735: [91976, 26401, 1465, 1667, 91470], 102823: [134796, 90630, 91860, 58425, 102823], 103027: [66203, 6765, 7137, 1784, 5485], 103075: [112818, 107997, 112727, 85788, 67923], 103253: [97752, 111759, 101864, 104841, 71530], 103339: [72720, 94018, 145418, 89840, 132796], 103372: [158528, 140016, 110771, 75805, 158813], 103602: [169912, 49735, 131826, 119714, 172321], 103609: [25752, 612, 90890, 130970, 1516], 103624: [90057, 179813, 162414, 5986, 8848], 103655: [114818, 26686, 77667, 3268, 59429], 103810: [133802, 148424, 118880, 67508, 76173], 103819: [155812, 6249, 2472, 4660, 118512], 104141: [44020, 95004, 95149, 95473, 108795], 104241: [83349, 67923, 114818, 31878, 81229], 104245: [6158, 156553, 7000, 31000, 4660], 104303: [104303, 81831, 99145, 98083, 26732], 104337: [104337, 5028, 113705, 135288, 179815], 104780: [84414, 5444, 100611, 4006, 2368], 104841: [111759, 103253, 101864, 68358, 56174], 104875: [130518, 140541, 140481, 72701, 131826], 104879: [85414, 80489, 97304, 108729, 52604], 104925: [34450, 8142, 26159, 73876, 27480], 105121: [105121, 113416, 2521, 110826, 91273], 105197: [85025, 138210, 72720, 145418, 101884], 105250: [118784, 86279, 117531, 58425, 179135], 105254: [127204, 71211, 43869, 68444, 8748], 105504: [97938, 97304, 91535, 90439, 91630], 105585: [7439, 89840, 160565, 94018, 6709], 105755: [124859, 118354, 157407, 139717, 127132], 105801: [27778, 149011, 7657, 110591, 142598], 105954: [126430, 82378, 141749, 168456, 115969], 106002: [101864, 135133, 122912, 86880, 112852], 106100: [112290, 72641, 89804, 102407, 97921], 106330: [109372, 94323, 73266, 134021, 144262], 106441: [145418, 1979, 160565, 66371, 1178], 106491: [132796, 93766, 94018, 101025, 69805], 106540: [26645, 128089, 59429, 184791, 119714], 106542: [98908, 116413, 4168, 144262, 118814], 106594: [143031, 128594, 133712, 84246, 79684], 106642: [169982, 96821, 84601, 163056, 162598], 106648: [188675, 7459, 92637, 90528, 111817], 106766: [140174, 8840, 104337, 71438, 113705], 106839: [92094, 97870, 101895, 72694, 148482], 106883: [155659, 98836, 528, 84950, 119068], 106918: [138036, 114678, 97921, 8807, 62434], 107410: [924, 106642, 52328, 171765, 85025], 107630: [107630, 95690, 91690, 100083, 133217], 107997: [80846, 114707, 97188, 89582, 89028], 108078: [53355, 149566, 133712, 134004, 84246], 108090: [187541, 152081, 26183, 111146, 63859], 108188: [2521, 149612, 97470, 157407, 93242], 108192: [7299, 6768, 981, 50923, 2546], 108540: [4306, 91414, 94833, 43869, 160569], 108689: [166526, 8477, 71438, 122246, 26743], 108727: [108727, 78218, 152284, 91470, 159415], 108729: [109578, 74228, 86295, 166534, 133802], 108795: [71129, 95149, 95473, 84414, 163056], 108981: [61011, 69118, 6234, 135288, 169958], 109317: [155812, 6249, 2472, 4660, 118512], 109372: [106330, 94323, 50942, 40581, 73266], 109374: [97921, 112183, 92259, 7323, 102407], 109578: [86295, 72424, 160341, 86835, 77364], 109633: [64993, 98604, 42422, 117545, 6192], 109723: [70301, 54274, 4450, 5465, 88593], 109846: [46865, 52279, 6687, 131714, 116887], 109848: [2827, 2664, 97988, 3661, 3664], 109853: [97024, 98203, 95449, 74450, 7154], 109895: [103819, 151317, 2472, 157270, 158022], 110297: [114818, 5803, 103655, 59429, 4662], 110330: [108727, 78218, 152284, 91470, 159415], 110591: [142598, 140267, 48150, 55492, 110591], 110718: [25752, 1585, 90890, 130970, 1516], 110771: [75805, 88785, 91628, 148956, 132660], 110826: [99005, 110826, 157407, 157432, 97470], 110882: [110330, 108727, 90057, 168266, 78218], 111146: [26183, 126921, 130518, 136355, 136353], 111360: [122920, 168252, 122912, 37380, 122898], 111443: [25752, 1585, 90890, 130970, 1516], 111617: [113453, 135861, 131013, 88785, 100507], 111680: [116413, 98908, 139915, 118814, 4168], 111743: [152091, 71520, 148956, 91690, 76077], 111759: [122886, 104841, 103253, 101864, 112852], 111785: [45722, 122890, 5040, 393, 2373], 111800: [25752, 585, 612, 90890, 130970], 111817: [87660, 111817, 773, 3845, 26059], 112171: [129937, 130634, 58826, 27480, 33158], 112183: [112290, 109374, 140928, 97921, 41712], 112290: [106100, 136562, 112183, 102407, 26498], 112316: [52579, 8535, 65810, 346, 6347], 112334: [112334, 155168, 166015, 92094, 106839], 112421: [135288, 166015, 104337, 8189, 113705], 112497: [155812, 6249, 2472, 4660, 118512], 112580: [135885, 144734, 116529, 128542, 62113], 112727: [52831, 163937, 97188, 138610, 113313], 112804: [82767, 51931, 135518, 128512, 79242], 112818: [103075, 132796, 94018, 67923, 106491], 112852: [122886, 87232, 77561, 122922, 68358], 112868: [5544, 4966, 1779, 179053, 880], 113159: [51498, 130840, 54910, 149011, 71732], 113186: [113186, 84696, 156706, 139717, 93242], 113207: [4091, 6978, 1104, 6787, 477], 113252: [54910, 3696, 97188, 113313, 74370], 113313: [138610, 70208, 89028, 74370, 97188], 113345: [60471, 146309, 26399, 6095, 8578], 113350: [69118, 142424, 97870, 129659, 101895], 113416: [99005, 110826, 157407, 157432, 97470], 113453: [131013, 135861, 111617, 155820, 94323], 113705: [104337, 5028, 113705, 135288, 179815], 113862: [97188, 142366, 163937, 160341, 70208], 114180: [101864, 109578, 57368, 83613, 85414], 114265: [5470, 1307, 94503, 5135, 7121], 114335: [172013, 134515, 96606, 172461, 46862], 114678: [140816, 66511, 26158, 91784, 71106], 114707: [80846, 48150, 55492, 140267, 7202], 114818: [110297, 103655, 5803, 3268, 77667], 115111: [115111, 167772, 50999, 157775, 99122], 115122: [51498, 144734, 71732, 54910, 113159], 115203: [96606, 115203, 105250, 175743, 44719], 115216: [148482, 72694, 101895, 140237, 165075], 115667: [132660, 139747, 6732, 74154, 77414], 115969: [92243, 141749, 126430, 760, 82378], 116413: [98908, 139915, 111680, 118814, 4168], 116529: [112580, 128542, 135885, 144734, 93766], 116799: [7367, 148424, 78836, 71211, 103810], 116887: [131714, 4632, 1003, 109846, 47952], 117109: [131826, 26645, 49735, 172321, 167854], 117364: [86279, 91860, 179135, 117531, 102823], 117444: [596, 71264, 172577, 2087, 5971], 117529: [95875, 71530, 67923, 112852, 96079], 117531: [134796, 90630, 91860, 58425, 102823], 117545: [134019, 2495, 4241, 145080, 136024], 117630: [8531, 79333, 32243, 104925, 103372], 117877: [166526, 26743, 64993, 71438, 113705], 117887: [122246, 131656, 8189, 453, 148881], 117895: [89840, 92420, 77667, 103655, 27801], 118082: [112727, 58826, 104925, 54910, 27480], 118354: [105755, 124859, 157407, 93242, 4212], 118512: [155812, 6249, 2472, 4660, 118512], 118696: [135143, 86880, 135133, 54001, 81834], 118784: [134796, 90630, 91860, 58425, 102823], 118814: [116413, 98908, 139915, 111680, 4168], 118880: [133802, 103810, 148424, 78836, 48638], 118930: [25752, 585, 612, 90890, 130970], 119068: [98836, 528, 106883, 84950, 155659], 119714: [131826, 26645, 49735, 172321, 167854], 119964: [25752, 585, 612, 90890, 130970], 120807: [163653, 120807, 8264, 146682, 42734], 121035: [6768, 981, 50923, 2546, 971], 121372: [25752, 585, 612, 90890, 130970], 121781: [136359, 170837, 136353, 72692, 136355], 122092: [41828, 74342, 78142, 184791, 131826], 122246: [8189, 117887, 71438, 179815, 8477], 122886: [112852, 111759, 101864, 77561, 95510], 122890: [42738, 103655, 162478, 93272, 122922], 122896: [136556, 100611, 135133, 122912, 122922], 122898: [122912, 169982, 122916, 170827, 163056], 122912: [122916, 122922, 122898, 168252, 135133], 122916: [122912, 122922, 122898, 168252, 135133], 122920: [168252, 111360, 122912, 27801, 86835], 122922: [122912, 135133, 122916, 168252, 95510], 123545: [54276, 61406, 25856, 8948, 1938], 124851: [166526, 2822, 2368, 2021, 135133], 124859: [124859, 118354, 157407, 139717, 127132], 125916: [5955, 8531, 134021, 157130, 129659], 126142: [80834, 129229, 91266, 90809, 65193], 126420: [6814, 157432, 105121, 149612, 2521], 126430: [115969, 92243, 141749, 105954, 760], 126921: [111146, 26183, 136353, 136359, 136355], 127098: [73290, 78209, 86833, 4728, 136562], 127108: [141749, 115969, 92243, 102407, 126430], 127132: [93242, 157130, 149612, 97470, 124859], 127136: [8848, 5986, 179813, 162414, 1757], 127202: [108727, 110330, 152284, 78218, 110882], 127204: [105254, 8748, 68444, 71211, 66511], 127298: [66511, 140816, 91784, 26158, 111817], 128089: [131826, 26645, 49735, 172321, 167854], 128197: [5470, 1307, 5135, 7121, 5151], 128512: [170827, 135518, 114678, 74228, 68848], 128542: [144734, 135885, 116529, 112580, 69805], 128594: [143031, 128594, 133712, 84246, 79684], 128914: [25752, 1546, 612, 90890, 130970], 128991: [2495, 43869, 68444, 84187, 8748], 129229: [126142, 90809, 89678, 91266, 84847], 129250: [49688, 151317, 156553, 155812, 109317], 129514: [25752, 1546, 612, 90890, 130970], 129659: [97870, 148482, 129659, 101895, 140237], 129937: [80126, 73741, 26159, 58826, 73876], 130452: [25887, 79684, 94661, 102378, 143031], 130482: [929, 6868, 628, 52604, 118354], 130518: [26183, 111146, 140541, 140481, 126921], 130520: [27619, 100611, 63859, 136556, 131656], 130634: [67923, 27480, 58826, 40723, 73741], 130840: [61692, 97988, 113159, 110591, 3696], 130842: [6294, 122922, 208, 2094, 113345], 130970: [25752, 1546, 34312, 612, 90890], 131013: [113453, 135861, 88812, 111617, 94323], 131023: [4217, 7786, 363, 6453, 3680], 131104: [93022, 32243, 34312, 117109, 128089], 131656: [117887, 453, 69524, 130520, 3593], 131714: [116887, 4632, 109846, 47952, 46865], 131826: [131826, 26645, 49735, 172321, 167854], 132584: [5480, 136353, 170837, 136355, 136359], 132660: [115667, 139747, 6732, 74154, 77414], 132796: [94018, 106491, 112818, 89840, 67923], 133115: [74545, 7171, 722, 146682, 145283], 133217: [166492, 107630, 149146, 95690, 167790], 133377: [4051, 26409, 8137, 161830, 8136], 133645: [4296, 26317, 8981, 1678, 25833], 133712: [53355, 149566, 134004, 108078, 84246], 133716: [3715, 1234, 6314, 63, 173619], 133802: [103810, 118880, 160341, 72424, 78836], 134004: [53355, 149566, 133712, 108078, 84246], 134019: [2495, 4241, 136024, 128991, 145080], 134021: [4168, 528, 139915, 116413, 106883], 134041: [103027, 52, 6765, 7137, 1784], 134326: [25752, 1546, 34312, 612, 90890], 134515: [27513, 172013, 44719, 46862, 164280], 134524: [104141, 40617, 71129, 169982, 72601], 134796: [134796, 90630, 91860, 58425, 102823], 135133: [122922, 106002, 122912, 101864, 122916], 135143: [118696, 79357, 74789, 3054, 86880], 135288: [71438, 113705, 104337, 5028, 179815], 135518: [170827, 128512, 122898, 112804, 108729], 135803: [6095, 26399, 141400, 135815, 26401], 135815: [26401, 36931, 73876, 88327, 73676], 135861: [155820, 131013, 87485, 113453, 101415], 135885: [144734, 112580, 128542, 116529, 62113], 136018: [55444, 26308, 73681, 52579, 134515], 136020: [122898, 136864, 94405, 6664, 96079], 136024: [69746, 84187, 134019, 67508, 188675], 136297: [193587, 99813, 26913, 95004, 136024], 136353: [136353, 136355, 121781, 126921, 167772], 136355: [136353, 136355, 121781, 126921, 167772], 136359: [136353, 136355, 121781, 126921, 167772], 136447: [25752, 585, 612, 90890, 130970], 136449: [98607, 68945, 84414, 84187, 44020], 136469: [25752, 585, 612, 90890, 130970], 136471: [4102, 6408, 98083, 103602, 43708], 136556: [100611, 27619, 87876, 93272, 130520], 136562: [73290, 112290, 102407, 140237, 97870], 136602: [113313, 142366, 89028, 74370, 138610], 136778: [155659, 98836, 528, 106883, 84950], 136864: [122898, 122886, 122922, 111360, 136020], 136958: [167538, 136958, 40478, 7891, 8894], 137345: [2605, 156706, 1785, 53322, 3895], 137517: [91273, 97870, 165075, 148482, 129659], 138036: [84772, 106918, 59022, 87222, 8807], 138186: [106648, 69140, 59604, 7492, 117], 138208: [101884, 127132, 93242, 85025, 157130], 138210: [80126, 129937, 26498, 72694, 140237], 138610: [70208, 89028, 74370, 113313, 97188], 139717: [156706, 105755, 124859, 148709, 113186], 139747: [77414, 115667, 132660, 82152, 74688], 139855: [166492, 107630, 95690, 167790, 159415], 139915: [116413, 98908, 111680, 118814, 4168], 140016: [158528, 103372, 158813, 85788, 166534], 140038: [25752, 1546, 612, 90890, 130970], 140174: [106766, 179709, 152270, 8840, 63179], 140237: [97870, 148482, 129659, 101895, 140237], 140267: [142598, 140267, 48150, 55492, 110591], 140481: [140541, 167772, 157775, 50999, 130518], 140541: [140541, 167772, 157775, 50999, 130518], 140737: [136024, 145080, 91784, 92637, 69746], 140816: [66511, 26158, 91784, 8748, 65037], 140928: [159415, 167790, 91470, 71520, 119068], 141131: [193587, 4289, 4327, 4325, 4323], 141400: [6095, 26399, 141400, 135815, 26401], 141544: [169982, 84414, 163056, 71129, 95473], 141749: [92243, 115969, 126430, 166946, 82378], 141810: [66511, 6992, 3174, 67267, 2596], 141836: [25752, 4040, 34312, 612, 90890], 141844: [89305, 8807, 3608, 105254, 51575], 141994: [188797, 185473, 26198, 40478, 4202], 142366: [138610, 70208, 89028, 74370, 113313], 142424: [113350, 140237, 165075, 97870, 101895], 142444: [99122, 44773, 131826, 62008, 172321], 142488: [27801, 52458, 117895, 152077, 113862], 142550: [32243, 49735, 131826, 117109, 128089], 142558: [148238, 6119, 59026, 142558, 73681], 142598: [142598, 140267, 48150, 55492, 110591], 142997: [120807, 163653, 159849, 42734, 110771], 143031: [143031, 128594, 133712, 84246, 79684], 143365: [32213, 90057, 184253, 65810, 185029], 143367: [179815, 113705, 104337, 71438, 5028], 143511: [7171, 4217, 363, 6453, 3680], 143859: [127204, 7460, 148424, 8748, 68444], 143969: [87485, 93805, 100843, 135861, 89904], 144262: [116413, 98908, 139915, 111680, 118814], 144352: [99005, 875, 7056, 73876, 113416], 144522: [50445, 63826, 112818, 47952, 80162], 144734: [135885, 128542, 112580, 116529, 115122], 145080: [69746, 134019, 2495, 106648, 136024], 145283: [112334, 155168, 166015, 92094, 106839], 145418: [106441, 66371, 72720, 1979, 160565], 145724: [161044, 5919, 158388, 176371, 27074], 146309: [113345, 61818, 26399, 135803, 141400], 146656: [73290, 8848, 5986, 162414, 179813], 146662: [104245, 95543, 170957, 109846, 43869], 146682: [146682, 120807, 163653, 159849, 93721], 147002: [48638, 26317, 87660, 26059, 65037], 147300: [4212, 8771, 50, 73323, 2579], 148172: [155820, 101415, 135861, 103075, 2368], 148238: [148238, 6119, 59026, 142558, 73681], 148424: [78836, 140816, 66511, 91784, 26158], 148482: [97870, 148482, 129659, 101895, 140237], 148652: [115122, 78209, 69784, 86833, 3968], 148709: [113186, 84696, 156706, 139717, 93242], 148881: [8189, 122246, 26743, 117877, 64993], 148956: [159415, 110771, 71520, 111680, 4168], 149011: [51498, 41712, 54910, 73676, 113159], 149146: [98607, 133217, 107630, 167790, 166492], 149330: [40478, 167538, 4202, 188797, 8894], 149406: [87876, 27619, 87222, 146309, 100611], 149566: [53355, 133712, 134004, 108078, 84246], 149612: [97470, 2521, 157407, 93242, 127132], 150254: [122246, 135288, 179815, 108689, 81681], 151311: [2736, 34528, 55156, 7786, 179813], 151317: [155812, 6249, 2472, 4660, 118512], 152077: [156726, 92420, 109578, 91535, 78349], 152081: [122886, 112852, 122922, 63859, 87222], 152091: [71520, 91690, 107630, 166492, 111743], 152270: [179709, 100843, 140174, 158966, 36535], 152284: [159415, 108727, 110330, 78218, 1844], 153236: [163112, 170597, 178111, 74791, 117545], 153408: [25887, 130452, 79684, 94661, 102378], 155064: [114707, 26681, 80846, 149011, 105801], 155168: [166015, 68073, 112334, 92094, 145283], 155589: [134004, 103602, 142550, 48649, 94661], 155659: [98836, 528, 106883, 84950, 119068], 155774: [69746, 43869, 105254, 136024, 2495], 155812: [155812, 6249, 2472, 4660, 118512], 155820: [135861, 101415, 100507, 113453, 152091], 156553: [119068, 136778, 106883, 528, 84950], 156675: [32, 94799, 103, 9005, 113350], 156706: [139717, 105755, 124859, 148709, 113186], 156726: [113862, 85788, 160341, 89028, 70208], 157130: [93242, 127132, 161830, 101884, 134021], 157270: [155812, 6249, 2472, 4660, 118512], 157369: [66511, 5461, 3174, 67267, 2596], 157407: [113416, 99005, 110826, 105755, 97470], 157432: [43558, 113416, 99005, 110826, 157407], 157775: [50999, 167772, 136353, 136355, 136359], 157865: [72701, 111146, 130518, 63859, 26183], 158022: [155812, 6249, 2472, 4660, 118512], 158388: [161044, 5919, 176371, 27074, 26124], 158528: [140016, 103372, 158813, 156726, 166534], 158813: [140016, 158528, 103372, 110771, 148956], 158966: [108727, 8848, 5986, 162414, 179709], 158972: [68073, 3845, 111817, 87304, 65037], 159415: [152284, 167790, 110330, 108727, 166492], 159779: [4333, 4327, 4325, 4323, 4321], 159849: [163653, 120807, 8264, 146682, 42734], 160341: [72424, 58826, 27480, 63826, 80162], 160422: [2106, 50068, 68872, 58876, 979], 160565: [1979, 94018, 93805, 105585, 106441], 160569: [175743, 175705, 134515, 46862, 96606], 160718: [59429, 65810, 32213, 143365, 26686], 161024: [25752, 585, 612, 90890, 130970], 161044: [5919, 158388, 176371, 27074, 26124], 161830: [93242, 127132, 2521, 105755, 124859], 161918: [53453, 5700, 4051, 2368, 8137], 161966: [78218, 95690, 152284, 149146, 166492], 162350: [26681, 141400, 6095, 26399, 135803], 162414: [8848, 179813, 162414, 45382, 6064], 162478: [91690, 71520, 133217, 152091, 77667], 162578: [43869, 4241, 3054, 155774, 69746], 162590: [5470, 5135, 7121, 5151, 8869], 162598: [32743, 6220, 166946, 64231, 96432], 162600: [183897, 177593, 168266, 135143, 25771], 162982: [84187, 42422, 31660, 2117, 3994], 163056: [71129, 169982, 108795, 84414, 95149], 163072: [3287, 6158, 4241, 4154, 3964], 163112: [170597, 178111, 74791, 117545, 153236], 163653: [163653, 120807, 8264, 146682, 42734], 163809: [2139, 117877, 2966, 35347, 8684], 163937: [138610, 70208, 89028, 74370, 113313], 164200: [136355, 136359, 136353, 126921, 121781], 164280: [46862, 172013, 27513, 44719, 134515], 165075: [97870, 148482, 129659, 101895, 140237], 165529: [7299, 6768, 981, 50923, 2546], 165551: [7299, 6768, 981, 50923, 2546], 165639: [163056, 71129, 7845, 8967, 182639], 166015: [155168, 92094, 68073, 106839, 112421], 166024: [88810, 176371, 122916, 152081, 5971], 166492: [107630, 95690, 91690, 100083, 133217], 166526: [117877, 8477, 108689, 104337, 81681], 166534: [74228, 156726, 136602, 109578, 143367], 166568: [90439, 112171, 45186, 4369, 91535], 166946: [141749, 162598, 92243, 115969, 126430], 167296: [55205, 87304, 87660, 3897, 1695], 167538: [167538, 136958, 40478, 7891, 8894], 167706: [7171, 8264, 6453, 3680, 7932], 167732: [32291, 617, 2447, 34528, 34164], 167772: [50999, 157775, 136353, 136355, 136359], 167790: [159415, 107630, 108727, 166492, 110330], 167854: [131826, 26645, 49735, 172321, 167854], 168026: [136864, 53453, 8782, 5700, 32898], 168218: [74553, 101962, 80834, 5618, 4927], 168250: [7202, 110591, 55492, 142598, 140267], 168252: [122920, 122922, 122912, 111360, 122916], 168266: [110882, 162478, 110330, 108727, 90057], 168456: [85025, 110826, 105121, 49688, 7000], 168608: [7299, 6768, 50923, 2546, 971], 168632: [25752, 4040, 34312, 612, 90890], 169670: [841, 7564, 3709, 42723, 8225], 169912: [131826, 26645, 49735, 172321, 167854], 169958: [61011, 69118, 6234, 135288, 108981], 169982: [163056, 84414, 71129, 95473, 44020], 170357: [25752, 4040, 34312, 612, 90890], 170551: [25752, 4040, 34312, 612, 90890], 170597: [163112, 178111, 74791, 117545, 153236], 170827: [135518, 128512, 122898, 114678, 74228], 170837: [121781, 132584, 5480, 72692, 153408], 170957: [104245, 95543, 146662, 109846, 43869], 171251: [7171, 27829, 363, 6453, 3680], 171695: [25752, 1546, 612, 90890, 130970], 171765: [117529, 48774, 187031, 27618, 94780], 171917: [104879, 36276, 350, 3505, 74545], 172013: [44719, 172013, 46862, 164280, 134515], 172215: [25752, 1546, 612, 90890, 130970], 172253: [25752, 1546, 612, 90890, 130970], 172321: [131826, 26645, 49735, 172321, 167854], 172461: [96606, 115203, 105250, 175743, 44719], 172577: [121781, 173351, 1, 53121, 65577], 172585: [89586, 13, 172825, 5109, 5218], 172825: [89586, 13, 172585, 5109, 5218], 173205: [25752, 585, 612, 90890, 130970], 173235: [7171, 4217, 363, 6453, 3680], 173351: [121781, 172577, 1, 53121, 65577], 173619: [3715, 6957, 6314, 63, 2027], 174479: [2446, 26116, 1333, 67186, 52644], 174551: [25752, 585, 612, 90890, 130970], 174909: [585, 612, 90890, 130970, 1516], 175197: [5146, 44243, 2668, 3648, 512], 175475: [136359, 164200, 136355, 53460, 88267], 175705: [175743, 160569, 172461, 114335, 44719], 175743: [175705, 160569, 164280, 96606, 114335], 176371: [122916, 122912, 122922, 168252, 71106], 176389: [2141, 126921, 131656, 43869, 5218], 176415: [112290, 92259, 60950, 109374, 106100], 177285: [71129, 6350, 27155, 168026, 5700], 177593: [7459, 188675, 68073, 158972, 92637], 177763: [4439, 145418, 4202, 106441, 7891], 178111: [163112, 170597, 74791, 117545, 153236], 179053: [5544, 112868, 4966, 1779, 880], 179133: [8645, 177593, 6279, 62792, 8158], 179135: [134796, 90630, 91860, 58425, 102823], 179427: [25752, 1546, 612, 90890, 130970], 179709: [179709, 100843, 140174, 158966, 36535], 179813: [8848, 179813, 162414, 45382, 6064], 179815: [5028, 71438, 104337, 113705, 143367], 179817: [8484, 5995, 5817, 58306, 73], 180265: [7171, 7786, 6453, 3680, 7932], 180297: [66511, 7089, 1060, 3174, 67267], 181315: [4296, 152284, 1678, 25833, 25856], 181413: [193587, 4292, 4329, 4327, 4325], 182297: [72692, 121781, 157775, 167772, 50999], 182639: [44020, 84414, 71129, 95004, 169982], 183227: [25752, 4040, 34312, 612, 90890], 183635: [135518, 57368, 85414, 6574, 7163], 183897: [148881, 8189, 26743, 117877, 122246], 183911: [25752, 4040, 34312, 612, 90890], 184253: [32213, 143365, 78349, 26686, 65810], 184791: [131826, 26645, 49735, 172321, 167854], 184997: [5461, 1060, 3174, 67267, 2596], 185029: [8894, 143365, 90057, 32213, 184253], 185135: [52604, 96432, 128512, 170827, 68848], 185473: [185473, 141994, 4215, 7891, 4202], 186587: [187031, 7891, 40478, 8894, 4202], 187031: [186587, 8894, 7891, 40478, 4202], 187541: [177593, 108090, 152081, 26183, 63859], 188675: [7459, 106648, 92637, 90528, 65037], 188797: [185473, 141994, 4215, 7891, 4202], 191005: [8633, 130518, 1831, 122916, 122912], 193573: [163112, 170597, 178111, 74791, 117545], 193583: [72692, 139855, 182297, 172577, 52435], 193587: [99813, 26913, 95004, 136297, 136024]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def neighborhood_selection(item_user_array, index_to_movie_id, item_similarity_matrix, neighborhood_size=5):\n",
    "    # Initialize an empty dictionary to store item neighborhoods\n",
    "    item_neighborhoods = {}\n",
    "\n",
    "    # Iterate over each item (movie) index in the dataset\n",
    "    for movie_index in range(item_user_array.shape[1]):\n",
    "        # Convert the item index to movie ID\n",
    "        movie_id = index_to_movie_id[movie_index]\n",
    "\n",
    "        # Extract all ratings for the current movie\n",
    "        movie_ratings = item_user_array[:, movie_index]\n",
    "\n",
    "        # Aggregate ratings (e.g., compute the mean rating)\n",
    "        movie_avg_rating = np.mean(movie_ratings)\n",
    "\n",
    "        # Retrieve similarity scores for the current movie\n",
    "        similarity_scores = item_similarity_matrix[movie_index]\n",
    "\n",
    "        # Sort similarity scores in descending order and get indices of most similar items\n",
    "        most_similar_indices = np.argsort(similarity_scores)[::-1][1:neighborhood_size+1]\n",
    "\n",
    "        # Convert indices back to movie IDs to form the neighborhood\n",
    "        neighborhood = [index_to_movie_id[idx] for idx in most_similar_indices]\n",
    "\n",
    "        # Store the neighborhood for the current item in the item_neighborhoods dictionary\n",
    "        item_neighborhoods[movie_id] = neighborhood\n",
    "\n",
    "    return item_neighborhoods\n",
    "\n",
    "# Example usage:\n",
    "item_neighborhoods_train = neighborhood_selection(item_user_array, index_to_movie_id, item_similarity_matrix_train)\n",
    "print(item_neighborhoods_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Rating Prediction\n",
    "\n",
    "- For each target item and user pair where the user hasn't rated the target item:\n",
    "Identify the neighborhood of similar items to the target item.\n",
    "- Predict the rating for the target item using a weighted average of the ratings of the items in its neighborhood, where the weights are the similarities between the items and the target item.\n",
    "- Adjust the prediction based on the user's average rating or other normalization techniques, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>185473</th>\n",
       "      <th>186587</th>\n",
       "      <th>187031</th>\n",
       "      <th>187541</th>\n",
       "      <th>188675</th>\n",
       "      <th>188797</th>\n",
       "      <th>191005</th>\n",
       "      <th>193573</th>\n",
       "      <th>193583</th>\n",
       "      <th>193587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "      <td>4.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>...</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "      <td>4.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         4         9         11        13        15        18      \\\n",
       "userId                                                                          \n",
       "53            5.0       5.0       5.0       5.0       5.0       5.0       5.0   \n",
       "578        4.1875    4.1875    4.1875    4.1875    4.1875    4.1875    4.1875   \n",
       "165           4.0       3.4       3.4       3.4       3.4       3.4       3.4   \n",
       "362           4.0  4.137931  4.137931  4.137931  4.137931  4.137931  4.137931   \n",
       "308      2.555556  2.555556  2.555556       0.5  2.555556  2.555556  2.555556   \n",
       "\n",
       "movieId    20        24        30      ...    185473    186587    187031  \\\n",
       "userId                                 ...                                 \n",
       "53            5.0       5.0       5.0  ...       5.0       5.0       5.0   \n",
       "578        4.1875    4.1875    4.1875  ...    4.1875    4.1875    4.1875   \n",
       "165           3.4       3.4       3.4  ...       3.4       3.4       3.4   \n",
       "362      4.137931  4.137931  4.137931  ...  4.137931  4.137931  4.137931   \n",
       "308      2.555556  2.555556  2.555556  ...  2.555556  2.555556  2.555556   \n",
       "\n",
       "movieId    187541    188675    188797    191005    193573    193583    193587  \n",
       "userId                                                                         \n",
       "53            5.0       5.0       5.0       5.0       5.0       5.0       5.0  \n",
       "578        4.1875    4.1875    4.1875    4.1875    4.1875    4.1875    4.1875  \n",
       "165           3.4       3.4       3.4       3.4       3.4       3.4       3.4  \n",
       "362      4.137931  4.137931  4.137931  4.137931  4.137931  4.137931  4.137931  \n",
       "308      2.555556  2.555556  2.555556  2.555556  2.555556  2.555556  2.555556  \n",
       "\n",
       "[5 rows x 2923 columns]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store predicted ratings\n",
    "predicted_ratings_train = pd.DataFrame(index=train_matrix.index, columns=train_matrix.columns)\n",
    "\n",
    "# Iterate over each user-item pair in the training set\n",
    "for user_id, user_ratings in train_matrix.iterrows():\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        \n",
    "        # Check if the movie has a neighborhood defined\n",
    "        if movie_id in item_neighborhoods_train:\n",
    "            neighborhood = item_neighborhoods_train[movie_id]\n",
    "            \n",
    "            # Filter out movies from the neighborhood that the user has rated in the training set\n",
    "            filtered_neighborhood = [neighbor_movie_id for neighbor_movie_id in neighborhood if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0]\n",
    "            \n",
    "            # Check if there are valid indices in the filtered neighborhood\n",
    "            if len(filtered_neighborhood) > 0:\n",
    "                # Calculate the predicted rating for the target movie based on the neighborhood\n",
    "                neighbor_ratings = [user_ratings.loc[neighbor_movie_id] for neighbor_movie_id in filtered_neighborhood]\n",
    "                \n",
    "                # Calculate the mean rating using only the movies in the neighborhood that have been rated by the user\n",
    "                predicted_rating = np.mean(neighbor_ratings)\n",
    "            else:\n",
    "                # If the filtered neighborhood is empty, assign the mean rating of all movies rated by the user\n",
    "                predicted_rating = user_ratings[user_ratings != 0].mean()\n",
    "            \n",
    "            # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "            predicted_ratings_train.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "# Fill NaN values with mean ratings across all users\n",
    "predicted_ratings_train.fillna(predicted_ratings_train.mean().mean(), inplace=True)\n",
    "\n",
    "# Display the head of the predicted_ratings DataFrame\n",
    "predicted_ratings_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We count the NaN values in the predicted_ratings_train dataframe\n",
    "predicted_ratings_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(user_id, predicted_ratings, df):\n",
    "    \"\"\"\n",
    "    Get top movie recommendations for a given user using predicted ratings.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "        predicted_ratings (pd.DataFrame): DataFrame containing predicted ratings for users and movies.\n",
    "        df (pd.DataFrame): DataFrame containing movie ratings.\n",
    "\n",
    "    Returns:\n",
    "        list: Top movie titles recommended for the user.\n",
    "    \"\"\"\n",
    "    # Ensure that predicted_ratings is a DataFrame\n",
    "    if not isinstance(predicted_ratings, pd.DataFrame):\n",
    "        raise ValueError(\"predicted_ratings must be a pandas DataFrame\")\n",
    "\n",
    "    # Check if the user ID exists in the predicted ratings DataFrame's index\n",
    "    if user_id not in predicted_ratings.index:\n",
    "        # If the user ID doesn't exist, return an empty list\n",
    "        return [\"The user doesn't exist\"]\n",
    "\n",
    "    # Get the predicted ratings for the user\n",
    "    user_predicted_ratings = predicted_ratings.loc[user_id]\n",
    "    \n",
    "    # Filter out the movies that the user has already seen\n",
    "    seen_movies = set(df[df['userId'] == user_id]['movieId'])\n",
    "    unseen_movies = [movie_id for movie_id in user_predicted_ratings.index if movie_id not in seen_movies]\n",
    "    \n",
    "    # Check if there are unseen movies with predicted ratings\n",
    "    if not unseen_movies:\n",
    "        # If all movies have been seen, return an empty list\n",
    "        return []\n",
    "    \n",
    "    # Sort the unseen movies by predicted rating in descending order\n",
    "    sorted_unseen_movies = user_predicted_ratings[unseen_movies].sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top 5 movie titles\n",
    "    top_movie_ids = sorted_unseen_movies.head(5).index.tolist()\n",
    "    \n",
    "    # Get the unique movie titles corresponding to the top movie IDs\n",
    "    top_movie_titles = set(df[df['movieId'].isin(top_movie_ids)]['title'])\n",
    "    \n",
    "    return list(top_movie_titles)[:5]  # Return only the first 5 unique movie titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['How the Grinch Stole Christmas! ',\n",
       "  'Sunshine ',\n",
       "  'Disturbia ',\n",
       "  'Vie en Rose, La (MÃ´me, La) ',\n",
       "  'Toy Story '],\n",
       " ['Closer ',\n",
       "  \"It's a Very Merry Muppet Christmas Movie \",\n",
       "  \"He's Just Not That Into You \",\n",
       "  'Bridges of Madison County, The ',\n",
       "  'Atonement '],\n",
       " ['Flight of the Navigator ',\n",
       "  'True Lies ',\n",
       "  'Rocketeer, The ',\n",
       "  'Mystery of the Third Planet, The (Tayna tretey planety) ',\n",
       "  'Toy Story '],\n",
       " ['Birds, The ',\n",
       "  'Bad Boys ',\n",
       "  'Blade Runner ',\n",
       "  'Exorcist, The ',\n",
       "  'Time Bandits '],\n",
       " ['Harry Potter and the Deathly Hallows: Part 1 ',\n",
       "  'Alice in Wonderland ',\n",
       "  'The Hobbit: The Battle of the Five Armies ',\n",
       "  'Harry Potter and the Half-Blood Prince ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['Excalibur ',\n",
       "  'Riki-Oh: The Story of Ricky (Lik Wong) ',\n",
       "  'Gamer ',\n",
       "  \"Heaven's Prisoners \",\n",
       "  'Old Boy '],\n",
       " ['Harry Potter and the Order of the Phoenix ',\n",
       "  'Sound of Thunder, A ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Unbreakable ',\n",
       "  'Aelita: The Queen of Mars (Aelita) '],\n",
       " ['What Happened Was... ',\n",
       "  'Pump Up the Volume ',\n",
       "  'Burnt by the Sun (Utomlyonnye solntsem) ',\n",
       "  'Larry Crowne ',\n",
       "  'Broken English '],\n",
       " ['Benny & Joon ',\n",
       "  'Dogma ',\n",
       "  'Nina Takes a Lover ',\n",
       "  'Toy Story ',\n",
       "  'As Good as It Gets '],\n",
       " ['Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Basic Instinct ',\n",
       "  'Frantic ',\n",
       "  'Reservoir Dogs ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Shrek ',\n",
       "  'King Kong ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \"],\n",
       " ['Little Girl Who Lives Down the Lane, The ',\n",
       "  'MystÃ¨re Ã  la Tour Eiffel ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Bridges of Madison County, The ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles '],\n",
       " ['Harry Potter and the Order of the Phoenix ',\n",
       "  'Lilo & Stitch ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Toy Story '],\n",
       " ['Dragon Ball Z: Bojack Unbound (Doragon bÃ´ru Z 9: Ginga girigiri!! Butchigiri no sugoi yatsu) ',\n",
       "  'Legends of the Fall ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'United States of Leland, The ',\n",
       "  'Mystery of the Third Planet, The (Tayna tretey planety) '],\n",
       " ['Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Adventures of Pinocchio, The ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'Muppet Treasure Island ',\n",
       "  'River Wild, The '],\n",
       " ['Killing Fields, The ',\n",
       "  'Swingers ',\n",
       "  'Leprechaun 2 ',\n",
       "  'Leprechaun 4: In Space ',\n",
       "  'Bad Santa '],\n",
       " ['Pianist, The ',\n",
       "  'True Romance ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  \"Pirates of the Caribbean: Dead Man's Chest \",\n",
       "  'Basic Instinct '],\n",
       " ['Rio Bravo ',\n",
       "  'Nine Months ',\n",
       "  \"Schindler's List \",\n",
       "  'Butch Cassidy and the Sundance Kid ',\n",
       "  'Reservoir Dogs '],\n",
       " ['King and I, The ',\n",
       "  'Whiplash ',\n",
       "  '8 Mile ',\n",
       "  'Cast Away ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Gotti ',\n",
       "  'True Romance ',\n",
       "  'United States of Leland, The ',\n",
       "  'Old Boy ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Black Mask (Hak hap) ',\n",
       "  'Protector, The (a.k.a. Warrior King) (Tom yum goong) ',\n",
       "  'Maze Runner: Scorch Trials ',\n",
       "  'Lord of the Rings: The Return of the King, The ',\n",
       "  'Iron Man 2 '],\n",
       " ['Turning Point, The ',\n",
       "  'Henry: Portrait of a Serial Killer ',\n",
       "  'Stand by Me ',\n",
       "  'Camille ',\n",
       "  'As Good as It Gets '],\n",
       " ['Generation X ',\n",
       "  'The Hunger Games: Mockingjay - Part 2 ',\n",
       "  'Logan ',\n",
       "  'Power/Rangers ',\n",
       "  'Kizumonogatari III: Cold Blood '],\n",
       " ['Runaway Bride ',\n",
       "  'Valley Girl ',\n",
       "  'Groundhog Day ',\n",
       "  'Damsels in Distress ',\n",
       "  'Getting Even with Dad '],\n",
       " ['Crush ', 'Camille ', 'Sidekicks ', 'Social Network, The ', 'Cocoon '],\n",
       " ['Running Man, The ',\n",
       "  'Red Planet ',\n",
       "  'Sting, The ',\n",
       "  'RoboCop ',\n",
       "  'Serial Mom '],\n",
       " ['Daddy Day Camp ',\n",
       "  'Naked Gun 33 1/3: The Final Insult ',\n",
       "  'Iron Monkey (Siu nin Wong Fei-hung ji: Tit Ma Lau) ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  \"It's All Gone Pete Tong \"],\n",
       " ['Twister ',\n",
       "  'Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'True Lies ',\n",
       "  'River Wild, The '],\n",
       " ['Mars Attacks! ',\n",
       "  'Letters from Iwo Jima ',\n",
       "  'Wild Wild West ',\n",
       "  'Men in Black (a.k.a. MIB) ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['How the Grinch Stole Christmas! ',\n",
       "  'Disturbia ',\n",
       "  'Hoax, The ',\n",
       "  'Toy Story ',\n",
       "  'Grindhouse '],\n",
       " ['Gravity ',\n",
       "  'District 9 ',\n",
       "  'Transformers: Revenge of the Fallen ',\n",
       "  '300 ',\n",
       "  'I Am Legend '],\n",
       " ['Turning Point, The ',\n",
       "  'Say Anything... ',\n",
       "  'Family Man, The ',\n",
       "  'Bull Durham ',\n",
       "  'L.A. Story '],\n",
       " ['Trainspotting ',\n",
       "  'Ice Age ',\n",
       "  'Yellow Sea, The (a.k.a. The Murderer) (Hwanghae) ',\n",
       "  'Basic Instinct ',\n",
       "  'Godfather: Part III, The '],\n",
       " ['Trainspotting ',\n",
       "  'Byzantium ',\n",
       "  \"Can't Buy Me Love \",\n",
       "  'Burnt by the Sun (Utomlyonnye solntsem) ',\n",
       "  'Something New '],\n",
       " ['Easy Rider ',\n",
       "  'High Fidelity ',\n",
       "  'Shining, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'As Good as It Gets '],\n",
       " ['Young Victoria, The ',\n",
       "  'Pianist, The ',\n",
       "  'Never Let Me Go ',\n",
       "  'Shrek ',\n",
       "  'Rocketeer, The '],\n",
       " ['Holes ',\n",
       "  'Goodfellas ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'True Romance ',\n",
       "  'Spy Kids '],\n",
       " ['Trainspotting ',\n",
       "  'Batman ',\n",
       "  'True Romance ',\n",
       "  \"Schindler's List \",\n",
       "  'Reservoir Dogs '],\n",
       " ['Batman ',\n",
       "  'Shining, The ',\n",
       "  'Alice in Wonderland ',\n",
       "  'Captain Phillips ',\n",
       "  'In Time '],\n",
       " ['Running Man, The ',\n",
       "  'French Connection, The ',\n",
       "  '2001: A Space Odyssey ',\n",
       "  'Godzilla ',\n",
       "  'Starship Troopers '],\n",
       " ['Sneakers ',\n",
       "  'Ice Age ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Spaceballs '],\n",
       " ['Cinderella ',\n",
       "  'Finding Neverland ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \"],\n",
       " ['Hunchback of Notre Dame, The ',\n",
       "  'Kazaam ',\n",
       "  'Wiz, The ',\n",
       "  'Toy Story ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Silence of the Lambs, The ',\n",
       "  'True Romance ',\n",
       "  'Frantic ',\n",
       "  'Fahrenheit 9/11 ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Blues Brothers 2000 ',\n",
       "  'Mortal Kombat: The Journey Begins ',\n",
       "  'Captain Phillips ',\n",
       "  'Bungo Stray Dogs: Dead Apple ',\n",
       "  'Town, The '],\n",
       " ['Riki-Oh: The Story of Ricky (Lik Wong) ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  \"Heaven's Prisoners \",\n",
       "  'Sidekicks ',\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Shining, The ',\n",
       "  'King Kong ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Almost Famous ',\n",
       "  'Righteous Kill '],\n",
       " ['In the Land of Women ',\n",
       "  'I Now Pronounce You Chuck and Larry ',\n",
       "  'Hitch ',\n",
       "  'Bridesmaids ',\n",
       "  'Zack and Miri Make a Porno '],\n",
       " ['Project X ',\n",
       "  'Goodfellas ',\n",
       "  'Bad Boys ',\n",
       "  \"Schindler's List \",\n",
       "  'Big Lebowski, The '],\n",
       " ['Pianist, The ',\n",
       "  'Bull Durham ',\n",
       "  'Mighty Aphrodite ',\n",
       "  'L.A. Story ',\n",
       "  'As Good as It Gets '],\n",
       " ['Game, The ',\n",
       "  'Lucky Number Slevin ',\n",
       "  'Sting, The ',\n",
       "  'Trainspotting ',\n",
       "  'True Romance '],\n",
       " ['Batman ',\n",
       "  'True Romance ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Gran Torino ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Plunkett & MaCleane ',\n",
       "  'Natural, The ',\n",
       "  'Babylon 5: The River of Souls ',\n",
       "  'Self/less ',\n",
       "  'Alles Inklusive '],\n",
       " ['Trainspotting ',\n",
       "  'True Romance ',\n",
       "  \"Schindler's List \",\n",
       "  'Jakob the Liar ',\n",
       "  'Star Trek V: The Final Frontier '],\n",
       " ['Trainspotting ',\n",
       "  'Bad Boys ',\n",
       "  \"Schindler's List \",\n",
       "  'Jackie Brown ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Pianist, The ',\n",
       "  'Heavenly Creatures ',\n",
       "  'Losing Isaiah ',\n",
       "  \"Things to Do in Denver When You're Dead \",\n",
       "  'Primal Fear '],\n",
       " ['Thing, The ',\n",
       "  'Godzilla ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Star Trek: First Contact '],\n",
       " ['Ledge, The ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  'Star Trek II: The Wrath of Khan ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " ['Leningrad Cowboys Go America ',\n",
       "  \"Hard Day's Night, A \",\n",
       "  'Brown Sugar ',\n",
       "  'Garage Days ',\n",
       "  'Meet Me in St. Louis '],\n",
       " ['Born in East L.A. ',\n",
       "  'Steal Big, Steal Little ',\n",
       "  'Kevin Hart: Laugh at My Pain ',\n",
       "  'Campus Man ',\n",
       "  'Out Cold '],\n",
       " ['Hard Core Logo ',\n",
       "  'Man with the Iron Fists, The ',\n",
       "  \"Bridget Jones's Baby \",\n",
       "  'Batman v Superman: Dawn of Justice ',\n",
       "  'I Love You, Beth Cooper '],\n",
       " ['Sisterhood of the Traveling Pants, The ',\n",
       "  'Road Home, The (Wo de fu qin mu qin) ',\n",
       "  'A Home at the End of the World ',\n",
       "  'Indochine ',\n",
       "  'Wuthering Heights '],\n",
       " ['Pianist, The ',\n",
       "  'General Died at Dawn, The ',\n",
       "  'United States of Leland, The ',\n",
       "  'Hoax, The ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['Waterworld ',\n",
       "  'Last Klezmer: Leopold Kozlowski, His Life and Music, The ',\n",
       "  'Peacemaker, The ',\n",
       "  'Rocketeer, The ',\n",
       "  'Anaconda '],\n",
       " ['How the Grinch Stole Christmas! ',\n",
       "  'Sunshine ',\n",
       "  'Disturbia ',\n",
       "  'Vie en Rose, La (MÃ´me, La) ',\n",
       "  'Toy Story '],\n",
       " ['Maya Lin: A Strong Clear Vision ',\n",
       "  'Bad Boys ',\n",
       "  'Jackie Brown ',\n",
       "  'Catwalk ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Goodfellas ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'Bad Boys ',\n",
       "  'True Romance ',\n",
       "  'American Beauty '],\n",
       " ['Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Shining, The ',\n",
       "  'Usual Suspects, The ',\n",
       "  'American Beauty ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Bridges of Madison County, The ',\n",
       "  'Old Boy ',\n",
       "  'Above the Rim '],\n",
       " ['Cuckoo, The (Kukushka) ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'Interview ',\n",
       "  'Sweetie ',\n",
       "  'Once Upon a Time in the Midlands '],\n",
       " ['Waterworld ', 'Cutthroat Island ', 'Twister ', 'Die Hard 2 ', 'Rock, The '],\n",
       " ['Project X ',\n",
       "  'Napoleon Dynamite ',\n",
       "  'Specialist, The ',\n",
       "  \"Heaven's Prisoners \",\n",
       "  'American Pie 2 '],\n",
       " ['Bakuman ',\n",
       "  'Conspiracy Theory ',\n",
       "  'Memories of Me ',\n",
       "  \"Decline of the American Empire, The (DÃ©clin de l'empire amÃ©ricain, Le) \",\n",
       "  'Love, Simon '],\n",
       " ['Argo ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Life of Pi ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Cinderella ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Shrek the Third ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) '],\n",
       " ['Ice Age ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  'Shrek ',\n",
       "  '101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \"],\n",
       " ['Love in the Afternoon ',\n",
       "  'Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Bootleggers ',\n",
       "  'Little Voice ',\n",
       "  'Toy Story '],\n",
       " ['Man with the Iron Fists, The ',\n",
       "  'Hunchback of Notre Dame, The ',\n",
       "  'Pinocchio ',\n",
       "  'Peter Pan ',\n",
       "  'Nightmare Before Christmas, The '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Cuckoo, The (Kukushka) ',\n",
       "  'Killing Fields, The ',\n",
       "  'Power/Rangers '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Shining, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['African Queen, The ',\n",
       "  'Knocked Up ',\n",
       "  'Natural, The ',\n",
       "  '42nd Street ',\n",
       "  'Chicago '],\n",
       " ['Silver Linings Playbook ',\n",
       "  '50/50 ',\n",
       "  'Cloverfield ',\n",
       "  'Old Boy ',\n",
       "  'Alles Inklusive '],\n",
       " ['Byzantium ',\n",
       "  'Black Swan ',\n",
       "  'Old Boy ',\n",
       "  'Others, The ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Trainspotting ',\n",
       "  'Batman ',\n",
       "  'Bad Boys ',\n",
       "  \"Schindler's List \",\n",
       "  'American Beauty '],\n",
       " ['Intouchables ',\n",
       "  \"Schindler's List \",\n",
       "  'The Ridiculous 6 ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'DÃ©jÃ  Vu (Deja Vu) '],\n",
       " ['Confidence ',\n",
       "  'Time to Kill, A ',\n",
       "  'In July (Im Juli) ',\n",
       "  'Shrek ',\n",
       "  'Camille '],\n",
       " ['Shining, The ',\n",
       "  'Basic Instinct ',\n",
       "  'Frantic ',\n",
       "  'Amer ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Say Anything... ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'L.A. Story ',\n",
       "  'As Good as It Gets ',\n",
       "  'Bend It Like Beckham '],\n",
       " ['Hard Core Logo ',\n",
       "  'Crush ',\n",
       "  \"Can't Buy Me Love \",\n",
       "  'High and Low (Tengoku to jigoku) ',\n",
       "  'Itty Bitty Titty Committee '],\n",
       " ['Incredibles 2 ',\n",
       "  'Loving Vincent ',\n",
       "  'Gosford Park ',\n",
       "  'Jimmy Hollywood ',\n",
       "  'Kung Fu Hustle (Gong fu) '],\n",
       " ['Tombstone ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Dangerous Ground ',\n",
       "  'Losing Isaiah '],\n",
       " ['Cinderella ',\n",
       "  'My Girl 2 ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Shrek the Third ',\n",
       "  'Forever Young '],\n",
       " ['Turning Point, The ',\n",
       "  'Crying Game, The ',\n",
       "  'Final Destination 3 ',\n",
       "  'Stand by Me ',\n",
       "  'Slumdog Millionaire '],\n",
       " ['Cinderella ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Hitch ',\n",
       "  'Mickey Blue Eyes ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) '],\n",
       " ['Bad Boys ',\n",
       "  \"Schindler's List \",\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Ice Age ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  'Basic Instinct ',\n",
       "  'Frantic ',\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Waterworld ',\n",
       "  'Of Mice and Men ',\n",
       "  'Leprechaun 2 ',\n",
       "  'Leprechaun 3 ',\n",
       "  'Meet the Feebles '],\n",
       " ['Black Mask (Hak hap) ',\n",
       "  'Abyss, The ',\n",
       "  'Escape from New York ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'Rocketeer, The '],\n",
       " ['Maniac Cop ',\n",
       "  \"Pee-wee's Big Adventure \",\n",
       "  'Disturbia ',\n",
       "  'Ladyhawke ',\n",
       "  'Toy Story '],\n",
       " ['Laggies ',\n",
       "  'Shining, The ',\n",
       "  'Pulp Fiction ',\n",
       "  \"Valentine's Day \",\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Layer Cake ',\n",
       "  'Goodfellas ',\n",
       "  'Captain America ',\n",
       "  'Three Outlaw Samurai (Sanbiki no samurai) ',\n",
       "  'Silverado '],\n",
       " ['Naked Gun 33 1/3: The Final Insult ',\n",
       "  'Star Trek II: The Wrath of Khan ',\n",
       "  'Shrek ',\n",
       "  '101 Dalmatians ',\n",
       "  'Rocketeer, The '],\n",
       " ['South Pacific ',\n",
       "  'Misery ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Deep End of the Ocean, The ',\n",
       "  'Africa: The Serengeti '],\n",
       " ['Running Man, The ',\n",
       "  '2001: A Space Odyssey ',\n",
       "  'Unforgiven ',\n",
       "  'Sling Blade ',\n",
       "  'Star Trek: First Contact '],\n",
       " ['Man with the Iron Fists, The ',\n",
       "  'Once Were Warriors ',\n",
       "  'Star Trek: First Contact ',\n",
       "  \"Things to Do in Denver When You're Dead \",\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " ['Turning Point, The ',\n",
       "  'Pulp Fiction ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Mobsters ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Hell Ride ',\n",
       "  'Great Silence, The (Grande silenzio, Il) ',\n",
       "  'Delirium ',\n",
       "  'Adventures of Buckaroo Banzai Across the 8th Dimension, The ',\n",
       "  'Voyage to the Bottom of the Sea '],\n",
       " ['Ice Age ',\n",
       "  'Shrek ',\n",
       "  '101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Slumdog Millionaire ',\n",
       "  'Jakob the Liar ',\n",
       "  '8 Mile ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Pursuit of Happyness, The '],\n",
       " ['Princess Mononoke (Mononoke-hime) ',\n",
       "  'Laputa: Castle in the Sky (TenkÃ» no shiro Rapyuta) ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'Kizumonogatari III: Cold Blood ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'MystÃ¨re Ã  la Tour Eiffel ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le '],\n",
       " ['Closer ',\n",
       "  'Much Ado About Nothing ',\n",
       "  'Young Victoria, The ',\n",
       "  'Say Anything... ',\n",
       "  'Best Man, The (Testimone dello sposo, Il) '],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'Intouchables ',\n",
       "  '50/50 ',\n",
       "  'King Kong ',\n",
       "  'Princess Mononoke (Mononoke-hime) '],\n",
       " ['United States of Leland, The ',\n",
       "  '8 Mile ',\n",
       "  'Frantic ',\n",
       "  'Gosford Park ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Much Ado About Nothing ',\n",
       "  'Trainspotting ',\n",
       "  'Frantic ',\n",
       "  'Toy Story ',\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " ['Pineapple Express ',\n",
       "  'Batman ',\n",
       "  'Legend of Sleepy Hollow, The ',\n",
       "  'Money Pit, The ',\n",
       "  'Evil Dead II (Dead by Dawn) '],\n",
       " ['Guarding Tess ', 'Bad Boys ', 'Frantic ', 'For Keeps ', 'Quiet Man, The '],\n",
       " ['Closer ',\n",
       "  'Intouchables ',\n",
       "  'Trainspotting ',\n",
       "  'Trapped in Paradise ',\n",
       "  'Decalogue, The (Dekalog) '],\n",
       " ['Project X ',\n",
       "  'JFK ',\n",
       "  'Starship Troopers ',\n",
       "  'Blues Brothers, The ',\n",
       "  'Spaceballs '],\n",
       " ['Addams Family Reunion ',\n",
       "  'Purgatory ',\n",
       "  'Android ',\n",
       "  '50/50 ',\n",
       "  'Brave New World '],\n",
       " ['Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'No Game No Life: Zero ',\n",
       "  'Great Gatsby, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Nine Months ',\n",
       "  'When Harry Met Sally... ',\n",
       "  'Sleepless in Seattle '],\n",
       " ['Iron Man ', 'Network ', 'What Lies Beneath ', 'Die Hard 2 ', 'Elysium '],\n",
       " ['Hard Core Logo ',\n",
       "  'Help, The ',\n",
       "  'Sting, The ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Steve Jobs '],\n",
       " ['High Fidelity ',\n",
       "  'Requiem for a Dream ',\n",
       "  'Jakob the Liar ',\n",
       "  'Cast Away ',\n",
       "  'Lords of Flatbush, The '],\n",
       " ['Silver Linings Playbook ',\n",
       "  'Unedited Footage of a Bear ',\n",
       "  'Letters from Iwo Jima ',\n",
       "  'True Romance ',\n",
       "  'Goonies, The '],\n",
       " ['Batman/Superman Movie, The ',\n",
       "  'Sword Art Online The Movie: Ordinal Scale ',\n",
       "  'Bad Boys ',\n",
       "  'Kizumonogatari III: Cold Blood ',\n",
       "  'Bad Santa '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Loving Vincent ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le '],\n",
       " ['Murder by Numbers ',\n",
       "  'Bad Boys ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'Hoax, The ',\n",
       "  'Crow, The '],\n",
       " ['Goodfellas ',\n",
       "  \"Schindler's List \",\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Big Lebowski, The '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Anaconda ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Primal Fear '],\n",
       " ['Little Girl Who Lives Down the Lane, The ',\n",
       "  'Nine Months ',\n",
       "  'Tombstone ',\n",
       "  'Four Weddings and a Funeral ',\n",
       "  'American President, The '],\n",
       " ['Twister ',\n",
       "  'Wild Wild West ',\n",
       "  'Almost Famous ',\n",
       "  \"Hitchhiker's Guide to the Galaxy, The \",\n",
       "  'Cocoon '],\n",
       " ['2001: A Space Odyssey ',\n",
       "  'Killing Fields, The ',\n",
       "  'Stand by Me ',\n",
       "  'Tombstone ',\n",
       "  'Blues Brothers, The '],\n",
       " ['Tigger Movie, The ',\n",
       "  'Center Stage ',\n",
       "  \"It's All Gone Pete Tong \",\n",
       "  'My Neighbor Totoro (Tonari no Totoro) ',\n",
       "  \"Everybody's Famous! (Iedereen beroemd!) \"],\n",
       " ['Elf ',\n",
       "  'Too Late for Tears ',\n",
       "  'Shrek ',\n",
       "  'Kazaam ',\n",
       "  'Nightmare Before Christmas, The '],\n",
       " ['Ice Age ',\n",
       "  'Shrek ',\n",
       "  '101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pulp Fiction ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Frantic ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Pulp Fiction ',\n",
       "  'Hoax, The ',\n",
       "  'Mobsters ',\n",
       "  'American Beauty ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Project X ',\n",
       "  'True Romance ',\n",
       "  'Bad Boys ',\n",
       "  'Shining, The ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Entrapment ',\n",
       "  'Murder by Numbers ',\n",
       "  'Bootleggers ',\n",
       "  'Jackie Brown ',\n",
       "  'Crow, The '],\n",
       " ['What Lies Beneath ',\n",
       "  'A Street Cat Named Bob ',\n",
       "  'Story of Us, The ',\n",
       "  'Deep End of the Ocean, The ',\n",
       "  'Sliver '],\n",
       " ['Nine Months ',\n",
       "  'NeverEnding Story, The ',\n",
       "  'Ready to Wear (Pret-A-Porter) ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Getting Even with Dad '],\n",
       " ['Ice Age ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  '101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['French Connection, The ',\n",
       "  'Killing Fields, The ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Little Voice '],\n",
       " ['King and I, The ',\n",
       "  'Casper ',\n",
       "  'Whiplash ',\n",
       "  'Laputa: Castle in the Sky (TenkÃ» no shiro Rapyuta) ',\n",
       "  'NeverEnding Story II: The Next Chapter, The '],\n",
       " ['Cinderella ',\n",
       "  'Lilo & Stitch ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'American Beauty '],\n",
       " ['Cutthroat Island ',\n",
       "  'Specialist, The ',\n",
       "  'Riki-Oh: The Story of Ricky (Lik Wong) ',\n",
       "  'Die Hard 2 ',\n",
       "  'Rock, The '],\n",
       " ['Miss Sloane ', 'Lara Croft: Tomb Raider ', 'Eragon ', 'Red Dragon ', '21 '],\n",
       " ['Killing Fields, The ',\n",
       "  'Shaft ',\n",
       "  'Children of the Revolution ',\n",
       "  'Shanghai Knights ',\n",
       "  \"Jane Austen's Mafia! \"],\n",
       " ['...All the Marbles ',\n",
       "  'Band of Outsiders (Bande Ã  part) ',\n",
       "  'Grand Budapest Hotel, The ',\n",
       "  'Alphaville (Alphaville, une Ã©trange aventure de Lemmy Caution) ',\n",
       "  'Meet the Feebles '],\n",
       " ['Napoleon Dynamite ',\n",
       "  'Big Daddy ',\n",
       "  'Robin Hood: Men in Tights ',\n",
       "  'Starship Troopers ',\n",
       "  'American Pie 2 '],\n",
       " ['Confidence ',\n",
       "  'Conspiracy Theory ',\n",
       "  'Public Eye, The ',\n",
       "  'That Demon Within ',\n",
       "  'Toy Story '],\n",
       " ['Turning Point, The ',\n",
       "  'Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'High Fidelity ',\n",
       "  'Camille ',\n",
       "  'Shakespeare in Love '],\n",
       " ['Just Cause ',\n",
       "  'Little Girl Who Lives Down the Lane, The ',\n",
       "  'Nine Months ',\n",
       "  'Children of the Revolution ',\n",
       "  'Sliver '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Cutthroat Island ',\n",
       "  'Pianist, The ',\n",
       "  'Die Hard 2 ',\n",
       "  'Rock, The '],\n",
       " ['Hard Core Logo ',\n",
       "  \"Monty Python's And Now for Something Completely Different \",\n",
       "  'Bad Boys ',\n",
       "  'Hudsucker Proxy, The ',\n",
       "  'Blues Brothers, The '],\n",
       " ['Game, The ',\n",
       "  \"Ocean's Thirteen \",\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Little Shop of Horrors ',\n",
       "  'Righteous Kill '],\n",
       " ['Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Pulp Fiction ',\n",
       "  'Basic Instinct ',\n",
       "  'Frantic ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Pianist, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Reservoir Dogs ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Little Girl Who Lives Down the Lane, The ',\n",
       "  'Adventures of Pinocchio, The ',\n",
       "  'Shrek ',\n",
       "  'Rock, The ',\n",
       "  'Anaconda '],\n",
       " ['Running Man, The ',\n",
       "  'Pi ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Syriana ',\n",
       "  'Rock, The '],\n",
       " ['Silence of the Lambs, The ',\n",
       "  'True Romance ',\n",
       "  'Frantic ',\n",
       "  'Iron Man 2 ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Birds, The ',\n",
       "  'Shining, The ',\n",
       "  'Riki-Oh: The Story of Ricky (Lik Wong) ',\n",
       "  'Father of the Bride ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Beyond Borders ',\n",
       "  'From Here to Eternity ',\n",
       "  'African Queen, The ',\n",
       "  \"I Know Where I'm Going! \",\n",
       "  'Lawrence of Arabia '],\n",
       " ['Batman ', 'JFK ', 'Bad Boys ', 'Jackie Brown ', 'Slumdog Millionaire '],\n",
       " ['Silver Linings Playbook ',\n",
       "  \"Schindler's List \",\n",
       "  'Camille ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Shakespeare in Love '],\n",
       " ['Goodfellas ', 'Bad Boys ', 'Shining, The ', 'Frantic ', 'Reservoir Dogs '],\n",
       " ['Ice Age ',\n",
       "  'Mission: Impossible III ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Toy Story ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Goodfellas ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  \"Schindler's List \",\n",
       "  'American Beauty ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Gotti ',\n",
       "  'Lucky Number Slevin ',\n",
       "  'Jackie Brown ',\n",
       "  'Mobsters ',\n",
       "  'Gran Torino '],\n",
       " ['101 Dalmatians ', 'Camille ', 'Shanghai Knights ', 'Babel ', 'Toy Story '],\n",
       " ['Turning Point, The ',\n",
       "  'Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'High Fidelity ',\n",
       "  'Crying Game, The ',\n",
       "  'Shakespeare in Love '],\n",
       " ['Beyond Borders ',\n",
       "  'African Queen, The ',\n",
       "  'Crying Game, The ',\n",
       "  'Broken English ',\n",
       "  \"I Know Where I'm Going! \"],\n",
       " ['Serendipity ', 'Fever Pitch ', 'Gran Torino ', 'Longest Day, The ', 'Eva '],\n",
       " ['Batman/Superman Movie, The ',\n",
       "  'Sword Art Online The Movie: Ordinal Scale ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Naked Gun 33 1/3: The Final Insult ',\n",
       "  'American Werewolf in London, An ',\n",
       "  'Coneheads ',\n",
       "  'Legend of Sleepy Hollow, The ',\n",
       "  'Major Payne '],\n",
       " ['Harry Potter and the Order of the Phoenix ',\n",
       "  'Harry Potter and the Deathly Hallows: Part 1 ',\n",
       "  'Blues Brothers, The ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Spaceballs '],\n",
       " ['Birds, The ',\n",
       "  'Little Girl Who Lives Down the Lane, The ',\n",
       "  'Misery ',\n",
       "  'Conspiracy Theory ',\n",
       "  'Austin Powers in Goldmember '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " ['Blues Brothers 2000 ',\n",
       "  'Shrek ',\n",
       "  'Grand Budapest Hotel, The ',\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl ',\n",
       "  'Broken English '],\n",
       " ['Help, The ',\n",
       "  'Okja ',\n",
       "  'Dallas Buyers Club ',\n",
       "  'Adventures of Pinocchio, The ',\n",
       "  'Social Network, The '],\n",
       " ['1984 (Nineteen Eighty-Four) ',\n",
       "  'Maze Runner, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) ',\n",
       "  'Camille ',\n",
       "  'Garden of Words, The (Koto no ha no niwa) '],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'Running Man, The ',\n",
       "  'Sound of Thunder, A ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'X-Men: The Last Stand '],\n",
       " ['Big Daddy ',\n",
       "  'League of Extraordinary Gentlemen, The (a.k.a. LXG) ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'And Starring Pancho Villa as Himself ',\n",
       "  '21 Jump Street '],\n",
       " ['Lucky Number Slevin ',\n",
       "  'Goodfellas ',\n",
       "  'Plunkett & MaCleane ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Elite Squad (Tropa de Elite) '],\n",
       " ['Trainspotting ',\n",
       "  'Spider-Man ',\n",
       "  'Dogma ',\n",
       "  'Teenage Mutant Ninja Turtles II: The Secret of the Ooze ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Ice Age ',\n",
       "  'Shrek ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Lucky Number Slevin ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Starship Troopers ',\n",
       "  'Blues Brothers, The ',\n",
       "  'Spaceballs '],\n",
       " ['Confidence ',\n",
       "  'Star Trek II: The Wrath of Khan ',\n",
       "  'Madame Sousatzka ',\n",
       "  'American Graffiti ',\n",
       "  'Public Eye, The '],\n",
       " ['Patton ',\n",
       "  'Stand by Me ',\n",
       "  'Guest from the Future (Gostya iz buduschego) ',\n",
       "  'Unbreakable ',\n",
       "  'Time Bandits '],\n",
       " ['Cinderella ',\n",
       "  'Elf ',\n",
       "  'Nightmare Before Christmas, The ',\n",
       "  'Toy Story ',\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Bolt '],\n",
       " ['Addams Family Reunion ',\n",
       "  'Mission: Impossible - Ghost Protocol ',\n",
       "  'Transformers: Revenge of the Fallen ',\n",
       "  'Cloud Atlas ',\n",
       "  'Iron Man 2 '],\n",
       " ['Ice Age ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Shrek the Third ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Toy Story '],\n",
       " ['Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Wallace & Gromit: The Wrong Trousers ',\n",
       "  \"Schindler's List \",\n",
       "  'Crimewave ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Ice Age ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Children of the Revolution ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Twelfth Night ',\n",
       "  \"Can't Buy Me Love \",\n",
       "  'Secret Life of Walter Mitty, The ',\n",
       "  'Loose Cannons ',\n",
       "  'Harold & Kumar Escape from Guantanamo Bay '],\n",
       " ['Howards End ',\n",
       "  'Tombstone ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Blade Runner ',\n",
       "  'Sliver '],\n",
       " ['Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Hoax, The ',\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Major Dundee ',\n",
       "  'Guardians '],\n",
       " ['Prince of Egypt, The ',\n",
       "  'Hunchback of Notre Dame, The ',\n",
       "  'Happy Gilmore ',\n",
       "  'Hell Ride ',\n",
       "  'Toy Story '],\n",
       " ['Star Trek II: The Wrath of Khan ',\n",
       "  'Specialist, The ',\n",
       "  'Abyss, The ',\n",
       "  'Speed ',\n",
       "  'Rock, The '],\n",
       " ['Angels & Demons ',\n",
       "  'Cast Away ',\n",
       "  'Harvard Man ',\n",
       "  'Rain Man ',\n",
       "  'Into the Wild '],\n",
       " ['Citizen Kane ',\n",
       "  'Searchers, The ',\n",
       "  'Great Silence, The (Grande silenzio, Il) ',\n",
       "  'Tombstone ',\n",
       "  'Best Years of Our Lives, The '],\n",
       " ['Cinderella ',\n",
       "  'Old Boy ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Righteous Kill '],\n",
       " ['NeverEnding Story, The ',\n",
       "  'Miracle on 34th Street ',\n",
       "  'Dangerous Ground ',\n",
       "  'Dark Crystal, The ',\n",
       "  'Mystery of the Third Planet, The (Tayna tretey planety) '],\n",
       " ['Cinderella ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Lilo & Stitch ',\n",
       "  'Shrek the Third ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) '],\n",
       " ['Trainspotting ',\n",
       "  'Batman ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'Hoax, The ',\n",
       "  'Mobsters '],\n",
       " ['Closer ',\n",
       "  'Trainspotting ',\n",
       "  'Jackie Brown ',\n",
       "  'American Beauty ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Goodfellas ',\n",
       "  'Abyss, The ',\n",
       "  'Jackie Brown ',\n",
       "  'American Beauty ',\n",
       "  'Rock, The '],\n",
       " ['Elizabeth ',\n",
       "  \"Schindler's List \",\n",
       "  'Key Largo ',\n",
       "  'Deep End of the Ocean, The ',\n",
       "  'Incredibly True Adventure of Two Girls in Love, The '],\n",
       " ['French Connection, The ',\n",
       "  'Crying Game, The ',\n",
       "  'Sunshine ',\n",
       "  'Basic Instinct ',\n",
       "  'Surrogates '],\n",
       " ['What Lies Beneath ',\n",
       "  'Requiem for a Dream ',\n",
       "  'Stand by Me ',\n",
       "  'Jakob the Liar ',\n",
       "  'To Kill a Mockingbird '],\n",
       " ['V. I. Warshawski ',\n",
       "  'Whiplash ',\n",
       "  'Double Trouble ',\n",
       "  'Kuffs ',\n",
       "  'Louis C.K.: Live at The Comedy Store '],\n",
       " ['Sharkwater ',\n",
       "  'Breakdown ',\n",
       "  'JFK ',\n",
       "  'Long Kiss Goodnight, The ',\n",
       "  'Basic Instinct '],\n",
       " ['Man with the Iron Fists, The ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  '101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Elf ',\n",
       "  'Shining, The ',\n",
       "  'Jackie Brown ',\n",
       "  'Wild Wild West ',\n",
       "  'Men in Black (a.k.a. MIB) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Pulp Fiction ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le '],\n",
       " ['Naked Gun 33 1/3: The Final Insult ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Laputa: Castle in the Sky (TenkÃ» no shiro Rapyuta) ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'Kizumonogatari III: Cold Blood '],\n",
       " ['Trainspotting ',\n",
       "  'Goodfellas ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'Big Lebowski, The ',\n",
       "  'Anaconda '],\n",
       " ['Sword of Doom, The (Dai-bosatsu tÃ´ge) ',\n",
       "  'Renaissance ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Righteous Kill ',\n",
       "  'Loose Cannons '],\n",
       " ['Bulworth ',\n",
       "  'L.A. Story ',\n",
       "  'As Good as It Gets ',\n",
       "  'Me, Myself & Irene ',\n",
       "  'Bend It Like Beckham '],\n",
       " ['Mars Attacks! ',\n",
       "  'School of Rock ',\n",
       "  'Blues Brothers 2000 ',\n",
       "  \"It's All Gone Pete Tong \",\n",
       "  \"Everybody's Famous! (Iedereen beroemd!) \"],\n",
       " ['Napoleon Dynamite ',\n",
       "  'Big Daddy ',\n",
       "  'Robin Hood: Men in Tights ',\n",
       "  'Irony of Fate, or Enjoy Your Bath! (Ironiya sudby, ili S legkim parom!) ',\n",
       "  'Bio-Dome '],\n",
       " ['30 Minutes or Less ',\n",
       "  'V. I. Warshawski ',\n",
       "  'Camille ',\n",
       "  'Burn After Reading ',\n",
       "  'Kuffs '],\n",
       " ['Thor: Ragnarok ',\n",
       "  'Avengers: Infinity War - Part I ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Almost Famous ',\n",
       "  'Doctor Strange '],\n",
       " ['Game, The ',\n",
       "  'Lucky Number Slevin ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Killing Fields, The ',\n",
       "  'Mobsters '],\n",
       " ['Bad Boys ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Frantic ',\n",
       "  'Old Boy ',\n",
       "  'Godfather: Part III, The '],\n",
       " ['Gotti ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Mobsters ',\n",
       "  'Above the Rim ',\n",
       "  'Gran Torino '],\n",
       " ['French Connection, The ',\n",
       "  'Godzilla ',\n",
       "  'Exorcist, The ',\n",
       "  'Others, The ',\n",
       "  'As Good as It Gets '],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'Dragon Ball Z: Bio-Broly (Doragon bÃ´ru Z 11: SÃ»pÃ¢ senshi gekiha! Katsu no wa ore da) ',\n",
       "  'Starship Troopers ',\n",
       "  'Sidekicks ',\n",
       "  'Gran Torino '],\n",
       " ['Rio Bravo ',\n",
       "  \"Ocean's Thirteen \",\n",
       "  'Fever Pitch ',\n",
       "  'My Big Fat Greek Wedding ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Game, The ',\n",
       "  'Blues Brothers 2000 ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Wiz, The '],\n",
       " ['Dune ', 'Birds, The ', 'Transformers ', 'Spider-Man ', 'Children of Men '],\n",
       " ['Thing, The ',\n",
       "  'Godzilla ',\n",
       "  'High and Low (Tengoku to jigoku) ',\n",
       "  'Touch of Evil ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Hard Core Logo ',\n",
       "  'Argo ',\n",
       "  'Vicky Cristina Barcelona ',\n",
       "  'Fourth Protocol, The ',\n",
       "  'Alles Inklusive '],\n",
       " ['Twister ',\n",
       "  'High Fidelity ',\n",
       "  'Stand by Me ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Sleepless in Seattle '],\n",
       " ['Hard Core Logo ',\n",
       "  'Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Cutthroat Island ',\n",
       "  'Waterworld ',\n",
       "  'Casper '],\n",
       " ['Young Victoria, The ',\n",
       "  'Descent ',\n",
       "  'Good Son, The ',\n",
       "  'Atonement ',\n",
       "  'One Missed Call (Chakushin ari) '],\n",
       " ['High Art ',\n",
       "  'Mudbound ',\n",
       "  'Happy-Go-Lucky ',\n",
       "  'Bulworth ',\n",
       "  'Once Upon a Time in the Midlands '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Shining, The ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Shining, The ',\n",
       "  'Day of the Doctor, The ',\n",
       "  'Spy Game ',\n",
       "  'Kizumonogatari III: Cold Blood ',\n",
       "  'Alles Inklusive '],\n",
       " ['Friday ',\n",
       "  'Raising Arizona ',\n",
       "  'Outland ',\n",
       "  'Bowfinger ',\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " [\"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Wow! A Talking Fish! '],\n",
       " [\"Ocean's Thirteen \",\n",
       "  'Bad Boys ',\n",
       "  'Red Dragon ',\n",
       "  'Righteous Kill ',\n",
       "  'Crow, The '],\n",
       " ['Goodfellas ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Bad Boys ',\n",
       "  'Jackie Brown ',\n",
       "  'American Beauty '],\n",
       " ['Rush Hour ',\n",
       "  'Houseguest ',\n",
       "  'Wild Wild West ',\n",
       "  'Coneheads ',\n",
       "  'Brady Bunch Movie, The '],\n",
       " ['Help, The ', \"Ocean's Thirteen \", 'Oblivion ', 'Duplicity ', 'Elysium '],\n",
       " ['Casper ',\n",
       "  'Song of the Sea ',\n",
       "  'Beauty and the Beast: The Enchanted Christmas ',\n",
       "  'Dumbo ',\n",
       "  'Wiz, The '],\n",
       " ['Project X ',\n",
       "  'Usual Suspects, The ',\n",
       "  'True Lies ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'River Wild, The '],\n",
       " ['True Romance ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Broken English ',\n",
       "  'Big Lebowski, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Indochine ',\n",
       "  'Black Swan ',\n",
       "  'Gosford Park ',\n",
       "  'Others, The ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Turning Point, The ',\n",
       "  'Happy Gilmore ',\n",
       "  'High Fidelity ',\n",
       "  'My Cousin Vinny ',\n",
       "  'Dr. Dolittle '],\n",
       " ['South Pacific ',\n",
       "  'Shining, The ',\n",
       "  'Pulp Fiction ',\n",
       "  'Reservoir Dogs ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Ice Age ',\n",
       "  'NeverEnding Story, The ',\n",
       "  'Dark Crystal, The ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Shrek the Third '],\n",
       " ['Batman/Superman Movie, The ',\n",
       "  'Saved! ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'Kizumonogatari III: Cold Blood ',\n",
       "  'Wiz, The '],\n",
       " ['Pineapple Express ',\n",
       "  'Help, The ',\n",
       "  'Intouchables ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Dying Young '],\n",
       " ['Project X ',\n",
       "  'Trainspotting ',\n",
       "  'Goodfellas ',\n",
       "  'Jackie Brown ',\n",
       "  'American Beauty '],\n",
       " ['Game, The ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'True Romance ',\n",
       "  'Jackie Brown ',\n",
       "  'Godfather: Part III, The '],\n",
       " ['School of Rock ',\n",
       "  'Pretty Persuasion ',\n",
       "  'Sidekicks ',\n",
       "  'Mobsters ',\n",
       "  'Serial Mom '],\n",
       " ['Cutthroat Island ',\n",
       "  'Twister ',\n",
       "  'Shining, The ',\n",
       "  'Die Hard 2 ',\n",
       "  'Rock, The '],\n",
       " ['Waterworld ',\n",
       "  'Twister ',\n",
       "  'Shining, The ',\n",
       "  'Rock, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['How the Grinch Stole Christmas! ',\n",
       "  'Little Shop of Horrors ',\n",
       "  'Legend of Sleepy Hollow, The ',\n",
       "  'Lady and the Tramp ',\n",
       "  'Sleeping Beauty '],\n",
       " ['Ice Age ',\n",
       "  'Adventures of Pinocchio, The ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Muppet Treasure Island ',\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Byzantium ',\n",
       "  'Black Swan ',\n",
       "  'Cube ',\n",
       "  'Others, The ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['Hard Core Logo ',\n",
       "  'Bootleggers ',\n",
       "  \"Pirates of the Caribbean: Dead Man's Chest \",\n",
       "  'Lara Croft: Tomb Raider ',\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl '],\n",
       " ['Turning Point, The ',\n",
       "  'Thirteenth Floor, The ',\n",
       "  'Game, The ',\n",
       "  'Frantic ',\n",
       "  'Righteous Kill '],\n",
       " [\"Emperor's New Groove, The \",\n",
       "  'Fantastic Beasts and Where to Find Them ',\n",
       "  'Eragon ',\n",
       "  'Phineas and Ferb the Movie: Across the 2nd Dimension ',\n",
       "  'Extraordinary Adventures of AdÃ¨le Blanc-Sec, The '],\n",
       " ['Turning Point, The ',\n",
       "  'Elf ',\n",
       "  'Camille ',\n",
       "  'James and the Giant Peach ',\n",
       "  'Nightmare Before Christmas, The '],\n",
       " ['Shining, The ',\n",
       "  'American Haunting, An ',\n",
       "  'Cold Comfort Farm ',\n",
       "  'Dumbo ',\n",
       "  'Chicago '],\n",
       " ['Sting, The ',\n",
       "  'Darkest Hour ',\n",
       "  'Invasion of the Body Snatchers ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Day the Earth Stood Still, The '],\n",
       " ['In July (Im Juli) ',\n",
       "  'High Fidelity ',\n",
       "  'Goonies, The ',\n",
       "  'Ladyhawke ',\n",
       "  'Toy Story '],\n",
       " ['Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Wallace & Gromit: The Wrong Trousers ',\n",
       "  'Crying Game, The ',\n",
       "  'Bootleggers ',\n",
       "  'Hoax, The '],\n",
       " ['Fame ',\n",
       "  'Chorus Line, A ',\n",
       "  'Left Behind: The Movie ',\n",
       "  'Tigger Movie, The ',\n",
       "  'Toy Story '],\n",
       " ['Shining, The ',\n",
       "  'Pulp Fiction ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Reservoir Dogs ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Much Ado About Nothing ',\n",
       "  'Proof ',\n",
       "  'Sideways ',\n",
       "  'Bulworth ',\n",
       "  'Larry Crowne '],\n",
       " ['Twister ',\n",
       "  'Angels & Demons ',\n",
       "  'Spy Game ',\n",
       "  'True Lies ',\n",
       "  'River Wild, The '],\n",
       " ['Say Anything... ',\n",
       "  'Flashdance ',\n",
       "  'Coyote Ugly ',\n",
       "  'Reality Bites ',\n",
       "  'Forever Young '],\n",
       " ['Swing Kids ',\n",
       "  'Bowling for Columbine ',\n",
       "  'Dangerous Minds ',\n",
       "  'Natural, The ',\n",
       "  'Missing in Action '],\n",
       " ['Project X ',\n",
       "  'Abyss, The ',\n",
       "  'Starship Troopers ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Rocketeer, The '],\n",
       " ['Dragon Ball Z: Bojack Unbound (Doragon bÃ´ru Z 9: Ginga girigiri!! Butchigiri no sugoi yatsu) ',\n",
       "  'Ninja Scroll (JÃ»bei ninpÃ»chÃ´) ',\n",
       "  'Willy Wonka & the Chocolate Factory ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['When Harry Met Sally... ',\n",
       "  'Dogma ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Four Weddings and a Funeral ',\n",
       "  'Toy Story '],\n",
       " ['Get on Up ',\n",
       "  'Dirty Harry ',\n",
       "  'Dick Tracy ',\n",
       "  'Butch Cassidy and the Sundance Kid ',\n",
       "  'Toy Story '],\n",
       " ['Pulp Fiction ',\n",
       "  'So I Married an Axe Murderer ',\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Reservoir Dogs ',\n",
       "  'Primal Fear '],\n",
       " ['Waterworld ',\n",
       "  'Nine Months ',\n",
       "  'Goodfellas ',\n",
       "  'American Beauty ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'Casper ',\n",
       "  'Never Let Me Go ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Syriana '],\n",
       " ['NeverEnding Story, The ',\n",
       "  'Whiplash ',\n",
       "  'Alice in Wonderland ',\n",
       "  'Dark Crystal, The ',\n",
       "  'Blind Side, The  '],\n",
       " ['Mars Attacks! ',\n",
       "  'Hard Core Logo ',\n",
       "  'Blues Brothers 2000 ',\n",
       "  'School of Rock ',\n",
       "  'Adventures of Milo and Otis, The (Koneko monogatari) '],\n",
       " ['Project X ',\n",
       "  'French Connection, The ',\n",
       "  'Batman ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Plunkett & MaCleane '],\n",
       " ['High Fidelity ',\n",
       "  'My Girl 2 ',\n",
       "  'Bulworth ',\n",
       "  'Best Man, The (Testimone dello sposo, Il) ',\n",
       "  'Itty Bitty Titty Committee '],\n",
       " ['Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Black Mask (Hak hap) ',\n",
       "  'Escape from New York ',\n",
       "  'True Lies ',\n",
       "  'River Wild, The '],\n",
       " ['Iron Man ', 'Eden Lake ', 'Stand by Me ', 'Jakob the Liar ', 'Cube '],\n",
       " ['Whiplash ',\n",
       "  'Dragon Ball: The Path to Power (Doragon bÃ´ru: SaikyÃ´ e no michi) ',\n",
       "  'Alice in Wonderland ',\n",
       "  'Shrek the Third ',\n",
       "  'Dark Crystal, The '],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'King Kong ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \"],\n",
       " ['Anger Management ',\n",
       "  \"Wayne's World 2 \",\n",
       "  'Whole Nine Yards, The ',\n",
       "  'Gosford Park ',\n",
       "  'American Pie 2 '],\n",
       " ['Plunkett & MaCleane ',\n",
       "  'Steve Jobs ',\n",
       "  'Inside Llewyn Davis ',\n",
       "  'Great Gatsby, The ',\n",
       "  'Dark Shadows '],\n",
       " ['Eyes Wide Shut ',\n",
       "  'I Love You, Beth Cooper ',\n",
       "  'Mobsters ',\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Gran Torino '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Trainspotting ',\n",
       "  'Alice in Wonderland ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Shrek ',\n",
       "  'Byzantium ',\n",
       "  'King Kong ',\n",
       "  \"Pirates of the Caribbean: Dead Man's Chest \",\n",
       "  'Others, The '],\n",
       " ['Game, The ',\n",
       "  \"Ocean's Thirteen \",\n",
       "  'Long Goodbye, The ',\n",
       "  'Killing Fields, The ',\n",
       "  'Hedwig and the Angry Inch '],\n",
       " ['Say Anything... ',\n",
       "  'Defending Your Life ',\n",
       "  'Bootleggers ',\n",
       "  \"Look Who's Talking \",\n",
       "  'Lawrence of Arabia '],\n",
       " ['Iron Man ',\n",
       "  'What Lies Beneath ',\n",
       "  'Requiem for a Dream ',\n",
       "  'Stand by Me ',\n",
       "  'To Kill a Mockingbird '],\n",
       " ['Batman ',\n",
       "  'Houseguest ',\n",
       "  'Zapped! ',\n",
       "  'Big Lebowski, The ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Turning Point, The ',\n",
       "  'Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'High Fidelity ',\n",
       "  'Crying Game, The ',\n",
       "  'As Good as It Gets '],\n",
       " ['Naked Gun 33 1/3: The Final Insult ',\n",
       "  'Nine Months ',\n",
       "  'Sgt. Bilko ',\n",
       "  'Coneheads ',\n",
       "  'American Pie 2 '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Patton ',\n",
       "  '2001: A Space Odyssey ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le '],\n",
       " ['The Man from U.N.C.L.E. ',\n",
       "  'Manhunter ',\n",
       "  'Apollo 18 ',\n",
       "  'Camille ',\n",
       "  'Toy Story '],\n",
       " [\"America's Sweethearts \",\n",
       "  'Casper ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Crimewave ',\n",
       "  'Dying Young '],\n",
       " ['Mars Attacks! ',\n",
       "  'Wild Wild West ',\n",
       "  'Starship Troopers ',\n",
       "  'Blues Brothers, The ',\n",
       "  'Spaceballs '],\n",
       " ['Client, The ',\n",
       "  '101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Big Lebowski, The ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Hard Core Logo ',\n",
       "  'Citizen Kane ',\n",
       "  'Goodfellas ',\n",
       "  'Stand by Me ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['Zootopia ',\n",
       "  \"Ender's Game \",\n",
       "  'Jurassic World ',\n",
       "  'Edge of Tomorrow ',\n",
       "  'Star Trek '],\n",
       " ['Black Book (Zwartboek) ',\n",
       "  'Sunshine ',\n",
       "  'Hoax, The ',\n",
       "  'Toy Story ',\n",
       "  'Grindhouse '],\n",
       " ['Birds, The ',\n",
       "  'Goodfellas ',\n",
       "  'High and Low (Tengoku to jigoku) ',\n",
       "  'Exorcist, The ',\n",
       "  'Patlabor: The Movie (KidÃ´ keisatsu patorebÃ¢: The Movie) '],\n",
       " ['Project X ',\n",
       "  'Little Girl Who Lives Down the Lane, The ',\n",
       "  'Boyhood ',\n",
       "  'MystÃ¨re Ã  la Tour Eiffel ',\n",
       "  'Princess Mononoke (Mononoke-hime) '],\n",
       " ['Project X ',\n",
       "  'Goodfellas ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'Jackie Brown ',\n",
       "  'Usual Suspects, The '],\n",
       " ['Lethal Weapon 3 ',\n",
       "  'Bad Boys ',\n",
       "  \"Heaven's Prisoners \",\n",
       "  'Star Trek: First Contact ',\n",
       "  'Training Day '],\n",
       " ['Sex Drive ',\n",
       "  'Lucky Number Slevin ',\n",
       "  'Serious Man, A ',\n",
       "  'Jakob the Liar ',\n",
       "  \"Child's Play 3 \"],\n",
       " ['Napoleon Dynamite ',\n",
       "  'Old School ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Abyss, The ',\n",
       "  'Rocketeer, The '],\n",
       " ['Vicky Cristina Barcelona ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Alles Inklusive '],\n",
       " [\"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) ',\n",
       "  'Harry Potter and the Half-Blood Prince ',\n",
       "  'Wiz, The '],\n",
       " ['Ken Park ',\n",
       "  'Man for All Seasons, A ',\n",
       "  'Last Orders ',\n",
       "  'Avalon ',\n",
       "  'Fat Girl (Ã€ ma soeur!) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Bad Boys ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'We Own the Night ',\n",
       "  'American Beauty '],\n",
       " ['Gravity ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Lord of the Rings: The Return of the King, The ',\n",
       "  'Great Gatsby, The ',\n",
       "  'Gran Torino '],\n",
       " ['Dune ',\n",
       "  'Guest from the Future (Gostya iz buduschego) ',\n",
       "  'Blade Runner ',\n",
       "  'Day the Earth Stood Still, The ',\n",
       "  'Time Bandits '],\n",
       " ['Crying Game, The ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  '8 Mile ',\n",
       "  'Shrek the Third ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) '],\n",
       " ['Daddy Day Camp ',\n",
       "  'Sting, The ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Serial Mom '],\n",
       " ['Byzantium ',\n",
       "  'Black Swan ',\n",
       "  'Dark Crystal, The ',\n",
       "  'Others, The ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Pulp Fiction ',\n",
       "  \"Heaven's Prisoners \",\n",
       "  'Usual Suspects, The ',\n",
       "  'Four Weddings and a Funeral ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Star Trek II: The Wrath of Khan ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Abyss, The ',\n",
       "  'Star Trek VI: The Undiscovered Country ',\n",
       "  'Rocketeer, The '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  \"Widows' Peak \",\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le '],\n",
       " ['Love in the Afternoon ',\n",
       "  'Pianist, The ',\n",
       "  \"Muriel's Wedding \",\n",
       "  'Bowfinger ',\n",
       "  'Flirting With Disaster '],\n",
       " [\"Ocean's Thirteen \",\n",
       "  'Bowling for Columbine ',\n",
       "  'Camille ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Face in the Crowd, A '],\n",
       " ['Eden Lake ',\n",
       "  'Game, The ',\n",
       "  'Old Boy ',\n",
       "  'Red Dragon ',\n",
       "  'Godfather: Part III, The '],\n",
       " ['Turning Point, The ',\n",
       "  'Hudsucker Proxy, The ',\n",
       "  'Slumdog Millionaire ',\n",
       "  \"Young Poisoner's Handbook, The \",\n",
       "  'Fahrenheit 9/11 '],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'Dallas Buyers Club ',\n",
       "  'Birdman: Or (The Unexpected Virtue of Ignorance) ',\n",
       "  'King Kong ',\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl '],\n",
       " ['Scary Movie 3 ',\n",
       "  'Messenger: The Story of Joan of Arc, The ',\n",
       "  'Angels & Demons ',\n",
       "  'Gran Torino ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Willy Wonka & the Chocolate Factory ',\n",
       "  'Shrek ',\n",
       "  'Die Hard 2 ',\n",
       "  'Tombstone ',\n",
       "  'Rock, The '],\n",
       " ['Black Mask (Hak hap) ',\n",
       "  'Die Hard 2 ',\n",
       "  'Sound of Thunder, A ',\n",
       "  'Lord of the Rings: The Return of the King, The ',\n",
       "  'Children of Men '],\n",
       " [\"Ocean's Thirteen \",\n",
       "  'Basic Instinct ',\n",
       "  'Frantic ',\n",
       "  'Old Boy ',\n",
       "  'Broken English '],\n",
       " ['Long Goodbye, The ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Day the Earth Stood Still, The ',\n",
       "  'Wiz, The ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['Happy-Go-Lucky ',\n",
       "  'Black Swan ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Babel ',\n",
       "  'We Own the Night '],\n",
       " ['Elf ',\n",
       "  'Incredibles 2 ',\n",
       "  'Whiplash ',\n",
       "  'Dragon Ball: The Path to Power (Doragon bÃ´ru: SaikyÃ´ e no michi) ',\n",
       "  'Spy Kids '],\n",
       " ['Incredibles 2 ',\n",
       "  'Loving Vincent ',\n",
       "  'Cast Away ',\n",
       "  'Pursuit of Happyness, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Trainspotting ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'True Romance ',\n",
       "  'Lilo & Stitch ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) '],\n",
       " ['Little Girl Who Lives Down the Lane, The ',\n",
       "  'Eyes Wide Shut ',\n",
       "  \"Schindler's List \",\n",
       "  'Mission: Impossible - Ghost Protocol ',\n",
       "  'Jurassic World '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Groundhog Day ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Fried Green Tomatoes ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Byzantium ',\n",
       "  'Sunshine ',\n",
       "  'Alles Inklusive '],\n",
       " [\"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Four Weddings and a Funeral ',\n",
       "  'Rock, The ',\n",
       "  'Sleepless in Seattle '],\n",
       " ['Running Man, The ',\n",
       "  'Life of Pi ',\n",
       "  'And Starring Pancho Villa as Himself ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Margin Call '],\n",
       " [\"Pee-wee's Big Adventure \",\n",
       "  'My Fair Lady ',\n",
       "  'Meet Me in St. Louis ',\n",
       "  '42nd Street ',\n",
       "  'Broken English '],\n",
       " ['Mars Attacks! ',\n",
       "  \"Elevator to the Gallows (a.k.a. Frantic) (Ascenseur pour l'Ã©chafaud) \",\n",
       "  'Jackie Brown ',\n",
       "  'Fracture ',\n",
       "  'Godfather: Part III, The '],\n",
       " ['Project X ',\n",
       "  'Birds, The ',\n",
       "  \"Rosemary's Baby \",\n",
       "  'Usual Suspects, The ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles '],\n",
       " ['Twister ', 'Maniac Cop ', 'Batman ', 'True Lies ', 'Toy Story '],\n",
       " ['Goodfellas ', 'Batman ', 'Bad Boys ', \"Schindler's List \", 'Jackie Brown '],\n",
       " ['Hard Core Logo ',\n",
       "  'Vicky Cristina Barcelona ',\n",
       "  'Darkest Hour ',\n",
       "  'Plunkett & MaCleane ',\n",
       "  'Colonel Chabert, Le '],\n",
       " ['Pianist, The ',\n",
       "  'Goodfellas ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'Larry Crowne ',\n",
       "  'Afonya '],\n",
       " ['Sting, The ',\n",
       "  'Short Circuit ',\n",
       "  'Sidekicks ',\n",
       "  \"Hitchhiker's Guide to the Galaxy, The \",\n",
       "  'Wiz, The '],\n",
       " ['Rio Bravo ',\n",
       "  'Tales from the Darkside: The Movie ',\n",
       "  \"Child's Play 2 \",\n",
       "  'Pi ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['How the Grinch Stole Christmas! ',\n",
       "  'Sunshine ',\n",
       "  'Are We Done Yet? ',\n",
       "  'Hoax, The ',\n",
       "  'Toy Story '],\n",
       " ['Turning Point, The ',\n",
       "  'Crying Game, The ',\n",
       "  'Basic Instinct ',\n",
       "  'Elysium ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Birds, The ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'Frida ',\n",
       "  'Exorcist, The ',\n",
       "  'Hedwig and the Angry Inch '],\n",
       " ['Sneakers ',\n",
       "  'Dogma ',\n",
       "  \"Pirates of the Caribbean: Dead Man's Chest \",\n",
       "  'Starship Troopers ',\n",
       "  'Ladyhawke '],\n",
       " ['Project X ',\n",
       "  'Napoleon Dynamite ',\n",
       "  'I Heart Huckabees ',\n",
       "  'Usual Suspects, The ',\n",
       "  'BrÃ¼no (Bruno) '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Colonel Chabert, Le ',\n",
       "  'Them (Ils) '],\n",
       " ['Intouchables ',\n",
       "  \"Can't Buy Me Love \",\n",
       "  'Coyote Ugly ',\n",
       "  'Chocolat ',\n",
       "  \"Things to Do in Denver When You're Dead \"],\n",
       " ['Pianist, The ',\n",
       "  '8 Mile ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \",\n",
       "  'Pursuit of Happyness, The ',\n",
       "  'Rain Man '],\n",
       " ['French Connection, The ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'When Harry Met Sally... ',\n",
       "  'Godzilla ',\n",
       "  'Star Trek: First Contact '],\n",
       " ['Byzantium ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'Gran Torino ',\n",
       "  'Guest from the Future (Gostya iz buduschego) ',\n",
       "  'Garden of Words, The (Koto no ha no niwa) '],\n",
       " ['Frisco Kid, The ',\n",
       "  'Think Like a Man ',\n",
       "  'Jakob the Liar ',\n",
       "  'Er ist wieder da ',\n",
       "  'Get Smart '],\n",
       " ['Specialist, The ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Riki-Oh: The Story of Ricky (Lik Wong) ',\n",
       "  'Frantic ',\n",
       "  'Crow, The '],\n",
       " ['Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Deep End of the Ocean, The ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'Away from Her ',\n",
       "  'River Wild, The '],\n",
       " ['Ice Age ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Shrek the Third ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Toy Story '],\n",
       " ['Eden Lake ',\n",
       "  'Sphere ',\n",
       "  'Basic Instinct ',\n",
       "  'Reservoir Dogs ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Birds, The ',\n",
       "  'Short Circuit ',\n",
       "  'Coneheads ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles ',\n",
       "  'Adventures of Buckaroo Banzai Across the 8th Dimension, The '],\n",
       " ['Willy Wonka & the Chocolate Factory ',\n",
       "  'Song of the Sea ',\n",
       "  'Alice in Wonderland ',\n",
       "  'James and the Giant Peach ',\n",
       "  'Beauty and the Beast: The Enchanted Christmas '],\n",
       " ['Bulworth ',\n",
       "  \"Muriel's Wedding \",\n",
       "  'Face in the Crowd, A ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Ernest & CÃ©lestine (Ernest et CÃ©lestine) '],\n",
       " ['Goodfellas ',\n",
       "  \"Schindler's List \",\n",
       "  'Jackie Brown ',\n",
       "  'Sliver ',\n",
       "  'Reservoir Dogs '],\n",
       " [\"Child's Play 2 \",\n",
       "  'Shrooms ',\n",
       "  'Laputa: Castle in the Sky (TenkÃ» no shiro Rapyuta) ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) '],\n",
       " ['Hard Core Logo ',\n",
       "  'Guest from the Future (Gostya iz buduschego) ',\n",
       "  'Day the Earth Stood Still, The ',\n",
       "  'Butch Cassidy and the Sundance Kid ',\n",
       "  'Bad Santa '],\n",
       " ['Batman ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'Elite Squad (Tropa de Elite) ',\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan '],\n",
       " ['Alex and Emma ',\n",
       "  'Sideways ',\n",
       "  'Baxter, The ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Larry Crowne '],\n",
       " ['Demolition Man ',\n",
       "  'Shining, The ',\n",
       "  'Unforgiven ',\n",
       "  'Four Weddings and a Funeral ',\n",
       "  'American President, The '],\n",
       " ['Shining, The ',\n",
       "  'Groundhog Day ',\n",
       "  \"Muriel's Wedding \",\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Power/Rangers '],\n",
       " ['Beyond Borders ',\n",
       "  'Henry: Portrait of a Serial Killer ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Crimewave ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Naked Gun 33 1/3: The Final Insult ',\n",
       "  'Old School ',\n",
       "  'Waterboy, The ',\n",
       "  'Bio-Dome ',\n",
       "  'Black Sheep '],\n",
       " ['Gravity ',\n",
       "  'Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Bridesmaids ',\n",
       "  'Day the Earth Stood Still, The ',\n",
       "  'Bolt '],\n",
       " ['Silence of the Lambs, The ',\n",
       "  'True Romance ',\n",
       "  'Die Hard 2 ',\n",
       "  'Rock, The ',\n",
       "  'Crow, The '],\n",
       " ['Requiem for a Dream ',\n",
       "  'Die Hard 2 ',\n",
       "  'Usual Suspects, The ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Almost Famous ']]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_recommendations = []\n",
    "\n",
    "# Iterate over each row (user) in the train_matrix\n",
    "for user_id in train_matrix.index:\n",
    "    # Get the actual user ID corresponding to the user index\n",
    "    recommendations = get_top_recommendations(user_id, predicted_ratings_train, df)\n",
    "    top_recommendations.append(recommendations)\n",
    "\n",
    "# Output: List of top movie recommendations for each user in the train matrix\n",
    "top_recommendations\n",
    "\n",
    "# print size of top_recommendations\n",
    "len(top_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Model Evaluation\n",
    "- We evaluate the performance of the ItemKNN algorithm using appropriate evaluation metrics such as Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
    "- Split the dataset into training and testing sets to assess the model's predictive accuracy on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 2923)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(389, 2923)"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "\n",
    "predicted_ratings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Training Data: 0.7196990469744047\n",
      "Root Mean Squared Error (RMSE) on Training Data: 0.9729005196085564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_model(train_matrix, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance on the training data.\n",
    "\n",
    "    Parameters:\n",
    "        train_matrix (numpy.ndarray): Item-user matrix from the training data.\n",
    "        predicted_ratings (pandas.DataFrame or numpy.ndarray): Predicted ratings DataFrame or array for the training data.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Absolute Error (MAE) on the training data.\n",
    "        float: Root Mean Squared Error (RMSE) on the training data.\n",
    "    \"\"\"\n",
    "    # Convert predicted_ratings to a numpy array if it's a DataFrame\n",
    "    if isinstance(predicted_ratings, pd.DataFrame):\n",
    "        predicted_ratings = predicted_ratings.to_numpy()\n",
    "\n",
    "    # Ensure train_matrix and predicted_ratings have the same shape\n",
    "    assert train_matrix.shape == predicted_ratings.shape, \"Shapes of train_matrix and predicted_ratings are not consistent.\"\n",
    "\n",
    "    # Initialize lists to store true and predicted ratings\n",
    "    true_ratings = []\n",
    "    pred_ratings = []\n",
    "\n",
    "    # Iterate over each user and their ratings\n",
    "    for user_id, user_ratings in enumerate(train_matrix):\n",
    "        for movie_id, rating in enumerate(user_ratings):\n",
    "            # Skip unrated movies\n",
    "            if rating == 0:\n",
    "                continue\n",
    "\n",
    "            # Check if the indices are within the bounds of the predicted ratings array\n",
    "            if user_id < predicted_ratings.shape[0] and movie_id < predicted_ratings.shape[1]:\n",
    "                # Get the predicted rating for the corresponding movie\n",
    "                pred_rating = predicted_ratings[user_id, movie_id]\n",
    "\n",
    "                # Append the true and predicted ratings\n",
    "                true_ratings.append(rating)\n",
    "                pred_ratings.append(pred_rating)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    true_ratings = np.array(true_ratings)\n",
    "    pred_ratings = np.array(pred_ratings)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(true_ratings, pred_ratings)\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, pred_ratings))\n",
    "\n",
    "    return mae, rmse\n",
    "\n",
    "# Assuming train is the numpy array or DataFrame representing the item-user matrix\n",
    "# Assuming predicted_ratings_train is the DataFrame or numpy array representing the predicted ratings for the training data\n",
    "\n",
    "# Evaluate the model\n",
    "mae, rmse = evaluate_model(train, predicted_ratings_train)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Training Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Training Data:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Parameter Tuning\n",
    "- Experiment with different parameters such as similarity threshold, neighborhood size, and similarity metric to optimize the performance of the ItemKNN algorithm.\n",
    "- Use cross-validation or other techniques to tune these parameters and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import Necessary Libraries:**\n",
    "   - We import the required libraries for performing grid search cross-validation (`GridSearchCV`), creating custom scorers (`make_scorer`), and utilizing the `NearestNeighbors` algorithm.\n",
    "\n",
    "2. **Define Cosine Similarity Function:**\n",
    "   - We define a custom function `cosine_similarity` to compute the cosine similarity between two vectors. This function calculates the dot product of the vectors and divides it by the product of their norms.\n",
    "\n",
    "3. **Define Custom Scorer:**\n",
    "   - We create a custom scorer `cosine_similarity_scorer` using `make_scorer`, which enables us to use cosine similarity as the scoring metric during grid search cross-validation.\n",
    "\n",
    "4. **Define Parameter Grid:**\n",
    "   - We specify a parameter grid `param_grid` containing the hyperparameters to be tuned. In this case, we're tuning the number of neighbors (`n_neighbors`) and the distance metric (`metric`) for the `NearestNeighbors` algorithm.\n",
    "\n",
    "5. **Initialize NearestNeighbors Model:**\n",
    "   - We initialize the `NearestNeighbors` model without specifying any hyperparameters.\n",
    "\n",
    "6. **Create GridSearchCV Object:**\n",
    "   - We create a `GridSearchCV` object named `grid_search` with the specified parameter grid, cross-validation strategy (5-fold cross-validation), and custom scoring metric (`cosine_similarity_scorer`).\n",
    "\n",
    "7. **Fit the Data:**\n",
    "   - We fit the `item_user_matrix` data to the `grid_search` object to perform hyperparameter tuning. `item_user_matrix` typically contains the item-item similarity matrix computed using collaborative filtering techniques.\n",
    "\n",
    "8. **Get Best Hyperparameters:**\n",
    "   - After fitting the data, we retrieve the best hyperparameters selected by the grid search using the `best_params_` attribute of the `grid_search` object.\n",
    "\n",
    "9. **Print Best Parameters:**\n",
    "   - Finally, we print the best hyperparameters obtained from the grid search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn (sklearn)`:\n",
    "\n",
    "- Scikit-learn is a popular machine learning library in Python that provides simple and efficient tools for data analysis and modeling.\n",
    "- It includes various modules for tasks such as classification, regression, clustering, dimensionality reduction, and model selection.\n",
    "- The GridSearchCV class from scikit-learn is used for hyperparameter tuning through grid search along with cross-validation.\n",
    "- The make_scorer function allows us to create a custom scoring function for use with GridSearchCV.\n",
    "- The NearestNeighbors class provides functionality for unsupervised nearest neighbors learning, which can be used for tasks such as finding k-nearest neighbors for a given data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: NearestNeighbors</label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={'metric': ['cosine', 'euclidean'],\n",
       "                         'n_neighbors': [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method='predict'))"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'cosine', 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom scorer based on cosine similarity defined above\n",
    "cosine_similarity_scorer = make_scorer(cosine_similarity)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 15, 30, 40],\n",
    "    'metric': ['cosine', 'euclidean']\n",
    "}\n",
    "\n",
    "# Initialize NearestNeighbors model\n",
    "knn_model = NearestNeighbors()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring=cosine_similarity_scorer)\n",
    "\n",
    "# Fit the data to perform hyperparameter tuning\n",
    "grid_search.fit(train_matrix)  # train_matrix contains item-user matrix for the train set\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a GridSearchCV object to perform hyperparameter tuning using the train set (train_matrix). It explores different combinations of hyperparameters specified in the param_grid, evaluates them using 5-fold cross-validation (cv=5), and uses the cosine_similarity scorer to optimize the model's performance based on cosine similarity. Finally, it prints the best hyperparameters found during the search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to perform the calculation of the predicted ratings for the train-val set to generate predicted ratings in order to evaluate the performance of our trained model on a validation dataset. \n",
    "\n",
    "If we computed the similarity matrix again specifically for the train_val set, it would essentially mean that we are using a different set of similarity measures for predicting ratings compared to what we used during training. This approach could lead to inconsistencies and potentially degrade the performance of our model. Here's what could happen:\n",
    "\n",
    "1. **Inconsistency**: The similarity measures computed for the train_val set might differ from those computed for the training set due to variations in the data. As a result, the predicted ratings based on these new similarity measures may not align well with the predictions made during training, leading to inconsistency in the model's behavior.\n",
    "\n",
    "2. **Overfitting**: Computing a new similarity matrix specifically for the train_val set might lead to overfitting on the validation data. The model may capture noise or idiosyncrasies present in the train_val set, which may not generalize well to unseen data.\n",
    "\n",
    "3. **Increased Complexity**: Computing the similarity matrix again for the train_val set adds computational complexity and redundancy, especially if the similarity computation process is resource-intensive. This can result in longer training times and increased resource utilization.\n",
    "\n",
    "Overall, it's generally recommended to use the same similarity measures or neighborhood definitions for both training and validation sets to ensure consistency and generalizability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store predicted ratings for train_val\n",
    "predicted_ratings_val = pd.DataFrame(index=val_matrix.index, columns=val_matrix.columns)\n",
    "\n",
    "# Iterate over each user and their ratings in the train_val set\n",
    "for user_id, user_ratings in val_matrix.iterrows():\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        \n",
    "        # Check if the movie has a neighborhood defined\n",
    "        if movie_id in item_neighborhoods_train:\n",
    "            neighborhood = item_neighborhoods_train[movie_id]\n",
    "            \n",
    "            # Filter out movies from the neighborhood that the user has rated in the train set\n",
    "            filtered_neighborhood = [neighbor_movie_id for neighbor_movie_id in neighborhood if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0]\n",
    "            \n",
    "            # Check if there are valid indices in the filtered neighborhood\n",
    "            if len(filtered_neighborhood) > 0:\n",
    "                # Calculate the predicted rating for the target movie based on the neighborhood\n",
    "                neighbor_ratings = [user_ratings.loc[neighbor_movie_id] for neighbor_movie_id in filtered_neighborhood]\n",
    "                \n",
    "                # Calculate the mean rating using only the movies in the neighborhood that have been rated by the user\n",
    "                predicted_rating = np.mean(neighbor_ratings)\n",
    "            else:\n",
    "                # If the filtered neighborhood is empty, assign the mean rating of all movies rated by the user\n",
    "                predicted_rating = user_ratings[user_ratings != 0].mean()\n",
    "            \n",
    "            # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "            predicted_ratings_val.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "# Fill NaN values with mean ratings across all users\n",
    "predicted_ratings_val.fillna(predicted_ratings_val.mean().mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>185473</th>\n",
       "      <th>186587</th>\n",
       "      <th>187031</th>\n",
       "      <th>187541</th>\n",
       "      <th>188675</th>\n",
       "      <th>188797</th>\n",
       "      <th>191005</th>\n",
       "      <th>193573</th>\n",
       "      <th>193583</th>\n",
       "      <th>193587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>...</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "      <td>3.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>...</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "      <td>4.15625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "      <td>2.776224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "      <td>3.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.125</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>...</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "      <td>3.570423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         4         9         11        13        15        18      \\\n",
       "userId                                                                          \n",
       "270           5.0     3.625     3.625     3.625     3.625       4.0     3.625   \n",
       "124       4.15625   4.15625   4.15625   4.15625   4.15625   4.15625   4.15625   \n",
       "368      2.776224  2.776224  2.776224  2.776224  2.776224       3.0  2.776224   \n",
       "213           4.0  3.616667  3.616667  3.616667  3.616667  3.616667  3.616667   \n",
       "63          3.125  3.570423  3.570423       4.0  3.570423  3.570423  3.570423   \n",
       "\n",
       "movieId    20        24        30      ...    185473    186587    187031  \\\n",
       "userId                                 ...                                 \n",
       "270         3.625     3.625     3.625  ...     3.625     3.625     3.625   \n",
       "124       4.15625   4.15625   4.15625  ...   4.15625   4.15625   4.15625   \n",
       "368      2.776224  2.776224  2.776224  ...  2.776224  2.776224  2.776224   \n",
       "213      3.616667  3.616667  3.616667  ...  3.616667  3.616667  3.616667   \n",
       "63       3.570423  3.570423  3.570423  ...  3.570423  3.570423  3.570423   \n",
       "\n",
       "movieId    187541    188675    188797    191005    193573    193583    193587  \n",
       "userId                                                                         \n",
       "270         3.625     3.625     3.625     3.625     3.625     3.625     3.625  \n",
       "124       4.15625   4.15625   4.15625   4.15625   4.15625   4.15625   4.15625  \n",
       "368      2.776224  2.776224  2.776224       1.0  2.776224  2.776224  2.776224  \n",
       "213      3.616667  3.616667  3.616667  3.616667  3.616667  3.616667  3.616667  \n",
       "63       3.570423  3.570423  3.570423  3.570423  3.570423  3.570423  3.570423  \n",
       "\n",
       "[5 rows x 2923 columns]"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(98, 2923)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings_val.head()\n",
    "\n",
    "predicted_ratings_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the model with the Validation item-user matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Validation Data: 0.7640488926024421\n",
      "Root Mean Squared Error (RMSE) on Validation Data: 1.026630924440244\n"
     ]
    }
   ],
   "source": [
    "# Now, we can evaluate the model using the evaluate_model function\n",
    "mae, rmse = evaluate_model(val_matrix.to_numpy(), predicted_ratings_val)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Validation Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Validation Data:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining of the model with the Train-Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the model evaluation on the validation set, we recalculate the similarity matrix\n",
    "# of the model on the train-val data\n",
    "item_similarity_matrix_train_val = calculate_item_similarity_matrix(train_val)\n",
    "\n",
    "# We combine the similarity matrices (the retrained one and the genres)\n",
    "item_similarity_matrix_train_val = combine_similarity_matrices(item_similarity_matrix_train_val, item_similarity_genres_matrix)\n",
    "\n",
    "# We calculate the item neighborhoods for the train_val data \n",
    "item_neighborhoods_train_val = neighborhood_selection(item_user_array, index_to_movie_id, item_similarity_matrix_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Deployment\n",
    "\n",
    "Once we have come up with the best parameters possible and trained the model with the whole train_validation set, we will test it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>20</th>\n",
       "      <th>24</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>185473</th>\n",
       "      <th>186587</th>\n",
       "      <th>187031</th>\n",
       "      <th>187541</th>\n",
       "      <th>188675</th>\n",
       "      <th>188797</th>\n",
       "      <th>191005</th>\n",
       "      <th>193573</th>\n",
       "      <th>193583</th>\n",
       "      <th>193587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 2923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       4       9       11      13      15      18      20      \\\n",
       "userId                                                                    \n",
       "293         3.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "367         5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "469         4.0     0.0     0.0     3.0     0.0     0.0     0.0     0.0   \n",
       "569         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "119         3.5     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "377         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "251         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "211         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "533         5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "201         5.0     0.0     0.0     4.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  24      30      ...  185473  186587  187031  187541  188675  188797  \\\n",
       "userId                   ...                                                   \n",
       "293         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "367         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "469         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "569         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "119         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "377         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "251         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "211         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "533         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "201         4.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  191005  193573  193583  193587  \n",
       "userId                                   \n",
       "293         0.0     0.0     0.0     0.0  \n",
       "367         0.0     0.0     0.0     0.0  \n",
       "469         0.0     0.0     0.0     0.0  \n",
       "569         0.0     0.0     0.0     0.0  \n",
       "119         0.0     0.0     0.0     0.0  \n",
       "...         ...     ...     ...     ...  \n",
       "377         0.0     0.0     0.0     0.0  \n",
       "251         0.0     0.0     0.0     0.0  \n",
       "211         0.0     0.0     0.0     0.0  \n",
       "533         0.0     0.0     0.0     0.0  \n",
       "201         0.0     0.0     0.0     0.0  \n",
       "\n",
       "[122 rows x 2923 columns]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are NaN values in the test matrix\n",
    "test_matrix.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Test Data using the Ratings given to the Test Set: 0.7192122089072419\n",
      "Root Mean Squared Error (RMSE) on Test Data using the Ratings given to the Test Set: 0.961897350285074\n"
     ]
    }
   ],
   "source": [
    "# Now, we can evaluate the model's predicted ratings on the test set\n",
    "\n",
    "# Initialize an empty DataFrame to store predicted ratings\n",
    "predicted_ratings_test = pd.DataFrame(index=test_matrix.index, columns=test_matrix.columns)\n",
    "\n",
    "# Iterate over each user-item pair in the training set\n",
    "for user_id, user_ratings in test_matrix.iterrows():\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "    \n",
    "        \n",
    "        # Check if the movie has a neighborhood defined\n",
    "        if movie_id in item_neighborhoods_train_val:\n",
    "            neighborhood = item_neighborhoods_train_val[movie_id]\n",
    "            \n",
    "            # Filter out movies from the neighborhood that the user has rated in the training set\n",
    "            filtered_neighborhood = [neighbor_movie_id for neighbor_movie_id in neighborhood if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0]\n",
    "            \n",
    "            # Check if there are valid indices in the filtered neighborhood\n",
    "            if len(filtered_neighborhood) > 0:\n",
    "                # Calculate the predicted rating for the target movie based on the neighborhood\n",
    "                neighbor_ratings = [user_ratings.loc[neighbor_movie_id] for neighbor_movie_id in filtered_neighborhood]\n",
    "                \n",
    "                # Calculate the mean rating using only the movies in the neighborhood that have been rated by the user\n",
    "                predicted_rating = np.mean(neighbor_ratings)\n",
    "            else:\n",
    "                # If the filtered neighborhood is empty, assign the mean rating of all movies rated by the user\n",
    "                predicted_rating = user_ratings[user_ratings != 0].mean()\n",
    "            \n",
    "            # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "            predicted_ratings_test.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "# Fill NaN values with mean ratings across all users\n",
    "predicted_ratings_test.fillna(predicted_ratings_test.mean().mean(), inplace=True)\n",
    "\n",
    "# Now, we can evaluate the model's predicted ratings on the test set\n",
    "mae, rmse = evaluate_model(test_matrix.to_numpy(), predicted_ratings_test.to_numpy())\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Test Data using the Ratings given to the Test Set:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Data using the Ratings given to the Test Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Shining, The ',\n",
       "  'Pulp Fiction ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Wallace & Gromit: The Wrong Trousers ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Tigger Movie, The ',\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl '],\n",
       " ['Flags of Our Fathers ',\n",
       "  'Dick Tracy ',\n",
       "  'Jagged Edge ',\n",
       "  'Missing in Action ',\n",
       "  'Dumbo '],\n",
       " ['Trainspotting ',\n",
       "  \"Schindler's List \",\n",
       "  'Quick and the Dead, The ',\n",
       "  'Jackie Brown ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Game 6 ',\n",
       "  'Little Man ',\n",
       "  'Dirty Harry ',\n",
       "  'A Pigeon Sat on a Branch Reflecting on Existence ',\n",
       "  'Coffee and Cigarettes '],\n",
       " ['Twister ',\n",
       "  'Pulp Fiction ',\n",
       "  'Twelfth Night ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Dune ', 'Trainspotting ', 'Ghost World ', 'Sunshine ', 'Time Bandits '],\n",
       " ['Gravity ',\n",
       "  'Batman v Superman: Dawn of Justice ',\n",
       "  'Zootopia ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Edge of Tomorrow '],\n",
       " ['Little Mermaid, The ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Peter Pan ',\n",
       "  'Basic Instinct ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Shining, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) ',\n",
       "  'Basic Instinct ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Much Ado About Nothing ',\n",
       "  'Bulworth ',\n",
       "  'Usual Suspects, The ',\n",
       "  'American Beauty ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Intouchables ',\n",
       "  'Sting, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'My Fair Lady ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Adventures of Pinocchio, The ',\n",
       "  '101 Dalmatians ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Last Emperor, The ',\n",
       "  'Beverly Hills Cop II '],\n",
       " ['NeverEnding Story, The ',\n",
       "  'Harry Potter and the Deathly Hallows: Part 1 ',\n",
       "  'Harry Potter and the Half-Blood Prince ',\n",
       "  'Black Hawk Down ',\n",
       "  'Seven Years in Tibet '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Raise the Titanic ',\n",
       "  'Intouchables ',\n",
       "  'Defending Your Life ',\n",
       "  'Pie in the Sky ',\n",
       "  \"Things to Do in Denver When You're Dead \"],\n",
       " ['Intouchables ',\n",
       "  'Ice Age ',\n",
       "  \"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Shrek the Third ',\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl '],\n",
       " ['Lilo & Stitch ',\n",
       "  'Alice in Wonderland ',\n",
       "  'Mobsters ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Shrek the Third '],\n",
       " ['Cutthroat Island ',\n",
       "  'Star Trek II: The Wrath of Khan ',\n",
       "  'Wallace & Gromit: The Wrong Trousers ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Ninja Scroll (JÃ»bei ninpÃ»chÃ´) ',\n",
       "  'Laputa: Castle in the Sky (TenkÃ» no shiro Rapyuta) ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Song of the Sea ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) '],\n",
       " ['Say Anything... ',\n",
       "  'Sting, The ',\n",
       "  \"Schindler's List \",\n",
       "  'Righteous Kill ',\n",
       "  'Lawrence of Arabia '],\n",
       " ['Star Wars: Episode VII - The Force Awakens ',\n",
       "  'Shrek the Third ',\n",
       "  'Bolt ',\n",
       "  'X-Men: First Class ',\n",
       "  'Star Trek '],\n",
       " [\"Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) \",\n",
       "  'Midnight Chronicles ',\n",
       "  'Resident Evil ',\n",
       "  'Transformers: Revenge of the Fallen ',\n",
       "  'Eragon '],\n",
       " ['Protector, The ',\n",
       "  'Goonies, The ',\n",
       "  'Teenage Mutant Ninja Turtles II: The Secret of the Ooze ',\n",
       "  'Rat Race ',\n",
       "  'Red Sonja '],\n",
       " ['Elf ',\n",
       "  'Mr. Nanny ',\n",
       "  'Doctor Zhivago ',\n",
       "  'Sidekicks ',\n",
       "  'James and the Giant Peach '],\n",
       " ['Pianist, The ',\n",
       "  'Stand by Me ',\n",
       "  'Legionnaire ',\n",
       "  'Musa the Warrior (Musa) ',\n",
       "  'One Missed Call (Chakushin ari) '],\n",
       " ['PokÃ©mon 3: The Movie ',\n",
       "  'Brothers Solomon, The ',\n",
       "  'Monterey Pop ',\n",
       "  'Fading Gigolo ',\n",
       "  'Generation War '],\n",
       " ['Roaring Twenties, The ',\n",
       "  'True Lies ',\n",
       "  'Speed ',\n",
       "  'River Wild, The ',\n",
       "  'Rock, The '],\n",
       " ['Elf ', 'Entrapment ', 'Harrison Bergeron ', 'Speed ', 'American Pie 2 '],\n",
       " ['Webmaster ',\n",
       "  'Wasp Woman, The ',\n",
       "  'Idaho Transfer ',\n",
       "  'Buck Rogers in the 25th Century ',\n",
       "  'Brave New World '],\n",
       " ['Pirates of the Caribbean: On Stranger Tides ',\n",
       "  'Intouchables ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Alice in Wonderland '],\n",
       " ['Turning Point, The ',\n",
       "  'Change-Up, The ',\n",
       "  'Bourne Legacy, The ',\n",
       "  'Dragon Ball: The Path to Power (Doragon bÃ´ru: SaikyÃ´ e no michi) ',\n",
       "  'Louis C.K.: Live at The Comedy Store '],\n",
       " ['Trainspotting ',\n",
       "  'Lights in the Dusk (Laitakaupungin valot) ',\n",
       "  'High Fidelity ',\n",
       "  'The Ridiculous 6 ',\n",
       "  'Unbreakable '],\n",
       " ['Laggies ',\n",
       "  'Children of the Revolution ',\n",
       "  'High Noon ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Fever Pitch '],\n",
       " ['Wallace & Gromit: The Wrong Trousers ',\n",
       "  'Shrek ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Starship Troopers ',\n",
       "  'Men in Black (a.k.a. MIB) '],\n",
       " ['Pianist, The ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Basic Instinct ',\n",
       "  'Frantic ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Jackie Brown ',\n",
       "  'Butch Cassidy and the Sundance Kid ',\n",
       "  'Big Lebowski, The ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Addams Family Reunion ',\n",
       "  '2001: A Space Odyssey ',\n",
       "  \"Dracula (Bram Stoker's Dracula) \",\n",
       "  'Flight of the Navigator ',\n",
       "  'Amer '],\n",
       " ['Much Ado About Nothing ',\n",
       "  'Trainspotting ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Baxter, The ',\n",
       "  'Afonya '],\n",
       " ['Brothers Bloom, The ',\n",
       "  'Drunken Master (Jui kuen) ',\n",
       "  'First Beautiful Thing, The (La prima cosa bella) ',\n",
       "  'Miracles - Mr. Canton and Lady Rose ',\n",
       "  'The Voices '],\n",
       " ['Old School ',\n",
       "  'Specialist, The ',\n",
       "  'Long Kiss Goodnight, The ',\n",
       "  'Toy Story ',\n",
       "  'Bend It Like Beckham '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Specialist, The ',\n",
       "  'Sideways ',\n",
       "  'Speed ',\n",
       "  'Afonya '],\n",
       " ['Pianist, The ',\n",
       "  'Ready to Wear (Pret-A-Porter) ',\n",
       "  'Raising Arizona ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Flirting With Disaster '],\n",
       " ['Birds, The ',\n",
       "  'Day Watch (Dnevnoy dozor) ',\n",
       "  'Exorcist, The ',\n",
       "  'Vie en Rose, La (MÃ´me, La) ',\n",
       "  'Toy Story '],\n",
       " ['Wallace & Gromit: The Wrong Trousers ',\n",
       "  'Bootleggers ',\n",
       "  'Blues Brothers, The ',\n",
       "  'Crimewave ',\n",
       "  'Flirting With Disaster '],\n",
       " ['Black Mask (Hak hap) ',\n",
       "  'King Kong ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'I, Robot ',\n",
       "  'X-Men: The Last Stand '],\n",
       " ['Cutthroat Island ',\n",
       "  'Nine Months ',\n",
       "  'Quick and the Dead, The ',\n",
       "  'Nick of Time ',\n",
       "  'Rock, The '],\n",
       " ['Shining, The ',\n",
       "  'Tombstone ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'Usual Suspects, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Wallace & Gromit: The Wrong Trousers ',\n",
       "  'Adventures of Pinocchio, The ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Wow! A Talking Fish! ',\n",
       "  \"Things to Do in Denver When You're Dead \"],\n",
       " ['Elf ',\n",
       "  'King Kong ',\n",
       "  'Heartbreak Ridge ',\n",
       "  'James and the Giant Peach ',\n",
       "  'Wiz, The '],\n",
       " ['Vacancy ',\n",
       "  'Waiting to Exhale ',\n",
       "  'Fracture ',\n",
       "  'Cry, the Beloved Country ',\n",
       "  'Vie en Rose, La (MÃ´me, La) '],\n",
       " ['Alice in Wonderland ',\n",
       "  'Frantic ',\n",
       "  'The Hobbit: The Battle of the Five Armies ',\n",
       "  'Legend of Sleepy Hollow, The ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Oblivion ',\n",
       "  'V. I. Warshawski ',\n",
       "  'Transformers: Revenge of the Fallen ',\n",
       "  'Pirates of the Caribbean: The Curse of the Black Pearl ',\n",
       "  'Hot Fuzz '],\n",
       " ['Citizen Kane ',\n",
       "  \"Young Poisoner's Handbook, The \",\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Kazaam ',\n",
       "  'Legend of Sleepy Hollow, The '],\n",
       " ['Grapes of Wrath, The ',\n",
       "  \"Pirates of the Caribbean: Dead Man's Chest \",\n",
       "  '300 ',\n",
       "  'Deep End of the Ocean, The ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \"],\n",
       " ['Indiana Jones and the Temple of Doom ',\n",
       "  'Loving Vincent ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'The Hunger Games: Mockingjay - Part 2 ',\n",
       "  \"Pan's Labyrinth (Laberinto del fauno, El) \"],\n",
       " ['Hiroshima Mon Amour ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Brother 2 (Brat 2) ',\n",
       "  'Mobsters ',\n",
       "  'Married to the Mob '],\n",
       " ['Project X ',\n",
       "  'Star Trek II: The Wrath of Khan ',\n",
       "  'Abyss, The ',\n",
       "  'Star Trek VI: The Undiscovered Country ',\n",
       "  'Rocketeer, The '],\n",
       " ['Raising Arizona ',\n",
       "  'Shrek ',\n",
       "  'Groundhog Day ',\n",
       "  'So I Married an Axe Murderer ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Goodfellas ',\n",
       "  'Shrek ',\n",
       "  'Jackie Brown ',\n",
       "  'Guardians of the Galaxy '],\n",
       " ['Turning Point, The ',\n",
       "  'Bag Man, The ',\n",
       "  'Flags of Our Fathers ',\n",
       "  \"Elevator to the Gallows (a.k.a. Frantic) (Ascenseur pour l'Ã©chafaud) \",\n",
       "  'Camille '],\n",
       " ['Turning Point, The ',\n",
       "  'Legends of the Fall ',\n",
       "  'Crying Game, The ',\n",
       "  'School for Scoundrels ',\n",
       "  'Camille '],\n",
       " [\"I'm Gonna Git You Sucka \",\n",
       "  'Celebrity ',\n",
       "  'Polyester ',\n",
       "  \"What's Up, Doc? \",\n",
       "  \"Midsummer Night's Sex Comedy, A \"],\n",
       " ['Dune ',\n",
       "  'Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Pianist, The ',\n",
       "  'It Could Happen to You ',\n",
       "  'MisÃ©rables, Les '],\n",
       " ['Much Ado About Nothing ',\n",
       "  'Elf ',\n",
       "  'I Love You Phillip Morris ',\n",
       "  'Proof ',\n",
       "  'Best Man, The (Testimone dello sposo, Il) '],\n",
       " ['Dogma ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Harry Potter and the Deathly Hallows: Part 1 ',\n",
       "  'Harry Potter and the Half-Blood Prince ',\n",
       "  'Toy Story '],\n",
       " ['Running Man, The ',\n",
       "  'Dragon Ball Z: Bojack Unbound (Doragon bÃ´ru Z 9: Ginga girigiri!! Butchigiri no sugoi yatsu) ',\n",
       "  'Intouchables ',\n",
       "  '101 Reykjavik (101 ReykjavÃ­k) ',\n",
       "  'Guest from the Future (Gostya iz buduschego) '],\n",
       " ['Eyes Wide Shut ',\n",
       "  'Sting, The ',\n",
       "  'Others, The ',\n",
       "  'Bad Santa ',\n",
       "  'Patlabor: The Movie (KidÃ´ keisatsu patorebÃ¢: The Movie) '],\n",
       " ['African Queen, The ',\n",
       "  'Cat on a Hot Tin Roof ',\n",
       "  'Above the Rim ',\n",
       "  'Gran Torino ',\n",
       "  'Best Years of Our Lives, The '],\n",
       " ['Birds, The ',\n",
       "  'Pianist, The ',\n",
       "  'Bloodsport 2 (a.k.a. Bloodsport II: The Next Kumite) ',\n",
       "  'Omen, The ',\n",
       "  'Lawnmower Man 2: Beyond Cyberspace '],\n",
       " ['Cutthroat Island ',\n",
       "  'Rumble in the Bronx (Hont faan kui) ',\n",
       "  'Client, The ',\n",
       "  'Four Weddings and a Funeral ',\n",
       "  'American President, The '],\n",
       " ['Game 6 ',\n",
       "  'Pianist, The ',\n",
       "  'Byzantium ',\n",
       "  'Memories of Me ',\n",
       "  \"Decline of the American Empire, The (DÃ©clin de l'empire amÃ©ricain, Le) \"],\n",
       " [\"Dr. Terror's House of Horrors \",\n",
       "  'Abominable Snowman, The (Abominable Snowman of the Himalayas, The) ',\n",
       "  'Legends of the Fall ',\n",
       "  'Quatermass and the Pit ',\n",
       "  'Exorcist, The '],\n",
       " ['Shrek ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Jackie Brown ',\n",
       "  'Wow! A Talking Fish! ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Little Girl Who Lives Down the Lane, The ',\n",
       "  'Time to Kill, A ',\n",
       "  'Dead Man Walking ',\n",
       "  'Source Code ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Rumble in the Bronx (Hont faan kui) ',\n",
       "  'What Lies Beneath ',\n",
       "  'Drunken Master (Jui kuen) ',\n",
       "  'Armour of God (Long xiong hu di) ',\n",
       "  'To Kill a Mockingbird '],\n",
       " [\"America's Sweethearts \",\n",
       "  'When Harry Met Sally... ',\n",
       "  'Frantic ',\n",
       "  'Serendipity ',\n",
       "  'Adventures Of Sherlock Holmes And Dr. Watson: The Twentieth Century Approaches '],\n",
       " ['Silence of the Lambs, The ',\n",
       "  'True Romance ',\n",
       "  'Twelfth Night ',\n",
       "  'Reservoir Dogs ',\n",
       "  'As Good as It Gets '],\n",
       " ['Shining, The ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'My Neighbor Totoro (Tonari no Totoro) ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Batman ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'True Romance ',\n",
       "  'Madame Sousatzka ',\n",
       "  'Big Lebowski, The '],\n",
       " ['True Romance ',\n",
       "  'Killing Fields, The ',\n",
       "  \"Schindler's List \",\n",
       "  'Jackie Brown ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Gravity ',\n",
       "  'NeverEnding Story, The ',\n",
       "  'Oblivion ',\n",
       "  'Cloud Atlas ',\n",
       "  'Blind Side, The  '],\n",
       " ['How the Grinch Stole Christmas! ',\n",
       "  'Disturbia ',\n",
       "  'Hoax, The ',\n",
       "  'Toy Story ',\n",
       "  'Grindhouse '],\n",
       " ['Goodfellas ',\n",
       "  'True Romance ',\n",
       "  'Quick and the Dead, The ',\n",
       "  'Usual Suspects, The ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " [\"Sophie's Choice \",\n",
       "  'Grass Is Greener, The ',\n",
       "  'Father Goose ',\n",
       "  'X-Men: The Last Stand ',\n",
       "  'Toy Story '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Goodfellas ',\n",
       "  '101 Dalmatians ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Pirates of the Caribbean: On Stranger Tides ',\n",
       "  'NeverEnding Story, The ',\n",
       "  'Alice in Wonderland ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Shrek the Third '],\n",
       " ['Jungle Book, The ',\n",
       "  'Shining, The ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Secret of NIMH, The ',\n",
       "  'Leprechaun 2 '],\n",
       " ['Turning Point, The ',\n",
       "  'Nine Months ',\n",
       "  'Crying Game, The ',\n",
       "  'So I Married an Axe Murderer ',\n",
       "  'Camille '],\n",
       " ['Max Manus ',\n",
       "  'Camille Claudel ',\n",
       "  'Music Box ',\n",
       "  \"Before the Devil Knows You're Dead \",\n",
       "  'I Stand Alone (Seul contre tous) '],\n",
       " ['Silver Linings Playbook ',\n",
       "  'Project X ',\n",
       "  'Vicky Cristina Barcelona ',\n",
       "  'Birdman: Or (The Unexpected Virtue of Ignorance) ',\n",
       "  '300 '],\n",
       " ['Breakdown ',\n",
       "  'For Your Eyes Only ',\n",
       "  'Peacemaker, The ',\n",
       "  'Long Kiss Goodnight, The ',\n",
       "  'Quick and the Dead, The '],\n",
       " ['Trainspotting ',\n",
       "  'Turkish Delight (Turks fruit) ',\n",
       "  'Time to Kill, A ',\n",
       "  'Jackie Brown ',\n",
       "  \"'Round Midnight \"],\n",
       " ['Last Klezmer: Leopold Kozlowski, His Life and Music, The ',\n",
       "  'Trainspotting ',\n",
       "  'Time to Kill, A ',\n",
       "  'Sliver ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Trainspotting ',\n",
       "  'Goodfellas ',\n",
       "  \"Schindler's List \",\n",
       "  'Jackie Brown ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Total Recall ',\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Cube ',\n",
       "  'Doctor Strange ',\n",
       "  'Blind Side, The  '],\n",
       " ['Goodfellas ',\n",
       "  'Twelve Monkeys (a.k.a. 12 Monkeys) ',\n",
       "  'Jackie Brown ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Ice Age ',\n",
       "  'High Fidelity ',\n",
       "  'Proof ',\n",
       "  'Usual Suspects, The ',\n",
       "  'Toy Story '],\n",
       " ['Life Is Beautiful (La Vita Ã¨ bella) ',\n",
       "  'Jackie Brown ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Basic Instinct ',\n",
       "  'Reservoir Dogs '],\n",
       " ['Elf ',\n",
       "  'Incredibles 2 ',\n",
       "  '39 Steps, The ',\n",
       "  'Loving Vincent ',\n",
       "  'The Hobbit: The Battle of the Five Armies '],\n",
       " ['Project X ',\n",
       "  'Entrapment ',\n",
       "  '8 Mile ',\n",
       "  'Righteous Kill ',\n",
       "  'Big Lebowski, The '],\n",
       " ['Iron Man ',\n",
       "  'Sherlock - A Study in Pink ',\n",
       "  'I Origins ',\n",
       "  'John Q ',\n",
       "  'Rabbit Hole '],\n",
       " ['Shining, The ',\n",
       "  'Johnny Mnemonic ',\n",
       "  'Lost in Space ',\n",
       "  'Reservoir Dogs ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Project X ',\n",
       "  'Ref, The ',\n",
       "  'Pianist, The ',\n",
       "  'Bio-Dome ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Turning Point, The ',\n",
       "  'Shining, The ',\n",
       "  'Stand by Me ',\n",
       "  'Autumn Marathon ',\n",
       "  'As Good as It Gets '],\n",
       " ['Young Victoria, The ',\n",
       "  \"He's Just Not That Into You \",\n",
       "  'Atonement ',\n",
       "  'Serendipity ',\n",
       "  'Bend It Like Beckham '],\n",
       " ['Elf ',\n",
       "  'For Your Eyes Only ',\n",
       "  'They Live ',\n",
       "  'Almost Famous ',\n",
       "  'Pursuit of Happyness, The '],\n",
       " ['Say Anything... ',\n",
       "  'Elizabeth ',\n",
       "  'Fever Pitch ',\n",
       "  'Deep End of the Ocean, The ',\n",
       "  'My Big Fat Greek Wedding '],\n",
       " ['Battle Royale (Batoru rowaiaru) ',\n",
       "  \"Amores Perros (Love's a Bitch) \",\n",
       "  'Riki-Oh: The Story of Ricky (Lik Wong) ',\n",
       "  'Gods Must Be Crazy, The ',\n",
       "  'Children of Men '],\n",
       " ['Star Trek: Insurrection ',\n",
       "  'High Noon ',\n",
       "  'Starship Troopers ',\n",
       "  'Superman IV: The Quest for Peace ',\n",
       "  'Butch Cassidy and the Sundance Kid '],\n",
       " ['Pianist, The ',\n",
       "  'Thing, The ',\n",
       "  'Flight of the Navigator ',\n",
       "  'MisÃ©rables, Les ',\n",
       "  'Dangerous Minds '],\n",
       " ['...All the Marbles ',\n",
       "  'Star Trek: First Contact ',\n",
       "  'River Wild, The ',\n",
       "  'Autumn Marathon ',\n",
       "  'MÃ©nage (Tenue de soirÃ©e) '],\n",
       " ['Pulp Fiction ',\n",
       "  'Slumdog Millionaire ',\n",
       "  'Interview with the Vampire: The Vampire Chronicles ',\n",
       "  'Gran Torino ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['39 Steps, The ',\n",
       "  'Princess Mononoke (Mononoke-hime) ',\n",
       "  'Porco Rosso (Crimson Pig) (Kurenai no buta) ',\n",
       "  'Toy Story ',\n",
       "  'FearDotCom (a.k.a. Fear.com) (a.k.a. Fear Dot Com) '],\n",
       " ['Entrapment ',\n",
       "  'Silence of the Lambs, The ',\n",
       "  'Jackie Brown ',\n",
       "  'Crimewave ',\n",
       "  'Crow, The '],\n",
       " [\"Emperor's New Groove, The \",\n",
       "  'Harry Potter and the Order of the Phoenix ',\n",
       "  'Adventures of Mowgli: The Kidnapping ',\n",
       "  'Sliver ',\n",
       "  'Phineas and Ferb the Movie: Across the 2nd Dimension '],\n",
       " ['Gravity ',\n",
       "  'Batman v Superman: Dawn of Justice ',\n",
       "  'Cars 3 ',\n",
       "  'Zootopia ',\n",
       "  'Bolt '],\n",
       " ['Get on Up ',\n",
       "  \"Beat That My Heart Skipped, The (battre mon coeur s'est arrÃªtÃ©, De) \",\n",
       "  'Band of Outsiders (Bande Ã  part) ',\n",
       "  'Pi ',\n",
       "  'Lawrence of Arabia '],\n",
       " ['Disturbia ',\n",
       "  'Fracture ',\n",
       "  'Hoax, The ',\n",
       "  'Vie en Rose, La (MÃ´me, La) ',\n",
       "  'Toy Story '],\n",
       " ['Jungle Book, The ',\n",
       "  \"Schindler's List \",\n",
       "  '101 Dalmatians ',\n",
       "  'Secret of NIMH, The ',\n",
       "  'American Tail, An '],\n",
       " ['101 Dalmatians ',\n",
       "  \"Last Year's Snow Was Falling \",\n",
       "  'Resident Evil ',\n",
       "  'Cube ',\n",
       "  'Wow! A Talking Fish! '],\n",
       " ['Hard Promises ',\n",
       "  'Dogma ',\n",
       "  'Secret of NIMH, The ',\n",
       "  'Serendipity ',\n",
       "  'Extraordinary Adventures of AdÃ¨le Blanc-Sec, The ']]"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of top_recommendations_test: 122\n"
     ]
    }
   ],
   "source": [
    "top_recommendations_test = []\n",
    "\n",
    "# Iterate over each row (user) in the test_matrix\n",
    "for user_id in test_matrix.index:\n",
    "    # Get the actual user ID corresponding to the user index\n",
    "    recommendations = get_top_recommendations(user_id, predicted_ratings_test, df)\n",
    "    top_recommendations_test.append(recommendations)\n",
    "\n",
    "# Output: List of top movie recommendations for each user in the test matrix\n",
    "top_recommendations_test\n",
    "\n",
    "# print size of top_recommendations\n",
    "print(\"Size of top_recommendations_test:\", len(top_recommendations_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Classification (ItemKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data preparation\n",
    "- We have to create a dataset with a user-item interactions. Each interaction should include the user ID, item ID, and the corresponding label or class for classification.\n",
    "- Additionally we will create a item-genre matrix to compute the similarity between objects using the genres.\n",
    "- Preprocess the data as needed, including handling missing values, encoding categorical variables, and splitting into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this step we are going to resuse the `item_user_matrix` that we created in the first model built. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compute Item Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2923, 2923)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No items with empty neighborhoods found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def item_neighborhood_selection(similarity_matrix, k=None, threshold=None, item_ids=None):\n",
    "    \"\"\"\n",
    "    Select a subset of similar items for each item based on similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "        similarity_matrix (numpy.ndarray): Item-item similarity matrix.\n",
    "        k (int): Number of similar items to select (optional).\n",
    "        threshold (float): Similarity threshold for selecting similar items (optional).\n",
    "        item_ids (list): List of item IDs corresponding to rows/columns of the similarity matrix.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing similar items for each item.\n",
    "    \"\"\"\n",
    "    num_items = similarity_matrix.shape[0]\n",
    "    item_neighborhood = {}\n",
    "\n",
    "    for i in range(num_items):\n",
    "        if k is not None:\n",
    "            # Select top-k similar items (excluding the item itself)\n",
    "            similar_items_indices = np.argsort(similarity_matrix[i])[::-1][:k]\n",
    "        elif threshold is not None:\n",
    "            # Select items with similarity above threshold (excluding the item itself)\n",
    "            similar_items_indices = np.where(similarity_matrix[i] > threshold)[0]\n",
    "\n",
    "        # Remove the item itself from the neighborhood\n",
    "        similar_items_indices = similar_items_indices[similar_items_indices != i]\n",
    "\n",
    "        # Get the item ID corresponding to the current index\n",
    "        current_item_id = item_ids[i] if item_ids is not None else i\n",
    "\n",
    "        # Get the item IDs for the neighborhood\n",
    "        neighborhood_item_ids = [item_ids[index] for index in similar_items_indices]\n",
    "\n",
    "        # Store the similar items with the item's ID as the key\n",
    "        item_neighborhood[current_item_id] = neighborhood_item_ids\n",
    "\n",
    "    return item_neighborhood\n",
    "\n",
    "# We have an item-item similarity matrix 'item_similarity_matrix_train'\n",
    "# and we want to select top-5 similar items for each item\n",
    "k = 5\n",
    "item_neighborhoods_classification_train = item_neighborhood_selection(item_similarity_matrix_train, k=k, item_ids=index_to_movie_id)\n",
    "\n",
    "# Check if there are any items with empty neighborhoods\n",
    "empty_neighborhoods = []\n",
    "\n",
    "for item_id, neighborhood in item_neighborhoods_classification_train.items():\n",
    "    if not neighborhood:\n",
    "        empty_neighborhoods.append(item_id)\n",
    "\n",
    "if empty_neighborhoods:\n",
    "    print(\"Items with empty neighborhoods:\", empty_neighborhoods)\n",
    "else:\n",
    "    print(\"No items with empty neighborhoods found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2923"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_neighborhoods_classification_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Ratings classification selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def recommend_movies(train_matrix, item_neighborhoods, movie_id_to_index, num_movies=5):\n",
    "    \"\"\"\n",
    "    Recommend top movies for each user based on item neighborhood.\n",
    "\n",
    "    Parameters:\n",
    "        train_matrix (np.ndarray or pd.DataFrame): Matrix containing user-item ratings in the train set.\n",
    "        item_neighborhoods (dict): Dictionary containing similar items for each item.\n",
    "        movie_id_to_index (dict): Dictionary mapping movie IDs to their corresponding indices in the train_matrix.\n",
    "        num_movies (int): Number of movies to recommend for each user.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing predicted ratings for recommended movies for each user.\n",
    "    \"\"\"\n",
    "    # Convert train_matrix to DataFrame if it's a numpy array\n",
    "    if isinstance(train_matrix, np.ndarray):\n",
    "        train_matrix = pd.DataFrame(train_matrix, index=np.arange(train_matrix.shape[0]), columns=np.arange(train_matrix.shape[1]))\n",
    "\n",
    "    # Initialize an empty DataFrame to store predicted ratings\n",
    "    predicted_ratings = pd.DataFrame(index=train_matrix.index, columns=train_matrix.columns)\n",
    "\n",
    "    # Iterate over each user-item pair in the training set\n",
    "    for user_id, user_ratings in train_matrix.iterrows():\n",
    "        for movie_id, rating in user_ratings.items():\n",
    "            \n",
    "            # Skip if the rating is non-zero (indicating a rating given by the user)\n",
    "            if rating != 0:\n",
    "                continue\n",
    "            \n",
    "            # Check if the movie has a neighborhood defined\n",
    "            if movie_id in item_neighborhoods:\n",
    "                neighborhood = item_neighborhoods[movie_id]\n",
    "                \n",
    "                # Initialize a flag to track if the rating has been predicted\n",
    "                rating_predicted = False\n",
    "                \n",
    "                # Iterate over the items in the neighborhood\n",
    "                for neighbor_movie_id in neighborhood:\n",
    "                    # Check if the neighbor movie has been rated by the user\n",
    "                    if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0:\n",
    "                        # Use the rating of the closest item in the neighborhood\n",
    "                        predicted_rating = user_ratings.loc[neighbor_movie_id]\n",
    "                        rating_predicted = True\n",
    "                        break\n",
    "                \n",
    "                # If none of the items in the neighborhood have been rated, use the user's average rating\n",
    "                if not rating_predicted:\n",
    "                    if user_ratings[user_ratings != 0].empty:\n",
    "                        # If the user hasn't rated any movies, use the global mean rating\n",
    "                        predicted_rating = train_matrix[train_matrix != 0].mean().mean()\n",
    "                    else:\n",
    "                        # Use the average of the ratings given by the user\n",
    "                        predicted_rating = user_ratings[user_ratings != 0].mean()\n",
    "                \n",
    "                # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "                predicted_ratings.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "    # Fill NaN values with mean ratings across all users\n",
    "    predicted_ratings.fillna(predicted_ratings.mean().mean(), inplace=True)\n",
    "\n",
    "    # Set the index of the DataFrame as the user ID of the train set\n",
    "    predicted_ratings.index = train_matrix.index\n",
    "\n",
    "    # Display the head of the predicted_ratings DataFrame\n",
    "    print(predicted_ratings.head())\n",
    "\n",
    "    return predicted_ratings\n",
    "\n",
    "\n",
    "# Recommend movies for each user in the train set\n",
    "predicted_ratings_classification_train = recommend_movies(train_matrix, item_neighborhoods_classification_train, movie_id_to_index)\n",
    "\n",
    "# Print the shape of the predicted ratings matrix\n",
    "print(\"Shape of predicted ratings matrix:\", predicted_ratings_classification_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>3.604726</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>...</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>2.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>3.604726</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.411765</td>\n",
       "      <td>2.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3.604726</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>...</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>3.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "      <td>4.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows Ã— 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         4         15        30        43        89        104     \\\n",
       "userId                                                                          \n",
       "428      1.000000  2.384615  2.384615  2.384615  2.384615  2.384615  3.604726   \n",
       "517      3.604726  2.411765  2.411765  2.411765  2.411765  2.411765  2.411765   \n",
       "197      3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000   \n",
       "160      3.604726  3.047619  3.047619  3.047619  3.047619  2.000000  3.047619   \n",
       "67       3.500000  4.166667  4.166667  4.166667  4.166667  4.166667  4.166667   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "51       5.000000  4.305556  4.305556  4.305556  4.305556  4.305556  5.000000   \n",
       "267      4.000000  4.000000  4.000000  4.000000  4.000000  4.000000  4.000000   \n",
       "326      4.000000  4.000000  4.000000  4.000000  4.000000  4.000000  4.000000   \n",
       "416      0.500000  1.250000  1.250000  1.250000  1.250000  1.250000  1.250000   \n",
       "168      4.625000  4.625000  4.625000  4.625000  4.625000  4.625000  4.625000   \n",
       "\n",
       "movieId    108       122       146     ...    174479    174551    175475  \\\n",
       "userId                                 ...                                 \n",
       "428      2.384615  2.384615  2.384615  ...  2.384615  2.384615  2.384615   \n",
       "517      2.411765  0.500000  2.411765  ...  2.411765  2.411765  2.411765   \n",
       "197      3.000000  3.000000  3.000000  ...  3.000000  3.000000  3.000000   \n",
       "160      3.047619  3.047619  3.047619  ...  3.047619  4.000000  3.047619   \n",
       "67       4.166667  4.166667  4.166667  ...  4.166667  4.166667  4.166667   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "51       4.305556  4.305556  4.305556  ...  4.305556  4.305556  4.305556   \n",
       "267      4.000000  4.000000  4.000000  ...  4.000000  4.000000  4.000000   \n",
       "326      4.000000  4.000000  4.000000  ...  4.000000  4.000000  4.000000   \n",
       "416      1.250000  1.250000  1.250000  ...  1.250000  1.250000  1.250000   \n",
       "168      4.625000  4.625000  4.625000  ...  4.625000  4.625000  4.625000   \n",
       "\n",
       "movieId    176371    176389    177593    179813    181413    185029    186587  \n",
       "userId                                                                         \n",
       "428      2.384615  2.384615  2.384615  2.384615  1.000000  2.384615  2.384615  \n",
       "517      2.411765  4.000000  2.411765  2.411765  4.000000  2.411765  2.411765  \n",
       "197      3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  \n",
       "160      3.047619  4.000000  3.047619  3.047619  4.000000  3.047619  3.047619  \n",
       "67       4.166667  4.166667  4.166667  4.166667  3.500000  4.166667  4.166667  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "51       4.305556  4.305556  4.305556  4.305556  4.305556  4.305556  4.305556  \n",
       "267      4.000000  4.000000  4.000000  4.000000  4.000000  4.000000  4.000000  \n",
       "326      4.000000  4.000000  3.500000  4.000000  4.000000  4.000000  4.000000  \n",
       "416      1.250000  1.250000  1.250000  1.250000  0.500000  1.250000  1.250000  \n",
       "168      4.625000  4.625000  4.625000  4.625000  4.625000  4.625000  4.625000  \n",
       "\n",
       "[340 rows x 487 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings_classification_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Recommendations Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 428 recommendations: ['How the Grinch Stole Christmas! ', 'Darkon ', 'We Could Be King ', 'Starsky & Hutch ', \"Outfoxed: Rupert Murdoch's War on Journalism \"]\n",
      "User 517 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', \"Can't Stop the Music \", 'Sandpiper, The ', 'Funny Face ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 197 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 160 recommendations: ['Fried Green Tomatoes ', 'How the Grinch Stole Christmas! ', 'Captain Newman, M.D. ', 'Chorus Line, A ', 'Jimmy Hollywood ']\n",
      "User 67 recommendations: ['All the Boys Love Mandy Lane ', 'Waitress ', 'Spy Next Door, The ', \"Nina's Heavenly Delights \", '42nd Street ']\n",
      "User 32 recommendations: ['Godzilla ', 'Star Trek V: The Final Frontier ', 'Mexican, The ', 'Men in Black (a.k.a. MIB) ', 'Time Bandits ']\n",
      "User 234 recommendations: ['What Women Want ', \"It's a Wonderful Life \", 'Spirited Away (Sen to Chihiro no kamikakushi) ', \"Hitchhiker's Guide to the Galaxy, The \", 'Nightmare Before Christmas, The ']\n",
      "User 381 recommendations: ['G.B.F. ', 'How the Grinch Stole Christmas! ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Source Code ', \"Nina's Heavenly Delights \"]\n",
      "User 333 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 116 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 78 recommendations: ['Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 317 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Starsky & Hutch ']\n",
      "User 95 recommendations: ['Cider House Rules, The ', \"It's a Wonderful Life \", 'Kazaam ', 'City Slickers ', 'Saving Christmas ']\n",
      "User 607 recommendations: ['My Life as McDull (Mak dau goo si) ', 'Nuremberg ', 'Happy Endings ', 'Heart of a Dog (Sobachye serdtse) ', 'Gardens of Stone ']\n",
      "User 508 recommendations: ['Reign of Fire ', 'Game of Death ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 300 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 372 recommendations: ['Patton ', 'Sandpiper, The ', 'Gremlins 2: The New Batch ', 'Fallen Angels (Duo luo tian shi) ', 'Leprechaun 3 ']\n",
      "User 279 recommendations: ['Three Billboards Outside Ebbing, Missouri ', 'Counselor, The ', 'Kill the Messenger ', 'Babel ', 'That Demon Within ']\n",
      "User 23 recommendations: ['Gone ', 'Cider House Rules, The ', \"Rosemary's Baby \", 'Sling Blade ', 'West Beirut (West Beyrouth) ']\n",
      "User 402 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 544 recommendations: ['Once ', 'Diabolique ', 'Foxy Brown ', 'Heart of a Dog (Sobachye serdtse) ', 'Violet & Daisy ']\n",
      "User 121 recommendations: ['Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 159 recommendations: ['Waitress ', 'The Nut Job 2: Nutty by Nature ', '4 Months, 3 Weeks and 2 Days (4 luni, 3 saptamÃ¢ni si 2 zile) ', 'Kazaam ', 'Nightmare Before Christmas, The ']\n",
      "User 357 recommendations: ['A Quiet Place ', 'My Cousin Vinny ', \"Ender's Game \", 'Babel ', 'Thief of Bagdad, The ']\n",
      "User 551 recommendations: ['10 Cloverfield Lane ', 'Confidence ', 'Captain Newman, M.D. ', 'Mojave ', 'Elle ']\n",
      "User 241 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Bonfire of the Vanities ']\n",
      "User 282 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Robin Hood ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Cloudy with a Chance of Meatballs ']\n",
      "User 444 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 219 recommendations: ['Joy Ride ', 'What Women Want ', \"It's a Wonderful Life \", 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Cloudy with a Chance of Meatballs ']\n",
      "User 598 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 165 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 58 recommendations: ['Happy Gilmore ', 'In July (Im Juli) ', 'How the Grinch Stole Christmas! ', 'Life Partners ', 'Toy Story ']\n",
      "User 153 recommendations: ['Gone ', 'Jimmy Hollywood ', 'Bonfire of the Vanities ', 'Town, The ', 'Chicago ']\n",
      "User 21 recommendations: ['10 Cloverfield Lane ', 'John Mulaney: New In Town ', 'Lilo & Stitch ', 'Mexican, The ', 'Children of Men ']\n",
      "User 445 recommendations: ['Kolya (Kolja) ', 'Shrek ', 'Lilo & Stitch ', 'Colonel Chabert, Le ', 'Harry Potter and the Deathly Hallows: Part 1 ']\n",
      "User 212 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Diabolique ', 'Robin Hood ', 'What Women Want ', 'Toy Story ']\n",
      "User 424 recommendations: ['2 Days in Paris ', 'Source Code ', 'Babel ', 'A Quiet Place ', 'Toy Story ']\n",
      "User 583 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 434 recommendations: ['Lars and the Real Girl ', 'Waiting to Exhale ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Source Code ', 'Babel ']\n",
      "User 540 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 437 recommendations: ['All the Boys Love Mandy Lane ', 'The Falcon and the Snowman ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 301 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', \"Hitchhiker's Guide to the Galaxy, The \", 'Cloudy with a Chance of Meatballs ', 'Toy Story ']\n",
      "User 534 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Evil Dead II (Dead by Dawn) ']\n",
      "User 188 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 290 recommendations: ['Patton ', 'Reign of Fire ', 'Night Listener, The ', 'Game of Death ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 286 recommendations: ['How the Grinch Stole Christmas! ', 'Hell Ride ', 'Conspiracy Theory ', 'Source Code ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 200 recommendations: ['Bootleggers ', 'Police Academy 4: Citizens on Patrol ', 'Chorus Line, A ', 'Little Shop of Horrors ', 'The Brain ']\n",
      "User 382 recommendations: ['Shrek ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Nightmare Before Christmas, The ']\n",
      "User 376 recommendations: ['How the Grinch Stole Christmas! ', 'Andrei Rublev (Andrey Rublyov) ', 'Steve Jobs ', 'Gardens of Stone ', 'Dam Busters, The ']\n",
      "User 115 recommendations: ['Happy Gilmore ', 'My Cousin Vinny ', 'Sling Blade ', \"It's a Wonderful Life \", 'City Slickers ']\n",
      "User 349 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 365 recommendations: ['Life Is a Long Quiet River (La vie est un long fleuve tranquille) ', 'Madly in Love ', \"Maggie's Plan \", 'Paddington ', 'Obsession ']\n",
      "User 16 recommendations: ['Once ', 'Shrek ', 'Lilo & Stitch ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Toy Story ']\n",
      "User 298 recommendations: ['Counselor, The ', 'Kill the Messenger ', 'Sling Blade ', 'Truth About Cats & Dogs, The ', 'Christmas Story, A ']\n",
      "User 41 recommendations: ['All Is Lost ', 'Mona Lisa Smile ', 'Happy Endings ', 'Last Supper, The ', 'A Quiet Place ']\n",
      "User 566 recommendations: ['Crush ', 'Happy Gilmore ', 'In July (Im Juli) ', 'Damsels in Distress ', 'Life Partners ']\n",
      "User 554 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Chicago ']\n",
      "User 570 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Lilo & Stitch ', 'What Women Want ', 'Source Code ', 'Nightmare Before Christmas, The ']\n",
      "User 413 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 608 recommendations: ['Paper Towns ', 'Nuremberg ', 'Cloudy with a Chance of Meatballs ', 'West Beirut (West Beyrouth) ', 'Gardens of Stone ']\n",
      "User 322 recommendations: ['Kolya (Kolja) ', 'Australia ', 'Captain Newman, M.D. ', 'Conspiracy Theory ', 'Source Code ']\n",
      "User 399 recommendations: ['Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Lilo & Stitch ', \"It's a Wonderful Life \", 'Spirited Away (Sen to Chihiro no kamikakushi) ', \"Hitchhiker's Guide to the Galaxy, The \"]\n",
      "User 477 recommendations: ['Kolya (Kolja) ', 'Ryuzo and the Seven Henchmen ', 'City Heat ', '2 Days in Paris ', 'Spy Next Door, The ']\n",
      "User 352 recommendations: ['Kolya (Kolja) ', 'Three Billboards Outside Ebbing, Missouri ', \"For Roseanna (Roseanna's Grave) \", 'Steve Jobs ', 'Town, The ']\n",
      "User 18 recommendations: ['Kolya (Kolja) ', 'Decline of Western Civilization Part II: The Metal Years, The ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Darkon ']\n",
      "User 358 recommendations: ['Lars and the Real Girl ', 'Bounty Hunter, The ', 'Last Winter, The ', 'Toy Story ', 'Untraceable ']\n",
      "User 226 recommendations: ['Bean ', 'Car Wash ', 'My Cousin Vinny ', 'Truth About Cats & Dogs, The ', 'Kazaam ']\n",
      "User 230 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Get Him to the Greek ', 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 235 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 190 recommendations: ['Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Alice in Wonderland ', 'Thief of Bagdad, The ']\n",
      "User 330 recommendations: ['How the Grinch Stole Christmas! ', 'Godzilla ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ']\n",
      "User 496 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Robin Hood ', 'What Women Want ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Toy Story ']\n",
      "User 310 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Robin Hood ', 'What Women Want ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Toy Story ']\n",
      "User 380 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Short Circuit ', 'Rampage ', 'Planes ', \"Ender's Game \"]\n",
      "User 341 recommendations: ['Shrek ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 152 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Sling Blade ', \"It's a Wonderful Life \", 'Toy Story ', 'Woods, The ']\n",
      "User 422 recommendations: ['Lincoln ', 'Happy Gilmore ', 'Robin Hood ', 'My Cousin Vinny ', \"It's a Wonderful Life \"]\n",
      "User 584 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 346 recommendations: ['Escape From Tomorrow ', 'Mona Lisa Smile ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Babel ', 'A Quiet Place ']\n",
      "User 167 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'What Women Want ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Cloudy with a Chance of Meatballs ']\n",
      "User 501 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 143 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Lilo & Stitch ', \"It's a Wonderful Life \", 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 467 recommendations: ['Kolya (Kolja) ', 'Once ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Toy Story ']\n",
      "User 455 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 22 recommendations: ['Babel ', 'Cloudy with a Chance of Meatballs ', 'Men in Black (a.k.a. MIB) ', 'A Quiet Place ', 'Toy Story ']\n",
      "User 522 recommendations: ['Paper Towns ', 'Gone ', 'Diabolique ', 'Good Son, The ', 'Andrei Rublev (Andrey Rublyov) ']\n",
      "User 390 recommendations: ['Shrek ', 'Andrei Rublev (Andrey Rublyov) ', 'Lilo & Stitch ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Gardens of Stone ']\n",
      "User 10 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Robin Hood ', 'Cloudy with a Chance of Meatballs ', 'Toy Story ']\n",
      "User 510 recommendations: ['Wonderful, Horrible Life of Leni Riefenstahl, The (Macht der Bilder: Leni Riefenstahl, Die) ', 'Darkon ', 'Catwalk ', \"Outfoxed: Rupert Murdoch's War on Journalism \", 'Corporation, The ']\n",
      "User 328 recommendations: ['Patton ', 'Sandpiper, The ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 478 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 572 recommendations: ['Lincoln ', 'Cider House Rules, The ', 'Unforgiven ', \"I'll Follow You Down \", 'Last Supper, The ']\n",
      "User 73 recommendations: ['Diabolique ', 'Good Son, The ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Nightmare Before Christmas, The ']\n",
      "User 227 recommendations: ['Babel ', 'Venus ', 'Source Code ', 'Last Winter, The ', 'Toy Story ']\n",
      "User 131 recommendations: ['My Life as McDull (Mak dau goo si) ', 'Fried Green Tomatoes ', 'Outsiders, The ', 'Heart of a Dog (Sobachye serdtse) ', 'Town, The ']\n",
      "User 337 recommendations: ['Crush ', 'Bean ', 'Car Wash ', 'Whole Nine Yards, The ', 'Life Partners ']\n",
      "User 46 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 232 recommendations: ['Gone ', 'Diabolique ', 'Three Billboards Outside Ebbing, Missouri ', 'Nuremberg ', 'Good Son, The ']\n",
      "User 359 recommendations: ['Kolya (Kolja) ', 'Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Colonel Chabert, Le ', 'What Women Want ', \"It's a Wonderful Life \"]\n",
      "User 460 recommendations: ['Waiting to Exhale ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Babel ', 'Nightmare Before Christmas, The ']\n",
      "User 100 recommendations: ['Rush Hour ', 'City Heat ', 'Short Circuit ', 'Star Trek V: The Final Frontier ', 'Children of Men ']\n",
      "User 351 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 447 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 214 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 196 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 307 recommendations: [\"Bridget Jones's Baby \", 'All Over the Guy ', 'Smokey and the Bandit ', 'Gremlins 2: The New Batch ', 'Leprechaun 3 ']\n",
      "User 520 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Short Circuit ', 'Star Trek V: The Final Frontier ', 'Mexican, The ']\n",
      "User 585 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 515 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 42 recommendations: ['Celebrity ', 'Nevada Smith ', 'Stingray Sam ', \"Hitchhiker's Guide to the Galaxy, The \", 'Toy Story ']\n",
      "User 6 recommendations: ['Crush ', 'Bloodmoon ', 'Life Partners ', 'Candleshoe ', 'Toy Story ']\n",
      "User 436 recommendations: ['How the Grinch Stole Christmas! ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ']\n",
      "User 169 recommendations: ['Patton ', 'Robin Hood ', 'Little Shop of Horrors ', 'Mexican, The ', 'City Slickers ']\n",
      "User 136 recommendations: ['Once ', 'Hell Ride ', 'Mona Lisa Smile ', 'Amazing Panda Adventure, The ', 'Rachel Getting Married ']\n",
      "User 316 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 386 recommendations: ['Once ', 'Cutthroat Island ', 'Bad Girls ', 'Mr. Woodcock ', 'S.W.A.T. ']\n",
      "User 2 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 324 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 278 recommendations: ['Fried Green Tomatoes ', \"Amores Perros (Love's a Bitch) \", 'Messenger: The Story of Joan of Arc, The ', 'Australia ', 'West Beirut (West Beyrouth) ']\n",
      "User 371 recommendations: ['All the Boys Love Mandy Lane ', 'Hot Tub Time Machine ', 'Last Winter, The ', \"Nina's Heavenly Delights \", 'Untraceable ']\n",
      "User 427 recommendations: ['Halloween H20: 20 Years Later (Halloween 7: The Revenge of Laurie Strode) ', 'Hell Ride ', 'Heart of a Dog (Sobachye serdtse) ', 'Leprechaun 3 ', 'Toy Story ']\n",
      "User 28 recommendations: ['Tin Man ', 'Steve Jobs ', 'City Slickers ', 'Biutiful ', 'To Kill a Mockingbird ']\n",
      "User 443 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 550 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 211 recommendations: ['2 Days in Paris ', 'The Nut Job 2: Nutty by Nature ', 'Lilo & Stitch ', 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 470 recommendations: ['Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 487 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 325 recommendations: ['Last Boy Scout, The ', 'Unforgiven ', \"It's a Wonderful Life \", 'Last Supper, The ', 'Departures (Okuribito) ']\n",
      "User 327 recommendations: ['Bean ', 'Car Wash ', 'My Cousin Vinny ', 'Fallen Angels (Duo luo tian shi) ', 'Toy Story ']\n",
      "User 492 recommendations: ['Bean ', 'All Over the Guy ', 'Robin Hood ', 'Waiting to Exhale ', 'My Cousin Vinny ']\n",
      "User 280 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 273 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 254 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Lilo & Stitch ', 'What Women Want ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Cloudy with a Chance of Meatballs ']\n",
      "User 270 recommendations: ['Shrek ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 181 recommendations: ['Once ', 'Hell Ride ', 'Substitute, The ', 'A Quiet Place ', 'Toy Story ']\n",
      "User 454 recommendations: ['Once ', 'Source Code ', 'Babel ', 'A Quiet Place ', 'Toy Story ']\n",
      "User 596 recommendations: ['Robin Hood ', 'Flight of the Navigator ', 'Transformers: The Movie ', 'Time Masters (MaÃ®tres du temps, Les) ', 'Return to Never Land ']\n",
      "User 246 recommendations: ['Klute ', 'Lilo & Stitch ', 'Unforgiven ', 'Conspiracy Theory ', 'Last Supper, The ']\n",
      "User 586 recommendations: ['Rush Hour ', 'Short Circuit ', 'Shrek ', 'Rampage ', 'Power/Rangers ']\n",
      "User 385 recommendations: ['Lincoln ', 'Madly in Love ', 'Think Like a Man ', \"It's a Wonderful Life \", 'Obsession ']\n",
      "User 396 recommendations: ['Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 107 recommendations: ['Shrek ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 421 recommendations: ['Kolya (Kolja) ', 'Eagle, The ', 'Colonel Chabert, Le ', 'Fallen Angels (Duo luo tian shi) ', 'Runaway Train ']\n",
      "User 117 recommendations: ['All the Boys Love Mandy Lane ', 'How the Grinch Stole Christmas! ', 'Robin Hood ', 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 603 recommendations: ['Good Son, The ', 'Star Trek V: The Final Frontier ', 'Black Swan ', 'Biutiful ', 'Guest from the Future (Gostya iz buduschego) ']\n",
      "User 145 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 31 recommendations: ['Star Trek V: The Final Frontier ', 'Mexican, The ', 'Kazaam ', 'Nightmare Before Christmas, The ', 'Time Bandits ']\n",
      "User 162 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 528 recommendations: ['Three Billboards Outside Ebbing, Missouri ', 'Shrek ', 'Steve Jobs ', 'Nightmare Before Christmas, The ', 'Town, The ']\n",
      "User 600 recommendations: ['Tin Man ', 'Zoom ', 'Captain Newman, M.D. ', 'Colonel Chabert, Le ', 'Harry Potter and the Deathly Hallows: Part 1 ']\n",
      "User 539 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Cloudy with a Chance of Meatballs ', 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 313 recommendations: ['Voices of a Distant Star (Hoshi no koe) ', 'Ratchet & Clank ', 'Conspiracy Theory ', 'Source Code ', 'Return to Never Land ']\n",
      "User 215 recommendations: ['Kolya (Kolja) ', '4 Months, 3 Weeks and 2 Days (4 luni, 3 saptamÃ¢ni si 2 zile) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ']\n",
      "User 323 recommendations: ['How the Grinch Stole Christmas! ', 'Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ']\n",
      "User 236 recommendations: [\"Class of Nuke 'Em High \", 'Short Circuit ', 'Gremlins 2: The New Batch ', 'I Sell the Dead ', 'Leprechaun 3 ']\n",
      "User 308 recommendations: ['Shrek ', 'Flight of the Navigator ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Transformers: The Movie ', 'Time Masters (MaÃ®tres du temps, Les) ']\n",
      "User 415 recommendations: ['Fried Green Tomatoes ', \"Amores Perros (Love's a Bitch) \", 'Messenger: The Story of Joan of Arc, The ', 'Australia ', 'West Beirut (West Beyrouth) ']\n",
      "User 80 recommendations: ['Paper Towns ', 'Gran Torino ', 'Counselor, The ', 'The Amazing Screw-On Head ', 'Equalizer, The ']\n",
      "User 582 recommendations: ['Once ', 'Venus ', \"Ender's Game \", 'Alice in Wonderland ', 'Thief of Bagdad, The ']\n",
      "User 59 recommendations: ['Tin Man ', 'Zoom ', 'Conspiracy Theory ', 'Babel ', 'A Quiet Place ']\n",
      "User 304 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Robin Hood ', 'Mexican, The ', \"It's a Wonderful Life \", 'Children of Men ']\n",
      "User 54 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 264 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Star Trek V: The Final Frontier ', 'Mexican, The ', \"Hitchhiker's Guide to the Galaxy, The \"]\n",
      "User 468 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 69 recommendations: ['All the Boys Love Mandy Lane ', 'Rachel Getting Married ', 'Sling Blade ', 'City Slickers ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 224 recommendations: ['John Mulaney: New In Town ', 'Kazaam ', 'Saving Christmas ', 'Time Bandits ', 'Chicago ']\n",
      "User 354 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Toy Story ']\n",
      "User 65 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 601 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 222 recommendations: ['Three Billboards Outside Ebbing, Missouri ', 'Osmosis Jones ', 'The Voices ', 'Red Dragon ', 'Town, The ']\n",
      "User 305 recommendations: ['Bean ', 'Colonel Chabert, Le ', 'Dead or Alive 2: TÃ´bÃ´sha ', 'Saving Christmas ', 'Guest from the Future (Gostya iz buduschego) ']\n",
      "User 476 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 88 recommendations: ['Unforgiven ', 'Source Code ', 'Babel ', 'Last Supper, The ', 'To Kill a Mockingbird ']\n",
      "User 256 recommendations: ['Bootleggers ', 'Robin Hood ', \"It's a Wonderful Life \", 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 259 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Robin Hood ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 151 recommendations: ['All Over the Guy ', 'Robin Hood ', 'My Cousin Vinny ', 'Truth About Cats & Dogs, The ', 'Christmas Story, A ']\n",
      "User 221 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Patton ', \"Beat That My Heart Skipped, The (battre mon coeur s'est arrÃªtÃ©, De) \", 'Darkon ', 'We Could Be King ']\n",
      "User 96 recommendations: ['Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 297 recommendations: ['I Know Who Killed Me ', 'Unforgiven ', 'Last Supper, The ', 'Toy Story ', 'To Kill a Mockingbird ']\n",
      "User 57 recommendations: ['Kolya (Kolja) ', 'Shrek ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Captain Newman, M.D. ']\n",
      "User 252 recommendations: ['Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 490 recommendations: ['Gone ', 'Diabolique ', 'Nuremberg ', 'Good Son, The ', 'Kazaam ']\n",
      "User 239 recommendations: ['Rush Hour ', 'Short Circuit ', 'Sling Blade ', 'Conspiracy Theory ', 'Spirited Away (Sen to Chihiro no kamikakushi) ']\n",
      "User 288 recommendations: ['Happy Gilmore ', 'Fried Green Tomatoes ', 'My Cousin Vinny ', 'Heart of a Dog (Sobachye serdtse) ', 'Saving Christmas ']\n",
      "User 571 recommendations: ['A Quiet Place ', 'Christmas Story, A ', 'Babel ', 'Time Bandits ', 'Chicago ']\n",
      "User 195 recommendations: ['Fried Green Tomatoes ', 'Klute ', 'City Slickers ', 'Last Supper, The ', 'To Kill a Mockingbird ']\n",
      "User 76 recommendations: ['Haunting in Connecticut, The ', 'John Mulaney: New In Town ', 'Lilo & Stitch ', 'Freddy vs. Jason ', 'Children of Men ']\n",
      "User 149 recommendations: ['Thirteenth Floor, The ', 'Halloween H20: 20 Years Later (Halloween 7: The Revenge of Laurie Strode) ', 'Star Trek V: The Final Frontier ', 'Nick of Time ', 'Time Bandits ']\n",
      "User 201 recommendations: ['Bean ', 'Shrek ', \"For Roseanna (Roseanna's Grave) \", 'Kazaam ', 'Christmas Story, A ']\n",
      "User 25 recommendations: ['Lars and the Real Girl ', 'Last Winter, The ', \"Nina's Heavenly Delights \", 'Gran Torino ', 'Toy Story ']\n",
      "User 272 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Star Trek V: The Final Frontier ', \"Hitchhiker's Guide to the Galaxy, The \", 'Children of Men ']\n",
      "User 50 recommendations: ['Zoom ', '4 Months, 3 Weeks and 2 Days (4 luni, 3 saptamÃ¢ni si 2 zile) ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Babel ', 'A Quiet Place ']\n",
      "User 284 recommendations: ['All Over the Guy ', 'Car Wash ', 'Truth About Cats & Dogs, The ', 'City Slickers ', 'Toy Story ']\n",
      "User 318 recommendations: ['Two Days, One Night (Deux jours, une nuit) ', 'The Amazing Screw-On Head ', 'Escape from Planet Earth ', \"I'll Follow You Down \", 'Doctor Strange ']\n",
      "User 312 recommendations: ['Lincoln ', 'Fried Green Tomatoes ', 'My Girl 2 ', 'Baxter, The ', 'A Quiet Place ']\n",
      "User 525 recommendations: ['Fried Green Tomatoes ', 'Chorus Line, A ', 'Source Code ', 'Jimmy Hollywood ', 'Town, The ']\n",
      "User 481 recommendations: ['Game, The ', 'Spy Next Door, The ', 'Despite the Falling Snow ', 'Cocktail ', 'Forever Young ']\n",
      "User 489 recommendations: ['Paper Towns ', 'Diabolique ', 'Nuremberg ', 'Florence Foster Jenkins ', 'Memories of Me ']\n",
      "User 369 recommendations: ['City Heat ', 'Transformers: The Movie ', 'Conspiracy Theory ', 'Source Code ', 'Toy Story ']\n",
      "User 223 recommendations: ['Robin Hood ', 'Lilo & Stitch ', \"It's a Wonderful Life \", 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Men in Black (a.k.a. MIB) ']\n",
      "User 375 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 363 recommendations: ['Crush ', 'Happy Gilmore ', 'In July (Im Juli) ', 'Damsels in Distress ', 'Life Partners ']\n",
      "User 140 recommendations: ['Lincoln ', 'My Life as McDull (Mak dau goo si) ', 'Fried Green Tomatoes ', 'Happy Endings ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 457 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 157 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 253 recommendations: [\"For Roseanna (Roseanna's Grave) \", 'Chorus Line, A ', 'Little Shop of Horrors ', 'Whole Nine Yards, The ', 'Jimmy Hollywood ']\n",
      "User 274 recommendations: ['Paper Towns ', 'Game, The ', 'Counselor, The ', 'The Amazing Screw-On Head ', \"I'll Follow You Down \"]\n",
      "User 277 recommendations: ['Godzilla ', 'Star Trek V: The Final Frontier ', 'Heart of a Dog (Sobachye serdtse) ', 'Men in Black (a.k.a. MIB) ', 'Time Bandits ']\n",
      "User 552 recommendations: ['Fried Green Tomatoes ', 'Tin Man ', 'Messenger: The Story of Joan of Arc, The ', 'Robin Hood ', 'Toy Story ']\n",
      "User 568 recommendations: [\"Amores Perros (Love's a Bitch) \", 'Waitress ', 'West Beirut (West Beyrouth) ', 'Major Dundee ', 'Toy Story ']\n",
      "User 339 recommendations: ['Kolya (Kolja) ', 'Mona Lisa Smile ', \"For Roseanna (Roseanna's Grave) \", 'Magic Mike ', 'Rachel Getting Married ']\n",
      "User 203 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 202 recommendations: ['Lincoln ', 'My Life as McDull (Mak dau goo si) ', 'Sandpiper, The ', 'Fallen Angels (Duo luo tian shi) ', 'City Slickers ']\n",
      "User 39 recommendations: ['Reign of Fire ', 'Game of Death ', \"Nina's Heavenly Delights \", '42nd Street ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 164 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 497 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Mr. Woodcock ']\n",
      "User 420 recommendations: ['Robin Hood ', 'Good Son, The ', 'John Mulaney: New In Town ', 'Lilo & Stitch ', \"It's a Wonderful Life \"]\n",
      "User 255 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 137 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Lincoln ', 'Robin Hood ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 398 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Shrek ', 'Lilo & Stitch ', 'Harry Potter and the Deathly Hallows: Part 1 ', \"It's a Wonderful Life \"]\n",
      "User 414 recommendations: ['My Life as McDull (Mak dau goo si) ', 'Hour of the Wolf (Vargtimmen) ', 'Voices of a Distant Star (Hoshi no koe) ', 'Shock Corridor ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 172 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Short Circuit ', 'Mexican, The ', \"Hitchhiker's Guide to the Galaxy, The \"]\n",
      "User 237 recommendations: ['Mars Attacks! ', 'Shrek ', 'Star Trek V: The Final Frontier ', 'Mexican, The ', \"Hitchhiker's Guide to the Galaxy, The \"]\n",
      "User 555 recommendations: ['Saving Christmas ', 'Whole Nine Yards, The ', 'Kazaam ', 'Last Supper, The ', 'Guest from the Future (Gostya iz buduschego) ']\n",
      "User 180 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 435 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 34 recommendations: ['What Women Want ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'The Voices ', 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 247 recommendations: ['The Nut Job 2: Nutty by Nature ', \"Ender's Game \", 'Alice in Wonderland ', 'Kazaam ', 'Nightmare Before Christmas, The ']\n",
      "User 541 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', 'Get Him to the Greek ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 356 recommendations: ['Tin Man ', 'Zoom ', 'All Is Lost ', 'Source Code ', 'Babel ']\n",
      "User 281 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 228 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 405 recommendations: ['Three Billboards Outside Ebbing, Missouri ', 'Conspiracy Theory ', 'Steve Jobs ', 'Source Code ', 'Town, The ']\n",
      "User 609 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 62 recommendations: ['Rampage ', 'Power/Rangers ', 'Starsky & Hutch ', 'Memories of Me ', \"Decline of the American Empire, The (DÃ©clin de l'empire amÃ©ricain, Le) \"]\n",
      "User 36 recommendations: ['My Life as McDull (Mak dau goo si) ', 'Fried Green Tomatoes ', 'Outsiders, The ', 'Happy Endings ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 179 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 590 recommendations: ['Anomalisa ', 'Lincoln ', 'Civil War, The ', \"For Roseanna (Roseanna's Grave) \", 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 287 recommendations: ['How the Grinch Stole Christmas! ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Eagle, The ', 'Runaway Train ', 'Guest from the Future (Gostya iz buduschego) ']\n",
      "User 111 recommendations: [\"A Merry Friggin' Christmas \", 'Surviving Christmas ', 'Brothers Solomon, The ', 'Beer League ', 'Stingray Sam ']\n",
      "User 353 recommendations: ['Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 542 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Too Funny to Fail: The Life and Death of The Dana Carvey Show ', \"It's a Wonderful Life \", 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 83 recommendations: ['All the Boys Love Mandy Lane ', 'Waitress ', 'Source Code ', 'Babel ', '42nd Street ']\n",
      "User 248 recommendations: ['Jupiter Ascending ', 'Rampage ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Power/Rangers ', 'Spirited Away (Sen to Chihiro no kamikakushi) ']\n",
      "User 269 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 451 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 482 recommendations: ['Mona Lisa Smile ', 'Colonel Chabert, Le ', 'Wuthering Heights ', 'Biutiful ', 'Crow, The ']\n",
      "User 70 recommendations: ['Once ', 'Sandpiper, The ', 'Reign of Fire ', 'Game of Death ', 'Fallen Angels (Duo luo tian shi) ']\n",
      "User 377 recommendations: ['My Life as McDull (Mak dau goo si) ', 'Fried Green Tomatoes ', 'Outsiders, The ', 'Happy Endings ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 545 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 104 recommendations: ['Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Fried Green Tomatoes ', \"It's a Wonderful Life \", 'Jimmy Hollywood ', 'Toy Story ']\n",
      "User 521 recommendations: ['Crush ', 'In July (Im Juli) ', 'Waiting to Exhale ', 'Damsels in Distress ', 'Life Partners ']\n",
      "User 529 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 361 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Shrek ', 'Star Trek V: The Final Frontier ', 'Mexican, The ']\n",
      "User 48 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Shrek ', 'Star Trek V: The Final Frontier ', \"Hitchhiker's Guide to the Galaxy, The \"]\n",
      "User 511 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 456 recommendations: ['Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ', 'A Quiet Place ']\n",
      "User 495 recommendations: ['I Know Who Killed Me ', '10 Cloverfield Lane ', 'Andrei Rublev (Andrey Rublyov) ', 'Counselor, The ', 'Gardens of Stone ']\n",
      "User 268 recommendations: ['Sandpiper, The ', 'Straight Story, The ', 'Leprechaun 3 ', \"I'll Follow You Down \", 'Melvin and Howard ']\n",
      "User 533 recommendations: ['Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 14 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 378 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 220 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', \"It's a Wonderful Life \", 'Source Code ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 74 recommendations: ['Culture High, The ', 'Game, The ', 'Zoom ', 'Black Swan ', 'A Quiet Place ']\n",
      "User 240 recommendations: ['Car Wash ', 'Robin Hood ', 'My Cousin Vinny ', 'Whole Nine Yards, The ', 'City Slickers ']\n",
      "User 412 recommendations: ['All the Boys Love Mandy Lane ', 'Ready to Wear (Pret-A-Porter) ', 'Waitress ', 'Waiting to Exhale ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 450 recommendations: ['Ryuzo and the Seven Henchmen ', 'City Heat ', 'How the Grinch Stole Christmas! ', 'Game of Death ', 'Toy Story ']\n",
      "User 345 recommendations: ['All the Boys Love Mandy Lane ', 'How the Grinch Stole Christmas! ', 'Reign of Fire ', 'Game of Death ', 'Toy Story ']\n",
      "User 271 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 370 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'What Women Want ', \"Hitchhiker's Guide to the Galaxy, The \", 'Men in Black (a.k.a. MIB) ', 'Toy Story ']\n",
      "User 578 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 112 recommendations: ['All Over the Guy ', 'Car Wash ', 'Mexican, The ', 'Kazaam ', 'City Slickers ']\n",
      "User 475 recommendations: ['Mars Attacks! ', 'Rush Hour ', 'Short Circuit ', 'Star Trek V: The Final Frontier ', 'Children of Men ']\n",
      "User 263 recommendations: ['Kolya (Kolja) ', 'Fried Green Tomatoes ', 'Chorus Line, A ', 'Colonel Chabert, Le ', 'Little Shop of Horrors ']\n",
      "User 465 recommendations: ['Lincoln ', 'All the Boys Love Mandy Lane ', 'Hell Ride ', \"It's a Wonderful Life \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 154 recommendations: ['Beer League ', 'Alice in Wonderland ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Thief of Bagdad, The ', 'Toy Story ']\n",
      "User 204 recommendations: ['Gone ', 'Diabolique ', 'Nuremberg ', 'Good Son, The ', 'Town, The ']\n",
      "User 71 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 362 recommendations: ['Paper Towns ', 'Lars and the Real Girl ', 'City Slickers ', 'Sling Blade ', 'Starsky & Hutch ']\n",
      "User 466 recommendations: ['Brothers Solomon, The ', 'Waitress ', \"Ender's Game \", 'Alice in Wonderland ', 'Thief of Bagdad, The ']\n",
      "User 408 recommendations: ['Lincoln ', 'Rampage ', \"Ender's Game \", \"It's a Wonderful Life \", 'Doctor Strange ']\n",
      "User 129 recommendations: ['The Nut Job 2: Nutty by Nature ', 'Harry Potter and the Deathly Hallows: Part 1 ', 'Conspiracy Theory ', 'Source Code ', 'Nightmare Before Christmas, The ']\n",
      "User 462 recommendations: ['Patton ', 'Star Trek V: The Final Frontier ', '4 Little Girls ', 'Source Code ', 'Leprechaun 3 ']\n",
      "User 68 recommendations: ['Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Clockstoppers ', 'Cloudy with a Chance of Meatballs ', 'Thief of Bagdad, The ', 'Untraceable ']\n",
      "User 449 recommendations: ['Kolya (Kolja) ', 'How the Grinch Stole Christmas! ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ']\n",
      "User 474 recommendations: ['Captain Newman, M.D. ', 'Colonel Chabert, Le ', 'What Women Want ', 'Damsels in Distress ', 'Last Supper, The ']\n",
      "User 453 recommendations: ['Gone ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Last Supper, The ', 'Apt Pupil ']\n",
      "User 604 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', 'Get Him to the Greek ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 438 recommendations: ['Ready to Wear (Pret-A-Porter) ', 'Robin Hood ', 'City Slickers ', 'Celebrity ', 'Nightmare Before Christmas, The ']\n",
      "User 9 recommendations: ['Much Ado About Nothing ', 'Once ', 'My Girl 2 ', 'Baxter, The ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 563 recommendations: ['Kolya (Kolja) ', 'Diabolique ', 'Shrek ', \"For Roseanna (Roseanna's Grave) \", 'Harry Potter and the Deathly Hallows: Part 1 ']\n",
      "User 391 recommendations: ['Patton ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Fallen Angels (Duo luo tian shi) ', 'Cloudy with a Chance of Meatballs ', 'To Kill a Mockingbird ']\n",
      "User 567 recommendations: ['Anomalisa ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Kazaam ', 'The Emoji Movie ']\n",
      "User 144 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'What Women Want ', \"It's a Wonderful Life \", \"Hitchhiker's Guide to the Galaxy, The \", 'Cloudy with a Chance of Meatballs ']\n",
      "User 233 recommendations: ['Lilo & Stitch ', 'What Women Want ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', \"Hitchhiker's Guide to the Galaxy, The \", 'Cloudy with a Chance of Meatballs ']\n",
      "User 594 recommendations: ['Mexican, The ', 'Bloodmoon ', 'Wrath of the Titans ', 'Thief of Bagdad, The ', 'Eva ']\n",
      "User 393 recommendations: ['Jupiter Ascending ', 'Rampage ', 'Venus ', 'Ratchet & Clank ', 'Last Winter, The ']\n",
      "User 471 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', 'Waiting to Exhale ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 573 recommendations: ['Bean ', 'The Nut Job 2: Nutty by Nature ', 'Truth About Cats & Dogs, The ', 'Christmas Story, A ', 'City Slickers ']\n",
      "User 27 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Waiting to Exhale ', 'Transformers: The Movie ', 'Sling Blade ', \"It's a Wonderful Life \"]\n",
      "User 63 recommendations: ['Anomalisa ', 'The Nut Job 2: Nutty by Nature ', 'Planes ', 'Kazaam ', 'Babel ']\n",
      "User 276 recommendations: ['Mexican, The ', 'Whole Nine Yards, The ', 'Truth About Cats & Dogs, The ', 'City Slickers ', 'Men in Black (a.k.a. MIB) ']\n",
      "User 146 recommendations: ['All the Boys Love Mandy Lane ', 'Spring ', 'Halloween H20: 20 Years Later (Halloween 7: The Revenge of Laurie Strode) ', 'Rachel Getting Married ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 440 recommendations: ['My Life as McDull (Mak dau goo si) ', 'Fried Green Tomatoes ', 'Outsiders, The ', 'Happy Endings ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 311 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 389 recommendations: ['Shrek ', 'Robin Hood ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 171 recommendations: ['Robin Hood ', 'Godzilla ', 'Star Trek V: The Final Frontier ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Men in Black (a.k.a. MIB) ']\n",
      "User 258 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 135 recommendations: ['Saving Christmas ', 'Unforgiven ', 'City Slickers ', 'Last Supper, The ', 'To Kill a Mockingbird ']\n",
      "User 64 recommendations: ['Gone ', 'Good Son, The ', \"Rosemary's Baby \", 'Babel ', 'Last Supper, The ']\n",
      "User 538 recommendations: [\"Bridget Jones's Baby \", 'Funny Face ', 'Shrek ', 'Robin Hood ', 'Harry Potter and the Deathly Hallows: Part 1 ']\n",
      "User 40 recommendations: ['Shrek ', 'Robin Hood ', 'Waiting to Exhale ', 'The Nut Job 2: Nutty by Nature ', 'Spirited Away (Sen to Chihiro no kamikakushi) ']\n",
      "User 182 recommendations: ['Gone ', 'Black Swan ', 'Babel ', 'Last Supper, The ', 'Biutiful ']\n",
      "User 185 recommendations: ['Shrek ', 'The Nut Job 2: Nutty by Nature ', 'Kazaam ', 'Spirited Away (Sen to Chihiro no kamikakushi) ', 'Nightmare Before Christmas, The ']\n",
      "User 303 recommendations: ['All the Boys Love Mandy Lane ', 'Hell Ride ', \"Block Party (a.k.a. Dave Chappelle's Block Party) \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 557 recommendations: ['Harry Potter and the Deathly Hallows: Part 1 ', \"It's a Wonderful Life \", \"Hitchhiker's Guide to the Galaxy, The \", 'Cloudy with a Chance of Meatballs ', 'Toy Story ']\n",
      "User 493 recommendations: ['Once ', 'Ryuzo and the Seven Henchmen ', 'City Heat ', 'Five Deadly Venoms ', 'Toy Story ']\n",
      "User 513 recommendations: ['Robin Hood ', 'Lilo & Stitch ', \"It's a Wonderful Life \", 'Nightmare Before Christmas, The ', 'Toy Story ']\n",
      "User 30 recommendations: ['All the Boys Love Mandy Lane ', \"World's Fastest Indian, The \", \"Nina's Heavenly Delights \", 'Toy Story ', 'Untraceable ']\n",
      "User 123 recommendations: ['Paper Towns ', 'Game, The ', 'The Amazing Screw-On Head ', \"I'll Follow You Down \", 'Children of Men ']\n",
      "User 426 recommendations: ['Thief of Bagdad, The ', 'Flight of the Navigator ', 'Transformers: The Movie ', 'Alice in Wonderland ', 'Return to Never Land ']\n",
      "User 373 recommendations: ['How the Grinch Stole Christmas! ', 'Waiting to Exhale ', \"For Roseanna (Roseanna's Grave) \", 'Cold Comfort Farm ', 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 364 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 98 recommendations: ['Too Funny to Fail: The Life and Death of The Dana Carvey Show ', 'Robin Hood ', 'What Women Want ', \"Hitchhiker's Guide to the Galaxy, The \", 'Men in Black (a.k.a. MIB) ']\n",
      "User 500 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', \"It's a Wonderful Life \", 'Spirited Away (Sen to Chihiro no kamikakushi) ', \"Hitchhiker's Guide to the Galaxy, The \", 'Cloudy with a Chance of Meatballs ']\n",
      "User 423 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 207 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 198 recommendations: ['All is Bright ', 'He Never Died ', 'Colonel Chabert, Le ', 'Memories of Me ', 'City of Women, The (CittÃ  delle donne, La) ']\n",
      "User 29 recommendations: ['Sandpiper, The ', 'Lincoln ', 'Venus ', 'Fallen Angels (Duo luo tian shi) ', 'Last Winter, The ']\n",
      "User 602 recommendations: ['How the Grinch Stole Christmas! ', 'Hell Ride ', 'Robin Hood ', 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 360 recommendations: ['All the Boys Love Mandy Lane ', 'Waitress ', 'Source Code ', \"Nina's Heavenly Delights \", 'Toy Story ']\n",
      "User 130 recommendations: ['All the Boys Love Mandy Lane ', 'Waiting to Exhale ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ']\n",
      "User 119 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Town, The ']\n",
      "User 331 recommendations: ['Star Trek V: The Final Frontier ', 'John Mulaney: New In Town ', 'Mexican, The ', 'Source Code ', 'Babel ']\n",
      "User 367 recommendations: ['Robin Hood ', 'My Cousin Vinny ', 'What Women Want ', 'Kazaam ', 'Time Bandits ']\n",
      "User 51 recommendations: ['Lincoln ', \"Amores Perros (Love's a Bitch) \", 'Christmas Story, A ', 'West Beirut (West Beyrouth) ', 'Toy Story ']\n",
      "User 267 recommendations: ['All the Boys Love Mandy Lane ', 'Tristram Shandy: A Cock and Bull Story ', \"Nina's Heavenly Delights \", 'Heart of a Dog (Sobachye serdtse) ', 'Toy Story ']\n",
      "User 326 recommendations: ['Kolya (Kolja) ', 'Captain Newman, M.D. ', \"For Roseanna (Roseanna's Grave) \", 'Colonel Chabert, Le ', 'Source Code ']\n",
      "User 416 recommendations: ['Rush Hour ', 'Short Circuit ', 'Star Trek V: The Final Frontier ', 'Mexican, The ', 'Children of Men ']\n",
      "User 168 recommendations: ['Life Is Beautiful (La Vita Ã¨ bella) ', 'Sling Blade ', \"Nina's Heavenly Delights \", 'Looking for Comedy in the Muslim World ', 'Untraceable ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert predicted_ratings_classification_train to a pandas DataFrame if it's a numpy array\n",
    "if isinstance(predicted_ratings_classification_train, np.ndarray):\n",
    "    # Use the length of train_matrix as the number of rows and items as columns\n",
    "    num_users, num_items = train_matrix.shape\n",
    "    predicted_ratings_classification_train = pd.DataFrame(predicted_ratings_classification_train, index=range(num_users), columns=range(num_items))\n",
    "\n",
    "# Initialize a dictionary to store top recommendations for each user\n",
    "top_recommendations_per_user = {}\n",
    "\n",
    "# Iterate over each user in the train matrix\n",
    "for user_id in train_matrix.index:\n",
    "    # Get the top recommendations for the current user using predicted_ratings_classification_train\n",
    "    recommendations = get_top_recommendations(user_id, predicted_ratings_classification_train, df)\n",
    "    \n",
    "    # Store the recommendations in the dictionary\n",
    "    top_recommendations_per_user[user_id] = recommendations\n",
    "\n",
    "# Print the top 5 recommendations for each user\n",
    "for user_id, recommendations in top_recommendations_per_user.items():\n",
    "    print(f\"User {user_id} recommendations:\", recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Model Evaluation (Item KNN Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Training Data: 0.822796188644207\n",
      "Root Mean Squared Error (RMSE) on Training Data: 1.0535259015044494\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure predicted_ratings_classification_train is a numpy array\n",
    "if isinstance(predicted_ratings_classification_train, pd.DataFrame):\n",
    "    predicted_ratings_classification_train = predicted_ratings_classification_train.to_numpy()\n",
    "\n",
    "# Assuming train_matrix is the numpy array representing the item-user matrix\n",
    "\n",
    "# Ensure train_matrix is a 2D array\n",
    "if isinstance(train_matrix, pd.DataFrame):\n",
    "    train_matrix = train_matrix.to_numpy()\n",
    "\n",
    "if train_matrix.ndim == 1:\n",
    "    train_matrix = np.expand_dims(train_matrix, axis=0)\n",
    "\n",
    "# Evaluate the model\n",
    "mae, rmse = evaluate_model(train, predicted_ratings_classification_train)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Training Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Training Data:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Parameter Tuning\n",
    "\n",
    "Experiment with different parameters such as similarity threshold, neighborhood size, and similarity metric to optimize the performance of the ItemKNN algorithm.\n",
    "Use techniques like cross-validation to tune these parameters and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: NearestNeighbors</label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={'metric': ['cosine', 'euclidean'],\n",
       "                         'n_neighbors': [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method='predict'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'cosine', 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom scorer based on cosine similarity defined above\n",
    "cosine_similarity_scorer = make_scorer(cosine_similarity)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 15, 30, 40],\n",
    "    'metric': ['cosine', 'euclidean']\n",
    "}\n",
    "\n",
    "# Initialize NearestNeighbors model\n",
    "knn_model = NearestNeighbors()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring=cosine_similarity_scorer)\n",
    "\n",
    "# Fit the data to perform hyperparameter tuning\n",
    "grid_search.fit(train_matrix)  # val_matrix contains item-user matrix\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to obtain again the ratings for the full val set to evaluate the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_2140\\4246365781.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  recalculated_predictions.fillna(recalculated_predictions.mean().mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Function to recalculate predictions for a given matrix using the trained model\n",
    "def recalculate_predictions(matrix, item_neighborhoods):\n",
    "    \"\"\"\n",
    "    Recalculate predictions for a given matrix using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "        matrix (pd.DataFrame): Matrix containing user-item ratings.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing recalculated predicted ratings for each user.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame to store recalculated predicted ratings\n",
    "    recalculated_predictions = pd.DataFrame(index=matrix.index, columns=matrix.columns)\n",
    "\n",
    "    # Iterate over each user-item pair in the matrix\n",
    "    for user_id, user_ratings in matrix.iterrows():\n",
    "        for movie_id, rating in user_ratings.items():\n",
    "            # Skip if the rating is non-zero (indicating a rating given by the user)\n",
    "            if rating != 0:\n",
    "                continue\n",
    "\n",
    "            # Check if the movie has a neighborhood defined\n",
    "            if movie_id in item_neighborhoods:\n",
    "                neighborhood = item_neighborhoods[movie_id]\n",
    "\n",
    "                # Initialize a flag to track if the rating has been predicted\n",
    "                rating_predicted = False\n",
    "\n",
    "                # Iterate over the items in the neighborhood\n",
    "                for neighbor_movie_id in neighborhood:\n",
    "                    # Check if the neighbor movie has been rated by the user\n",
    "                    if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0:\n",
    "                        # Use the rating of the closest item in the neighborhood\n",
    "                        predicted_rating = user_ratings.loc[neighbor_movie_id]\n",
    "                        rating_predicted = True\n",
    "                        break\n",
    "\n",
    "                # If none of the items in the neighborhood have been rated, use the user's average rating\n",
    "                if not rating_predicted:\n",
    "                    if user_ratings[user_ratings != 0].empty:\n",
    "                        # If the user hasn't rated any movies, use the global mean rating\n",
    "                        predicted_rating = matrix[matrix != 0].mean().mean()\n",
    "                    else:\n",
    "                        # Use the average of the ratings given by the user\n",
    "                        predicted_rating = user_ratings[user_ratings != 0].mean()\n",
    "\n",
    "                # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "                recalculated_predictions.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "    # Fill NaN values with mean ratings across all users\n",
    "    recalculated_predictions.fillna(recalculated_predictions.mean().mean(), inplace=True)\n",
    "\n",
    "    return recalculated_predictions\n",
    "\n",
    "\n",
    "# Recalculate predictions for the validation set (train_val_matrix)\n",
    "recalculated_val_predictions = recalculate_predictions(val_matrix, item_neighborhoods_classification_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>3.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>3.652444</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.652444</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>3.652444</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>...</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>2.829670</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>3.652444</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.652444</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.652444</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>3.652444</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows Ã— 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         4         15        30        43        89        104     \\\n",
       "userId                                                                          \n",
       "536      3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000   \n",
       "577      3.444444  3.444444  3.444444  3.444444  3.444444  3.444444  4.000000   \n",
       "113      3.500000  3.500000  3.500000  3.500000  3.500000  3.500000  3.500000   \n",
       "448      3.652444  2.829670  3.000000  2.829670  2.829670  4.000000  3.652444   \n",
       "523      4.166667  4.166667  4.166667  4.166667  4.166667  4.166667  4.166667   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "581      4.500000  4.500000  4.500000  4.500000  4.500000  4.500000  4.500000   \n",
       "605      3.652444  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000   \n",
       "79       4.500000  4.500000  4.500000  4.500000  4.500000  4.500000  4.500000   \n",
       "109      3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.652444   \n",
       "332      3.652444  3.250000  3.250000  3.250000  3.250000  3.250000  3.250000   \n",
       "\n",
       "movieId    108       122       146     ...    174479    174551    175475  \\\n",
       "userId                                 ...                                 \n",
       "536      3.000000  3.000000  3.000000  ...  3.000000  3.000000  3.000000   \n",
       "577      3.444444  3.444444  3.444444  ...  3.444444  3.444444  3.444444   \n",
       "113      3.500000  3.500000  3.500000  ...  3.500000  3.500000  3.500000   \n",
       "448      2.829670  3.652444  2.829670  ...  2.829670  4.000000  2.829670   \n",
       "523      4.166667  4.166667  4.166667  ...  4.166667  4.166667  4.166667   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "581      4.500000  4.500000  4.500000  ...  4.500000  4.500000  4.500000   \n",
       "605      3.000000  3.000000  3.000000  ...  3.000000  3.000000  3.000000   \n",
       "79       4.500000  4.500000  4.500000  ...  4.500000  4.500000  4.500000   \n",
       "109      3.000000  3.652444  3.000000  ...  3.000000  3.000000  3.000000   \n",
       "332      3.250000  3.250000  3.250000  ...  3.250000  3.250000  3.250000   \n",
       "\n",
       "movieId    176371    176389    177593    179813    181413    185029    186587  \n",
       "userId                                                                         \n",
       "536      3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  \n",
       "577      3.444444  3.444444  3.444444  3.444444  3.444444  3.444444  3.444444  \n",
       "113      3.500000  3.500000  3.500000  3.500000  3.500000  3.500000  3.500000  \n",
       "448      2.829670  5.000000  2.829670  2.829670  2.829670  2.829670  2.000000  \n",
       "523      4.166667  4.166667  4.166667  4.166667  4.166667  4.166667  4.166667  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "581      4.500000  4.500000  4.500000  4.500000  4.500000  4.500000  4.500000  \n",
       "605      3.000000  4.000000  3.000000  3.000000  3.500000  3.000000  3.000000  \n",
       "79       4.500000  4.500000  4.500000  4.500000  4.500000  4.500000  4.500000  \n",
       "109      3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  3.000000  \n",
       "332      3.250000  4.000000  3.250000  3.500000  4.500000  3.250000  3.250000  \n",
       "\n",
       "[85 rows x 487 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalculated_val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Train-Validation Data: 0.8862384903582982\n",
      "Root Mean Squared Error (RMSE) on Train-Validation Data: 1.1062703799857017\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae, rmse = evaluate_model(val, recalculated_val_predictions)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Train-Validation Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Train-Validation Data:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Deployment\n",
    "\n",
    "Once we have all the metrics, we have to recalculate the ratings for the test set, we are going to repeat the same process for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_2140\\4246365781.py:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  recalculated_predictions.fillna(recalculated_predictions.mean().mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# We have to reobtain the neighborhood for the train_val data\n",
    "# We will use the already calculated item-item similarity matrix for train_val data\n",
    "item_neighborhoods_classification_train_val = item_neighborhood_selection(item_similarity_matrix_train_val, k=5, item_ids=index_to_movie_id)\n",
    "\n",
    "# Recalculate predictions for the validation set (test matrix)\n",
    "recalculated_test_predictions = recalculate_predictions(test_matrix, item_neighborhoods_classification_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to evaluate the metrics for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Test Data: 0.809245626540846\n",
      "Root Mean Squared Error (RMSE) on Test Data: 1.0033399816659307\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae, rmse = evaluate_model(test, recalculated_test_predictions)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Test Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Data:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
