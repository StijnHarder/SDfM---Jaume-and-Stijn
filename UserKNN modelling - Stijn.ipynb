{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # to make jupyter print all outputs, not just the last one\n",
    "from IPython.core.display import HTML # to pretty print pandas df and be able to copy them over (e.g. to ppt slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_parquet('cleaned/netflix_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = netflix_df.sample(n=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['movieId','review_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2458112"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = df['review_data'].values\n",
    "user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(df['movieId'], review_data)])\n",
    "len(user_ids)\n",
    "len(np.unique(movieIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>review_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>1099</td>\n",
       "      <td>[{'date': 2003-03-31, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>573</td>\n",
       "      <td>[{'date': 2004-09-22, 'rating': 5.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>451</td>\n",
       "      <td>[{'date': 2005-08-16, 'rating': 5.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>384</td>\n",
       "      <td>[{'date': 2004-07-22, 'rating': 4.0, 'userId':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1492</td>\n",
       "      <td>[{'date': 2005-04-06, 'rating': 3.0, 'userId':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                        review_data\n",
       "1098     1099  [{'date': 2003-03-31, 'rating': 3.0, 'userId':...\n",
       "572       573  [{'date': 2004-09-22, 'rating': 5.0, 'userId':...\n",
       "450       451  [{'date': 2005-08-16, 'rating': 5.0, 'userId':...\n",
       "383       384  [{'date': 2004-07-22, 'rating': 4.0, 'userId':...\n",
       "1491     1492  [{'date': 2005-04-06, 'rating': 3.0, 'userId':..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'date': datetime.date(2004, 7, 23), 'rating': 5.0, 'userId': '2292389'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df['review_data'].iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(train_test_val_set):\n",
    "    \"\"\"\n",
    "    Creates a user-item matrix from the provided dataset containing review data.\n",
    "\n",
    "    Parameters:\n",
    "    train_test_val_set (DataFrame): DataFrame containing review data with columns 'review_data',\n",
    "                                    which is a list of dictionaries with keys 'userId', 'rating',\n",
    "                                    and 'movieId'.\n",
    "\n",
    "    Returns:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies), the matrix is an NumPy array which contains lists of user-item interactions, meaning a user and their corresponding ratings to the movieIds.    \n",
    "    \n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    \n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    \n",
    "    user_ids (numpy.ndarray): Array containing user IDs corresponding to each rating in the matrix.\n",
    "    \n",
    "    movie_ids (numpy.ndarray): Array containing movie IDs corresponding to each rating in the matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    review_data = train_test_val_set['review_data'].values\n",
    "    user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "    ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "    movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(train_test_val_set['movieId'], review_data)])\n",
    "\n",
    "    # create dictionaries to map user IDs and movie IDs to unique indices to map over\n",
    "    user_id_dict = {user_id: index for index, user_id in enumerate(np.unique(user_ids))}\n",
    "    movie_id_dict = {movie_id: index for index, movie_id in enumerate(np.unique(movieIds))}\n",
    "\n",
    "    # initialize an empty user-item matrix\n",
    "    user_count = len(user_id_dict)\n",
    "    movie_count = len(movie_id_dict)\n",
    "    user_item_matrix = np.zeros((user_count, movie_count))\n",
    "\n",
    "    # populate the user-item matrix with ratings from netflix dataset\n",
    "    for i, (user_id, movie_id, rating) in enumerate(zip(user_ids, movieIds, ratings)):\n",
    "        user_index = user_id_dict[user_id]\n",
    "        movie_index = movie_id_dict[movie_id]\n",
    "        user_item_matrix[user_index, movie_index] = rating\n",
    "\n",
    "    return user_item_matrix, user_id_dict, movie_id_dict, user_ids, movieIds\n",
    "\n",
    "def center_data(user_item_matrix):\n",
    "    \"\"\"\n",
    "    Creates a centered matrix of the previously created user-item matrix\n",
    "\n",
    "    Parameters:\n",
    "    User-item matrix which is made a Numpy array with appended lists with ratings of each users of each item. Each position in each list corresponds to the same movieId. Datatype within the matrix is float64. Each NaN value is converted to 0. In other words, for the time being the implicit feedback is converted to 0.\n",
    "\n",
    "    Return:\n",
    "    A centered user item matrix, where the row mean of each user is subtracted from the initial ratings, to account for variations in ratings\n",
    "    \n",
    "    \"\"\"\n",
    "    # Check for NaN values and replace them with 0\n",
    "    user_item_matrix[np.isnan(user_item_matrix)] = 0\n",
    "    \n",
    "    # Compute user means\n",
    "    user_means = np.mean(user_item_matrix, axis=1)\n",
    "    \n",
    "    # Center the data\n",
    "    centered_user_item_matrix = user_item_matrix - user_means[:, np.newaxis]\n",
    "    \n",
    "    return centered_user_item_matrix, user_means\n",
    "\n",
    "# I will decompose the user item matrix in this function using numpy\n",
    "def apply_svd(centered_user_item_matrix, num_latent_factors):\n",
    "    \"\"\"\n",
    "    Applies Singular Value Decomposition (SVD) to decompose the centered user-item matrix into three matrices:\n",
    "    U, Sigma, and Vt.\n",
    "\n",
    "    U: user matrix with values which represent the relation between the chosen latent factors, Users are the rows, matrix is orthonormal to Vt\n",
    "    Sigma: diagonal matrix where the chosen latent factors are in the diagonal line, ordered descendingly. \n",
    "    Vt: Item matrix with values which represent the relation between the chosen latent factors, Items are the columns, matrix is orthonormal to U\n",
    "\n",
    "    Parameters:\n",
    "    centered_user_item_matrix (numpy.ndarray): Centered user-item matrix to be decomposed.\n",
    "    num_latent_factors (int): Number of latent factors to retain in the decomposition.\n",
    "\n",
    "    Returns:\n",
    "    U (numpy.ndarray): Matrix representing the relationship between users and latent factors.\n",
    "    Sigma (numpy.ndarray): Diagonal matrix containing the singular values, representing the importance of each latent factor.\n",
    "    Vt (numpy.ndarray): Transpose of the matrix representing the relationship between items and latent factors.\n",
    "\n",
    "    \"\"\"\n",
    "    # U, sigma and Vt are created using the svd function from numpy\n",
    "    U, Sigma, Vt = np.linalg.svd(centered_user_item_matrix, full_matrices=False)\n",
    "    # set up sigma, which is the diagonal matrix from the decomposition\n",
    "    Sigma = np.diag(Sigma[:num_latent_factors])\n",
    "    # set up U and Vt which have to orthonormal to each other to ensure U represents each user and Vt represents each item, otherwise the total matrix would not add up.\n",
    "    U = U[:, :num_latent_factors]\n",
    "    Vt = Vt[:num_latent_factors, :]\n",
    "    return U, Sigma, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix, user_id_dict, movie_id_dict, user_ids, movie_ids = create_user_item_matrix(df)\n",
    "\n",
    "# get unique movieIds, use set to ensure unique values and put ids in a list\n",
    "user_ids = list(set(user_ids))\n",
    "item_ids = list(set(movie_ids))\n",
    "\n",
    "# unpack the tuple returned by center_data function to get an updates user item matrix which is more robust to variations in rating\n",
    "centered_user_item_matrix, user_means = center_data(user_item_matrix)\n",
    "\n",
    "num_latent_factors = 2\n",
    "\n",
    "# apply SVD using the centered matrix to reduce memory usage and to decompose the matrix to be able to make recommendations using the dot product method\n",
    "U, Sigma, Vt = apply_svd(centered_user_item_matrix, num_latent_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector_a, vector_b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors.\n",
    "\n",
    "    Parameters:\n",
    "    vector_a (numpy.ndarray): First vector.\n",
    "    vector_b (numpy.ndarray): Second vector.\n",
    "\n",
    "    Returns:\n",
    "    similarity (float): Cosine similarity score between the two vectors.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vector_a, vector_b)\n",
    "    norm_a = np.linalg.norm(vector_a)\n",
    "    norm_b = np.linalg.norm(vector_b)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "def predict_rating(user_vector, movie_vector, user_mean):\n",
    "    \"\"\"\n",
    "    Predicts a rating for a given user and movie.\n",
    "\n",
    "    Parameters:\n",
    "    user_vector (numpy.ndarray): Vector representing the user.\n",
    "    movie_vector (numpy.ndarray): Vector representing the movie.\n",
    "    user_mean (float): Mean rating of the user.\n",
    "\n",
    "    Returns:\n",
    "    predicted_rating (float): Predicted rating for the user-movie pair.\n",
    "    \"\"\"\n",
    "    predicted_rating = user_mean + np.dot(user_vector, movie_vector)\n",
    "    return predicted_rating\n",
    "\n",
    "def compute_recommendations(user_id, user_item_matrix, user_id_dict, movie_id_dict, U, Sigma, Vt, user_means, num_recommendations):\n",
    "    \"\"\"\n",
    "    Computes recommendations for a given user.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom to compute recommendations.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices.\n",
    "    U (numpy.ndarray): Matrix representing the relationship between users and latent factors.\n",
    "    Sigma (numpy.ndarray): Diagonal matrix containing the singular values.\n",
    "    Vt (numpy.ndarray): Transpose of the matrix representing the relationship between items and latent factors.\n",
    "    user_means (numpy.ndarray): Array containing mean ratings for each user.\n",
    "    num_recommendations (int): Number of recommendations to generate.\n",
    "\n",
    "    Returns:\n",
    "    recommendations (list): List of tuples containing recommended movie IDs and predicted ratings.\n",
    "    \"\"\"\n",
    "    user_index = user_id_dict[user_id]\n",
    "    user_vector = U[user_index]\n",
    "    user_mean = user_means[user_index]\n",
    "\n",
    "    # Initialize recommendations list\n",
    "    recommendations = []\n",
    "\n",
    "    # Iterate over all movies\n",
    "    for movie_id in movie_id_dict:\n",
    "        movie_index = movie_id_dict[movie_id]\n",
    "        if user_item_matrix[user_index, movie_index] == 0:  # Only predict for unrated movies\n",
    "            movie_vector = Vt[:, movie_index]\n",
    "            predicted_rating = predict_rating(user_vector, movie_vector, user_mean)\n",
    "            recommendations.append((movie_id, predicted_rating))\n",
    "\n",
    "    # Sort recommendations by predicted rating (descending order)\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top recommendations\n",
    "    top_recommendations = recommendations[:num_recommendations]\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Recommendations for User 2378815\n",
      "1. Movie ID: 985\n",
      "2. Movie ID: 483\n",
      "3. Movie ID: 241\n",
      "4. Movie ID: 1650\n",
      "5. Movie ID: 1110\n"
     ]
    }
   ],
   "source": [
    "# Example user ID\n",
    "example_user_id = user_ids[0]\n",
    "\n",
    "# Number of recommendations to generate\n",
    "num_recommendations = 5\n",
    "\n",
    "# Compute recommendations for the example user\n",
    "recommendations = compute_recommendations(example_user_id, user_item_matrix, user_id_dict, movie_id_dict, U, Sigma, Vt, user_means, num_recommendations)\n",
    "\n",
    "# Display top 5 recommendations\n",
    "print(\"Top 5 Recommendations for User\", example_user_id)\n",
    "for i, (movie_id, _) in enumerate(recommendations, start=1):\n",
    "    print(f\"{i}. Movie ID: {movie_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic statistics about the user-item matrix:\n",
    "\n",
    "Also to check whether the creation of user-item matrix went well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a set to store unique values\n",
    "# unique_values = set()\n",
    "\n",
    "# # Iterate over each row in the sparse matrix\n",
    "# for row in range(user_item_matrix.shape[0]):\n",
    "#     # Get the indices and data for the non-zero elements in the current row\n",
    "#     indices = user_item_matrix.indices[user_item_matrix.indptr[row]:user_item_matrix.indptr[row+1]]\n",
    "#     data = user_item_matrix.data[user_item_matrix.indptr[row]:user_item_matrix.indptr[row+1]]\n",
    "    \n",
    "#     # Update the set with unique values in the current row\n",
    "#     unique_values.update(data)\n",
    "\n",
    "# # Convert the set to a list for easier inspection\n",
    "# unique_values = list(unique_values)\n",
    "\n",
    "# # Look into results for checking\n",
    "# print(f\"Unique values in the user_item_matrix: {unique_values}\")\n",
    "# print(f\"There are {user_item_matrix.shape[0]} users in this matrix\")\n",
    "# print(f\"There are {user_item_matrix.shape[1]} items (movies) in this matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.sparse as sp\n",
    "\n",
    "# def create_user_item_matrix(train_test_val_set):\n",
    "#     \"\"\"\n",
    "#     Creates a user-item matrix from the provided dataset containing review data.\n",
    "\n",
    "#     Parameters:\n",
    "#     train_test_val_set (DataFrame): DataFrame containing review data with columns 'review_data',\n",
    "#                                     which is a list of dictionaries with keys 'userId', 'rating',\n",
    "#                                     and 'movieId'.\n",
    "\n",
    "#     Returns:\n",
    "#     user_item_matrix (scipy.sparse.csr_matrix): Sparse matrix representing users' ratings for items (movies).\n",
    "#     user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "#     movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "#     \"\"\"\n",
    "\n",
    "#     review_data = train_test_val_set['review_data'].values\n",
    "#     user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "#     ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "#     movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(train_test_val_set['movieId'], review_data)])\n",
    "\n",
    "#     # Create dictionaries to map user IDs and movie IDs to unique indices\n",
    "#     user_id_dict = {user_id: index for index, user_id in enumerate(np.unique(user_ids))}\n",
    "#     movie_id_dict = {movie_id: index for index, movie_id in enumerate(np.unique(movieIds))}\n",
    "\n",
    "#     # Initialize lists to store row, column, and data for the sparse matrix\n",
    "#     row_indices = [user_id_dict[user_id] for user_id in user_ids]\n",
    "#     col_indices = [movie_id_dict[movie_id] for movie_id in movieIds]\n",
    "#     data = ratings\n",
    "\n",
    "#     # Create the sparse user-item matrix\n",
    "#     user_item_matrix = sp.csr_matrix((data, (row_indices, col_indices)), shape=(len(user_id_dict), len(movie_id_dict)))\n",
    "\n",
    "#     return user_item_matrix, user_id_dict, movie_id_dict, user_ids, movieIds, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UserKNNRecommender:\n",
    "#     \"\"\"\n",
    "#     User-based Collaborative Filtering Recommender System.\n",
    "\n",
    "#     Parameters:\n",
    "#     - k (int): Number of similar users to consider for prediction (default is 5).\n",
    "#     - similarity_measure (str): Similarity measure to use (default is 'cosine').\n",
    "\n",
    "#     Methods:\n",
    "#     - fit(user_item_matrix): Fit the recommender system to the user-item matrix.\n",
    "#     - predict_ratings(user_id): Predict ratings for items for a given user.\n",
    "#     - recommend_items(user_id, top_n): Recommend top items for a given user.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, k=5, similarity_measure='cosine'):\n",
    "#         self.k = k\n",
    "#         self.similarity_measure = similarity_measure\n",
    "\n",
    "#     def fit(self, user_item_matrix):\n",
    "#         \"\"\"\n",
    "#         Fit the recommender system to the user-item matrix.\n",
    "\n",
    "#         Parameters:\n",
    "#         - user_item_matrix (scipy.sparse.csr_matrix): User-item matrix representing user ratings for items.\n",
    "#         \"\"\"\n",
    "#         self.user_item_matrix = user_item_matrix\n",
    "#         if self.similarity_measure == 'cosine':\n",
    "#             self.similarity_matrix = self.cosine_similarity(user_item_matrix)\n",
    "\n",
    "#     def cosine_similarity(self, matrix):\n",
    "#         \"\"\"\n",
    "#         Compute cosine similarity between rows of a matrix.\n",
    "\n",
    "#         Parameters:\n",
    "#         - matrix (scipy.sparse.csr_matrix): Input matrix.\n",
    "\n",
    "#         Returns:\n",
    "#         - similarity_matrix (numpy.ndarray): Cosine similarity matrix.\n",
    "#         \"\"\"\n",
    "#         norm_matrix = sp.linalg.norm(matrix, axis=1)\n",
    "#         normalized_matrix = matrix / norm_matrix[:, np.newaxis]\n",
    "#         similarity_matrix = normalized_matrix.dot(normalized_matrix.T)\n",
    "#         similarity_matrix.setdiag(0)  # Set diagonal to 0 to avoid self-similarity\n",
    "#         return similarity_matrix\n",
    "\n",
    "#     def predict_ratings(self, user_id):\n",
    "#         \"\"\"\n",
    "#         Predict ratings for items for a given user. This is the distinguishable step from ItemKNN, where the similarity scores are retrieved per user instaed of per Item (movies).\n",
    "\n",
    "#         Parameters:\n",
    "#         - user_id (int): ID of the user for whom ratings are to be predicted.\n",
    "\n",
    "#         Returns:\n",
    "#         - predicted_ratings (numpy.ndarray): Predicted ratings for items.\n",
    "#         \"\"\"\n",
    "#         user_index = user_id_dict[user_id]\n",
    "#         similarity_scores = self.similarity_matrix[user_index]\n",
    "#         top_similar_users_indices = np.argsort(similarity_scores)[::-1][:self.k]  # Indices of k most similar users\n",
    "#         similar_users_ratings = self.user_item_matrix[top_similar_users_indices]\n",
    "#         predicted_ratings = np.mean(similar_users_ratings, axis=0)  # Average ratings of similar users\n",
    "#         return predicted_ratings\n",
    "\n",
    "#     def recommend_items(self, user_id, top_n=5):\n",
    "#         \"\"\"\n",
    "#         Recommend top items for a given user. Within this function, the user similarities are also used, meaning this is also a distinguishable step for UserKNN.\n",
    "\n",
    "#         Parameters:\n",
    "#         - user_id (int): ID of the user for whom items are to be recommended.\n",
    "#         - top_n (int): Number of items to recommend (default is 5).\n",
    "\n",
    "#         Returns:\n",
    "#         - recommended_items (list): List of recommended item IDs.\n",
    "#         \"\"\"\n",
    "#         user_index = user_id_dict[user_id]\n",
    "#         predicted_ratings = self.predict_ratings(user_id)\n",
    "#         # Find top_n items with highest predicted ratings\n",
    "#         top_indices = np.argsort(predicted_ratings)[::-1][:top_n]\n",
    "#         recommended_items = [movie_id for movie_id, index in movie_id_dict.items() if index in top_indices]\n",
    "#         return recommended_items[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create user-item matrix and associated dictionaries\n",
    "# user_item_matrix, user_id_dict, movie_id_dict, _, _, _ = create_user_item_matrix(df)\n",
    "\n",
    "# # Randomly select a user ID from the user_id_dict\n",
    "# user_id = list(user_id_dict.keys())[0]\n",
    "\n",
    "# # Instantiate the UserKNNRecommender\n",
    "# user_knn_recommender = UserKNNRecommender(k=2)\n",
    "\n",
    "# # Fit the recommender to the user-item matrix\n",
    "# user_knn_recommender.fit(user_item_matrix)\n",
    "\n",
    "# # Predict ratings for the user\n",
    "# predicted_ratings = user_knn_recommender.predict_ratings(user_id)\n",
    "\n",
    "# # Recommend top items for the user\n",
    "# recommended_items = user_knn_recommender.recommend_items(user_id)\n",
    "\n",
    "# # Display the predicted ratings and recommended items\n",
    "# print(\"Recommended items:\", recommended_items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_ddb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
