{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we are going to proceed with the building in the models. Machine learning models to build recommender systems. The models that are going to be built are Collaborative filtering using Item-based rating prediction (ItemKNN) and Item-based classification (ItemKNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is a technique used in recommendation systems to predict or classify items based on the preferences or behavior of similar users or items. Item-based Collaborative Filtering (CF) focuses on the similarity between items rather than users. There are two main approaches within item-based CF: rating prediction and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # to make jupyter print all outputs, not just the last one\n",
    "from IPython.core.display import HTML # to pretty print pandas df and be able to copy them over (e.g. to ppt slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaume\\Documents\\MDDB\\SDM\\SDfM---Jaume-and-Stijn\n"
     ]
    }
   ],
   "source": [
    "# We print the directory where the file is located\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_sample5_parquet', 'movielens_parquet', 'netflix_parquet']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We set the directory to the cleaned folder\n",
    "os.listdir(os.path.join('.', 'cleaned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the final_sample file and store it in a dataframe\n",
    "df = pd.read_parquet('cleaned/final_sample5_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4665, 26)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Action</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Western</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>(no genres listed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45635</td>\n",
       "      <td>Notorious Bettie Page, The</td>\n",
       "      <td>2005</td>\n",
       "      <td>414</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2008-07-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45635</td>\n",
       "      <td>Notorious Bettie Page, The</td>\n",
       "      <td>2005</td>\n",
       "      <td>474</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2006-12-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1373</td>\n",
       "      <td>Star Trek V: The Final Frontier</td>\n",
       "      <td>1989</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1373</td>\n",
       "      <td>Star Trek V: The Final Frontier</td>\n",
       "      <td>1989</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2001-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1373</td>\n",
       "      <td>Star Trek V: The Final Frontier</td>\n",
       "      <td>1989</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                             title  year  userId  rating  \\\n",
       "0    45635       Notorious Bettie Page, The   2005     414     3.0   \n",
       "1    45635       Notorious Bettie Page, The   2005     474     3.0   \n",
       "2     1373  Star Trek V: The Final Frontier   1989      19     1.0   \n",
       "3     1373  Star Trek V: The Final Frontier   1989      42     4.0   \n",
       "4     1373  Star Trek V: The Final Frontier   1989      51     5.0   \n",
       "\n",
       "         date  Drama  Action  Sci-Fi  Comedy  ...  Adventure  Fantasy  IMAX  \\\n",
       "0  2008-07-15      1       0       0       0  ...          0        0     0   \n",
       "1  2006-12-08      1       0       0       0  ...          0        0     0   \n",
       "2  2000-08-08      0       1       1       0  ...          0        0     0   \n",
       "3  2001-07-27      0       1       1       0  ...          0        0     0   \n",
       "4  2009-01-02      0       1       1       0  ...          0        0     0   \n",
       "\n",
       "   Animation  Musical  Horror  Film-Noir  Western  Mystery  (no genres listed)  \n",
       "0          0        0       0          0        0        0                   0  \n",
       "1          0        0       0          0        0        0                   0  \n",
       "2          0        0       0          0        0        0                   0  \n",
       "3          0        0       0          0        0        0                   0  \n",
       "4          0        0       0          0        0        0                   0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'title', 'year', 'userId', 'rating', 'date', 'Drama',\n",
       "       'Action', 'Sci-Fi', 'Comedy', 'Crime', 'Thriller', 'Romance', 'War',\n",
       "       'Documentary', 'Children', 'Adventure', 'Fantasy', 'IMAX', 'Animation',\n",
       "       'Musical', 'Horror', 'Film-Noir', 'Western', 'Mystery',\n",
       "       '(no genres listed)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the columns of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n",
      "487\n"
     ]
    }
   ],
   "source": [
    "# We print the number of unique users and movies\n",
    "print(df['userId'].nunique())\n",
    "print(df['movieId'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Rating Prediction (ItemKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: User-Item matrix construction\n",
    "The first thing we have to do is build the user-item matrix:\n",
    "\n",
    "- Choose a similarity metric to calculate the similarity between items. Common metrics include cosine similarity, Pearson correlation coefficient, and Jaccard similarity.\n",
    "- Calculate the similarity between each pair of items based on the ratings provided by users. This will result in an item-item similarity matrix.\n",
    "\n",
    "#### Collaborative Filtering with Cosine Similarity\n",
    "\n",
    "This code snippet demonstrates how to perform item-based collaborative filtering using cosine similarity. Collaborative filtering is a technique commonly used in recommendation systems to predict a user's preferences for items based on the preferences of similar users/items.\n",
    "\n",
    "##### Libraries Used\n",
    "- **pandas**: A powerful data manipulation library in Python.\n",
    "- **numpy**: A library for numerical computing in Python.\n",
    "- **sklearn.metrics.pairwise.cosine_similarity**: A function from scikit-learn used to compute the cosine similarity between vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with the specified format\n",
    "# Convert userId column to integer type if needed\n",
    "if df['userId'].dtype != int:\n",
    "    df['userId'] = df['userId'].astype(int)\n",
    "\n",
    "# Get all unique user IDs and movie IDs\n",
    "all_user_ids = np.unique(df['userId'])\n",
    "all_movie_ids = np.unique(df['movieId'])\n",
    "\n",
    "# Create a DataFrame with all combinations of user IDs and movie IDs\n",
    "all_user_movie_pairs = np.array(np.meshgrid(all_user_ids, all_movie_ids)).T.reshape(-1, 2)\n",
    "df_pairs = pd.DataFrame(all_user_movie_pairs, columns=['userId', 'movieId'])\n",
    "\n",
    "# Merge the original DataFrame with all_user_movie_pairs to fill missing ratings with 0\n",
    "df_filled = pd.merge(df_pairs, df, on=['userId', 'movieId'], how='left').fillna(0)\n",
    "\n",
    "# Create user-item matrix using pivot_table\n",
    "item_user_matrix = pd.pivot_table(df_filled, values='rating', index='userId', columns='movieId', fill_value=0)\n",
    "\n",
    "# Convert user-item matrix to NumPy array for faster computation\n",
    "item_user_array = item_user_matrix.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       4       15      30      43      89      104     108     \\\n",
       "userId                                                                    \n",
       "1           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  122     146     ...  174479  174551  175475  176371  176389  177593  \\\n",
       "userId                   ...                                                   \n",
       "1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  179813  181413  185029  186587  \n",
       "userId                                   \n",
       "1           0.0     0.0     0.0     0.0  \n",
       "2           0.0     0.0     0.0     0.0  \n",
       "3           0.0     0.0     0.0     0.0  \n",
       "4           0.0     0.0     0.0     0.0  \n",
       "5           0.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 487 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [2.5, 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [3. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [5. , 0. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "The train-val-test split is a technique used in machine learning to evaluate the performance of a model. It involves dividing the dataset into three subsets: the training set, the validation set, and the test set.\n",
    "\n",
    "The training set is used to train the model and optimize its parameters.\n",
    "The validation set is used to fine-tune the model and select the best hyperparameters.\n",
    "The test set is used to evaluate the final performance of the model on unseen data.\n",
    "By using a train-val-test split, we can assess the model's performance on unseen data and ensure that it generalizes well to new examples. It helps prevent overfitting and provides a more reliable estimate of the model's performance in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (340, 487)\n",
      "Validation set shape: (85, 487)\n",
      "Test set shape: (107, 487)\n",
      " \n",
      "Training set matrix shape: (340, 487)\n",
      "Validation set matrix shape: (85, 487)\n",
      "Test set matrix shape: (107, 487)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and test sets\n",
    "train_val, test = train_test_split(item_user_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "train, val = train_test_split(train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training set shape:\", train.shape)\n",
    "print(\"Validation set shape:\", val.shape)\n",
    "print(\"Test set shape:\", test.shape)\n",
    "\n",
    "# We are also going to do the split for the matrix df\n",
    "# Split the user-item matrix into training and test sets\n",
    "train_val_matrix, test_matrix = train_test_split(item_user_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training set matrix into training and validation sets\n",
    "train_matrix, val_matrix = train_test_split(train_val_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# We print a ' ' to give some space inbetween lines\n",
    "print(' ')\n",
    "\n",
    "# Print the shapes of the matrix datasets\n",
    "print(\"Training set matrix shape:\", train_matrix.shape)\n",
    "print(\"Validation set matrix shape:\", val_matrix.shape)\n",
    "print(\"Test set matrix shape:\", test_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       4       15      30      43      89      104     108     \\\n",
       "userId                                                                    \n",
       "428         0.0     0.0     0.0     0.0     0.0     0.0     3.0     0.0   \n",
       "517         4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "197         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "160         4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "67          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "51          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "267         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "326         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "416         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "168         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  122     146     ...  174479  174551  175475  176371  176389  177593  \\\n",
       "userId                   ...                                                   \n",
       "428         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "517         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "197         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "160         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "67          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "51          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "267         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "326         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "416         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "168         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  179813  181413  185029  186587  \n",
       "userId                                   \n",
       "428         0.0     0.0     0.0     0.0  \n",
       "517         0.0     0.0     0.0     0.0  \n",
       "197         0.0     0.0     0.0     0.0  \n",
       "160         0.0     0.0     0.0     0.0  \n",
       "67          0.0     0.0     0.0     0.0  \n",
       "...         ...     ...     ...     ...  \n",
       "51          0.0     0.0     0.0     0.0  \n",
       "267         0.0     0.0     0.0     0.0  \n",
       "326         0.0     0.0     0.0     0.0  \n",
       "416         0.0     0.0     0.0     0.0  \n",
       "168         0.0     0.0     0.0     0.0  \n",
       "\n",
       "[340 rows x 487 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_4988\\3392059385.py:6: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarity = dot_product / (norm_a * norm_b)\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between items using NumPy functions\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity\n",
    "\n",
    "# Calculate item-item similarity matrix for train data\n",
    "item_similarity_matrix_train = np.zeros((train.shape[1], train.shape[1]))\n",
    "\n",
    "for i in range(train.shape[1]):\n",
    "    for j in range(i, train.shape[1]):\n",
    "        item_similarity_matrix_train[i, j] = cosine_similarity(train[:, i], train[:, j])\n",
    "        item_similarity_matrix_train[j, i] = item_similarity_matrix_train[i, j]\n",
    "\n",
    "# Create a mapping from movie IDs to indices\n",
    "movie_id_to_index = {movie_id: i for i, movie_id in enumerate(item_user_matrix.index)}\n",
    "index_to_movie_id = {i: movie_id for movie_id, i in movie_id_to_index.items()}\n",
    "\n",
    "# Create a mapping from user IDs to indices\n",
    "user_id_to_index = {user_id: i for i, user_id in enumerate(item_user_matrix.columns)}\n",
    "index_to_user_id = {i: user_id for user_id, i in user_id_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 4, 2: 15, 3: 30, 4: 43, 5: 89, 6: 104, 7: 108, 8: 122, 9: 146, 10: 290, 11: 303, 12: 305, 13: 346, 14: 353, 15: 358, 16: 363, 17: 389, 18: 393, 19: 416, 20: 423, 21: 478, 22: 504, 23: 522, 24: 551, 25: 556, 26: 605, 27: 627, 28: 640, 29: 694, 30: 708, 31: 728, 32: 790, 33: 810, 34: 835, 35: 901, 36: 953, 37: 1003, 38: 1006, 39: 1037, 40: 1040, 41: 1046, 42: 1207, 43: 1261, 44: 1266, 45: 1271, 46: 1272, 47: 1358, 48: 1373, 49: 1388, 50: 1391, 51: 1398, 52: 1415, 53: 1432, 54: 1446, 55: 1447, 56: 1507, 57: 1518, 58: 1564, 59: 1572, 60: 1580, 61: 1597, 62: 1625, 63: 1665, 64: 1757, 65: 1769, 66: 1816, 67: 1882, 68: 1940, 69: 1955, 70: 1964, 71: 1969, 72: 1995, 73: 2004, 74: 2013, 75: 2037, 76: 2046, 77: 2071, 78: 2107, 79: 2114, 80: 2148, 81: 2160, 82: 2171, 83: 2177, 84: 2273, 85: 2302, 86: 2310, 87: 2320, 88: 2324, 89: 2325, 90: 2336, 91: 2344, 92: 2356, 93: 2358, 94: 2366, 95: 2378, 96: 2381, 97: 2521, 98: 2540, 99: 2590, 100: 2606, 101: 2672, 102: 2746, 103: 2757, 104: 2803, 105: 2804, 106: 2810, 107: 2829, 108: 2839, 109: 2860, 110: 2924, 111: 2950, 112: 2962, 113: 2966, 114: 2968, 115: 2988, 116: 3016, 117: 3034, 118: 3053, 119: 3054, 120: 3073, 121: 3102, 122: 3130, 123: 3148, 124: 3169, 125: 3269, 126: 3295, 127: 3301, 128: 3308, 129: 3363, 130: 3364, 131: 3393, 132: 3442, 133: 3577, 134: 3586, 135: 3590, 136: 3592, 137: 3641, 138: 3669, 139: 3675, 140: 3680, 141: 3686, 142: 3691, 143: 3692, 144: 3707, 145: 3792, 146: 3830, 147: 3871, 148: 3926, 149: 3965, 150: 4006, 151: 4018, 152: 4055, 153: 4065, 154: 4111, 155: 4113, 156: 4124, 157: 4138, 158: 4154, 159: 4161, 160: 4202, 161: 4210, 162: 4217, 163: 4235, 164: 4289, 165: 4292, 166: 4306, 167: 4321, 168: 4441, 169: 4458, 170: 4487, 171: 4495, 172: 4545, 173: 4589, 174: 4621, 175: 4622, 176: 4624, 177: 4715, 178: 4719, 179: 4722, 180: 4723, 181: 4821, 182: 4822, 183: 4827, 184: 4831, 185: 4926, 186: 4966, 187: 5021, 188: 5065, 189: 5080, 190: 5109, 191: 5111, 192: 5139, 193: 5247, 194: 5264, 195: 5284, 196: 5322, 197: 5424, 198: 5440, 199: 5444, 200: 5451, 201: 5463, 202: 5497, 203: 5524, 204: 5556, 205: 5604, 206: 5618, 207: 5630, 208: 5646, 209: 5853, 210: 5863, 211: 5891, 212: 5969, 213: 5984, 214: 5991, 215: 6033, 216: 6057, 217: 6119, 218: 6145, 219: 6184, 220: 6254, 221: 6310, 222: 6322, 223: 6332, 224: 6345, 225: 6386, 226: 6410, 227: 6434, 228: 6516, 229: 6588, 230: 6595, 231: 6603, 232: 6615, 233: 6625, 234: 6666, 235: 6695, 236: 6702, 237: 6814, 238: 6816, 239: 6827, 240: 7007, 241: 7017, 242: 7024, 243: 7069, 244: 7080, 245: 7092, 246: 7154, 247: 7179, 248: 7202, 249: 7282, 250: 7302, 251: 7310, 252: 7325, 253: 7375, 254: 7419, 255: 7443, 256: 7647, 257: 7802, 258: 8126, 259: 8142, 260: 8264, 261: 8405, 262: 8461, 263: 8482, 264: 8578, 265: 8604, 266: 8677, 267: 8714, 268: 8771, 269: 8840, 270: 8920, 271: 8933, 272: 8946, 273: 8981, 274: 8982, 275: 25841, 276: 26142, 277: 26150, 278: 26158, 279: 26399, 280: 26587, 281: 26645, 282: 26686, 283: 27036, 284: 27178, 285: 27480, 286: 27618, 287: 27778, 288: 27846, 289: 27912, 290: 32009, 291: 32743, 292: 33004, 293: 34148, 294: 34164, 295: 34271, 296: 35347, 297: 36276, 298: 36477, 299: 39446, 300: 40870, 301: 41285, 302: 42422, 303: 42740, 304: 43396, 305: 43460, 306: 43708, 307: 44241, 308: 45635, 309: 46723, 310: 47261, 311: 47384, 312: 48150, 313: 48774, 314: 49688, 315: 49793, 316: 50147, 317: 50274, 318: 50610, 319: 50613, 320: 50685, 321: 52435, 322: 53123, 323: 54274, 324: 54796, 325: 54934, 326: 55069, 327: 55241, 328: 55280, 329: 55492, 330: 57526, 331: 59667, 332: 59738, 333: 60904, 334: 61073, 335: 62344, 336: 62970, 337: 63479, 338: 63853, 339: 64614, 340: 65601, 341: 65810, 342: 66090, 343: 66371, 344: 66427, 345: 66511, 346: 66544, 347: 67186, 348: 67508, 349: 69131, 350: 69746, 351: 69951, 352: 70208, 353: 71211, 354: 71264, 355: 71732, 356: 71745, 357: 72407, 358: 72489, 359: 73319, 360: 74342, 361: 74580, 362: 74789, 363: 75805, 364: 76077, 365: 77931, 366: 78209, 367: 79006, 368: 79798, 369: 80489, 370: 81591, 371: 81819, 372: 81834, 373: 82242, 374: 85025, 375: 85414, 376: 85881, 377: 86593, 378: 86835, 379: 87192, 380: 87304, 381: 87834, 382: 88812, 383: 89864, 384: 90863, 385: 91470, 386: 91628, 387: 93040, 388: 93242, 389: 93723, 390: 93766, 391: 94323, 392: 94478, 393: 94810, 394: 95449, 395: 97188, 396: 97870, 397: 97913, 398: 98154, 399: 100326, 400: 100507, 401: 100611, 402: 101864, 403: 102590, 404: 102823, 405: 103027, 406: 103372, 407: 103810, 408: 104141, 409: 104245, 410: 105197, 411: 105585, 412: 105755, 413: 105801, 414: 105954, 415: 106002, 416: 106883, 417: 107410, 418: 110591, 419: 111617, 420: 111800, 421: 112171, 422: 112334, 423: 112580, 424: 112727, 425: 113345, 426: 113350, 427: 113705, 428: 114678, 429: 115203, 430: 116413, 431: 117877, 432: 117887, 433: 118082, 434: 118354, 435: 119964, 436: 120807, 437: 122922, 438: 128512, 439: 128914, 440: 129229, 441: 129937, 442: 130518, 443: 130840, 444: 130842, 445: 131104, 446: 132796, 447: 133115, 448: 133716, 449: 134019, 450: 135861, 451: 135885, 452: 136562, 453: 137345, 454: 139855, 455: 140038, 456: 140541, 457: 141994, 458: 142550, 459: 143511, 460: 148709, 461: 148881, 462: 149011, 463: 151317, 464: 152077, 465: 152091, 466: 155659, 467: 157130, 468: 157432, 469: 157865, 470: 160341, 471: 161966, 472: 162590, 473: 166568, 474: 167538, 475: 167706, 476: 173235, 477: 174479, 478: 174551, 479: 175475, 480: 176371, 481: 176389, 482: 177593, 483: 179813, 484: 181413, 485: 185029, 486: 186587}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 4: 1, 15: 2, 30: 3, 43: 4, 89: 5, 104: 6, 108: 7, 122: 8, 146: 9, 290: 10, 303: 11, 305: 12, 346: 13, 353: 14, 358: 15, 363: 16, 389: 17, 393: 18, 416: 19, 423: 20, 478: 21, 504: 22, 522: 23, 551: 24, 556: 25, 605: 26, 627: 27, 640: 28, 694: 29, 708: 30, 728: 31, 790: 32, 810: 33, 835: 34, 901: 35, 953: 36, 1003: 37, 1006: 38, 1037: 39, 1040: 40, 1046: 41, 1207: 42, 1261: 43, 1266: 44, 1271: 45, 1272: 46, 1358: 47, 1373: 48, 1388: 49, 1391: 50, 1398: 51, 1415: 52, 1432: 53, 1446: 54, 1447: 55, 1507: 56, 1518: 57, 1564: 58, 1572: 59, 1580: 60, 1597: 61, 1625: 62, 1665: 63, 1757: 64, 1769: 65, 1816: 66, 1882: 67, 1940: 68, 1955: 69, 1964: 70, 1969: 71, 1995: 72, 2004: 73, 2013: 74, 2037: 75, 2046: 76, 2071: 77, 2107: 78, 2114: 79, 2148: 80, 2160: 81, 2171: 82, 2177: 83, 2273: 84, 2302: 85, 2310: 86, 2320: 87, 2324: 88, 2325: 89, 2336: 90, 2344: 91, 2356: 92, 2358: 93, 2366: 94, 2378: 95, 2381: 96, 2521: 97, 2540: 98, 2590: 99, 2606: 100, 2672: 101, 2746: 102, 2757: 103, 2803: 104, 2804: 105, 2810: 106, 2829: 107, 2839: 108, 2860: 109, 2924: 110, 2950: 111, 2962: 112, 2966: 113, 2968: 114, 2988: 115, 3016: 116, 3034: 117, 3053: 118, 3054: 119, 3073: 120, 3102: 121, 3130: 122, 3148: 123, 3169: 124, 3269: 125, 3295: 126, 3301: 127, 3308: 128, 3363: 129, 3364: 130, 3393: 131, 3442: 132, 3577: 133, 3586: 134, 3590: 135, 3592: 136, 3641: 137, 3669: 138, 3675: 139, 3680: 140, 3686: 141, 3691: 142, 3692: 143, 3707: 144, 3792: 145, 3830: 146, 3871: 147, 3926: 148, 3965: 149, 4006: 150, 4018: 151, 4055: 152, 4065: 153, 4111: 154, 4113: 155, 4124: 156, 4138: 157, 4154: 158, 4161: 159, 4202: 160, 4210: 161, 4217: 162, 4235: 163, 4289: 164, 4292: 165, 4306: 166, 4321: 167, 4441: 168, 4458: 169, 4487: 170, 4495: 171, 4545: 172, 4589: 173, 4621: 174, 4622: 175, 4624: 176, 4715: 177, 4719: 178, 4722: 179, 4723: 180, 4821: 181, 4822: 182, 4827: 183, 4831: 184, 4926: 185, 4966: 186, 5021: 187, 5065: 188, 5080: 189, 5109: 190, 5111: 191, 5139: 192, 5247: 193, 5264: 194, 5284: 195, 5322: 196, 5424: 197, 5440: 198, 5444: 199, 5451: 200, 5463: 201, 5497: 202, 5524: 203, 5556: 204, 5604: 205, 5618: 206, 5630: 207, 5646: 208, 5853: 209, 5863: 210, 5891: 211, 5969: 212, 5984: 213, 5991: 214, 6033: 215, 6057: 216, 6119: 217, 6145: 218, 6184: 219, 6254: 220, 6310: 221, 6322: 222, 6332: 223, 6345: 224, 6386: 225, 6410: 226, 6434: 227, 6516: 228, 6588: 229, 6595: 230, 6603: 231, 6615: 232, 6625: 233, 6666: 234, 6695: 235, 6702: 236, 6814: 237, 6816: 238, 6827: 239, 7007: 240, 7017: 241, 7024: 242, 7069: 243, 7080: 244, 7092: 245, 7154: 246, 7179: 247, 7202: 248, 7282: 249, 7302: 250, 7310: 251, 7325: 252, 7375: 253, 7419: 254, 7443: 255, 7647: 256, 7802: 257, 8126: 258, 8142: 259, 8264: 260, 8405: 261, 8461: 262, 8482: 263, 8578: 264, 8604: 265, 8677: 266, 8714: 267, 8771: 268, 8840: 269, 8920: 270, 8933: 271, 8946: 272, 8981: 273, 8982: 274, 25841: 275, 26142: 276, 26150: 277, 26158: 278, 26399: 279, 26587: 280, 26645: 281, 26686: 282, 27036: 283, 27178: 284, 27480: 285, 27618: 286, 27778: 287, 27846: 288, 27912: 289, 32009: 290, 32743: 291, 33004: 292, 34148: 293, 34164: 294, 34271: 295, 35347: 296, 36276: 297, 36477: 298, 39446: 299, 40870: 300, 41285: 301, 42422: 302, 42740: 303, 43396: 304, 43460: 305, 43708: 306, 44241: 307, 45635: 308, 46723: 309, 47261: 310, 47384: 311, 48150: 312, 48774: 313, 49688: 314, 49793: 315, 50147: 316, 50274: 317, 50610: 318, 50613: 319, 50685: 320, 52435: 321, 53123: 322, 54274: 323, 54796: 324, 54934: 325, 55069: 326, 55241: 327, 55280: 328, 55492: 329, 57526: 330, 59667: 331, 59738: 332, 60904: 333, 61073: 334, 62344: 335, 62970: 336, 63479: 337, 63853: 338, 64614: 339, 65601: 340, 65810: 341, 66090: 342, 66371: 343, 66427: 344, 66511: 345, 66544: 346, 67186: 347, 67508: 348, 69131: 349, 69746: 350, 69951: 351, 70208: 352, 71211: 353, 71264: 354, 71732: 355, 71745: 356, 72407: 357, 72489: 358, 73319: 359, 74342: 360, 74580: 361, 74789: 362, 75805: 363, 76077: 364, 77931: 365, 78209: 366, 79006: 367, 79798: 368, 80489: 369, 81591: 370, 81819: 371, 81834: 372, 82242: 373, 85025: 374, 85414: 375, 85881: 376, 86593: 377, 86835: 378, 87192: 379, 87304: 380, 87834: 381, 88812: 382, 89864: 383, 90863: 384, 91470: 385, 91628: 386, 93040: 387, 93242: 388, 93723: 389, 93766: 390, 94323: 391, 94478: 392, 94810: 393, 95449: 394, 97188: 395, 97870: 396, 97913: 397, 98154: 398, 100326: 399, 100507: 400, 100611: 401, 101864: 402, 102590: 403, 102823: 404, 103027: 405, 103372: 406, 103810: 407, 104141: 408, 104245: 409, 105197: 410, 105585: 411, 105755: 412, 105801: 413, 105954: 414, 106002: 415, 106883: 416, 107410: 417, 110591: 418, 111617: 419, 111800: 420, 112171: 421, 112334: 422, 112580: 423, 112727: 424, 113345: 425, 113350: 426, 113705: 427, 114678: 428, 115203: 429, 116413: 430, 117877: 431, 117887: 432, 118082: 433, 118354: 434, 119964: 435, 120807: 436, 122922: 437, 128512: 438, 128914: 439, 129229: 440, 129937: 441, 130518: 442, 130840: 443, 130842: 444, 131104: 445, 132796: 446, 133115: 447, 133716: 448, 134019: 449, 135861: 450, 135885: 451, 136562: 452, 137345: 453, 139855: 454, 140038: 455, 140541: 456, 141994: 457, 142550: 458, 143511: 459, 148709: 460, 148881: 461, 149011: 462, 151317: 463, 152077: 464, 152091: 465, 155659: 466, 157130: 467, 157432: 468, 157865: 469, 160341: 470, 161966: 471, 162590: 472, 166568: 473, 167538: 474, 167706: 475, 173235: 476, 174479: 477, 174551: 478, 175475: 479, 176371: 480, 176389: 481, 177593: 482, 179813: 483, 181413: 484, 185029: 485, 186587: 486}\n"
     ]
    }
   ],
   "source": [
    "print(user_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 487)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 487)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.0143568 , 0.04177427, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.0143568 , 1.        , 0.26332321, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.04177427, 0.26332321, 1.        , ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the item_similarity_matrix\n",
    "item_similarity_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 487)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_matrix_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Neighborhood Selection\n",
    "- Determine the neighborhood size, i.e., the number of most similar items to consider when predicting ratings for a target item.\n",
    "- Select the most similar items for each item in your dataset based on their calculated similarities. This forms the neighborhood for each item.\n",
    "\n",
    "#### Item-Based Neighborhoods and Ratings Aggregation\n",
    "\n",
    "This code following snippet enhances the previous item-based collaborative filtering approach by considering ratings aggregation within the item neighborhoods.\n",
    "\n",
    "##### Steps:\n",
    "\n",
    "1. **Defining Neighborhood Size**:\n",
    "   - The variable `neighborhood_size` determines the number of most similar items to consider in the neighborhood.\n",
    "\n",
    "2. **Initializing Data Structure**:\n",
    "   - An empty dictionary `item_neighborhoods` is initialized to store the neighborhoods for each item.\n",
    "\n",
    "3. **Iterating Over Items**:\n",
    "   - For each movie in the dataset:\n",
    "     - All ratings for the current movie are extracted from the DataFrame (`df`).\n",
    "     - Ratings aggregation is performed. In this example, the average rating for the movie is computed, but other aggregation methods can be used.\n",
    "     - The similarity scores for the current movie are retrieved from the precomputed `item_similarity_matrix`.\n",
    "     - Similarity scores are sorted in descending order, and the indices of the most similar items (excluding itself) are obtained.\n",
    "     - These indices are converted back to movie IDs, forming the neighborhood for the current item.\n",
    "     - The neighborhood for the current item is stored in the `item_neighborhoods` dictionary.\n",
    "\n",
    "4. **Output**:\n",
    "   - `item_neighborhoods`: A dictionary where keys are movie IDs, and values are lists of movie IDs representing the neighborhood of each item. Each movie's neighborhood includes movies with similar ratings and content.\n",
    "\n",
    "##### Note:\n",
    "- This approach considers both similarity in ratings and content (as captured by cosine similarity) when building item neighborhoods.\n",
    "- Aggregating ratings within item neighborhoods helps in providing more personalized recommendations.\n",
    "- The choice of rating aggregation method (e.g., mean, median) can impact the quality of recommendations and may need to be adjusted based on the characteristics of the dataset and user preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [357, 465, 344, 467, 342], 2: [317, 451, 183, 453, 182], 3: [422, 417, 149, 412, 409], 4: [248, 162, 164, 436, 167], 5: [441, 448, 223, 224, 445], 6: [164, 417, 412, 409, 403], 7: [357, 344, 465, 342, 467], 9: [477, 444, 182, 441, 183], 10: [149, 418, 417, 159, 412], 11: [254, 453, 228, 451, 248], 12: [436, 441, 344, 342, 444], 13: [482, 310, 441, 293, 444], 14: [412, 324, 453, 323, 455], 15: [422, 417, 412, 409, 403], 16: [286, 451, 323, 453, 318], 17: [436, 159, 160, 162, 164], 18: [477, 444, 182, 441, 183], 19: [412, 89, 403, 91, 391], 20: [436, 448, 445, 444, 223], 21: [558, 417, 412, 409, 403], 22: [477, 160, 162, 164, 422], 23: [214, 182, 183, 184, 185], 24: [286, 418, 417, 412, 149], 25: [436, 448, 445, 444, 217], 27: [317, 459, 332, 330, 328], 28: [196, 441, 182, 183, 436], 29: [422, 441, 436, 432, 182], 30: [467, 324, 453, 323, 455], 31: [293, 455, 456, 327, 325], 32: [441, 449, 448, 217, 445], 33: [476, 342, 332, 330, 465], 34: [432, 445, 444, 196, 441], 36: [254, 453, 228, 451, 248], 38: [476, 342, 332, 330, 465], 39: [418, 412, 114, 409, 403], 40: [160, 182, 448, 449, 451], 41: [455, 330, 328, 459, 327], 42: [477, 441, 436, 167, 432], 43: [444, 453, 451, 449, 448], 44: [217, 441, 183, 436, 190], 45: [286, 418, 417, 412, 149], 46: [328, 327, 453, 325, 455], 47: [453, 455, 456, 327, 325], 48: [223, 224, 453, 370, 455], 50: [224, 196, 445, 444, 441], 51: [477, 436, 182, 432, 183], 52: [444, 223, 449, 448, 224], 54: [477, 448, 190, 445, 444], 57: [217, 445, 444, 190, 196], 58: [223, 196, 445, 444, 217], 59: [477, 344, 342, 465, 332], 62: [436, 288, 441, 286, 444], 63: [477, 444, 182, 441, 183], 64: [436, 448, 196, 445, 444], 65: [449, 455, 254, 453, 259], 66: [217, 445, 444, 190, 441], 67: [436, 288, 441, 286, 444], 68: [228, 448, 217, 223, 445], 69: [451, 259, 456, 455, 266], 70: [476, 344, 342, 332, 465], 71: [477, 344, 342, 465, 332], 73: [432, 190, 445, 444, 196], 74: [259, 293, 444, 445, 288], 75: [477, 182, 183, 441, 190], 76: [330, 456, 328, 327, 459], 78: [182, 417, 412, 409, 149], 79: [456, 441, 330, 444, 445], 80: [477, 441, 183, 436, 432], 82: [436, 288, 441, 286, 444], 83: [432, 445, 444, 196, 441], 84: [223, 444, 183, 190, 441], 85: [477, 445, 444, 196, 441], 86: [441, 449, 448, 445, 444], 87: [477, 445, 444, 190, 441], 88: [491, 455, 456, 459, 167], 89: [214, 182, 183, 184, 185], 90: [217, 190, 445, 444, 196], 91: [214, 182, 183, 184, 185], 92: [477, 190, 445, 444, 196], 93: [217, 310, 293, 444, 445], 95: [422, 149, 412, 409, 403], 96: [445, 312, 448, 449, 310], 97: [248, 451, 228, 449, 448], 98: [224, 448, 445, 444, 217], 99: [217, 317, 448, 449, 312], 100: [441, 448, 217, 223, 445], 101: [432, 286, 436, 558, 275], 103: [432, 445, 444, 196, 441], 104: [317, 459, 332, 330, 328], 105: [459, 441, 149, 357, 444], 106: [403, 317, 448, 449, 451], 107: [149, 159, 160, 162, 164], 109: [275, 453, 558, 455, 456], 110: [412, 89, 403, 91, 391], 111: [477, 167, 436, 182, 432], 112: [477, 162, 164, 422, 167], 113: [412, 89, 403, 91, 391], 114: [214, 182, 183, 184, 185], 115: [114, 167, 441, 182, 183], 116: [459, 444, 445, 293, 288], 117: [312, 445, 344, 448, 449], 118: [418, 436, 254, 432, 288], 119: [228, 436, 167, 432, 182], 121: [436, 288, 441, 286, 444], 122: [477, 441, 182, 310, 436], 123: [459, 444, 445, 293, 448], 124: [412, 89, 403, 91, 391], 125: [477, 167, 441, 182, 183], 129: [217, 451, 323, 453, 318], 130: [432, 444, 183, 441, 190], 131: [477, 444, 183, 441, 190], 132: [353, 370, 459, 89, 365], 134: [445, 254, 451, 259, 449], 135: [477, 162, 164, 432, 167], 136: [149, 159, 160, 418, 417], 137: [259, 164, 167, 441, 182], 138: [223, 449, 448, 217, 445], 139: [217, 448, 449, 317, 451], 140: [385, 422, 160, 162, 164], 141: [167, 162, 465, 390, 467], 143: [455, 330, 328, 459, 327], 144: [441, 449, 448, 224, 228], 145: [412, 89, 403, 91, 391], 146: [558, 417, 412, 149, 409], 147: [286, 418, 417, 412, 149], 148: [477, 159, 160, 162, 418], 149: [214, 182, 183, 184, 185], 151: [310, 441, 288, 444, 445], 152: [167, 417, 412, 409, 403], 153: [436, 445, 444, 190, 196], 154: [436, 288, 441, 286, 444], 155: [293, 288, 286, 441, 558], 156: [254, 453, 228, 451, 248], 157: [477, 162, 432, 164, 167], 158: [477, 444, 182, 441, 183], 159: [214, 182, 183, 184, 185], 160: [214, 182, 183, 184, 185], 161: [436, 288, 441, 286, 444], 162: [214, 182, 183, 184, 185], 163: [459, 390, 266, 465, 275], 164: [214, 182, 183, 184, 185], 165: [383, 162, 422, 164, 418], 166: [254, 453, 228, 451, 248], 167: [214, 182, 183, 184, 185], 168: [558, 417, 412, 149, 409], 169: [477, 444, 182, 441, 183], 171: [445, 254, 451, 259, 449], 172: [436, 288, 286, 441, 558], 177: [441, 449, 448, 445, 444], 178: [436, 288, 441, 286, 444], 179: [455, 436, 558, 275, 441], 180: [441, 451, 449, 448, 228], 181: [455, 436, 286, 558, 441], 182: [214, 182, 183, 184, 185], 183: [214, 182, 183, 184, 185], 184: [436, 288, 441, 286, 444], 185: [449, 451, 323, 453, 455], 186: [436, 223, 445, 444, 224], 187: [412, 403, 89, 91, 391], 188: [228, 217, 445, 444, 223], 190: [214, 182, 183, 184, 185], 191: [436, 445, 444, 223, 224], 193: [436, 288, 441, 286, 444], 195: [293, 418, 417, 412, 409], 196: [214, 182, 183, 184, 185], 197: [436, 288, 441, 286, 444], 198: [477, 344, 342, 465, 332], 199: [477, 182, 183, 436, 432], 200: [412, 89, 403, 91, 391], 201: [286, 418, 417, 412, 149], 202: [332, 444, 445, 330, 328], 203: [436, 288, 441, 286, 444], 204: [383, 162, 164, 422, 418], 205: [436, 288, 441, 286, 444], 206: [196, 160, 162, 286, 164], 207: [385, 422, 160, 162, 418], 209: [286, 418, 417, 412, 149], 210: [412, 89, 403, 91, 391], 211: [453, 558, 275, 266, 432], 212: [467, 324, 453, 323, 455], 213: [441, 451, 228, 449, 448], 214: [422, 441, 183, 436, 190], 215: [385, 160, 162, 422, 164], 216: [412, 89, 403, 91, 391], 217: [214, 182, 183, 184, 185], 218: [286, 418, 417, 412, 149], 219: [441, 449, 448, 445, 444], 220: [293, 288, 286, 441, 558], 221: [432, 159, 422, 160, 162], 222: [358, 453, 370, 455, 456], 223: [214, 182, 183, 184, 185], 224: [214, 182, 183, 184, 185], 225: [477, 162, 164, 167, 422], 226: [330, 441, 357, 444, 445], 227: [360, 449, 217, 451, 358], 228: [214, 182, 183, 184, 185], 229: [286, 418, 417, 412, 149], 230: [286, 418, 417, 412, 149], 232: [436, 288, 441, 286, 444], 233: [453, 432, 558, 275, 436], 234: [217, 328, 444, 441, 436], 235: [385, 288, 162, 164, 422], 236: [441, 449, 448, 445, 444], 237: [477, 441, 312, 436, 182], 238: [441, 451, 449, 448, 228], 239: [436, 288, 441, 286, 444], 240: [312, 445, 310, 293, 448], 241: [114, 449, 451, 453, 353], 243: [370, 417, 412, 409, 403], 244: [441, 449, 448, 224, 228], 246: [436, 288, 441, 286, 444], 247: [441, 448, 223, 224, 445], 248: [214, 182, 183, 184, 185], 249: [286, 418, 417, 412, 149], 250: [436, 441, 288, 286, 444], 252: [286, 418, 417, 412, 149], 253: [459, 318, 444, 445, 317], 254: [214, 182, 183, 184, 185], 255: [412, 89, 403, 91, 391], 256: [477, 160, 162, 164, 422], 258: [436, 288, 441, 286, 444], 259: [214, 182, 183, 184, 185], 260: [459, 353, 444, 445, 224], 261: [385, 160, 162, 422, 164], 262: [451, 453, 325, 455, 456], 263: [459, 444, 445, 293, 288], 264: [412, 89, 403, 91, 391], 265: [436, 288, 441, 286, 444], 266: [214, 182, 183, 184, 185], 267: [436, 448, 196, 445, 444], 268: [477, 441, 182, 436, 183], 269: [436, 288, 441, 286, 444], 270: [432, 444, 183, 190, 317], 271: [254, 286, 432, 558, 436], 272: [310, 453, 327, 455, 456], 273: [477, 445, 444, 196, 441], 274: [455, 275, 432, 436, 266], 275: [214, 182, 183, 184, 185], 276: [286, 418, 417, 412, 149], 277: [441, 449, 448, 223, 445], 278: [114, 409, 403, 89, 391], 279: [482, 293, 288, 441, 286], 280: [441, 228, 451, 449, 448], 281: [357, 465, 344, 467, 342], 282: [432, 436, 286, 441, 558], 283: [436, 288, 441, 286, 444], 284: [224, 445, 444, 441, 217], 285: [476, 344, 342, 332, 465], 286: [214, 182, 183, 184, 185], 287: [445, 254, 451, 259, 449], 288: [214, 182, 183, 184, 185], 289: [286, 418, 417, 412, 149], 290: [382, 160, 422, 162, 418], 291: [196, 445, 444, 441, 190], 292: [217, 449, 318, 451, 317], 293: [214, 182, 183, 184, 185], 294: [436, 288, 441, 286, 444], 296: [477, 183, 441, 190, 196], 297: [312, 445, 310, 448, 449], 298: [441, 449, 448, 224, 228], 300: [448, 324, 451, 323, 453], 301: [476, 344, 342, 332, 465], 303: [436, 288, 441, 286, 444], 304: [436, 288, 441, 286, 444], 305: [441, 449, 448, 224, 228], 306: [453, 558, 275, 432, 436], 307: [449, 451, 323, 453, 455], 308: [436, 288, 441, 286, 444], 309: [436, 288, 441, 286, 444], 310: [214, 182, 183, 184, 185], 311: [436, 288, 441, 286, 444], 312: [214, 182, 183, 184, 185], 313: [455, 310, 293, 441, 288], 314: [196, 445, 444, 441, 436], 315: [441, 451, 449, 448, 248], 316: [436, 288, 441, 286, 444], 317: [214, 182, 183, 184, 185], 318: [214, 182, 183, 184, 185], 322: [412, 403, 391, 390, 385], 323: [214, 182, 183, 184, 185], 324: [214, 182, 183, 184, 185], 325: [214, 182, 183, 184, 185], 326: [445, 254, 451, 259, 449], 327: [214, 182, 183, 184, 185], 328: [214, 182, 183, 184, 185], 330: [214, 182, 183, 184, 185], 331: [149, 448, 445, 444, 441], 332: [214, 182, 183, 184, 185], 333: [196, 445, 325, 190, 441], 334: [453, 286, 436, 558, 275], 335: [228, 448, 223, 445, 444], 336: [224, 217, 449, 448, 223], 337: [310, 293, 444, 445, 288], 338: [412, 89, 403, 91, 391], 339: [412, 89, 403, 91, 391], 341: [459, 248, 328, 465, 412], 342: [214, 182, 183, 184, 185], 343: [436, 288, 441, 286, 444], 344: [214, 182, 183, 184, 185], 345: [451, 558, 275, 422, 266], 346: [328, 327, 455, 456, 325], 347: [477, 436, 167, 432, 182], 348: [312, 445, 310, 448, 449], 349: [436, 288, 441, 286, 444], 350: [114, 358, 441, 357, 444], 351: [455, 558, 436, 275, 266], 352: [217, 310, 293, 444, 445], 353: [214, 182, 183, 184, 185], 354: [436, 223, 445, 444, 224], 355: [491, 448, 449, 160, 451], 356: [441, 449, 448, 445, 444], 357: [214, 182, 183, 184, 185], 358: [214, 182, 183, 184, 185], 359: [476, 459, 342, 332, 465], 360: [214, 182, 183, 184, 185], 361: [422, 412, 149, 409, 403], 362: [441, 449, 448, 224, 228], 363: [432, 436, 288, 286, 441], 364: [217, 444, 445, 310, 293], 365: [214, 182, 183, 184, 185], 367: [453, 558, 275, 432, 436], 368: [224, 448, 445, 444, 217], 369: [422, 445, 444, 441, 190], 370: [214, 182, 183, 184, 185], 371: [114, 409, 403, 89, 391], 372: [217, 444, 445, 310, 293], 373: [412, 89, 403, 91, 391], 375: [445, 453, 451, 254, 449], 376: [288, 286, 558, 275, 432], 377: [214, 182, 183, 184, 185], 378: [459, 318, 444, 445, 317], 380: [328, 327, 455, 456, 325], 381: [214, 182, 183, 184, 185], 382: [214, 182, 183, 184, 185], 383: [214, 182, 183, 184, 185], 384: [453, 455, 456, 328, 327], 385: [214, 182, 183, 184, 185], 386: [422, 286, 558, 432, 275], 387: [412, 89, 403, 91, 391], 388: [310, 293, 441, 444, 445], 389: [445, 254, 451, 259, 449], 390: [214, 182, 183, 184, 185], 391: [214, 182, 183, 184, 185], 393: [224, 448, 217, 445, 444], 396: [441, 449, 448, 224, 228], 398: [217, 448, 449, 317, 451], 399: [476, 344, 342, 332, 465], 401: [476, 223, 390, 217, 465], 402: [412, 403, 391, 390, 385], 403: [214, 182, 183, 184, 185], 405: [412, 403, 391, 390, 385], 408: [453, 328, 432, 327, 436], 409: [214, 182, 183, 184, 185], 410: [477, 190, 445, 444, 196], 411: [223, 445, 312, 310, 448], 412: [214, 182, 183, 184, 185], 413: [418, 409, 403, 391, 390], 414: [459, 441, 310, 293, 444], 415: [432, 445, 444, 190, 441], 416: [465, 318, 448, 449, 317], 417: [214, 182, 183, 184, 185], 418: [214, 182, 183, 184, 185], 419: [383, 432, 164, 167, 422], 420: [444, 318, 448, 449, 317], 421: [310, 182, 444, 445, 183], 422: [214, 182, 183, 184, 185], 423: [432, 444, 323, 441, 190], 424: [476, 344, 342, 332, 465], 425: [328, 327, 455, 456, 325], 426: [223, 445, 444, 441, 217], 427: [422, 448, 445, 444, 436], 428: [288, 558, 445, 444, 441], 430: [482, 436, 288, 286, 441], 431: [441, 228, 449, 448, 445], 432: [214, 182, 183, 184, 185], 434: [228, 449, 448, 223, 224], 435: [422, 417, 412, 409, 403], 436: [214, 182, 183, 184, 185], 437: [224, 217, 449, 448, 223], 438: [365, 114, 412, 409, 403], 440: [422, 417, 412, 409, 403], 441: [214, 182, 183, 184, 185], 442: [441, 451, 228, 449, 448], 443: [422, 417, 412, 409, 149], 444: [214, 182, 183, 184, 185], 445: [214, 182, 183, 184, 185], 446: [164, 441, 275, 436, 432], 447: [217, 323, 451, 318, 453], 448: [214, 182, 183, 184, 185], 449: [214, 182, 183, 184, 185], 450: [467, 449, 451, 323, 453], 451: [214, 182, 183, 184, 185], 452: [412, 403, 391, 390, 385], 453: [214, 182, 183, 184, 185], 454: [183, 182, 558, 465, 167], 455: [214, 182, 183, 184, 185], 456: [214, 182, 183, 184, 185], 457: [217, 432, 436, 288, 286], 458: [412, 403, 89, 91, 391], 459: [214, 182, 183, 184, 185], 460: [482, 436, 288, 286, 441], 462: [412, 403, 89, 91, 391], 464: [228, 217, 223, 445, 444], 465: [214, 182, 183, 184, 185], 466: [412, 403, 391, 390, 385], 467: [214, 182, 183, 184, 185], 468: [422, 558, 275, 432, 266], 469: [449, 422, 266, 259, 254], 470: [224, 217, 449, 448, 223], 471: [214, 182, 183, 184, 185], 474: [412, 167, 422, 418, 417], 475: [217, 441, 183, 190, 436], 476: [214, 182, 183, 184, 185], 477: [214, 182, 183, 184, 185], 478: [217, 445, 312, 448, 449], 479: [477, 164, 167, 436, 432], 480: [214, 182, 183, 184, 185], 481: [214, 182, 183, 184, 185], 482: [214, 182, 183, 184, 185], 483: [482, 436, 288, 286, 558], 484: [328, 327, 455, 456, 325], 486: [288, 448, 449, 318, 451], 487: [330, 456, 328, 327, 459], 488: [467, 449, 451, 323, 453], 489: [214, 182, 183, 184, 185], 490: [214, 182, 183, 184, 185], 491: [214, 182, 183, 184, 185], 492: [328, 327, 453, 325, 455], 493: [412, 403, 391, 390, 385], 495: [330, 456, 328, 327, 459], 496: [214, 182, 183, 184, 185], 497: [328, 327, 453, 325, 455], 498: [217, 318, 448, 449, 317], 499: [214, 182, 183, 184, 185], 500: [214, 182, 183, 184, 185], 501: [448, 324, 451, 323, 453], 502: [448, 324, 451, 323, 453], 503: [490, 228, 451, 370, 453], 504: [455, 436, 288, 286, 441], 505: [412, 403, 391, 390, 385], 506: [214, 182, 183, 184, 185], 508: [214, 182, 183, 184, 185], 509: [412, 403, 89, 91, 391], 510: [214, 182, 183, 184, 185], 511: [412, 403, 89, 91, 391], 513: [214, 182, 183, 184, 185], 514: [441, 451, 449, 448, 228], 515: [114, 409, 403, 89, 391], 516: [214, 182, 183, 184, 185], 517: [412, 403, 391, 390, 385], 518: [217, 444, 441, 190, 436], 520: [467, 449, 451, 323, 453], 521: [217, 448, 449, 318, 451], 522: [214, 182, 183, 184, 185], 523: [214, 182, 183, 184, 185], 524: [214, 182, 183, 184, 185], 525: [214, 182, 183, 184, 185], 526: [214, 182, 183, 184, 185], 527: [214, 182, 183, 184, 185], 528: [214, 182, 183, 184, 185], 529: [214, 182, 183, 184, 185], 531: [328, 327, 453, 325, 455], 532: [214, 182, 183, 184, 185], 533: [214, 182, 183, 184, 185], 534: [223, 312, 310, 444, 445], 535: [422, 444, 441, 436, 432], 536: [214, 182, 183, 184, 185], 537: [214, 182, 183, 184, 185], 538: [214, 182, 183, 184, 185], 539: [214, 182, 183, 184, 185], 540: [214, 182, 183, 184, 185], 541: [214, 182, 183, 184, 185], 542: [453, 455, 456, 327, 325], 543: [471, 91, 182, 459, 89], 544: [214, 182, 183, 184, 185], 545: [214, 182, 183, 184, 185], 546: [214, 182, 183, 184, 185], 547: [214, 182, 183, 184, 185], 550: [214, 182, 183, 184, 185], 551: [214, 182, 183, 184, 185], 552: [259, 436, 441, 444, 445], 554: [412, 89, 403, 91, 391], 555: [491, 456, 370, 91, 459], 556: [330, 456, 328, 327, 459], 557: [214, 182, 183, 184, 185], 558: [214, 182, 183, 184, 185], 559: [214, 182, 183, 184, 185]}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Neighborhood Selection\n",
    "\n",
    "# Define the neighborhood size\n",
    "neighborhood_size = 5\n",
    "\n",
    "# Initialize an empty dictionary to store item neighborhoods\n",
    "item_neighborhoods = {}\n",
    "\n",
    "# Iterate over each item (movie) index in the dataset\n",
    "for movie_index in range(item_user_array.shape[1]):\n",
    "    # Convert the item index to movie ID\n",
    "    movie_id = index_to_movie_id[movie_index]\n",
    "    \n",
    "    # Extract all ratings for the current movie\n",
    "    movie_ratings = item_user_array[:, movie_index]  # Changed to item_user_array\n",
    "    \n",
    "    # Aggregate ratings (e.g., compute the mean rating)\n",
    "    movie_avg_rating = np.mean(movie_ratings)\n",
    "    \n",
    "    # Retrieve similarity scores for the current movie\n",
    "    similarity_scores = item_similarity_matrix_train[movie_index]\n",
    "    \n",
    "    # Sort similarity scores in descending order and get indices of most similar items\n",
    "    most_similar_indices = np.argsort(similarity_scores)[::-1][1:neighborhood_size+1]\n",
    "    \n",
    "    # Convert indices back to movie IDs to form the neighborhood\n",
    "    neighborhood = [index_to_movie_id[idx] for idx in most_similar_indices]\n",
    "    \n",
    "    # Store the neighborhood for the current item in the item_neighborhoods dictionary\n",
    "    item_neighborhoods[movie_id] = neighborhood\n",
    "\n",
    "# Output: item_neighborhoods dictionary containing neighborhoods for each item\n",
    "print(item_neighborhoods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Rating Prediction\n",
    "\n",
    "- For each target item and user pair where the user hasn't rated the target item:\n",
    "Identify the neighborhood of similar items to the target item.\n",
    "- Predict the rating for the target item using a weighted average of the ratings of the items in its neighborhood, where the weights are the similarities between the items and the target item.\n",
    "- Adjust the prediction based on the user's average rating or other normalization techniques, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_4988\\1523731210.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  predicted_ratings.fillna(predicted_ratings.mean().mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>0.063655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>0.084189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>0.056225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         4         15        30        43        89        104     \\\n",
       "userId                                                                          \n",
       "428      0.063655  0.063655  0.063655  0.063655  0.063655  0.063655  0.056225   \n",
       "517      0.056225  0.084189  0.084189  0.084189  0.084189  0.084189  0.084189   \n",
       "197      0.006160  0.006160  0.006160  0.006160  0.006160  0.006160  0.006160   \n",
       "160      0.056225  0.131417  0.131417  0.131417  0.131417  0.131417  0.131417   \n",
       "67       0.025667  0.025667  0.025667  0.025667  0.025667  0.025667  0.025667   \n",
       "\n",
       "movieId    108       122       146     ...    174479    174551    175475  \\\n",
       "userId                                 ...                                 \n",
       "428      0.056225  0.063655  0.063655  ...  0.056225  0.056225  0.056225   \n",
       "517      0.056225  0.084189  0.084189  ...  0.056225  0.056225  0.056225   \n",
       "197      0.056225  0.006160  0.006160  ...  0.056225  0.056225  0.056225   \n",
       "160      0.056225  0.131417  0.131417  ...  0.056225  0.056225  0.056225   \n",
       "67       0.056225  0.025667  0.025667  ...  0.056225  0.056225  0.056225   \n",
       "\n",
       "movieId    176371    176389    177593    179813    181413    185029    186587  \n",
       "userId                                                                         \n",
       "428      0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  \n",
       "517      0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  \n",
       "197      0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  \n",
       "160      0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  \n",
       "67       0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  0.056225  \n",
       "\n",
       "[5 rows x 487 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your model and create the item_neighborhoods dictionary using the training data (steps 1-3)\n",
    "\n",
    "# Initialize an empty DataFrame to store predicted ratings\n",
    "predicted_ratings = pd.DataFrame(index=train_matrix.index, columns=train_matrix.columns)\n",
    "\n",
    "# Iterate over each user-item pair in the training set\n",
    "for user_id, user_ratings in train_matrix.iterrows():\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        \n",
    "        # Skip if the rating is non-zero (indicating a rating given by the user)\n",
    "        if rating != 0:\n",
    "            continue\n",
    "        \n",
    "        # Check if the movie has a neighborhood defined\n",
    "        if movie_id in item_neighborhoods:\n",
    "            neighborhood = item_neighborhoods[movie_id]\n",
    "            \n",
    "            # Filter out movies from the neighborhood that the user has rated in the training set\n",
    "            filtered_neighborhood = [neighbor_movie_id for neighbor_movie_id in neighborhood if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0]\n",
    "            \n",
    "            # Check if there are valid indices in the filtered neighborhood\n",
    "            if len(filtered_neighborhood) > 0:\n",
    "                # Calculate the predicted rating for the target movie based on the neighborhood\n",
    "                neighbor_ratings = [user_ratings.loc[neighbor_movie_id] for neighbor_movie_id in filtered_neighborhood]\n",
    "                predicted_rating = np.mean(neighbor_ratings)\n",
    "            else:\n",
    "                # If the filtered neighborhood is empty, assign the mean rating of all movies for the user in the training set\n",
    "                predicted_rating = user_ratings.mean()\n",
    "            \n",
    "            # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "            predicted_ratings.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "# Fill NaN values with mean ratings across all users\n",
    "predicted_ratings.fillna(predicted_ratings.mean().mean(), inplace=True)\n",
    "\n",
    "# Display the head of the predicted_ratings DataFrame\n",
    "predicted_ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 487)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings.shape\n",
    "\n",
    "# We transform predicted_ratings into a df to export it as a csv\n",
    "predicted_ratings_df = pd.DataFrame(predicted_ratings)\n",
    "\n",
    "# We export the predicted_ratings_df as a csv\n",
    "predicted_ratings_df.to_csv('predicted_ratings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "416      0.084189\n",
       "346      0.084189\n",
       "556      0.084189\n",
       "551      0.084189\n",
       "522      0.084189\n",
       "504      0.084189\n",
       "478      0.084189\n",
       "423      0.084189\n",
       "4        0.084189\n",
       "393      0.084189\n",
       "389      0.084189\n",
       "363      0.084189\n",
       "353      0.084189\n",
       "358      0.084189\n",
       "305      0.084189\n",
       "303      0.084189\n",
       "290      0.084189\n",
       "146      0.084189\n",
       "122      0.084189\n",
       "104      0.084189\n",
       "89       0.084189\n",
       "43       0.084189\n",
       "30       0.084189\n",
       "15       0.084189\n",
       "62344    0.056225\n",
       "57526    0.056225\n",
       "59667    0.056225\n",
       "59738    0.056225\n",
       "60904    0.056225\n",
       "61073    0.056225\n",
       "1        0.056225\n",
       "62970    0.056225\n",
       "63479    0.056225\n",
       "63853    0.056225\n",
       "64614    0.056225\n",
       "55280    0.056225\n",
       "65601    0.056225\n",
       "55492    0.056225\n",
       "50274    0.056225\n",
       "55241    0.056225\n",
       "55069    0.056225\n",
       "54934    0.056225\n",
       "54796    0.056225\n",
       "54274    0.056225\n",
       "53123    0.056225\n",
       "52435    0.056225\n",
       "50685    0.056225\n",
       "50613    0.056225\n",
       "50610    0.056225\n",
       "66090    0.056225\n",
       "Name: 517, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We print the top 50 highest rated movies for user 517\n",
    "predicted_ratings.loc[517].sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We count the NaN values in the predicted_ratings dataframe\n",
    "predicted_ratings.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(user_id):\n",
    "    \"\"\"\n",
    "    Get top movie recommendations for a given user using predicted ratings.\n",
    "\n",
    "    Parameters:\n",
    "        user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "\n",
    "    Returns:\n",
    "        list: Top movie titles recommended for the user.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the DataFrame to get ratings for the specified user\n",
    "    user_ratings = df[df['userId'] == user_id]\n",
    "    \n",
    "    # Check if the user has any ratings\n",
    "    if user_ratings.empty:\n",
    "        # If the user hasn't reviewed any movies, return the top 5 best-rated movies\n",
    "        top_movies = df.groupby('title')['rating'].mean().sort_values(ascending=False).head(5).index.tolist()\n",
    "        return top_movies\n",
    "    \n",
    "    # Sort the movies by rating in descending order\n",
    "    sorted_movies = user_ratings.sort_values(by='rating', ascending=False)\n",
    "    \n",
    "    # Get the top 5 movie titles\n",
    "    top_movie_titles = sorted_movies.head(5)['title'].tolist()\n",
    "    \n",
    "    # If the user has rated fewer than 5 movies, fill recommendations with the best-rated movies\n",
    "    if len(top_movie_titles) < 5:\n",
    "        # Calculate the number of additional recommendations needed\n",
    "        additional_recommendations = 5 - len(top_movie_titles)\n",
    "        \n",
    "        # Get the best-rated movies that the user hasn't rated\n",
    "        unrated_movies = df[~df['title'].isin(top_movie_titles)]\n",
    "        best_unrated_movies = unrated_movies.groupby('title')['rating'].mean().sort_values(ascending=False).head(additional_recommendations).index.tolist()\n",
    "        \n",
    "        # Add the additional recommendations to the list\n",
    "        top_movie_titles.extend(best_unrated_movies)\n",
    "    \n",
    "    return top_movie_titles[:5]  # Return only the top 5 recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Robin Hood ',\n",
       "  'Game, The ',\n",
       "  'Messenger: The Story of Joan of Arc, The ',\n",
       "  'King Kong ',\n",
       "  'Transformers: The Movie '],\n",
       " ['Beautiful Thing ',\n",
       "  'Unforgiven ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Men in Black (a.k.a. MIB) ',\n",
       "  'Elizabeth '],\n",
       " ['10 Cloverfield Lane ',\n",
       "  'What Women Want ',\n",
       "  'Oblivion ',\n",
       "  'Gran Torino ',\n",
       "  'Source Code '],\n",
       " ['Wreck-It Ralph ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Obsession '],\n",
       " ['Toy Story ',\n",
       "  'Kazaam ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Tom Segura: Completely Normal '],\n",
       " ['My Life as McDull (Mak dau goo si) ',\n",
       "  'The Amazing Screw-On Head ',\n",
       "  'Ryuzo and the Seven Henchmen ',\n",
       "  'Dead Meat ',\n",
       "  'Captain Newman, M.D. '],\n",
       " ['Chicago ',\n",
       "  'Shrek ',\n",
       "  'Robin Hood ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Harry Potter and the Deathly Hallows: Part 1 '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Children of Men ',\n",
       "  'Black Swan ',\n",
       "  \"Rosemary's Baby \",\n",
       "  'Nightmare Before Christmas, The ',\n",
       "  'Christmas Story, A '],\n",
       " ['Flatliners ',\n",
       "  'Godzilla ',\n",
       "  'My Life as McDull (Mak dau goo si) ',\n",
       "  'Crossing Delancey ',\n",
       "  'Sandpiper, The '],\n",
       " ['King Kong ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Kolya (Kolja) ',\n",
       "  'Melvin and Howard ',\n",
       "  'Klute '],\n",
       " ['Men in Black (a.k.a. MIB) ',\n",
       "  'Sling Blade ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Obsession ',\n",
       "  'Eva '],\n",
       " ['Life Is Beautiful (La Vita è bella) ',\n",
       "  'Departures (Okuribito) ',\n",
       "  'Gran Torino ',\n",
       "  'Christmas Story, A ',\n",
       "  'My Cousin Vinny '],\n",
       " [\"Rosemary's Baby \",\n",
       "  'Hour of the Wolf (Vargtimmen) ',\n",
       "  'Closer ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Elizabeth '],\n",
       " ['Toy Story ',\n",
       "  'Crow, The ',\n",
       "  'Boomerang ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Sandpiper, The '],\n",
       " ['One Fine Day ', 'Black Swan ', 'Human ', 'Eva ', 'Obsession '],\n",
       " ['Truth About Cats & Dogs, The ',\n",
       "  'The Nut Job 2: Nutty by Nature ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'My Life as McDull (Mak dau goo si) ',\n",
       "  'Obsession '],\n",
       " ['Toy Story ',\n",
       "  'Happy Gilmore ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Tom Segura: Completely Normal '],\n",
       " ['The Amazing Screw-On Head ',\n",
       "  'Power/Rangers ',\n",
       "  'Source Code ',\n",
       "  'Game, The ',\n",
       "  'Red Dragon '],\n",
       " ['Men in Black (a.k.a. MIB) ',\n",
       "  'Shrek ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Obsession ',\n",
       "  'Eva '],\n",
       " ['Happy Gilmore ',\n",
       "  'Sandpiper, The ',\n",
       "  'Eva ',\n",
       "  'Human ',\n",
       "  'My Life as McDull (Mak dau goo si) '],\n",
       " ['Happy Gilmore ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) '],\n",
       " ['Jagged Edge ',\n",
       "  'Shrek ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Toy Story ',\n",
       "  'Chicago '],\n",
       " ['Black Swan ',\n",
       "  \"Empire of Dreams: The Story of the 'Star Wars' Trilogy \",\n",
       "  'Star Trek V: The Final Frontier ',\n",
       "  'Source Code ',\n",
       "  'Nuremberg '],\n",
       " ['Miss Sloane ',\n",
       "  'Life Is Beautiful (La Vita è bella) ',\n",
       "  'Equalizer, The ',\n",
       "  'Shrek ',\n",
       "  'Children of Men '],\n",
       " ['Alice in Wonderland ',\n",
       "  'Duel in the Sun ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Crossing Delancey ',\n",
       "  'Human '],\n",
       " ['Forever Young ',\n",
       "  'Toy Story ',\n",
       "  'Shrek ',\n",
       "  'How the Grinch Stole Christmas! ',\n",
       "  'Twilight Saga: New Moon, The '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey ']]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_recommendations = []\n",
    "\n",
    "# Iterate over each row (user) in the train_matrix\n",
    "for user_index in range(train_matrix.shape[0]):\n",
    "    # Get the actual user ID corresponding to the user index\n",
    "    user_id = index_to_user_id[user_index]\n",
    "    recommendations = get_top_recommendations(user_id)\n",
    "    top_recommendations.append(recommendations)\n",
    "\n",
    "# Output: List of top movie recommendations for each user in the train matrix\n",
    "top_recommendations\n",
    "\n",
    "# print size of top_recommendations\n",
    "len(top_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last version\n"
     ]
    }
   ],
   "source": [
    "print(\"Last version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Model Evaluation\n",
    "- We evaluate the performance of your ItemKNN algorithm using appropriate evaluation metrics such as Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), or others.\n",
    "- Split your dataset into training and testing sets to assess the model's predictive accuracy on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 487)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(340, 487)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "\n",
    "predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Training Data: 0.11541909354372394\n",
      "Root Mean Squared Error (RMSE) on Training Data: 0.4785515075368112\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def evaluate_model(train_matrix, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance on the training data.\n",
    "\n",
    "    Parameters:\n",
    "        train_matrix (numpy.ndarray): Item-user matrix from the training data.\n",
    "        predicted_ratings (pandas.DataFrame): Predicted ratings DataFrame for the training data.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Absolute Error (MAE) on the training data.\n",
    "        float: Root Mean Squared Error (RMSE) on the training data.\n",
    "    \"\"\"\n",
    "    # Ensure train_matrix and predicted_ratings have the same shape\n",
    "    assert train_matrix.shape == predicted_ratings.shape, \"Shapes of train_matrix and predicted_ratings are not consistent.\"\n",
    "\n",
    "    # Convert predicted_ratings DataFrame to numpy array\n",
    "    predicted_ratings_array = predicted_ratings.to_numpy()\n",
    "\n",
    "    # Flatten the arrays\n",
    "    train_ratings = train_matrix.flatten()\n",
    "    predicted_ratings = predicted_ratings_array.flatten()\n",
    "\n",
    "    # Filter out NaN values\n",
    "    valid_indices = ~np.isnan(train_ratings) & ~np.isnan(predicted_ratings)\n",
    "    train_ratings = train_ratings[valid_indices]\n",
    "    predicted_ratings = predicted_ratings[valid_indices]\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(train_ratings, predicted_ratings)\n",
    "    rmse = np.sqrt(mean_squared_error(train_ratings, predicted_ratings))\n",
    "\n",
    "    return mae, rmse\n",
    "\n",
    "# Assuming train is the numpy array representing the item-user matrix\n",
    "# Assuming predicted_ratings is the DataFrame representing the predicted ratings for the training data\n",
    "\n",
    "# Evaluate the model\n",
    "mae, rmse = evaluate_model(train, predicted_ratings)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Training Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Training Data:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Parameter Tuning\n",
    "- Experiment with different parameters such as similarity threshold, neighborhood size, and similarity metric to optimize the performance of your ItemKNN algorithm.\n",
    "- Use cross-validation or other techniques to tune these parameters and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import Necessary Libraries:**\n",
    "   - We import the required libraries for performing grid search cross-validation (`GridSearchCV`), creating custom scorers (`make_scorer`), and utilizing the `NearestNeighbors` algorithm.\n",
    "\n",
    "2. **Define Cosine Similarity Function:**\n",
    "   - We define a custom function `cosine_similarity` to compute the cosine similarity between two vectors. This function calculates the dot product of the vectors and divides it by the product of their norms.\n",
    "\n",
    "3. **Define Custom Scorer:**\n",
    "   - We create a custom scorer `cosine_similarity_scorer` using `make_scorer`, which enables us to use cosine similarity as the scoring metric during grid search cross-validation.\n",
    "\n",
    "4. **Define Parameter Grid:**\n",
    "   - We specify a parameter grid `param_grid` containing the hyperparameters to be tuned. In this case, we're tuning the number of neighbors (`n_neighbors`) and the distance metric (`metric`) for the `NearestNeighbors` algorithm.\n",
    "\n",
    "5. **Initialize NearestNeighbors Model:**\n",
    "   - We initialize the `NearestNeighbors` model without specifying any hyperparameters.\n",
    "\n",
    "6. **Create GridSearchCV Object:**\n",
    "   - We create a `GridSearchCV` object named `grid_search` with the specified parameter grid, cross-validation strategy (5-fold cross-validation), and custom scoring metric (`cosine_similarity_scorer`).\n",
    "\n",
    "7. **Fit the Data:**\n",
    "   - We fit the `item_user_matrix` data to the `grid_search` object to perform hyperparameter tuning. `item_user_matrix` typically contains the item-item similarity matrix computed using collaborative filtering techniques.\n",
    "\n",
    "8. **Get Best Hyperparameters:**\n",
    "   - After fitting the data, we retrieve the best hyperparameters selected by the grid search using the `best_params_` attribute of the `grid_search` object.\n",
    "\n",
    "9. **Print Best Parameters:**\n",
    "   - Finally, we print the best hyperparameters obtained from the grid search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn (sklearn)`:\n",
    "\n",
    "- Scikit-learn is a popular machine learning library in Python that provides simple and efficient tools for data analysis and modeling.\n",
    "- It includes various modules for tasks such as classification, regression, clustering, dimensionality reduction, and model selection.\n",
    "- The GridSearchCV class from scikit-learn is used for hyperparameter tuning through grid search along with cross-validation.\n",
    "- The make_scorer function allows you to create a custom scoring function for use with GridSearchCV.\n",
    "- The NearestNeighbors class provides functionality for unsupervised nearest neighbors learning, which can be used for tasks such as finding k-nearest neighbors for a given data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: NearestNeighbors</label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={'metric': ['cosine', 'euclidean'],\n",
       "                         'n_neighbors': [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method='predict'))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'cosine', 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Define a custom scorer based on cosine similarity defined above\n",
    "cosine_similarity_scorer = make_scorer(cosine_similarity)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 15, 30, 40],\n",
    "    'metric': ['cosine', 'euclidean']\n",
    "}\n",
    "\n",
    "# Initialize NearestNeighbors model\n",
    "knn_model = NearestNeighbors()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring=cosine_similarity_scorer)\n",
    "\n",
    "# Fit the data to perform hyperparameter tuning\n",
    "grid_search.fit(train_val_matrix)  # train_val_matrix contains item-user matrix\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up a GridSearchCV object to perform hyperparameter tuning using the validation set (train_val_matrix). It explores different combinations of hyperparameters specified in the param_grid, evaluates them using 5-fold cross-validation (cv=5), and uses the cosine_similarity scorer to optimize the model's performance based on cosine similarity. Finally, it prints the best hyperparameters found during the search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to perform the calculation of the predicted ratings for the train-val set to generate predicted ratings in order to evaluate the performance of our trained model on a validation dataset. \n",
    "\n",
    "If we computed the similarity matrix again specifically for the train_val set, it would essentially mean that we are using a different set of similarity measures for predicting ratings compared to what we used during training. This approach could lead to inconsistencies and potentially degrade the performance of our model. Here's what could happen:\n",
    "\n",
    "1. **Inconsistency**: The similarity measures computed for the train_val set might differ from those computed for the training set due to variations in the data. As a result, the predicted ratings based on these new similarity measures may not align well with the predictions made during training, leading to inconsistency in the model's behavior.\n",
    "\n",
    "2. **Overfitting**: Computing a new similarity matrix specifically for the train_val set might lead to overfitting on the validation data. The model may capture noise or idiosyncrasies present in the train_val set, which may not generalize well to unseen data.\n",
    "\n",
    "3. **Increased Complexity**: Computing the similarity matrix again for the train_val set adds computational complexity and redundancy, especially if the similarity computation process is resource-intensive. This can result in longer training times and increased resource utilization.\n",
    "\n",
    "Overall, it's generally recommended to use the same similarity measures or neighborhood definitions for both training and validation sets to ensure consistency and generalizability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_4988\\568664895.py:33: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  predicted_ratings_train_val.fillna(predicted_ratings_train_val.mean().mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained your model and obtained the item_neighborhoods dictionary\n",
    "\n",
    "# Initialize an empty DataFrame to store predicted ratings for train_val\n",
    "predicted_ratings_train_val = pd.DataFrame(index=train_val_matrix.index, columns=train_val_matrix.columns)\n",
    "\n",
    "# Iterate over each user and their ratings in the train_val set\n",
    "for user_id, user_ratings in train_val_matrix.iterrows():\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        # Skip if the rating is non-zero (indicating a rating given by the user)\n",
    "        if rating != 0:\n",
    "            continue\n",
    "        \n",
    "        # Check if the movie has a neighborhood defined\n",
    "        if movie_id in item_neighborhoods:\n",
    "            neighborhood = item_neighborhoods[movie_id]\n",
    "            \n",
    "            # Filter out movies from the neighborhood that the user has rated in the train set\n",
    "            filtered_neighborhood = [neighbor_movie_id for neighbor_movie_id in neighborhood if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0]\n",
    "            \n",
    "            # Check if there are valid indices in the filtered neighborhood\n",
    "            if len(filtered_neighborhood) > 0:\n",
    "                # Calculate the predicted rating for the target movie based on the neighborhood\n",
    "                neighbor_ratings = [user_ratings.loc[neighbor_movie_id] for neighbor_movie_id in filtered_neighborhood]\n",
    "                predicted_rating = np.mean(neighbor_ratings)\n",
    "            else:\n",
    "                # If the filtered neighborhood is empty, assign the mean rating of all movies for the user in the train set\n",
    "                predicted_rating = user_ratings.mean()\n",
    "            \n",
    "            # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "            predicted_ratings_train_val.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "# Fill NaN values with mean ratings across all users\n",
    "predicted_ratings_train_val.fillna(predicted_ratings_train_val.mean().mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>0.019507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>0.041068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>0.185832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "      <td>0.054999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         4         15        30        43        89        104     \\\n",
       "userId                                                                          \n",
       "344      0.019507  0.019507  0.019507  0.019507  0.019507  0.019507  0.019507   \n",
       "465      0.041068  0.041068  0.041068  0.041068  0.041068  0.041068  0.041068   \n",
       "515      0.010267  0.010267  0.010267  0.010267  0.010267  0.010267  0.010267   \n",
       "357      0.054999  0.185832  0.185832  0.185832  0.185832  0.185832  0.185832   \n",
       "164      0.010267  0.010267  0.010267  0.010267  0.010267  0.010267  0.010267   \n",
       "\n",
       "movieId    108       122       146     ...    174479    174551    175475  \\\n",
       "userId                                 ...                                 \n",
       "344      0.054999  0.019507  0.019507  ...  0.054999  0.054999  0.054999   \n",
       "465      0.054999  0.041068  0.041068  ...  0.054999  0.054999  0.054999   \n",
       "515      0.054999  0.010267  0.010267  ...  0.054999  0.054999  0.054999   \n",
       "357      0.054999  0.185832  0.185832  ...  0.054999  0.054999  0.054999   \n",
       "164      0.054999  0.010267  0.010267  ...  0.054999  0.054999  0.054999   \n",
       "\n",
       "movieId    176371    176389    177593    179813    181413    185029    186587  \n",
       "userId                                                                         \n",
       "344      0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  \n",
       "465      0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  \n",
       "515      0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  \n",
       "357      0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  \n",
       "164      0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  0.054999  \n",
       "\n",
       "[5 rows x 487 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(425, 487)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings_train_val.head()\n",
    "\n",
    "predicted_ratings_train_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the model with the train-val item-user matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_4988\\3392059385.py:6: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  similarity = dot_product / (norm_a * norm_b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Train-Validation Data: 0.11270438375369393\n",
      "Root Mean Squared Error (RMSE) on Train-Validation Data: 0.4715288573983273\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate item-item similarity matrix for train data\n",
    "item_similarity_matrix_train = np.zeros((train.shape[1], train.shape[1]))\n",
    "\n",
    "for i in range(train.shape[1]):\n",
    "    for j in range(i, train.shape[1]):\n",
    "        item_similarity_matrix_train[i, j] = cosine_similarity(train[:, i], train[:, j])\n",
    "        item_similarity_matrix_train[j, i] = item_similarity_matrix_train[i, j]\n",
    "\n",
    "# Assuming train_val_matrix and predicted_ratings_train_val are properly defined\n",
    "\n",
    "# Now, you can evaluate the model using the evaluate_model function\n",
    "mae, rmse = evaluate_model(train_val_matrix.to_numpy(), predicted_ratings_train_val)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Train-Validation Data:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Train-Validation Data:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Deployment\n",
    "\n",
    "Once we have come up with the best parameters possible and trained the model with the whole train_validation set, we will test it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on Test Data using Predicted Ratings from Train-Validation Set: 0.1279818499213286\n",
      "Root Mean Squared Error (RMSE) on Test Data using Predicted Ratings from Train-Validation Set: 0.4995626957908083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaume\\AppData\\Local\\Temp\\ipykernel_4988\\438452714.py:35: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  predicted_ratings_test.fillna(predicted_ratings_test.mean().mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained your model and obtained the item_neighborhoods dictionary\n",
    "\n",
    "# Now, we can evaluate the model's predicted ratings on the test set\n",
    "\n",
    "# Initialize an empty DataFrame to store predicted ratings for the test set\n",
    "predicted_ratings_test = pd.DataFrame(index=test_matrix.index, columns=test_matrix.columns)\n",
    "\n",
    "# Iterate over each user and their ratings in the test set\n",
    "for user_id, user_ratings in test_matrix.iterrows():\n",
    "    for movie_id, rating in user_ratings.items():\n",
    "        # Skip if the rating is non-zero (indicating a rating given by the user)\n",
    "        if rating != 0:\n",
    "            continue\n",
    "        \n",
    "        # Check if the movie has a neighborhood defined\n",
    "        if movie_id in item_neighborhoods:\n",
    "            neighborhood = item_neighborhoods[movie_id]\n",
    "            \n",
    "            # Filter out movies from the neighborhood that the user has rated in the train set\n",
    "            filtered_neighborhood = [neighbor_movie_id for neighbor_movie_id in neighborhood if neighbor_movie_id in user_ratings.index and user_ratings.loc[neighbor_movie_id] != 0]\n",
    "            \n",
    "            # Check if there are valid indices in the filtered neighborhood\n",
    "            if len(filtered_neighborhood) > 0:\n",
    "                # Calculate the predicted rating for the target movie based on the neighborhood\n",
    "                neighbor_ratings = [user_ratings.loc[neighbor_movie_id] for neighbor_movie_id in filtered_neighborhood]\n",
    "                predicted_rating = np.mean(neighbor_ratings)\n",
    "            else:\n",
    "                # If the filtered neighborhood is empty, assign the mean rating of all movies for the user in the train set\n",
    "                predicted_rating = user_ratings.mean()\n",
    "            \n",
    "            # Assign the predicted rating to the corresponding cell in the DataFrame\n",
    "            predicted_ratings_test.at[user_id, movie_id] = predicted_rating\n",
    "\n",
    "# Fill NaN values with mean ratings across all users\n",
    "predicted_ratings_test.fillna(predicted_ratings_test.mean().mean(), inplace=True)\n",
    "\n",
    "# Now, you can evaluate the model's predicted ratings on the test set\n",
    "mae, rmse = evaluate_model(test_matrix.to_numpy(), predicted_ratings_test)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE) on Test Data using Predicted Ratings from Train-Validation Set:\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Data using Predicted Ratings from Train-Validation Set:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>89</th>\n",
       "      <th>104</th>\n",
       "      <th>108</th>\n",
       "      <th>122</th>\n",
       "      <th>146</th>\n",
       "      <th>...</th>\n",
       "      <th>174479</th>\n",
       "      <th>174551</th>\n",
       "      <th>175475</th>\n",
       "      <th>176371</th>\n",
       "      <th>176389</th>\n",
       "      <th>177593</th>\n",
       "      <th>179813</th>\n",
       "      <th>181413</th>\n",
       "      <th>185029</th>\n",
       "      <th>186587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       4       15      30      43      89      104     108     \\\n",
       "userId                                                                    \n",
       "7           4.5     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "561         4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "122         0.0     0.0     0.0     0.0     0.0     0.0     4.0     0.0   \n",
       "559         5.0     0.0     3.0     0.0     0.0     0.0     3.0     0.0   \n",
       "516         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "209         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "350         4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "610         5.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "441         0.0     0.0     0.0     0.0     0.0     0.0     3.5     0.0   \n",
       "579         4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  122     146     ...  174479  174551  175475  176371  176389  177593  \\\n",
       "userId                   ...                                                   \n",
       "7           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "561         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "122         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "559         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "516         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "209         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     4.5   \n",
       "350         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "610         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "441         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "579         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "movieId  179813  181413  185029  186587  \n",
       "userId                                   \n",
       "7           0.0     0.0     0.0     0.0  \n",
       "561         0.0     0.0     0.0     0.0  \n",
       "122         0.0     0.0     0.0     0.0  \n",
       "559         0.0     0.0     0.0     0.0  \n",
       "516         0.0     0.0     0.0     0.0  \n",
       "...         ...     ...     ...     ...  \n",
       "209         0.0     0.0     1.5     0.0  \n",
       "350         0.0     0.0     0.0     0.0  \n",
       "610         0.0     0.0     0.0     0.0  \n",
       "441         0.0     0.0     0.0     0.0  \n",
       "579         0.0     0.0     0.0     0.0  \n",
       "\n",
       "[107 rows x 487 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Robin Hood ',\n",
       "  'Game, The ',\n",
       "  'Messenger: The Story of Joan of Arc, The ',\n",
       "  'King Kong ',\n",
       "  'Transformers: The Movie '],\n",
       " ['Beautiful Thing ',\n",
       "  'Unforgiven ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Men in Black (a.k.a. MIB) ',\n",
       "  'Elizabeth '],\n",
       " ['10 Cloverfield Lane ',\n",
       "  'What Women Want ',\n",
       "  'Oblivion ',\n",
       "  'Gran Torino ',\n",
       "  'Source Code '],\n",
       " ['Wreck-It Ralph ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Obsession '],\n",
       " ['Toy Story ',\n",
       "  'Kazaam ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Tom Segura: Completely Normal '],\n",
       " ['My Life as McDull (Mak dau goo si) ',\n",
       "  'The Amazing Screw-On Head ',\n",
       "  'Ryuzo and the Seven Henchmen ',\n",
       "  'Dead Meat ',\n",
       "  'Captain Newman, M.D. '],\n",
       " ['Chicago ',\n",
       "  'Shrek ',\n",
       "  'Robin Hood ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Harry Potter and the Deathly Hallows: Part 1 '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Children of Men ',\n",
       "  'Black Swan ',\n",
       "  \"Rosemary's Baby \",\n",
       "  'Nightmare Before Christmas, The ',\n",
       "  'Christmas Story, A '],\n",
       " ['Flatliners ',\n",
       "  'Godzilla ',\n",
       "  'My Life as McDull (Mak dau goo si) ',\n",
       "  'Crossing Delancey ',\n",
       "  'Sandpiper, The '],\n",
       " ['King Kong ',\n",
       "  \"It's a Wonderful Life \",\n",
       "  'Kolya (Kolja) ',\n",
       "  'Melvin and Howard ',\n",
       "  'Klute '],\n",
       " ['Men in Black (a.k.a. MIB) ',\n",
       "  'Sling Blade ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Obsession ',\n",
       "  'Eva '],\n",
       " ['Life Is Beautiful (La Vita è bella) ',\n",
       "  'Departures (Okuribito) ',\n",
       "  'Gran Torino ',\n",
       "  'Christmas Story, A ',\n",
       "  'My Cousin Vinny '],\n",
       " [\"Rosemary's Baby \",\n",
       "  'Hour of the Wolf (Vargtimmen) ',\n",
       "  'Closer ',\n",
       "  'Spirited Away (Sen to Chihiro no kamikakushi) ',\n",
       "  'Elizabeth '],\n",
       " ['Toy Story ',\n",
       "  'Crow, The ',\n",
       "  'Boomerang ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Sandpiper, The '],\n",
       " ['One Fine Day ', 'Black Swan ', 'Human ', 'Eva ', 'Obsession '],\n",
       " ['Truth About Cats & Dogs, The ',\n",
       "  'The Nut Job 2: Nutty by Nature ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'My Life as McDull (Mak dau goo si) ',\n",
       "  'Obsession '],\n",
       " ['Toy Story ',\n",
       "  'Happy Gilmore ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Tom Segura: Completely Normal '],\n",
       " ['The Amazing Screw-On Head ',\n",
       "  'Power/Rangers ',\n",
       "  'Source Code ',\n",
       "  'Game, The ',\n",
       "  'Red Dragon '],\n",
       " ['Men in Black (a.k.a. MIB) ',\n",
       "  'Shrek ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Obsession ',\n",
       "  'Eva '],\n",
       " ['Happy Gilmore ',\n",
       "  'Sandpiper, The ',\n",
       "  'Eva ',\n",
       "  'Human ',\n",
       "  'My Life as McDull (Mak dau goo si) '],\n",
       " ['Happy Gilmore ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) '],\n",
       " ['Jagged Edge ',\n",
       "  'Shrek ',\n",
       "  'Truth About Cats & Dogs, The ',\n",
       "  'Toy Story ',\n",
       "  'Chicago '],\n",
       " ['Black Swan ',\n",
       "  \"Empire of Dreams: The Story of the 'Star Wars' Trilogy \",\n",
       "  'Star Trek V: The Final Frontier ',\n",
       "  'Source Code ',\n",
       "  'Nuremberg '],\n",
       " ['Miss Sloane ',\n",
       "  'Life Is Beautiful (La Vita è bella) ',\n",
       "  'Equalizer, The ',\n",
       "  'Shrek ',\n",
       "  'Children of Men '],\n",
       " ['Alice in Wonderland ',\n",
       "  'Duel in the Sun ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Crossing Delancey ',\n",
       "  'Human '],\n",
       " ['Forever Young ',\n",
       "  'Toy Story ',\n",
       "  'Shrek ',\n",
       "  'How the Grinch Stole Christmas! ',\n",
       "  'Twilight Saga: New Moon, The '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey '],\n",
       " ['Duel in the Sun ',\n",
       "  'Human ',\n",
       "  'Decalogue, The (Dekalog) ',\n",
       "  'Tom Segura: Completely Normal ',\n",
       "  'Crossing Delancey ']]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of top_recommendations_test: 107\n"
     ]
    }
   ],
   "source": [
    "top_recommendations_test = []\n",
    "\n",
    "# Iterate over each row (user) in the test_matrix\n",
    "for user_index in range(test_matrix.shape[0]):\n",
    "    # Get the actual user ID corresponding to the user index\n",
    "    user_id = index_to_user_id[user_index]\n",
    "    recommendations = get_top_recommendations(user_id)\n",
    "    top_recommendations_test.append(recommendations)\n",
    "\n",
    "# Output: List of top movie recommendations for each user in the test matrix\n",
    "top_recommendations_test\n",
    "\n",
    "# print size of top_recommendations\n",
    "print(\"Size of top_recommendations_test:\", len(top_recommendations_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Classification (ItemKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data preparation\n",
    "- Ensure you have a dataset with user-item interactions. Each interaction should include the user ID, item ID, and the corresponding label or class for classification.\n",
    "- Preprocess the data as needed, including handling missing values, encoding categorical variables, and splitting into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this step we are going to resuse the `item_user_matrix` that we created in the first model built. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compute Item Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [357, 465, 344, 467, 342],\n",
       " 2: [317, 451, 183, 453, 182],\n",
       " 3: [422, 417, 149, 412, 409],\n",
       " 4: [248, 162, 164, 436, 167],\n",
       " 5: [441, 448, 223, 224, 445],\n",
       " 6: [164, 417, 412, 409, 403],\n",
       " 7: [357, 344, 465, 342, 467],\n",
       " 9: [477, 444, 182, 441, 183],\n",
       " 10: [149, 418, 417, 159, 412],\n",
       " 11: [254, 453, 228, 451, 248],\n",
       " 12: [436, 441, 344, 342, 444],\n",
       " 13: [482, 310, 441, 293, 444],\n",
       " 14: [412, 324, 453, 323, 455],\n",
       " 15: [422, 417, 412, 409, 403],\n",
       " 16: [286, 451, 323, 453, 318],\n",
       " 17: [436, 159, 160, 162, 164],\n",
       " 18: [477, 444, 182, 441, 183],\n",
       " 19: [412, 89, 403, 91, 391],\n",
       " 20: [436, 448, 445, 444, 223],\n",
       " 21: [558, 417, 412, 409, 403],\n",
       " 22: [477, 160, 162, 164, 422],\n",
       " 23: [214, 182, 183, 184, 185],\n",
       " 24: [286, 418, 417, 412, 149],\n",
       " 25: [436, 448, 445, 444, 217],\n",
       " 27: [317, 459, 332, 330, 328],\n",
       " 28: [196, 441, 182, 183, 436],\n",
       " 29: [422, 441, 436, 432, 182],\n",
       " 30: [467, 324, 453, 323, 455],\n",
       " 31: [293, 455, 456, 327, 325],\n",
       " 32: [441, 449, 448, 217, 445],\n",
       " 33: [476, 342, 332, 330, 465],\n",
       " 34: [432, 445, 444, 196, 441],\n",
       " 36: [254, 453, 228, 451, 248],\n",
       " 38: [476, 342, 332, 330, 465],\n",
       " 39: [418, 412, 114, 409, 403],\n",
       " 40: [160, 182, 448, 449, 451],\n",
       " 41: [455, 330, 328, 459, 327],\n",
       " 42: [477, 441, 436, 167, 432],\n",
       " 43: [444, 453, 451, 449, 448],\n",
       " 44: [217, 441, 183, 436, 190],\n",
       " 45: [286, 418, 417, 412, 149],\n",
       " 46: [328, 327, 453, 325, 455],\n",
       " 47: [453, 455, 456, 327, 325],\n",
       " 48: [223, 224, 453, 370, 455],\n",
       " 50: [224, 196, 445, 444, 441],\n",
       " 51: [477, 436, 182, 432, 183],\n",
       " 52: [444, 223, 449, 448, 224],\n",
       " 54: [477, 448, 190, 445, 444],\n",
       " 57: [217, 445, 444, 190, 196],\n",
       " 58: [223, 196, 445, 444, 217],\n",
       " 59: [477, 344, 342, 465, 332],\n",
       " 62: [436, 288, 441, 286, 444],\n",
       " 63: [477, 444, 182, 441, 183],\n",
       " 64: [436, 448, 196, 445, 444],\n",
       " 65: [449, 455, 254, 453, 259],\n",
       " 66: [217, 445, 444, 190, 441],\n",
       " 67: [436, 288, 441, 286, 444],\n",
       " 68: [228, 448, 217, 223, 445],\n",
       " 69: [451, 259, 456, 455, 266],\n",
       " 70: [476, 344, 342, 332, 465],\n",
       " 71: [477, 344, 342, 465, 332],\n",
       " 73: [432, 190, 445, 444, 196],\n",
       " 74: [259, 293, 444, 445, 288],\n",
       " 75: [477, 182, 183, 441, 190],\n",
       " 76: [330, 456, 328, 327, 459],\n",
       " 78: [182, 417, 412, 409, 149],\n",
       " 79: [456, 441, 330, 444, 445],\n",
       " 80: [477, 441, 183, 436, 432],\n",
       " 82: [436, 288, 441, 286, 444],\n",
       " 83: [432, 445, 444, 196, 441],\n",
       " 84: [223, 444, 183, 190, 441],\n",
       " 85: [477, 445, 444, 196, 441],\n",
       " 86: [441, 449, 448, 445, 444],\n",
       " 87: [477, 445, 444, 190, 441],\n",
       " 88: [491, 455, 456, 459, 167],\n",
       " 89: [214, 182, 183, 184, 185],\n",
       " 90: [217, 190, 445, 444, 196],\n",
       " 91: [214, 182, 183, 184, 185],\n",
       " 92: [477, 190, 445, 444, 196],\n",
       " 93: [217, 310, 293, 444, 445],\n",
       " 95: [422, 149, 412, 409, 403],\n",
       " 96: [445, 312, 448, 449, 310],\n",
       " 97: [248, 451, 228, 449, 448],\n",
       " 98: [224, 448, 445, 444, 217],\n",
       " 99: [217, 317, 448, 449, 312],\n",
       " 100: [441, 448, 217, 223, 445],\n",
       " 101: [432, 286, 436, 558, 275],\n",
       " 103: [432, 445, 444, 196, 441],\n",
       " 104: [317, 459, 332, 330, 328],\n",
       " 105: [459, 441, 149, 357, 444],\n",
       " 106: [403, 317, 448, 449, 451],\n",
       " 107: [149, 159, 160, 162, 164],\n",
       " 109: [275, 453, 558, 455, 456],\n",
       " 110: [412, 89, 403, 91, 391],\n",
       " 111: [477, 167, 436, 182, 432],\n",
       " 112: [477, 162, 164, 422, 167],\n",
       " 113: [412, 89, 403, 91, 391],\n",
       " 114: [214, 182, 183, 184, 185],\n",
       " 115: [114, 167, 441, 182, 183],\n",
       " 116: [459, 444, 445, 293, 288],\n",
       " 117: [312, 445, 344, 448, 449],\n",
       " 118: [418, 436, 254, 432, 288],\n",
       " 119: [228, 436, 167, 432, 182],\n",
       " 121: [436, 288, 441, 286, 444],\n",
       " 122: [477, 441, 182, 310, 436],\n",
       " 123: [459, 444, 445, 293, 448],\n",
       " 124: [412, 89, 403, 91, 391],\n",
       " 125: [477, 167, 441, 182, 183],\n",
       " 129: [217, 451, 323, 453, 318],\n",
       " 130: [432, 444, 183, 441, 190],\n",
       " 131: [477, 444, 183, 441, 190],\n",
       " 132: [353, 370, 459, 89, 365],\n",
       " 134: [445, 254, 451, 259, 449],\n",
       " 135: [477, 162, 164, 432, 167],\n",
       " 136: [149, 159, 160, 418, 417],\n",
       " 137: [259, 164, 167, 441, 182],\n",
       " 138: [223, 449, 448, 217, 445],\n",
       " 139: [217, 448, 449, 317, 451],\n",
       " 140: [385, 422, 160, 162, 164],\n",
       " 141: [167, 162, 465, 390, 467],\n",
       " 143: [455, 330, 328, 459, 327],\n",
       " 144: [441, 449, 448, 224, 228],\n",
       " 145: [412, 89, 403, 91, 391],\n",
       " 146: [558, 417, 412, 149, 409],\n",
       " 147: [286, 418, 417, 412, 149],\n",
       " 148: [477, 159, 160, 162, 418],\n",
       " 149: [214, 182, 183, 184, 185],\n",
       " 151: [310, 441, 288, 444, 445],\n",
       " 152: [167, 417, 412, 409, 403],\n",
       " 153: [436, 445, 444, 190, 196],\n",
       " 154: [436, 288, 441, 286, 444],\n",
       " 155: [293, 288, 286, 441, 558],\n",
       " 156: [254, 453, 228, 451, 248],\n",
       " 157: [477, 162, 432, 164, 167],\n",
       " 158: [477, 444, 182, 441, 183],\n",
       " 159: [214, 182, 183, 184, 185],\n",
       " 160: [214, 182, 183, 184, 185],\n",
       " 161: [436, 288, 441, 286, 444],\n",
       " 162: [214, 182, 183, 184, 185],\n",
       " 163: [459, 390, 266, 465, 275],\n",
       " 164: [214, 182, 183, 184, 185],\n",
       " 165: [383, 162, 422, 164, 418],\n",
       " 166: [254, 453, 228, 451, 248],\n",
       " 167: [214, 182, 183, 184, 185],\n",
       " 168: [558, 417, 412, 149, 409],\n",
       " 169: [477, 444, 182, 441, 183],\n",
       " 171: [445, 254, 451, 259, 449],\n",
       " 172: [436, 288, 286, 441, 558],\n",
       " 177: [441, 449, 448, 445, 444],\n",
       " 178: [436, 288, 441, 286, 444],\n",
       " 179: [455, 436, 558, 275, 441],\n",
       " 180: [441, 451, 449, 448, 228],\n",
       " 181: [455, 436, 286, 558, 441],\n",
       " 182: [214, 182, 183, 184, 185],\n",
       " 183: [214, 182, 183, 184, 185],\n",
       " 184: [436, 288, 441, 286, 444],\n",
       " 185: [449, 451, 323, 453, 455],\n",
       " 186: [436, 223, 445, 444, 224],\n",
       " 187: [412, 403, 89, 91, 391],\n",
       " 188: [228, 217, 445, 444, 223],\n",
       " 190: [214, 182, 183, 184, 185],\n",
       " 191: [436, 445, 444, 223, 224],\n",
       " 193: [436, 288, 441, 286, 444],\n",
       " 195: [293, 418, 417, 412, 409],\n",
       " 196: [214, 182, 183, 184, 185],\n",
       " 197: [436, 288, 441, 286, 444],\n",
       " 198: [477, 344, 342, 465, 332],\n",
       " 199: [477, 182, 183, 436, 432],\n",
       " 200: [412, 89, 403, 91, 391],\n",
       " 201: [286, 418, 417, 412, 149],\n",
       " 202: [332, 444, 445, 330, 328],\n",
       " 203: [436, 288, 441, 286, 444],\n",
       " 204: [383, 162, 164, 422, 418],\n",
       " 205: [436, 288, 441, 286, 444],\n",
       " 206: [196, 160, 162, 286, 164],\n",
       " 207: [385, 422, 160, 162, 418],\n",
       " 209: [286, 418, 417, 412, 149],\n",
       " 210: [412, 89, 403, 91, 391],\n",
       " 211: [453, 558, 275, 266, 432],\n",
       " 212: [467, 324, 453, 323, 455],\n",
       " 213: [441, 451, 228, 449, 448],\n",
       " 214: [422, 441, 183, 436, 190],\n",
       " 215: [385, 160, 162, 422, 164],\n",
       " 216: [412, 89, 403, 91, 391],\n",
       " 217: [214, 182, 183, 184, 185],\n",
       " 218: [286, 418, 417, 412, 149],\n",
       " 219: [441, 449, 448, 445, 444],\n",
       " 220: [293, 288, 286, 441, 558],\n",
       " 221: [432, 159, 422, 160, 162],\n",
       " 222: [358, 453, 370, 455, 456],\n",
       " 223: [214, 182, 183, 184, 185],\n",
       " 224: [214, 182, 183, 184, 185],\n",
       " 225: [477, 162, 164, 167, 422],\n",
       " 226: [330, 441, 357, 444, 445],\n",
       " 227: [360, 449, 217, 451, 358],\n",
       " 228: [214, 182, 183, 184, 185],\n",
       " 229: [286, 418, 417, 412, 149],\n",
       " 230: [286, 418, 417, 412, 149],\n",
       " 232: [436, 288, 441, 286, 444],\n",
       " 233: [453, 432, 558, 275, 436],\n",
       " 234: [217, 328, 444, 441, 436],\n",
       " 235: [385, 288, 162, 164, 422],\n",
       " 236: [441, 449, 448, 445, 444],\n",
       " 237: [477, 441, 312, 436, 182],\n",
       " 238: [441, 451, 449, 448, 228],\n",
       " 239: [436, 288, 441, 286, 444],\n",
       " 240: [312, 445, 310, 293, 448],\n",
       " 241: [114, 449, 451, 453, 353],\n",
       " 243: [370, 417, 412, 409, 403],\n",
       " 244: [441, 449, 448, 224, 228],\n",
       " 246: [436, 288, 441, 286, 444],\n",
       " 247: [441, 448, 223, 224, 445],\n",
       " 248: [214, 182, 183, 184, 185],\n",
       " 249: [286, 418, 417, 412, 149],\n",
       " 250: [436, 441, 288, 286, 444],\n",
       " 252: [286, 418, 417, 412, 149],\n",
       " 253: [459, 318, 444, 445, 317],\n",
       " 254: [214, 182, 183, 184, 185],\n",
       " 255: [412, 89, 403, 91, 391],\n",
       " 256: [477, 160, 162, 164, 422],\n",
       " 258: [436, 288, 441, 286, 444],\n",
       " 259: [214, 182, 183, 184, 185],\n",
       " 260: [459, 353, 444, 445, 224],\n",
       " 261: [385, 160, 162, 422, 164],\n",
       " 262: [451, 453, 325, 455, 456],\n",
       " 263: [459, 444, 445, 293, 288],\n",
       " 264: [412, 89, 403, 91, 391],\n",
       " 265: [436, 288, 441, 286, 444],\n",
       " 266: [214, 182, 183, 184, 185],\n",
       " 267: [436, 448, 196, 445, 444],\n",
       " 268: [477, 441, 182, 436, 183],\n",
       " 269: [436, 288, 441, 286, 444],\n",
       " 270: [432, 444, 183, 190, 317],\n",
       " 271: [254, 286, 432, 558, 436],\n",
       " 272: [310, 453, 327, 455, 456],\n",
       " 273: [477, 445, 444, 196, 441],\n",
       " 274: [455, 275, 432, 436, 266],\n",
       " 275: [214, 182, 183, 184, 185],\n",
       " 276: [286, 418, 417, 412, 149],\n",
       " 277: [441, 449, 448, 223, 445],\n",
       " 278: [114, 409, 403, 89, 391],\n",
       " 279: [482, 293, 288, 441, 286],\n",
       " 280: [441, 228, 451, 449, 448],\n",
       " 281: [357, 465, 344, 467, 342],\n",
       " 282: [432, 436, 286, 441, 558],\n",
       " 283: [436, 288, 441, 286, 444],\n",
       " 284: [224, 445, 444, 441, 217],\n",
       " 285: [476, 344, 342, 332, 465],\n",
       " 286: [214, 182, 183, 184, 185],\n",
       " 287: [445, 254, 451, 259, 449],\n",
       " 288: [214, 182, 183, 184, 185],\n",
       " 289: [286, 418, 417, 412, 149],\n",
       " 290: [382, 160, 422, 162, 418],\n",
       " 291: [196, 445, 444, 441, 190],\n",
       " 292: [217, 449, 318, 451, 317],\n",
       " 293: [214, 182, 183, 184, 185],\n",
       " 294: [436, 288, 441, 286, 444],\n",
       " 296: [477, 183, 441, 190, 196],\n",
       " 297: [312, 445, 310, 448, 449],\n",
       " 298: [441, 449, 448, 224, 228],\n",
       " 300: [448, 324, 451, 323, 453],\n",
       " 301: [476, 344, 342, 332, 465],\n",
       " 303: [436, 288, 441, 286, 444],\n",
       " 304: [436, 288, 441, 286, 444],\n",
       " 305: [441, 449, 448, 224, 228],\n",
       " 306: [453, 558, 275, 432, 436],\n",
       " 307: [449, 451, 323, 453, 455],\n",
       " 308: [436, 288, 441, 286, 444],\n",
       " 309: [436, 288, 441, 286, 444],\n",
       " 310: [214, 182, 183, 184, 185],\n",
       " 311: [436, 288, 441, 286, 444],\n",
       " 312: [214, 182, 183, 184, 185],\n",
       " 313: [455, 310, 293, 441, 288],\n",
       " 314: [196, 445, 444, 441, 436],\n",
       " 315: [441, 451, 449, 448, 248],\n",
       " 316: [436, 288, 441, 286, 444],\n",
       " 317: [214, 182, 183, 184, 185],\n",
       " 318: [214, 182, 183, 184, 185],\n",
       " 322: [412, 403, 391, 390, 385],\n",
       " 323: [214, 182, 183, 184, 185],\n",
       " 324: [214, 182, 183, 184, 185],\n",
       " 325: [214, 182, 183, 184, 185],\n",
       " 326: [445, 254, 451, 259, 449],\n",
       " 327: [214, 182, 183, 184, 185],\n",
       " 328: [214, 182, 183, 184, 185],\n",
       " 330: [214, 182, 183, 184, 185],\n",
       " 331: [149, 448, 445, 444, 441],\n",
       " 332: [214, 182, 183, 184, 185],\n",
       " 333: [196, 445, 325, 190, 441],\n",
       " 334: [453, 286, 436, 558, 275],\n",
       " 335: [228, 448, 223, 445, 444],\n",
       " 336: [224, 217, 449, 448, 223],\n",
       " 337: [310, 293, 444, 445, 288],\n",
       " 338: [412, 89, 403, 91, 391],\n",
       " 339: [412, 89, 403, 91, 391],\n",
       " 341: [459, 248, 328, 465, 412],\n",
       " 342: [214, 182, 183, 184, 185],\n",
       " 343: [436, 288, 441, 286, 444],\n",
       " 344: [214, 182, 183, 184, 185],\n",
       " 345: [451, 558, 275, 422, 266],\n",
       " 346: [328, 327, 455, 456, 325],\n",
       " 347: [477, 436, 167, 432, 182],\n",
       " 348: [312, 445, 310, 448, 449],\n",
       " 349: [436, 288, 441, 286, 444],\n",
       " 350: [114, 358, 441, 357, 444],\n",
       " 351: [455, 558, 436, 275, 266],\n",
       " 352: [217, 310, 293, 444, 445],\n",
       " 353: [214, 182, 183, 184, 185],\n",
       " 354: [436, 223, 445, 444, 224],\n",
       " 355: [491, 448, 449, 160, 451],\n",
       " 356: [441, 449, 448, 445, 444],\n",
       " 357: [214, 182, 183, 184, 185],\n",
       " 358: [214, 182, 183, 184, 185],\n",
       " 359: [476, 459, 342, 332, 465],\n",
       " 360: [214, 182, 183, 184, 185],\n",
       " 361: [422, 412, 149, 409, 403],\n",
       " 362: [441, 449, 448, 224, 228],\n",
       " 363: [432, 436, 288, 286, 441],\n",
       " 364: [217, 444, 445, 310, 293],\n",
       " 365: [214, 182, 183, 184, 185],\n",
       " 367: [453, 558, 275, 432, 436],\n",
       " 368: [224, 448, 445, 444, 217],\n",
       " 369: [422, 445, 444, 441, 190],\n",
       " 370: [214, 182, 183, 184, 185],\n",
       " 371: [114, 409, 403, 89, 391],\n",
       " 372: [217, 444, 445, 310, 293],\n",
       " 373: [412, 89, 403, 91, 391],\n",
       " 375: [445, 453, 451, 254, 449],\n",
       " 376: [288, 286, 558, 275, 432],\n",
       " 377: [214, 182, 183, 184, 185],\n",
       " 378: [459, 318, 444, 445, 317],\n",
       " 380: [328, 327, 455, 456, 325],\n",
       " 381: [214, 182, 183, 184, 185],\n",
       " 382: [214, 182, 183, 184, 185],\n",
       " 383: [214, 182, 183, 184, 185],\n",
       " 384: [453, 455, 456, 328, 327],\n",
       " 385: [214, 182, 183, 184, 185],\n",
       " 386: [422, 286, 558, 432, 275],\n",
       " 387: [412, 89, 403, 91, 391],\n",
       " 388: [310, 293, 441, 444, 445],\n",
       " 389: [445, 254, 451, 259, 449],\n",
       " 390: [214, 182, 183, 184, 185],\n",
       " 391: [214, 182, 183, 184, 185],\n",
       " 393: [224, 448, 217, 445, 444],\n",
       " 396: [441, 449, 448, 224, 228],\n",
       " 398: [217, 448, 449, 317, 451],\n",
       " 399: [476, 344, 342, 332, 465],\n",
       " 401: [476, 223, 390, 217, 465],\n",
       " 402: [412, 403, 391, 390, 385],\n",
       " 403: [214, 182, 183, 184, 185],\n",
       " 405: [412, 403, 391, 390, 385],\n",
       " 408: [453, 328, 432, 327, 436],\n",
       " 409: [214, 182, 183, 184, 185],\n",
       " 410: [477, 190, 445, 444, 196],\n",
       " 411: [223, 445, 312, 310, 448],\n",
       " 412: [214, 182, 183, 184, 185],\n",
       " 413: [418, 409, 403, 391, 390],\n",
       " 414: [459, 441, 310, 293, 444],\n",
       " 415: [432, 445, 444, 190, 441],\n",
       " 416: [465, 318, 448, 449, 317],\n",
       " 417: [214, 182, 183, 184, 185],\n",
       " 418: [214, 182, 183, 184, 185],\n",
       " 419: [383, 432, 164, 167, 422],\n",
       " 420: [444, 318, 448, 449, 317],\n",
       " 421: [310, 182, 444, 445, 183],\n",
       " 422: [214, 182, 183, 184, 185],\n",
       " 423: [432, 444, 323, 441, 190],\n",
       " 424: [476, 344, 342, 332, 465],\n",
       " 425: [328, 327, 455, 456, 325],\n",
       " 426: [223, 445, 444, 441, 217],\n",
       " 427: [422, 448, 445, 444, 436],\n",
       " 428: [288, 558, 445, 444, 441],\n",
       " 430: [482, 436, 288, 286, 441],\n",
       " 431: [441, 228, 449, 448, 445],\n",
       " 432: [214, 182, 183, 184, 185],\n",
       " 434: [228, 449, 448, 223, 224],\n",
       " 435: [422, 417, 412, 409, 403],\n",
       " 436: [214, 182, 183, 184, 185],\n",
       " 437: [224, 217, 449, 448, 223],\n",
       " 438: [365, 114, 412, 409, 403],\n",
       " 440: [422, 417, 412, 409, 403],\n",
       " 441: [214, 182, 183, 184, 185],\n",
       " 442: [441, 451, 228, 449, 448],\n",
       " 443: [422, 417, 412, 409, 149],\n",
       " 444: [214, 182, 183, 184, 185],\n",
       " 445: [214, 182, 183, 184, 185],\n",
       " 446: [164, 441, 275, 436, 432],\n",
       " 447: [217, 323, 451, 318, 453],\n",
       " 448: [214, 182, 183, 184, 185],\n",
       " 449: [214, 182, 183, 184, 185],\n",
       " 450: [467, 449, 451, 323, 453],\n",
       " 451: [214, 182, 183, 184, 185],\n",
       " 452: [412, 403, 391, 390, 385],\n",
       " 453: [214, 182, 183, 184, 185],\n",
       " 454: [183, 182, 558, 465, 167],\n",
       " 455: [214, 182, 183, 184, 185],\n",
       " 456: [214, 182, 183, 184, 185],\n",
       " 457: [217, 432, 436, 288, 286],\n",
       " 458: [412, 403, 89, 91, 391],\n",
       " 459: [214, 182, 183, 184, 185],\n",
       " 460: [482, 436, 288, 286, 441],\n",
       " 462: [412, 403, 89, 91, 391],\n",
       " 464: [228, 217, 223, 445, 444],\n",
       " 465: [214, 182, 183, 184, 185],\n",
       " 466: [412, 403, 391, 390, 385],\n",
       " 467: [214, 182, 183, 184, 185],\n",
       " 468: [422, 558, 275, 432, 266],\n",
       " 469: [449, 422, 266, 259, 254],\n",
       " 470: [224, 217, 449, 448, 223],\n",
       " 471: [214, 182, 183, 184, 185],\n",
       " 474: [412, 167, 422, 418, 417],\n",
       " 475: [217, 441, 183, 190, 436],\n",
       " 476: [214, 182, 183, 184, 185],\n",
       " 477: [214, 182, 183, 184, 185],\n",
       " 478: [217, 445, 312, 448, 449],\n",
       " 479: [477, 164, 167, 436, 432],\n",
       " 480: [214, 182, 183, 184, 185],\n",
       " 481: [214, 182, 183, 184, 185],\n",
       " 482: [214, 182, 183, 184, 185],\n",
       " 483: [482, 436, 288, 286, 558],\n",
       " 484: [328, 327, 455, 456, 325],\n",
       " 486: [288, 448, 449, 318, 451],\n",
       " 487: [330, 456, 328, 327, 459],\n",
       " 488: [467, 449, 451, 323, 453],\n",
       " 489: [214, 182, 183, 184, 185],\n",
       " 490: [214, 182, 183, 184, 185],\n",
       " 491: [214, 182, 183, 184, 185],\n",
       " 492: [328, 327, 453, 325, 455],\n",
       " 493: [412, 403, 391, 390, 385],\n",
       " 495: [330, 456, 328, 327, 459],\n",
       " 496: [214, 182, 183, 184, 185],\n",
       " 497: [328, 327, 453, 325, 455],\n",
       " 498: [217, 318, 448, 449, 317],\n",
       " 499: [214, 182, 183, 184, 185],\n",
       " 500: [214, 182, 183, 184, 185],\n",
       " 501: [448, 324, 451, 323, 453],\n",
       " 502: [448, 324, 451, 323, 453],\n",
       " 503: [490, 228, 451, 370, 453],\n",
       " 504: [455, 436, 288, 286, 441],\n",
       " 505: [412, 403, 391, 390, 385],\n",
       " 506: [214, 182, 183, 184, 185],\n",
       " 508: [214, 182, 183, 184, 185],\n",
       " 509: [412, 403, 89, 91, 391],\n",
       " 510: [214, 182, 183, 184, 185],\n",
       " 511: [412, 403, 89, 91, 391],\n",
       " 513: [214, 182, 183, 184, 185],\n",
       " 514: [441, 451, 449, 448, 228],\n",
       " 515: [114, 409, 403, 89, 391],\n",
       " 516: [214, 182, 183, 184, 185],\n",
       " 517: [412, 403, 391, 390, 385],\n",
       " 518: [217, 444, 441, 190, 436],\n",
       " 520: [467, 449, 451, 323, 453],\n",
       " 521: [217, 448, 449, 318, 451],\n",
       " 522: [214, 182, 183, 184, 185],\n",
       " 523: [214, 182, 183, 184, 185],\n",
       " 524: [214, 182, 183, 184, 185],\n",
       " 525: [214, 182, 183, 184, 185],\n",
       " 526: [214, 182, 183, 184, 185],\n",
       " 527: [214, 182, 183, 184, 185],\n",
       " 528: [214, 182, 183, 184, 185],\n",
       " 529: [214, 182, 183, 184, 185],\n",
       " 531: [328, 327, 453, 325, 455],\n",
       " 532: [214, 182, 183, 184, 185],\n",
       " 533: [214, 182, 183, 184, 185],\n",
       " 534: [223, 312, 310, 444, 445],\n",
       " 535: [422, 444, 441, 436, 432],\n",
       " 536: [214, 182, 183, 184, 185],\n",
       " 537: [214, 182, 183, 184, 185],\n",
       " 538: [214, 182, 183, 184, 185],\n",
       " 539: [214, 182, 183, 184, 185],\n",
       " 540: [214, 182, 183, 184, 185],\n",
       " 541: [214, 182, 183, 184, 185],\n",
       " 542: [453, 455, 456, 327, 325],\n",
       " 543: [471, 91, 182, 459, 89],\n",
       " 544: [214, 182, 183, 184, 185],\n",
       " 545: [214, 182, 183, 184, 185],\n",
       " 546: [214, 182, 183, 184, 185],\n",
       " 547: [214, 182, 183, 184, 185],\n",
       " 550: [214, 182, 183, 184, 185],\n",
       " 551: [214, 182, 183, 184, 185],\n",
       " 552: [259, 436, 441, 444, 445],\n",
       " 554: [412, 89, 403, 91, 391],\n",
       " 555: [491, 456, 370, 91, 459],\n",
       " 556: [330, 456, 328, 327, 459],\n",
       " 557: [214, 182, 183, 184, 185],\n",
       " 558: [214, 182, 183, 184, 185],\n",
       " 559: [214, 182, 183, 184, 185]}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def item_neighborhood_selection(similarity_matrix, k=None, threshold=None):\n",
    "    \"\"\"\n",
    "    Select a subset of similar items for each item based on similarity matrix.\n",
    "\n",
    "    Parameters:\n",
    "        similarity_matrix (numpy.ndarray): Item-item similarity matrix.\n",
    "        k (int): Number of similar items to select (optional).\n",
    "        threshold (float): Similarity threshold for selecting similar items (optional).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing similar items for each item.\n",
    "    \"\"\"\n",
    "    num_items = similarity_matrix.shape[0]\n",
    "    item_neighborhood = {}\n",
    "\n",
    "    for i in range(num_items):\n",
    "        if k is not None:\n",
    "            # Select top-k similar items (excluding the item itself)\n",
    "            similar_items_indices = np.argsort(similarity_matrix[i])[::-1][:k+1]\n",
    "        elif threshold is not None:\n",
    "            # Select items with similarity above threshold (excluding the item itself)\n",
    "            similar_items_indices = np.where(similarity_matrix[i] > threshold)[0]\n",
    "\n",
    "        # Remove the item itself from the neighborhood\n",
    "        similar_items_indices = similar_items_indices[similar_items_indices != i]\n",
    "\n",
    "        item_neighborhood[i] = similar_items_indices\n",
    "\n",
    "    return item_neighborhood\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have an item-item similarity matrix 'item_similarity_matrix_train'\n",
    "# and you want to select top-5 similar items for each item\n",
    "k = 5\n",
    "item_neighborhood = item_neighborhood_selection(item_similarity_matrix_train, k=k)\n",
    "\n",
    "item_neighborhoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity_matrix_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Class Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([486, 311, 403, 298, 405, 296], dtype=int64), 1: array([486, 276, 391, 154, 393, 153], dtype=int64), 2: array([486, 365, 360, 126, 355, 352], dtype=int64), 3: array([486, 212, 138, 140, 377, 143], dtype=int64), 4: array([486, 381, 388, 190, 191, 385], dtype=int64), 5: array([486, 140, 360, 355, 352, 349], dtype=int64), 6: array([486, 311, 298, 403, 296, 405], dtype=int64), 7: array([486, 413, 384, 153, 381, 154], dtype=int64), 8: array([486, 126, 361, 360, 135, 355], dtype=int64), 9: array([486, 217, 393, 195, 391, 212], dtype=int64), 10: array([486, 377, 381, 298, 296, 384], dtype=int64), 11: array([486, 418, 269, 381, 255, 384], dtype=int64), 12: array([486, 355, 280, 393, 279, 395], dtype=int64), 13: array([486, 365, 360, 355, 352, 349], dtype=int64), 14: array([486, 248, 391, 279, 393, 277], dtype=int64), 15: array([486, 377, 135, 136, 138, 140], dtype=int64), 16: array([486, 413, 384, 153, 381, 154], dtype=int64), 17: array([486, 355,  75, 349,  77, 342], dtype=int64), 18: array([486, 377, 388, 385, 384, 190], dtype=int64), 19: array([486, 485, 360, 355, 352, 349], dtype=int64), 20: array([486, 413, 136, 138, 140, 365], dtype=int64), 21: array([486, 181, 153, 154, 155, 156], dtype=int64), 22: array([486, 248, 361, 360, 355, 126], dtype=int64), 23: array([486, 377, 388, 385, 384, 184], dtype=int64), 24: array([486, 276, 399, 287, 285, 284], dtype=int64), 25: array([486, 164, 381, 153, 154, 377], dtype=int64), 26: array([486, 365, 381, 377, 374, 153], dtype=int64), 27: array([486, 405, 280, 393, 279, 395], dtype=int64), 28: array([486, 255, 395, 396, 283, 281], dtype=int64), 29: array([486, 381, 389, 388, 184, 385], dtype=int64), 30: array([486, 412, 296, 287, 285, 403], dtype=int64), 31: array([486, 374, 385, 384, 164, 381], dtype=int64), 32: array([486, 217, 393, 195, 391, 212], dtype=int64), 33: array([486, 412, 296, 287, 285, 403], dtype=int64), 34: array([486, 361, 355,  97, 352, 349], dtype=int64), 35: array([486, 136, 153, 388, 389, 391], dtype=int64), 36: array([486, 395, 285, 284, 399, 283], dtype=int64), 37: array([486, 413, 381, 377, 143, 374], dtype=int64), 38: array([486, 384, 393, 391, 389, 388], dtype=int64), 39: array([486, 184, 381, 154, 377, 160], dtype=int64), 40: array([486, 248, 361, 360, 355, 126], dtype=int64), 41: array([486, 284, 283, 393, 281, 395], dtype=int64), 42: array([486, 393, 395, 396, 283, 281], dtype=int64), 43: array([486, 190, 191, 393, 323, 395], dtype=int64), 44: array([486, 191, 164, 385, 384, 381], dtype=int64), 45: array([486, 413, 377, 153, 374, 154], dtype=int64), 46: array([486, 384, 190, 389, 388, 191], dtype=int64), 47: array([486, 413, 388, 160, 385, 384], dtype=int64), 48: array([486, 184, 385, 384, 160, 164], dtype=int64), 49: array([486, 190, 164, 385, 384, 184], dtype=int64), 50: array([486, 413, 298, 296, 403, 287], dtype=int64), 51: array([486, 377, 250, 381, 248, 384], dtype=int64), 52: array([486, 413, 384, 153, 381, 154], dtype=int64), 53: array([486, 377, 388, 164, 385, 384], dtype=int64), 54: array([486, 389, 395, 217, 393, 221], dtype=int64), 55: array([486, 184, 385, 384, 160, 381], dtype=int64), 56: array([486, 377, 250, 381, 248, 384], dtype=int64), 57: array([486, 195, 388, 184, 190, 385], dtype=int64), 58: array([486, 391, 221, 396, 395, 228], dtype=int64), 59: array([486, 412, 298, 296, 287, 403], dtype=int64), 60: array([486, 413, 298, 296, 403, 287], dtype=int64), 61: array([486, 374, 160, 385, 384, 164], dtype=int64), 62: array([486, 221, 255, 384, 385, 250], dtype=int64), 63: array([486, 413, 153, 154, 381, 160], dtype=int64), 64: array([486, 285, 396, 284, 283, 399], dtype=int64), 65: array([486, 153, 360, 355, 352, 126], dtype=int64), 66: array([486, 396, 381, 285, 384, 385], dtype=int64), 67: array([486, 413, 381, 154, 377, 374], dtype=int64), 68: array([486, 377, 250, 381, 248, 384], dtype=int64), 69: array([486, 374, 385, 384, 164, 381], dtype=int64), 70: array([486, 190, 384, 154, 160, 381], dtype=int64), 71: array([486, 413, 385, 384, 164, 381], dtype=int64), 72: array([486, 381, 389, 388, 385, 384], dtype=int64), 73: array([486, 413, 385, 384, 160, 381], dtype=int64), 74: array([486, 426, 395, 396, 399, 143], dtype=int64), 75: array([486, 181, 153, 154, 155, 156], dtype=int64), 76: array([486, 184, 160, 385, 384, 164], dtype=int64), 77: array([486, 181, 153, 154, 155, 156], dtype=int64), 78: array([486, 413, 160, 385, 384, 164], dtype=int64), 79: array([486, 184, 269, 255, 384, 385], dtype=int64), 80: array([486, 365, 126, 355, 352, 349], dtype=int64), 81: array([486, 385, 271, 388, 389, 269], dtype=int64), 82: array([486, 212, 391, 195, 389, 388], dtype=int64), 83: array([486, 191, 388, 385, 384, 184], dtype=int64), 84: array([486, 184, 276, 388, 389, 271], dtype=int64), 85: array([486, 381, 388, 184, 190, 385], dtype=int64), 86: array([486, 374, 248, 377, 485, 237], dtype=int64), 87: array([486, 374, 385, 384, 164, 381], dtype=int64), 88: array([486, 276, 399, 287, 285, 284], dtype=int64), 89: array([486, 399, 381, 126, 311, 384], dtype=int64), 90: array([486, 349, 276, 388, 389, 391], dtype=int64), 91: array([486, 126, 135, 136, 138, 140], dtype=int64), 92: array([486, 237, 393, 485, 395, 396], dtype=int64), 93: array([486, 355,  75, 349,  77, 342], dtype=int64), 94: array([486, 413, 143, 377, 153, 374], dtype=int64), 95: array([486, 413, 138, 140, 365, 143], dtype=int64), 96: array([486, 355,  75, 349,  77, 342], dtype=int64), 97: array([486, 181, 153, 154, 155, 156], dtype=int64), 98: array([486,  97, 143, 381, 153, 154], dtype=int64), 99: array([486, 399, 384, 385, 255, 250], dtype=int64), 100: array([486, 271, 385, 298, 388, 389], dtype=int64), 101: array([486, 361, 377, 217, 374, 250], dtype=int64), 102: array([486, 195, 377, 143, 374, 153], dtype=int64), 103: array([486, 377, 250, 381, 248, 384], dtype=int64), 104: array([486, 413, 381, 153, 269, 377], dtype=int64), 105: array([486, 399, 384, 385, 255, 388], dtype=int64), 106: array([486, 355,  75, 349,  77, 342], dtype=int64), 107: array([486, 413, 143, 381, 153, 154], dtype=int64), 108: array([486, 184, 391, 279, 393, 277], dtype=int64), 109: array([486, 374, 384, 154, 381, 160], dtype=int64), 110: array([486, 413, 384, 154, 381, 160], dtype=int64), 111: array([486, 307, 323, 399,  75, 319], dtype=int64), 112: array([486, 385, 217, 391, 221, 389], dtype=int64), 113: array([486, 413, 138, 140, 374, 143], dtype=int64), 114: array([486, 126, 135, 136, 361, 360], dtype=int64), 115: array([486, 221, 140, 143, 381, 153], dtype=int64), 116: array([486, 190, 389, 388, 184, 385], dtype=int64), 117: array([486, 184, 388, 389, 276, 391], dtype=int64), 118: array([486, 336, 365, 136, 138, 140], dtype=int64), 119: array([486, 143, 138, 403, 341, 405], dtype=int64), 120: array([486, 395, 285, 284, 399, 283], dtype=int64), 121: array([486, 381, 389, 388, 191, 195], dtype=int64), 122: array([486, 355,  75, 349,  77, 342], dtype=int64), 123: array([486, 485, 360, 355, 126, 352], dtype=int64), 124: array([486, 248, 361, 360, 355, 126], dtype=int64), 125: array([486, 413, 135, 136, 138, 361], dtype=int64), 126: array([486, 181, 153, 154, 155, 156], dtype=int64), 127: array([486, 269, 381, 250, 384, 385], dtype=int64), 128: array([486, 143, 360, 355, 352, 349], dtype=int64), 129: array([486, 377, 385, 384, 160, 164], dtype=int64), 130: array([486, 377, 250, 381, 248, 384], dtype=int64), 131: array([486, 255, 250, 248, 381, 485], dtype=int64), 132: array([486, 217, 393, 195, 391, 212], dtype=int64), 133: array([486, 413, 138, 374, 140, 143], dtype=int64), 134: array([486, 413, 384, 153, 381, 154], dtype=int64), 135: array([486, 181, 153, 154, 155, 156], dtype=int64), 136: array([486, 181, 153, 154, 155, 156], dtype=int64), 137: array([486, 377, 250, 381, 248, 384], dtype=int64), 138: array([486, 181, 153, 154, 155, 156], dtype=int64), 139: array([486, 399, 341, 228, 403, 237], dtype=int64), 140: array([486, 181, 153, 154, 155, 156], dtype=int64), 141: array([486, 334, 138, 365, 140, 361], dtype=int64), 142: array([486, 217, 393, 195, 391, 212], dtype=int64), 143: array([486, 181, 153, 154, 155, 156], dtype=int64), 144: array([486, 485, 360, 355, 126, 352], dtype=int64), 145: array([486, 413, 384, 153, 381, 154], dtype=int64), 146: array([486, 385, 217, 391, 221, 389], dtype=int64), 147: array([486, 377, 250, 248, 381, 485], dtype=int64), 148: array([486, 381, 389, 388, 385, 384], dtype=int64), 149: array([486, 377, 250, 381, 248, 384], dtype=int64), 150: array([486, 395, 377, 485, 237, 381], dtype=int64), 151: array([486, 381, 391, 389, 388, 195], dtype=int64), 152: array([486, 395, 377, 248, 485, 381], dtype=int64), 153: array([486, 181, 154, 155, 156], dtype=int64), 154: array([486, 181, 153, 155, 156], dtype=int64), 155: array([486, 377, 250, 381, 248, 384], dtype=int64), 156: array([486, 389, 391, 279, 393, 395], dtype=int64), 157: array([486, 377, 190, 385, 384, 191], dtype=int64), 158: array([486, 355, 349,  75,  77, 342], dtype=int64), 159: array([486, 195, 184, 385, 384, 190], dtype=int64), 160: array([486, 181, 153, 154, 155, 156], dtype=int64), 161: array([486, 377, 385, 384, 190, 191], dtype=int64), 162: array([486, 377, 250, 381, 248, 384], dtype=int64), 163: array([486, 255, 361, 360, 355, 352], dtype=int64), 164: array([486, 181, 153, 154, 155, 156], dtype=int64), 165: array([486, 377, 250, 381, 248, 384], dtype=int64), 166: array([486, 413, 298, 296, 403, 287], dtype=int64), 167: array([486, 413, 153, 154, 377, 374], dtype=int64), 168: array([486, 355,  75, 349,  77, 342], dtype=int64), 169: array([486, 248, 361, 360, 355, 126], dtype=int64), 170: array([486, 287, 384, 385, 285, 284], dtype=int64), 171: array([486, 377, 250, 381, 248, 384], dtype=int64), 172: array([486, 334, 138, 140, 365, 361], dtype=int64), 173: array([486, 377, 250, 381, 248, 384], dtype=int64), 174: array([486, 164, 136, 138, 248, 140], dtype=int64), 175: array([486, 336, 365, 136, 138, 361], dtype=int64), 176: array([486, 248, 361, 360, 355, 126], dtype=int64), 177: array([486, 355,  75, 349,  77, 342], dtype=int64), 178: array([486, 393, 485, 237, 228, 374], dtype=int64), 179: array([486, 405, 280, 393, 279, 395], dtype=int64), 180: array([486, 381, 391, 195, 389, 388], dtype=int64), 181: array([486, 365, 381, 154, 377, 160], dtype=int64), 182: array([486, 336, 136, 138, 365, 140], dtype=int64), 183: array([486, 355,  75, 349,  77, 342], dtype=int64), 184: array([486, 181, 153, 154, 155, 156], dtype=int64), 185: array([486, 248, 361, 360, 355, 126], dtype=int64), 186: array([486, 381, 389, 388, 385, 384], dtype=int64), 187: array([486, 255, 250, 248, 381, 485], dtype=int64), 188: array([486, 374, 135, 365, 136, 138], dtype=int64), 189: array([486, 312, 393, 323, 395, 396], dtype=int64), 190: array([486, 181, 153, 154, 155, 156], dtype=int64), 191: array([486, 181, 153, 154, 155, 156], dtype=int64), 192: array([486, 413, 138, 140, 143, 365], dtype=int64), 193: array([486, 285, 381, 311, 384, 385], dtype=int64), 194: array([486, 314, 389, 184, 391, 312], dtype=int64), 195: array([486, 181, 153, 154, 155, 156], dtype=int64), 196: array([486, 248, 361, 360, 355, 126], dtype=int64), 197: array([486, 248, 361, 360, 355, 126], dtype=int64), 198: array([486, 377, 250, 381, 248, 384], dtype=int64), 199: array([486, 393, 374, 485, 237, 377], dtype=int64), 200: array([486, 184, 284, 384, 381, 377], dtype=int64), 201: array([486, 336, 250, 138, 140, 365], dtype=int64), 202: array([486, 381, 389, 388, 385, 384], dtype=int64), 203: array([486, 413, 381, 271, 377, 153], dtype=int64), 204: array([486, 381, 391, 389, 388, 195], dtype=int64), 205: array([486, 377, 250, 381, 248, 384], dtype=int64), 206: array([486, 271, 385, 269, 255, 388], dtype=int64), 207: array([486,  97, 389, 391, 393, 307], dtype=int64), 208: array([486, 323, 360, 355, 352, 349], dtype=int64), 209: array([486, 381, 389, 388, 191, 195], dtype=int64), 210: array([486, 377, 250, 381, 248, 384], dtype=int64), 211: array([486, 381, 388, 190, 191, 385], dtype=int64), 212: array([486, 181, 153, 154, 155, 156], dtype=int64), 213: array([486, 248, 361, 360, 355, 126], dtype=int64), 214: array([486, 377, 381, 250, 248, 384], dtype=int64), 215: array([486, 248, 361, 360, 355, 126], dtype=int64), 216: array([486, 399, 277, 384, 385, 276], dtype=int64), 217: array([486, 181, 153, 154, 155, 156], dtype=int64), 218: array([486, 355,  75, 349,  77, 342], dtype=int64), 219: array([486, 413, 136, 138, 140, 365], dtype=int64), 220: array([486, 377, 250, 381, 248, 384], dtype=int64), 221: array([486, 181, 153, 154, 155, 156], dtype=int64), 222: array([486, 399, 307, 384, 385, 191], dtype=int64), 223: array([486, 336, 136, 138, 365, 140], dtype=int64), 224: array([486, 391, 393, 281, 395, 396], dtype=int64), 225: array([486, 399, 384, 385, 255, 250], dtype=int64), 226: array([486, 355,  75, 349,  77, 342], dtype=int64), 227: array([486, 377, 250, 381, 248, 384], dtype=int64), 228: array([486, 181, 153, 154, 155, 156], dtype=int64), 229: array([486, 377, 388, 164, 385, 384], dtype=int64), 230: array([486, 413, 381, 153, 377, 154], dtype=int64), 231: array([486, 377, 250, 381, 248, 384], dtype=int64), 232: array([486, 374, 384, 154, 160, 276], dtype=int64), 233: array([486, 217, 248, 374, 485, 377], dtype=int64), 234: array([486, 269, 393, 283, 395, 396], dtype=int64), 235: array([486, 413, 385, 384, 164, 381], dtype=int64), 236: array([486, 395, 237, 374, 377, 228], dtype=int64), 237: array([486, 181, 153, 154, 155, 156], dtype=int64), 238: array([486, 248, 361, 360, 355, 126], dtype=int64), 239: array([486, 381, 389, 388, 190, 385], dtype=int64), 240: array([486,  97, 352, 349,  75, 342], dtype=int64), 241: array([486, 418, 255, 250, 381, 248], dtype=int64), 242: array([486, 381, 195, 391, 389, 388], dtype=int64), 243: array([486, 311, 403, 298, 405, 296], dtype=int64), 244: array([486, 374, 377, 248, 381, 485], dtype=int64), 245: array([486, 377, 250, 381, 248, 384], dtype=int64), 246: array([486, 191, 385, 384, 381, 184], dtype=int64), 247: array([486, 412, 298, 296, 287, 403], dtype=int64), 248: array([486, 181, 153, 154, 155, 156], dtype=int64), 249: array([486, 385, 217, 391, 221, 389], dtype=int64), 250: array([486, 181, 153, 154, 155, 156], dtype=int64), 251: array([486, 248, 361, 360, 355, 126], dtype=int64), 252: array([486, 333, 136, 365, 138, 361], dtype=int64), 253: array([486, 164, 385, 384, 381, 160], dtype=int64), 254: array([486, 184, 389, 277, 391, 276], dtype=int64), 255: array([486, 181, 153, 154, 155, 156], dtype=int64), 256: array([486, 377, 250, 381, 248, 384], dtype=int64), 257: array([486, 413, 154, 381, 160, 164], dtype=int64), 258: array([486, 271, 385, 269, 388, 389], dtype=int64), 259: array([486, 381, 389, 388, 191, 195], dtype=int64), 260: array([486, 388, 280, 391, 279, 393], dtype=int64), 261: array([486, 412, 298, 296, 287, 403], dtype=int64), 262: array([486, 377, 250, 381, 248, 384], dtype=int64), 263: array([486, 377, 250, 381, 248, 384], dtype=int64), 264: array([486, 381, 389, 388, 191, 195], dtype=int64), 265: array([486, 393, 485, 237, 374, 377], dtype=int64), 266: array([486, 389, 391, 279, 393, 395], dtype=int64), 267: array([486, 377, 250, 381, 248, 384], dtype=int64), 268: array([486, 377, 250, 381, 248, 384], dtype=int64), 269: array([486, 181, 153, 154, 155, 156], dtype=int64), 270: array([486, 377, 250, 381, 248, 384], dtype=int64), 271: array([486, 181, 153, 154, 155, 156], dtype=int64), 272: array([486, 395, 269, 255, 381, 250], dtype=int64), 273: array([486, 164, 385, 384, 381, 377], dtype=int64), 274: array([486, 381, 391, 389, 388, 212], dtype=int64), 275: array([486, 377, 250, 381, 248, 384], dtype=int64), 276: array([486, 181, 153, 154, 155, 156], dtype=int64), 277: array([486, 181, 153, 154, 155, 156], dtype=int64), 278: array([486, 355, 349, 342, 341, 336], dtype=int64), 279: array([486, 181, 153, 154, 155, 156], dtype=int64), 280: array([486, 181, 153, 154, 155, 156], dtype=int64), 281: array([486, 181, 153, 154, 155, 156], dtype=int64), 282: array([486, 385, 217, 391, 221, 389], dtype=int64), 283: array([486, 181, 153, 154, 155, 156], dtype=int64), 284: array([486, 181, 153, 154, 155, 156], dtype=int64), 285: array([486, 181, 153, 154, 155, 156], dtype=int64), 286: array([486, 126, 388, 385, 384, 381], dtype=int64), 287: array([486, 181, 153, 154, 155, 156], dtype=int64), 288: array([486, 164, 385, 281, 160, 381], dtype=int64), 289: array([486, 393, 248, 377, 485, 237], dtype=int64), 290: array([486, 195, 388, 190, 385, 384], dtype=int64), 291: array([486, 191, 184, 389, 388, 190], dtype=int64), 292: array([486, 269, 255, 384, 385, 250], dtype=int64), 293: array([486, 355,  75, 349,  77, 342], dtype=int64), 294: array([486, 355,  75, 349,  77, 342], dtype=int64), 295: array([486, 399, 212, 284, 403, 355], dtype=int64), 296: array([486, 181, 153, 154, 155, 156], dtype=int64), 297: array([486, 377, 250, 381, 248, 384], dtype=int64), 298: array([486, 181, 153, 154, 155, 156], dtype=int64), 299: array([486, 391, 485, 237, 365, 228], dtype=int64), 300: array([486, 284, 283, 395, 396, 281], dtype=int64), 301: array([486, 413, 377, 143, 374, 153], dtype=int64), 302: array([486, 271, 385, 269, 388, 389], dtype=int64), 303: array([486, 377, 250, 381, 248, 384], dtype=int64), 304: array([486,  97, 312, 381, 311, 384], dtype=int64), 305: array([486, 395, 485, 377, 237, 228], dtype=int64), 306: array([486, 184, 269, 255, 384, 385], dtype=int64), 307: array([486, 181, 153, 154, 155, 156], dtype=int64), 308: array([486, 377, 190, 385, 384, 191], dtype=int64), 309: array([486, 426, 388, 389, 136, 391], dtype=int64), 310: array([486, 381, 389, 388, 385, 384], dtype=int64), 311: array([486, 181, 153, 154, 155, 156], dtype=int64), 312: array([486, 181, 153, 154, 155, 156], dtype=int64), 313: array([486, 412, 399, 296, 287, 403], dtype=int64), 314: array([486, 181, 153, 154, 155, 156], dtype=int64), 315: array([486, 365, 355, 126, 352, 349], dtype=int64), 316: array([486, 381, 389, 388, 191, 195], dtype=int64), 317: array([486, 374, 377, 250, 248, 381], dtype=int64), 318: array([486, 184, 384, 385, 269, 255], dtype=int64), 319: array([486, 181, 153, 154, 155, 156], dtype=int64), 320: array([486, 393, 485, 237, 374, 377], dtype=int64), 321: array([486, 191, 388, 385, 384, 184], dtype=int64), 322: array([486, 365, 385, 384, 381, 160], dtype=int64), 323: array([486, 181, 153, 154, 155, 156], dtype=int64), 324: array([486,  97, 352, 349,  75, 342], dtype=int64), 325: array([486, 184, 384, 385, 269, 255], dtype=int64), 326: array([486, 355,  75, 349,  77, 342], dtype=int64), 327: array([486, 385, 393, 391, 217, 389], dtype=int64), 328: array([486, 250, 248, 485, 237, 374], dtype=int64), 329: array([486, 181, 153, 154, 155, 156], dtype=int64), 330: array([486, 399, 277, 384, 385, 276], dtype=int64), 331: array([486, 284, 283, 395, 396, 281], dtype=int64), 332: array([486, 181, 153, 154, 155, 156], dtype=int64), 333: array([486, 181, 153, 154, 155, 156], dtype=int64), 334: array([486, 181, 153, 154, 155, 156], dtype=int64), 335: array([486, 393, 395, 396, 284, 283], dtype=int64), 336: array([486, 181, 153, 154, 155, 156], dtype=int64), 337: array([486, 365, 248, 485, 374, 237], dtype=int64), 338: array([486, 355,  75, 349,  77, 342], dtype=int64), 339: array([486, 269, 255, 381, 384, 385], dtype=int64), 340: array([486, 385, 217, 391, 221, 389], dtype=int64), 341: array([486, 181, 153, 154, 155, 156], dtype=int64), 342: array([486, 181, 153, 154, 155, 156], dtype=int64), 343: array([486, 191, 388, 184, 385, 384], dtype=int64), 344: array([486, 381, 389, 388, 191, 195], dtype=int64), 345: array([486, 184, 388, 389, 276, 391], dtype=int64), 346: array([486, 412, 298, 296, 287, 403], dtype=int64), 347: array([486, 412, 190, 341, 184, 403], dtype=int64), 348: array([486, 355, 349, 342, 341, 336], dtype=int64), 349: array([486, 181, 153, 154, 155, 156], dtype=int64), 350: array([486, 355, 349, 342, 341, 336], dtype=int64), 351: array([486, 393, 284, 374, 283, 377], dtype=int64), 352: array([486, 181, 153, 154, 155, 156], dtype=int64), 353: array([486, 413, 160, 385, 384, 164], dtype=int64), 354: array([486, 190, 385, 271, 269, 388], dtype=int64), 355: array([486, 181, 153, 154, 155, 156], dtype=int64), 356: array([486, 361, 352, 349, 342, 341], dtype=int64), 357: array([486, 399, 381, 269, 255, 384], dtype=int64), 358: array([486, 374, 385, 384, 160, 381], dtype=int64), 359: array([486, 403, 277, 388, 389, 276], dtype=int64), 360: array([486, 181, 153, 154, 155, 156], dtype=int64), 361: array([486, 181, 153, 154, 155, 156], dtype=int64), 362: array([486, 334, 374, 140, 143, 365], dtype=int64), 363: array([486, 384, 277, 388, 389, 276], dtype=int64), 364: array([486, 269, 153, 384, 385, 154], dtype=int64), 365: array([486, 181, 153, 154, 155, 156], dtype=int64), 366: array([486, 374, 384, 279, 381, 160], dtype=int64), 367: array([486, 412, 298, 296, 287, 403], dtype=int64), 368: array([486, 284, 283, 395, 396, 281], dtype=int64), 369: array([486, 190, 385, 384, 381, 184], dtype=int64), 370: array([486, 365, 388, 385, 384, 377], dtype=int64), 371: array([486, 250, 485, 385, 384, 381], dtype=int64), 372: array([486, 418, 377, 250, 248, 381], dtype=int64), 373: array([486, 381, 195, 389, 388, 385], dtype=int64), 374: array([486, 181, 153, 154, 155, 156], dtype=int64), 375: array([486, 195, 389, 388, 190, 191], dtype=int64), 376: array([486, 365, 360, 355, 352, 349], dtype=int64), 377: array([486, 181, 153, 154, 155, 156], dtype=int64), 378: array([486, 191, 184, 389, 388, 190], dtype=int64), 379: array([486, 319,  97, 355, 352, 349], dtype=int64), 380: array([486, 365, 360, 355, 352, 349], dtype=int64), 381: array([486, 181, 153, 154, 155, 156], dtype=int64), 382: array([486, 381, 391, 195, 389, 388], dtype=int64), 383: array([486, 365, 360, 355, 352, 126], dtype=int64), 384: array([486, 181, 153, 154, 155, 156], dtype=int64), 385: array([486, 181, 153, 154, 155, 156], dtype=int64), 386: array([486, 140, 381, 237, 377, 374], dtype=int64), 387: array([486, 184, 279, 391, 277, 393], dtype=int64), 388: array([486, 181, 153, 154, 155, 156], dtype=int64), 389: array([486, 181, 153, 154, 155, 156], dtype=int64), 390: array([486, 405, 389, 391, 279, 393], dtype=int64), 391: array([486, 181, 153, 154, 155, 156], dtype=int64), 392: array([486, 355, 349, 342, 341, 336], dtype=int64), 393: array([486, 181, 153, 154, 155, 156], dtype=int64), 394: array([486, 154, 153, 485, 403, 143], dtype=int64), 395: array([486, 181, 153, 154, 155, 156], dtype=int64), 396: array([486, 181, 153, 154, 155, 156], dtype=int64), 397: array([486, 184, 374, 377, 250, 248], dtype=int64), 398: array([486, 355, 349,  75,  77, 342], dtype=int64), 399: array([486, 181, 153, 154, 155, 156], dtype=int64), 400: array([486, 418, 377, 250, 248, 381], dtype=int64), 401: array([486, 355, 349,  75,  77, 342], dtype=int64), 402: array([486, 195, 184, 190, 385, 384], dtype=int64), 403: array([486, 181, 153, 154, 155, 156], dtype=int64), 404: array([486, 355, 349, 342, 341, 336], dtype=int64), 405: array([486, 181, 153, 154, 155, 156], dtype=int64), 406: array([486, 365, 485, 237, 374, 228], dtype=int64), 407: array([486, 389, 365, 228, 221, 217], dtype=int64), 408: array([486, 191, 184, 389, 388, 190], dtype=int64), 409: array([486, 181, 153, 154, 155, 156], dtype=int64), 410: array([486, 355, 143, 365, 361, 360], dtype=int64), 411: array([486, 184, 381, 154, 160, 377], dtype=int64), 412: array([486, 181, 153, 154, 155, 156], dtype=int64), 413: array([486, 181, 153, 154, 155, 156], dtype=int64), 414: array([486, 184, 385, 271, 388, 389], dtype=int64), 415: array([486, 413, 140, 143, 377, 374], dtype=int64), 416: array([486, 181, 153, 154, 155, 156], dtype=int64), 417: array([486, 181, 153, 154, 155, 156], dtype=int64), 418: array([486, 181, 153, 154, 155, 156], dtype=int64), 419: array([486, 418, 377, 250, 248, 485], dtype=int64), 420: array([486, 284, 283, 395, 396, 281], dtype=int64), 421: array([486, 250, 388, 389, 277, 391], dtype=int64), 422: array([486, 285, 396, 284, 283, 399], dtype=int64), 423: array([486, 405, 389, 391, 279, 393], dtype=int64), 424: array([486, 181, 153, 154, 155, 156], dtype=int64), 425: array([486, 181, 153, 154, 155, 156], dtype=int64), 426: array([486, 181, 153, 154, 155, 156], dtype=int64), 427: array([486, 284, 283, 393, 281, 395], dtype=int64), 428: array([486, 355, 349, 342, 341, 336], dtype=int64), 429: array([486, 285, 396, 284, 283, 399], dtype=int64), 430: array([486, 181, 153, 154, 155, 156], dtype=int64), 431: array([486, 284, 283, 393, 281, 395], dtype=int64), 432: array([486, 184, 277, 388, 389, 276], dtype=int64), 433: array([486, 181, 153, 154, 155, 156], dtype=int64), 434: array([486, 181, 153, 154, 155, 156], dtype=int64), 435: array([486, 388, 280, 391, 279, 393], dtype=int64), 436: array([486, 388, 280, 391, 279, 393], dtype=int64), 437: array([486, 425, 195, 391, 323, 393], dtype=int64), 438: array([486, 395, 377, 250, 248, 381], dtype=int64), 439: array([486, 355, 349, 342, 341, 336], dtype=int64), 440: array([486, 181, 153, 154, 155, 156], dtype=int64), 441: array([486, 181, 153, 154, 155, 156], dtype=int64), 442: array([486, 355, 349,  75,  77, 342], dtype=int64), 443: array([486, 181, 153, 154, 155, 156], dtype=int64), 444: array([486, 355, 349,  75,  77, 342], dtype=int64), 445: array([486, 181, 153, 154, 155, 156], dtype=int64), 446: array([486, 381, 391, 389, 388, 195], dtype=int64), 447: array([486,  97, 352, 349,  75, 342], dtype=int64), 448: array([486, 181, 153, 154, 155, 156], dtype=int64), 449: array([486, 355, 349, 342, 341, 336], dtype=int64), 450: array([486, 184, 384, 381, 160, 377], dtype=int64), 451: array([486, 405, 389, 391, 279, 393], dtype=int64), 452: array([486, 184, 388, 389, 277, 391], dtype=int64), 453: array([486, 181, 153, 154, 155, 156], dtype=int64), 454: array([486, 181, 153, 154, 155, 156], dtype=int64), 455: array([486, 181, 153, 154, 155, 156], dtype=int64), 456: array([486, 181, 153, 154, 155, 156], dtype=int64), 457: array([486, 181, 153, 154, 155, 156], dtype=int64), 458: array([486, 181, 153, 154, 155, 156], dtype=int64), 459: array([486, 181, 153, 154, 155, 156], dtype=int64), 460: array([486, 181, 153, 154, 155, 156], dtype=int64), 461: array([486, 284, 283, 393, 281, 395], dtype=int64), 462: array([486, 181, 153, 154, 155, 156], dtype=int64), 463: array([486, 181, 153, 154, 155, 156], dtype=int64), 464: array([486, 190, 271, 269, 384, 385], dtype=int64), 465: array([486, 365, 384, 381, 377, 374], dtype=int64), 466: array([486, 181, 153, 154, 155, 156], dtype=int64), 467: array([486, 181, 153, 154, 155, 156], dtype=int64), 468: array([486, 181, 153, 154, 155, 156], dtype=int64), 469: array([486, 181, 153, 154, 155, 156], dtype=int64), 470: array([486, 181, 153, 154, 155, 156], dtype=int64), 471: array([486, 181, 153, 154, 155, 156], dtype=int64), 472: array([486, 393, 395, 396, 283, 281], dtype=int64), 473: array([486, 409,  77, 153, 399,  75], dtype=int64), 474: array([486, 181, 153, 154, 155, 156], dtype=int64), 475: array([486, 181, 153, 154, 155, 156], dtype=int64), 476: array([486, 181, 153, 154, 155, 156], dtype=int64), 477: array([486, 181, 153, 154, 155, 156], dtype=int64), 478: array([486, 181, 153, 154, 155, 156], dtype=int64), 479: array([486, 181, 153, 154, 155, 156], dtype=int64), 480: array([486, 221, 377, 381, 384, 385], dtype=int64), 481: array([486, 355,  75, 349,  77, 342], dtype=int64), 482: array([486, 426, 396, 323,  77, 399], dtype=int64), 483: array([486, 285, 396, 284, 283, 399], dtype=int64), 484: array([486, 181, 153, 154, 155, 156], dtype=int64), 485: array([486, 181, 153, 154, 155, 156], dtype=int64), 486: array([181, 153, 154, 155, 156], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "print(item_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.05475701574264202, 1: 0.11310746064339494, 2: 0.029603011635865845, 3: 0.03182751540041068, 4: 0.11447638603696099, 5: 0.023271731690622865, 6: 0.05475701574264202, 7: 0.11516084873374403, 8: 0.02498288843258042, 9: 0.054414784394250515, 10: 0.022073921971252564, 11: 0.025496235455167698, 12: 0.04021218343600274, 13: 0.028747433264887063, 14: 0.08247775496235456, 15: 0.041752224503764555, 16: 0.11516084873374403, 17: 0.08281998631074605, 18: 0.11242299794661192, 19: 0.024982888432580425, 20: 0.07905544147843942, 21: 0.08915126625598906, 22: 0.02446954140999315, 23: 0.14082819986310746, 24: 0.07067077344284736, 25: 0.08042436687200548, 26: 0.10130047912388775, 27: 0.04123887748117728, 28: 0.04449007529089665, 29: 0.13997262149212866, 30: 0.04911019849418206, 31: 0.037987679671457907, 32: 0.054414784394250515, 33: 0.04911019849418206, 34: 0.02292950034223135, 35: 0.1856605065023956, 36: 0.04911019849418207, 37: 0.08247775496235456, 38: 0.1266255989048597, 39: 0.05886379192334018, 40: 0.02446954140999315, 41: 0.06930184804928131, 42: 0.06570841889117043, 43: 0.04431895961670088, 44: 0.02549623545516769, 45: 0.13175906913073238, 46: 0.10951403148528405, 47: 0.15143737166324436, 48: 0.058692676249144426, 49: 0.05390143737166325, 50: 0.07203969883641341, 51: 0.06964407939767282, 52: 0.11516084873374403, 53: 0.10985626283367557, 54: 0.04962354551676934, 55: 0.060232717316906235, 56: 0.06964407939767282, 57: 0.141854893908282, 58: 0.0376454483230664, 59: 0.03542094455852156, 60: 0.07203969883641341, 61: 0.04380561259411362, 62: 0.06947296372347707, 63: 0.12200547570157427, 64: 0.055954825462012324, 65: 0.08350444900752908, 66: 0.04431895961670088, 67: 0.07340862422997947, 68: 0.06964407939767282, 69: 0.037987679671457907, 70: 0.02840520191649555, 71: 0.058692676249144426, 72: 0.10951403148528405, 73: 0.06605065023956194, 74: 0.0391854893908282, 75: 0.08915126625598906, 76: 0.058692676249144426, 77: 0.08915126625598906, 78: 0.06451060917180014, 79: 0.05355920602327174, 80: 0.028918548939082824, 81: 0.1288501026694045, 82: 0.11002737850787132, 83: 0.141854893908282, 84: 0.16632443531827515, 85: 0.141854893908282, 86: 0.05989048596851473, 87: 0.037987679671457907, 88: 0.07067077344284736, 89: 0.05304585900068446, 90: 0.11995208761122518, 91: 0.04140999315537303, 92: 0.06639288158795345, 93: 0.08281998631074605, 94: 0.14082819986310746, 95: 0.06861738535249827, 96: 0.08281998631074605, 97: 0.08915126625598906, 98: 0.0886379192334018, 99: 0.07135523613963039, 100: 0.12850787132101302, 101: 0.09394250513347023, 102: 0.10557837097878166, 103: 0.06964407939767282, 104: 0.11841204654346338, 105: 0.1108829568788501, 106: 0.08281998631074605, 107: 0.12491444216290214, 108: 0.11105407255304588, 109: 0.041923340177960296, 110: 0.06262833675564682, 111: 0.06827515400410678, 112: 0.03559206023271732, 113: 0.07871321013004791, 114: 0.04483230663928816, 115: 0.08932238193018481, 116: 0.14099931553730322, 117: 0.149555099247091, 118: 0.0489390828199863, 119: 0.03678986995208761, 120: 0.04911019849418207, 121: 0.10951403148528405, 122: 0.08281998631074605, 123: 0.025838466803559206, 124: 0.02446954140999315, 125: 0.07717316906228609, 126: 0.08915126625598906, 127: 0.0716974674880219, 128: 0.03302532511978098, 129: 0.030287474332648872, 130: 0.06964407939767282, 131: 0.0686173853524983, 132: 0.054414784394250515, 133: 0.07871321013004791, 134: 0.11516084873374403, 135: 0.08915126625598906, 136: 0.08915126625598906, 137: 0.06964407939767282, 138: 0.08915126625598906, 139: 0.06177275838466804, 140: 0.08915126625598906, 141: 0.02378507871321013, 142: 0.054414784394250515, 143: 0.08915126625598906, 144: 0.025838466803559206, 145: 0.11516084873374403, 146: 0.03559206023271732, 147: 0.07135523613963039, 148: 0.10951403148528405, 149: 0.06964407939767282, 150: 0.04277891854893909, 151: 0.10814510609171801, 152: 0.02378507871321013, 153: 0.03367556468172485, 154: 0.10410677618069815, 155: 0.06964407939767282, 156: 0.04243668720054757, 157: 0.02908966461327858, 158: 0.08281998631074605, 159: 0.05544147843942505, 160: 0.08915126625598906, 161: 0.02908966461327858, 162: 0.06964407939767282, 163: 0.02292950034223135, 164: 0.08915126625598906, 165: 0.06964407939767282, 166: 0.07203969883641341, 167: 0.13175906913073235, 168: 0.08281998631074605, 169: 0.02446954140999315, 170: 0.058521560574948665, 171: 0.06964407939767282, 172: 0.02378507871321013, 173: 0.06964407939767282, 174: 0.03867214236824093, 175: 0.0501368925393566, 176: 0.02446954140999315, 177: 0.08281998631074605, 178: 0.087782340862423, 179: 0.04123887748117728, 180: 0.108145106091718, 181: 0.033880903490759756, 182: 0.0489390828199863, 183: 0.08281998631074605, 184: 0.08915126625598906, 185: 0.02446954140999315, 186: 0.10951403148528405, 187: 0.0686173853524983, 188: 0.0607460643394935, 189: 0.04534565366187543, 190: 0.08915126625598906, 191: 0.08915126625598906, 192: 0.06861738535249828, 193: 0.06741957563312799, 194: 0.05082135523613962, 195: 0.08915126625598906, 196: 0.02446954140999315, 197: 0.02446954140999315, 198: 0.06964407939767282, 199: 0.07854209445585217, 200: 0.061088295687885014, 201: 0.07563312799452428, 202: 0.10951403148528405, 203: 0.13501026694045173, 204: 0.10814510609171801, 205: 0.06964407939767282, 206: 0.12799452429842573, 207: 0.04226557152635182, 208: 0.02481177275838467, 209: 0.10951403148528405, 210: 0.06964407939767282, 211: 0.11447638603696099, 212: 0.08915126625598906, 213: 0.02446954140999315, 214: 0.06964407939767282, 215: 0.02446954140999315, 216: 0.07580424366872006, 217: 0.08915126625598906, 218: 0.08281998631074605, 219: 0.07905544147843942, 220: 0.06964407939767282, 221: 0.08915126625598906, 222: 0.030287474332648872, 223: 0.0489390828199863, 224: 0.06365503080082134, 225: 0.07135523613963039, 226: 0.08281998631074605, 227: 0.06964407939767282, 228: 0.08915126625598906, 229: 0.10985626283367557, 230: 0.11721423682409308, 231: 0.06964407939767282, 232: 0.05390143737166323, 233: 0.04945242984257358, 234: 0.049452429842573586, 235: 0.058692676249144426, 236: 0.06690622861054073, 237: 0.08915126625598906, 238: 0.02446954140999315, 239: 0.11156741957563314, 240: 0.06365503080082136, 241: 0.07238193018480493, 242: 0.108145106091718, 243: 0.05475701574264202, 244: 0.040041067761806985, 245: 0.06964407939767282, 246: 0.05646817248459959, 247: 0.03542094455852156, 248: 0.08915126625598906, 249: 0.03559206023271732, 250: 0.08915126625598906, 251: 0.02446954140999315, 252: 0.0556125941136208, 253: 0.029260780287474336, 254: 0.10078713210130048, 255: 0.08915126625598906, 256: 0.06964407939767282, 257: 0.062114989733059546, 258: 0.12885010266940453, 259: 0.10951403148528405, 260: 0.12867898699520877, 261: 0.03542094455852156, 262: 0.06964407939767282, 263: 0.06964407939767282, 264: 0.10951403148528405, 265: 0.07854209445585215, 266: 0.04243668720054757, 267: 0.06964407939767282, 268: 0.06964407939767282, 269: 0.08915126625598906, 270: 0.06964407939767282, 271: 0.08915126625598906, 272: 0.06622176591375771, 273: 0.02446954140999316, 274: 0.11002737850787132, 275: 0.06964407939767282, 276: 0.08915126625598906, 277: 0.08915126625598906, 278: 0.043976728268309374, 279: 0.08915126625598906, 280: 0.08915126625598906, 281: 0.08915126625598906, 282: 0.03559206023271732, 283: 0.08915126625598906, 284: 0.08915126625598906, 285: 0.08915126625598906, 286: 0.11105407255304585, 287: 0.08915126625598906, 288: 0.04739904175222451, 289: 0.06485284052019165, 290: 0.11139630390143739, 291: 0.13997262149212866, 292: 0.06998631074606433, 293: 0.08281998631074605, 294: 0.08281998631074605, 295: 0.0391854893908282, 296: 0.08915126625598906, 297: 0.06964407939767282, 298: 0.08915126625598906, 299: 0.058863791923340174, 300: 0.054928131416837785, 301: 0.14082819986310746, 302: 0.12885010266940453, 303: 0.06964407939767282, 304: 0.04808350444900753, 305: 0.05304585900068446, 306: 0.05355920602327174, 307: 0.08915126625598906, 308: 0.02908966461327858, 309: 0.12919233401779603, 310: 0.10951403148528405, 311: 0.08915126625598906, 312: 0.08915126625598906, 313: 0.03713210130047912, 314: 0.08915126625598906, 315: 0.028918548939082824, 316: 0.10951403148528405, 317: 0.08521560574948665, 318: 0.05355920602327174, 319: 0.08915126625598906, 320: 0.07854209445585215, 321: 0.141854893908282, 322: 0.03524982888432581, 323: 0.08915126625598906, 324: 0.06365503080082136, 325: 0.05355920602327174, 326: 0.08281998631074605, 327: 0.05475701574264202, 328: 0.10472279260780287, 329: 0.08915126625598906, 330: 0.07580424366872006, 331: 0.054928131416837785, 332: 0.08915126625598906, 333: 0.08915126625598906, 334: 0.08915126625598906, 335: 0.05732375085557837, 336: 0.08915126625598906, 337: 0.06331279945242985, 338: 0.08281998631074605, 339: 0.024127310061601643, 340: 0.03559206023271732, 341: 0.08915126625598906, 342: 0.08915126625598906, 343: 0.141854893908282, 344: 0.10951403148528405, 345: 0.149555099247091, 346: 0.03542094455852156, 347: 0.058521560574948665, 348: 0.043976728268309374, 349: 0.08915126625598906, 350: 0.043976728268309374, 351: 0.06947296372347707, 352: 0.08915126625598906, 353: 0.06451060917180014, 354: 0.13073237508555782, 355: 0.08915126625598906, 356: 0.04140999315537303, 357: 0.023271731690622865, 358: 0.04534565366187543, 359: 0.16016427104722794, 360: 0.08915126625598906, 361: 0.08915126625598906, 362: 0.048596851471594794, 363: 0.15503080082135523, 364: 0.08384668035592062, 365: 0.08915126625598906, 366: 0.04414784394250513, 367: 0.03542094455852156, 368: 0.054928131416837785, 369: 0.05544147843942506, 370: 0.11584531143052705, 371: 0.07152635181382615, 372: 0.07511978097193704, 373: 0.11054072553045859, 374: 0.08915126625598906, 375: 0.11054072553045859, 376: 0.028747433264887063, 377: 0.08915126625598906, 378: 0.13997262149212866, 379: 0.038501026694045176, 380: 0.028747433264887063, 381: 0.08915126625598906, 382: 0.108145106091718, 383: 0.029603011635865845, 384: 0.08915126625598906, 385: 0.08915126625598906, 386: 0.05732375085557837, 387: 0.11105407255304588, 388: 0.08915126625598906, 389: 0.08915126625598906, 390: 0.04449007529089665, 391: 0.08915126625598906, 392: 0.043976728268309374, 393: 0.08915126625598906, 394: 0.0944558521560575, 395: 0.08915126625598906, 396: 0.08915126625598906, 397: 0.11464750171115673, 398: 0.08281998631074605, 399: 0.08915126625598906, 400: 0.07511978097193704, 401: 0.08281998631074605, 402: 0.05544147843942505, 403: 0.08915126625598906, 404: 0.043976728268309374, 405: 0.08915126625598906, 406: 0.07272416153319644, 407: 0.04654346338124573, 408: 0.13997262149212866, 409: 0.08915126625598906, 410: 0.03610540725530459, 411: 0.05886379192334018, 412: 0.08915126625598906, 413: 0.08915126625598906, 414: 0.15742642026009582, 415: 0.08145106091718, 416: 0.08915126625598906, 417: 0.08915126625598906, 418: 0.08915126625598906, 419: 0.07580424366872006, 420: 0.054928131416837785, 421: 0.19062286105407253, 422: 0.055954825462012324, 423: 0.04449007529089665, 424: 0.08915126625598906, 425: 0.08915126625598906, 426: 0.08915126625598906, 427: 0.06930184804928131, 428: 0.043976728268309374, 429: 0.055954825462012324, 430: 0.08915126625598906, 431: 0.06930184804928131, 432: 0.18548939082819985, 433: 0.08915126625598906, 434: 0.08915126625598906, 435: 0.12867898699520877, 436: 0.12867898699520877, 437: 0.04791238877481178, 438: 0.0689596167008898, 439: 0.043976728268309374, 440: 0.08915126625598906, 441: 0.08915126625598906, 442: 0.08281998631074605, 443: 0.08915126625598906, 444: 0.08281998631074605, 445: 0.08915126625598906, 446: 0.10814510609171801, 447: 0.06365503080082136, 448: 0.08915126625598906, 449: 0.043976728268309374, 450: 0.05817932922655716, 451: 0.04449007529089665, 452: 0.17419575633127993, 453: 0.08915126625598906, 454: 0.08915126625598906, 455: 0.08915126625598906, 456: 0.08915126625598906, 457: 0.08915126625598906, 458: 0.08915126625598906, 459: 0.08915126625598906, 460: 0.08915126625598906, 461: 0.06930184804928131, 462: 0.08915126625598906, 463: 0.08915126625598906, 464: 0.0443189596167009, 465: 0.041923340177960296, 466: 0.08915126625598906, 467: 0.08915126625598906, 468: 0.08915126625598906, 469: 0.08915126625598906, 470: 0.08915126625598906, 471: 0.08915126625598906, 472: 0.06570841889117043, 473: 0.13056125941136207, 474: 0.08915126625598906, 475: 0.08915126625598906, 476: 0.08915126625598906, 477: 0.08915126625598906, 478: 0.08915126625598906, 479: 0.08915126625598906, 480: 0.026351813826146476, 481: 0.08281998631074605, 482: 0.05321697467488023, 483: 0.055954825462012324, 484: 0.08915126625598906, 485: 0.08915126625598906, 486: 0.09589322381930185}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rating_propagation(item_neighborhood, item_user_matrix):\n",
    "    \"\"\"\n",
    "    Propagate ratings from similar items to the target item using averaging.\n",
    "\n",
    "    Parameters:\n",
    "        item_neighborhood (dict): Dictionary containing similar items for each item.\n",
    "        item_user_matrix (pandas.DataFrame): User-item matrix containing user ratings.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing propagated ratings for each item.\n",
    "    \"\"\"\n",
    "    propagated_ratings = {}\n",
    "\n",
    "    for target_item_index, similar_item_indices in item_neighborhood.items():\n",
    "        ratings = []\n",
    "        for similar_item_index in similar_item_indices:\n",
    "            if similar_item_index < item_user_matrix.shape[0]:\n",
    "                rating = item_user_matrix.iloc[similar_item_index].mean()  # Mean rating for similar item\n",
    "                ratings.append(rating)\n",
    "            else:\n",
    "                print(f\"Index {similar_item_index} is out of bounds.\")\n",
    "\n",
    "        propagated_rating = sum(ratings) / len(ratings) if ratings else None\n",
    "        propagated_ratings[target_item_index] = propagated_rating\n",
    "\n",
    "    return propagated_ratings\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have item_neighborhood and train DataFrame with user-item interactions\n",
    "# where each cell contains a user's rating for an item\n",
    "propagated_ratings = rating_propagation(item_neighborhood, item_user_matrix)\n",
    "\n",
    "print(propagated_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Classify Items\n",
    "\n",
    "- For each item in the testing set, find its nearest neighbors based on the precomputed item neighborhoods.\n",
    "- Determine the class labels of these neighbors.\n",
    "- Use a strategy such as majority voting to assign the class label to the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_classification(item_neighborhood, propagated_ratings):\n",
    "    \"\"\"\n",
    "    Perform classification by aggregating the propagated ratings from similar items.\n",
    "\n",
    "    Parameters:\n",
    "        item_neighborhood (dict): Dictionary containing similar items for each item.\n",
    "        propagated_ratings (dict): Propagated ratings for each item.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing classified ratings for each item.\n",
    "    \"\"\"\n",
    "    classified_ratings = {}\n",
    "\n",
    "    for target_item_index, similar_item_indices in item_neighborhood.items():\n",
    "        rating_sum = 0\n",
    "        count = 0\n",
    "        for similar_item_index in similar_item_indices:\n",
    "            propagated_rating = propagated_ratings.get(similar_item_index)\n",
    "            if propagated_rating is not None:\n",
    "                rating_sum += propagated_rating\n",
    "                count += 1\n",
    "        \n",
    "        if count > 0:\n",
    "            classified_rating = rating_sum / count\n",
    "            classified_ratings[target_item_index] = classified_rating\n",
    "        else:\n",
    "            # If there are no similar items or propagated ratings available, assign NaN\n",
    "            classified_ratings[target_item_index] = float('nan')\n",
    "\n",
    "    return classified_ratings\n",
    "\n",
    "# Example usage:\n",
    "classified_ratings = perform_classification(item_neighborhood, propagated_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check for the NaN values in the classified_ratings\n",
    "pd.Series(classified_ratings).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Recommendation Generation\n",
    "\n",
    "Once the model is trained and evaluated, you can use it to generate item recommendations for users. For a given user, recommend items that are highly rated or predicted to be liked based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ratings for users: {1: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 2: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 3: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 4: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 5: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 6: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 7: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 9: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 10: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 11: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 12: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 13: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 14: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 15: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 16: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 17: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 18: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 19: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 20: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 21: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 22: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 23: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 24: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 25: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 27: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 28: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 29: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 30: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 31: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 32: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 33: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 34: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 36: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 38: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 39: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 40: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 41: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 42: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 43: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 44: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 45: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 46: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 47: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 48: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 50: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 51: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 52: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 54: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 57: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 58: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 59: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 62: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 63: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 64: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 65: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 66: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 67: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 68: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 69: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 70: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 71: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 73: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 74: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 75: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 76: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 78: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 79: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 80: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 82: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 83: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 84: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 85: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 86: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 87: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 88: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 89: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 90: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 91: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 92: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 93: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 95: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 96: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 97: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 98: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 99: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 100: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 101: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 103: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 104: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 105: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 106: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 107: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 109: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 110: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 111: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 112: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 113: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 114: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 115: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 116: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 117: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 118: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 119: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 121: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 122: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 123: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 124: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 125: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 129: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 130: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 131: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 132: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 134: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 135: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 136: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 137: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 138: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 139: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 140: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 141: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 143: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 144: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 145: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 146: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 147: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 148: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 149: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 151: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 152: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 153: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 154: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 155: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 156: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 157: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 158: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 159: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 160: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 161: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 162: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 163: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 164: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 165: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 166: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 167: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 168: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 169: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 171: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 172: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 177: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 178: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 179: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 180: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 181: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 182: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 183: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 184: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 185: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 186: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 187: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 188: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 190: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 191: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 193: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 195: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 196: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 197: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 198: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 199: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 200: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 201: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 202: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 203: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 204: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 205: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 206: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 207: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 209: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 210: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 211: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 212: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 213: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 214: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 215: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 216: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 217: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 218: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 219: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 220: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 221: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 222: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 223: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 224: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 225: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 226: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 227: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 228: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 229: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 230: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 232: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 233: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 234: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 235: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 236: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 237: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 238: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 239: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 240: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 241: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 243: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 244: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 246: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 247: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 248: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 249: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 250: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 252: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 253: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 254: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 255: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 256: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 258: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 259: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 260: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 261: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 262: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 263: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 264: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 265: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 266: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 267: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 268: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 269: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 270: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 271: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 272: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 273: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 274: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 275: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 276: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 277: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 278: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 279: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 280: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 281: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 282: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 283: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 284: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 285: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 286: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 287: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 288: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 289: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 290: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 291: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 292: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 293: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 294: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 296: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 297: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 298: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 300: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 301: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 303: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 304: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 305: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 306: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 307: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 308: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 309: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 310: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 311: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 312: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 313: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 314: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 315: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 316: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 317: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 318: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 322: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 323: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 324: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 325: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 326: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 327: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 328: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 330: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 331: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 332: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 333: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 334: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 335: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 336: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 337: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 338: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 339: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 341: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 342: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 343: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 344: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 345: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 346: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 347: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 348: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 349: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 350: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 351: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 352: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 353: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 354: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 355: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 356: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 357: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 358: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 359: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 360: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 361: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 362: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 363: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 364: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 365: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 367: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 368: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 369: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 370: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 371: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 372: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 373: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 375: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 376: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 377: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 378: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 380: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 381: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 382: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 383: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 384: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 385: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 386: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 387: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 388: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 389: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 390: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 391: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 393: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 396: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 398: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 399: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 401: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 402: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 403: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 405: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 408: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 409: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 410: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 411: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 412: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 413: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 414: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 415: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 416: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 417: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 418: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 419: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 420: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 421: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 422: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 423: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 424: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 425: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 426: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 427: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 428: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 430: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 431: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 432: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 434: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 435: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 436: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 437: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 438: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 440: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 441: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 442: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 443: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 444: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 445: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 446: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 447: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 448: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 449: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 450: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 451: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 452: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 453: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 454: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 455: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 456: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 457: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 458: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 459: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 460: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 462: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 464: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 465: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 466: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 467: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 468: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 469: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 470: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 471: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 474: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 475: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 476: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 477: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 478: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 479: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 480: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 481: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 482: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 483: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 484: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 486: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 487: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 488: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 489: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 490: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 491: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 492: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 493: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 495: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 496: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 497: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 498: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 499: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 500: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 501: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 502: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 503: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 504: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 505: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 506: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 508: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 509: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 510: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 511: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 513: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 514: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 515: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 516: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 517: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 518: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 520: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 521: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 522: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 523: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 524: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 525: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 526: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 527: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 528: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 529: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 531: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 532: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 533: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 534: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 535: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 536: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 537: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 538: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 539: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 540: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 541: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 542: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 543: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 544: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 545: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 546: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 547: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 550: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 551: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 552: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 554: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 555: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 556: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 557: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 558: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 559: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 560: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 561: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 562: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 563: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 564: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 566: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 567: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 568: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 570: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 571: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 572: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 573: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 575: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 576: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 577: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 578: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 579: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 580: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 581: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 582: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 583: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 584: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 585: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 586: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 587: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 590: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 592: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 593: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 594: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 595: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 596: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 597: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 598: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 599: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 600: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 601: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 602: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 603: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 604: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 605: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 606: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 607: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 608: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 609: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}, 610: {1: 0.08352156057494868, 4: 0.09027492584987452, 15: 0.09027492584987452, 30: 0.09027492584987452, 43: 0.09027492584987452, 89: 0.09027492584987452, 104: 0.08102897558749715, 108: 0.09027492584987452, 122: 0.09027492584987452, 146: 0.09027492584987452, 290: 0.09027492584987452, 303: 0.09027492584987452, 305: 0.09027492584987452, 346: 0.09027492584987452, 353: 0.09027492584987452, 358: 0.09027492584987452, 363: 0.09027492584987452, 389: 0.06327287246178416, 393: 0.06327287246178416, 416: 0.06327287246178416, 423: 0.09027492584987452, 478: 0.06327287246178416}}\n",
      "Recommended items for users: {1: [384, 385, 388, 391, 135], 2: [384, 385, 388, 391, 135], 3: [384, 385, 388, 391, 135], 4: [384, 385, 388, 391, 135], 5: [384, 385, 388, 391, 135], 6: [384, 385, 388, 391, 135], 7: [384, 385, 388, 391, 135], 9: [384, 385, 388, 391, 135], 10: [384, 385, 388, 391, 135], 11: [384, 385, 388, 391, 135], 12: [384, 385, 388, 391, 135], 13: [384, 385, 388, 391, 135], 14: [384, 385, 388, 391, 135], 15: [384, 385, 388, 391, 135], 16: [384, 385, 388, 391, 135], 17: [384, 385, 388, 391, 135], 18: [384, 385, 388, 391, 135], 19: [384, 385, 388, 391, 135], 20: [384, 385, 388, 391, 135], 21: [384, 385, 388, 391, 135], 22: [384, 385, 388, 391, 135], 23: [384, 385, 388, 391, 135], 24: [384, 385, 388, 391, 135], 25: [384, 385, 388, 391, 135], 27: [384, 385, 388, 391, 135], 28: [384, 385, 388, 391, 135], 29: [384, 385, 388, 391, 135], 30: [384, 385, 388, 391, 135], 31: [384, 385, 388, 391, 135], 32: [384, 385, 388, 391, 135], 33: [384, 385, 388, 391, 135], 34: [384, 385, 388, 391, 135], 36: [384, 385, 388, 391, 135], 38: [384, 385, 388, 391, 135], 39: [384, 385, 388, 391, 135], 40: [384, 385, 388, 391, 135], 41: [384, 385, 388, 391, 135], 42: [384, 385, 388, 391, 135], 43: [384, 385, 388, 391, 135], 44: [384, 385, 388, 391, 135], 45: [384, 385, 388, 391, 135], 46: [384, 385, 388, 391, 135], 47: [384, 385, 388, 391, 135], 48: [384, 385, 388, 391, 135], 50: [384, 385, 388, 391, 135], 51: [384, 385, 388, 391, 135], 52: [384, 385, 388, 391, 135], 54: [384, 385, 388, 391, 135], 57: [384, 385, 388, 391, 135], 58: [384, 385, 388, 391, 135], 59: [384, 385, 388, 391, 135], 62: [384, 385, 388, 391, 135], 63: [384, 385, 388, 391, 135], 64: [384, 385, 388, 391, 135], 65: [384, 385, 388, 391, 135], 66: [384, 385, 388, 391, 135], 67: [384, 385, 388, 391, 135], 68: [384, 385, 388, 391, 135], 69: [384, 385, 388, 391, 135], 70: [384, 385, 388, 391, 135], 71: [384, 385, 388, 391, 135], 73: [384, 385, 388, 391, 135], 74: [384, 385, 388, 391, 135], 75: [384, 385, 388, 391, 135], 76: [384, 385, 388, 391, 135], 78: [384, 385, 388, 391, 135], 79: [384, 385, 388, 391, 135], 80: [384, 385, 388, 391, 135], 82: [384, 385, 388, 391, 135], 83: [384, 385, 388, 391, 135], 84: [384, 385, 388, 391, 135], 85: [384, 385, 388, 391, 135], 86: [384, 385, 388, 391, 135], 87: [384, 385, 388, 391, 135], 88: [384, 385, 388, 391, 135], 89: [384, 385, 388, 391, 135], 90: [384, 385, 388, 391, 135], 91: [384, 385, 388, 391, 135], 92: [384, 385, 388, 391, 135], 93: [384, 385, 388, 391, 135], 95: [384, 385, 388, 391, 135], 96: [384, 385, 388, 391, 135], 97: [384, 385, 388, 391, 135], 98: [384, 385, 388, 391, 135], 99: [384, 385, 388, 391, 135], 100: [384, 385, 388, 391, 135], 101: [384, 385, 388, 391, 135], 103: [384, 385, 388, 391, 135], 104: [384, 385, 388, 391, 135], 105: [384, 385, 388, 391, 135], 106: [384, 385, 388, 391, 135], 107: [384, 385, 388, 391, 135], 109: [384, 385, 388, 391, 135], 110: [384, 385, 388, 391, 135], 111: [384, 385, 388, 391, 135], 112: [384, 385, 388, 391, 135], 113: [384, 385, 388, 391, 135], 114: [384, 385, 388, 391, 135], 115: [384, 385, 388, 391, 135], 116: [384, 385, 388, 391, 135], 117: [384, 385, 388, 391, 135], 118: [384, 385, 388, 391, 135], 119: [384, 385, 388, 391, 135], 121: [384, 385, 388, 391, 135], 122: [384, 385, 388, 391, 135], 123: [384, 385, 388, 391, 135], 124: [384, 385, 388, 391, 135], 125: [384, 385, 388, 391, 135], 129: [384, 385, 388, 391, 135], 130: [384, 385, 388, 391, 135], 131: [384, 385, 388, 391, 135], 132: [384, 385, 388, 391, 135], 134: [384, 385, 388, 391, 135], 135: [384, 385, 388, 391, 135], 136: [384, 385, 388, 391, 135], 137: [384, 385, 388, 391, 135], 138: [384, 385, 388, 391, 135], 139: [384, 385, 388, 391, 135], 140: [384, 385, 388, 391, 135], 141: [384, 385, 388, 391, 135], 143: [384, 385, 388, 391, 135], 144: [384, 385, 388, 391, 135], 145: [384, 385, 388, 391, 135], 146: [384, 385, 388, 391, 135], 147: [384, 385, 388, 391, 135], 148: [384, 385, 388, 391, 135], 149: [384, 385, 388, 391, 135], 151: [384, 385, 388, 391, 135], 152: [384, 385, 388, 391, 135], 153: [384, 385, 388, 391, 135], 154: [384, 385, 388, 391, 135], 155: [384, 385, 388, 391, 135], 156: [384, 385, 388, 391, 135], 157: [384, 385, 388, 391, 135], 158: [384, 385, 388, 391, 135], 159: [384, 385, 388, 391, 135], 160: [384, 385, 388, 391, 135], 161: [384, 385, 388, 391, 135], 162: [384, 385, 388, 391, 135], 163: [384, 385, 388, 391, 135], 164: [384, 385, 388, 391, 135], 165: [384, 385, 388, 391, 135], 166: [384, 385, 388, 391, 135], 167: [384, 385, 388, 391, 135], 168: [384, 385, 388, 391, 135], 169: [384, 385, 388, 391, 135], 171: [384, 385, 388, 391, 135], 172: [384, 385, 388, 391, 135], 177: [384, 385, 388, 391, 135], 178: [384, 385, 388, 391, 135], 179: [384, 385, 388, 391, 135], 180: [384, 385, 388, 391, 135], 181: [384, 385, 388, 391, 135], 182: [384, 385, 388, 391, 135], 183: [384, 385, 388, 391, 135], 184: [384, 385, 388, 391, 135], 185: [384, 385, 388, 391, 135], 186: [384, 385, 388, 391, 135], 187: [384, 385, 388, 391, 135], 188: [384, 385, 388, 391, 135], 190: [384, 385, 388, 391, 135], 191: [384, 385, 388, 391, 135], 193: [384, 385, 388, 391, 135], 195: [384, 385, 388, 391, 135], 196: [384, 385, 388, 391, 135], 197: [384, 385, 388, 391, 135], 198: [384, 385, 388, 391, 135], 199: [384, 385, 388, 391, 135], 200: [384, 385, 388, 391, 135], 201: [384, 385, 388, 391, 135], 202: [384, 385, 388, 391, 135], 203: [384, 385, 388, 391, 135], 204: [384, 385, 388, 391, 135], 205: [384, 385, 388, 391, 135], 206: [384, 385, 388, 391, 135], 207: [384, 385, 388, 391, 135], 209: [384, 385, 388, 391, 135], 210: [384, 385, 388, 391, 135], 211: [384, 385, 388, 391, 135], 212: [384, 385, 388, 391, 135], 213: [384, 385, 388, 391, 135], 214: [384, 385, 388, 391, 135], 215: [384, 385, 388, 391, 135], 216: [384, 385, 388, 391, 135], 217: [384, 385, 388, 391, 135], 218: [384, 385, 388, 391, 135], 219: [384, 385, 388, 391, 135], 220: [384, 385, 388, 391, 135], 221: [384, 385, 388, 391, 135], 222: [384, 385, 388, 391, 135], 223: [384, 385, 388, 391, 135], 224: [384, 385, 388, 391, 135], 225: [384, 385, 388, 391, 135], 226: [384, 385, 388, 391, 135], 227: [384, 385, 388, 391, 135], 228: [384, 385, 388, 391, 135], 229: [384, 385, 388, 391, 135], 230: [384, 385, 388, 391, 135], 232: [384, 385, 388, 391, 135], 233: [384, 385, 388, 391, 135], 234: [384, 385, 388, 391, 135], 235: [384, 385, 388, 391, 135], 236: [384, 385, 388, 391, 135], 237: [384, 385, 388, 391, 135], 238: [384, 385, 388, 391, 135], 239: [384, 385, 388, 391, 135], 240: [384, 385, 388, 391, 135], 241: [384, 385, 388, 391, 135], 243: [384, 385, 388, 391, 135], 244: [384, 385, 388, 391, 135], 246: [384, 385, 388, 391, 135], 247: [384, 385, 388, 391, 135], 248: [384, 385, 388, 391, 135], 249: [384, 385, 388, 391, 135], 250: [384, 385, 388, 391, 135], 252: [384, 385, 388, 391, 135], 253: [384, 385, 388, 391, 135], 254: [384, 385, 388, 391, 135], 255: [384, 385, 388, 391, 135], 256: [384, 385, 388, 391, 135], 258: [384, 385, 388, 391, 135], 259: [384, 385, 388, 391, 135], 260: [384, 385, 388, 391, 135], 261: [384, 385, 388, 391, 135], 262: [384, 385, 388, 391, 135], 263: [384, 385, 388, 391, 135], 264: [384, 385, 388, 391, 135], 265: [384, 385, 388, 391, 135], 266: [384, 385, 388, 391, 135], 267: [384, 385, 388, 391, 135], 268: [384, 385, 388, 391, 135], 269: [384, 385, 388, 391, 135], 270: [384, 385, 388, 391, 135], 271: [384, 385, 388, 391, 135], 272: [384, 385, 388, 391, 135], 273: [384, 385, 388, 391, 135], 274: [384, 385, 388, 391, 135], 275: [384, 385, 388, 391, 135], 276: [384, 385, 388, 391, 135], 277: [384, 385, 388, 391, 135], 278: [384, 385, 388, 391, 135], 279: [384, 385, 388, 391, 135], 280: [384, 385, 388, 391, 135], 281: [384, 385, 388, 391, 135], 282: [384, 385, 388, 391, 135], 283: [384, 385, 388, 391, 135], 284: [384, 385, 388, 391, 135], 285: [384, 385, 388, 391, 135], 286: [384, 385, 388, 391, 135], 287: [384, 385, 388, 391, 135], 288: [384, 385, 388, 391, 135], 289: [384, 385, 388, 391, 135], 290: [384, 385, 388, 391, 135], 291: [384, 385, 388, 391, 135], 292: [384, 385, 388, 391, 135], 293: [384, 385, 388, 391, 135], 294: [384, 385, 388, 391, 135], 296: [384, 385, 388, 391, 135], 297: [384, 385, 388, 391, 135], 298: [384, 385, 388, 391, 135], 300: [384, 385, 388, 391, 135], 301: [384, 385, 388, 391, 135], 303: [384, 385, 388, 391, 135], 304: [384, 385, 388, 391, 135], 305: [384, 385, 388, 391, 135], 306: [384, 385, 388, 391, 135], 307: [384, 385, 388, 391, 135], 308: [384, 385, 388, 391, 135], 309: [384, 385, 388, 391, 135], 310: [384, 385, 388, 391, 135], 311: [384, 385, 388, 391, 135], 312: [384, 385, 388, 391, 135], 313: [384, 385, 388, 391, 135], 314: [384, 385, 388, 391, 135], 315: [384, 385, 388, 391, 135], 316: [384, 385, 388, 391, 135], 317: [384, 385, 388, 391, 135], 318: [384, 385, 388, 391, 135], 322: [384, 385, 388, 391, 135], 323: [384, 385, 388, 391, 135], 324: [384, 385, 388, 391, 135], 325: [384, 385, 388, 391, 135], 326: [384, 385, 388, 391, 135], 327: [384, 385, 388, 391, 135], 328: [384, 385, 388, 391, 135], 330: [384, 385, 388, 391, 135], 331: [384, 385, 388, 391, 135], 332: [384, 385, 388, 391, 135], 333: [384, 385, 388, 391, 135], 334: [384, 385, 388, 391, 135], 335: [384, 385, 388, 391, 135], 336: [384, 385, 388, 391, 135], 337: [384, 385, 388, 391, 135], 338: [384, 385, 388, 391, 135], 339: [384, 385, 388, 391, 135], 341: [384, 385, 388, 391, 135], 342: [384, 385, 388, 391, 135], 343: [384, 385, 388, 391, 135], 344: [384, 385, 388, 391, 135], 345: [384, 385, 388, 391, 135], 346: [384, 385, 388, 391, 135], 347: [384, 385, 388, 391, 135], 348: [384, 385, 388, 391, 135], 349: [384, 385, 388, 391, 135], 350: [384, 385, 388, 391, 135], 351: [384, 385, 388, 391, 135], 352: [384, 385, 388, 391, 135], 353: [384, 385, 388, 391, 135], 354: [384, 385, 388, 391, 135], 355: [384, 385, 388, 391, 135], 356: [384, 385, 388, 391, 135], 357: [384, 385, 388, 391, 135], 358: [384, 385, 388, 391, 135], 359: [384, 385, 388, 391, 135], 360: [384, 385, 388, 391, 135], 361: [384, 385, 388, 391, 135], 362: [384, 385, 388, 391, 135], 363: [384, 385, 388, 391, 135], 364: [384, 385, 388, 391, 135], 365: [384, 385, 388, 391, 135], 367: [384, 385, 388, 391, 135], 368: [384, 385, 388, 391, 135], 369: [384, 385, 388, 391, 135], 370: [384, 385, 388, 391, 135], 371: [384, 385, 388, 391, 135], 372: [384, 385, 388, 391, 135], 373: [384, 385, 388, 391, 135], 375: [384, 385, 388, 391, 135], 376: [384, 385, 388, 391, 135], 377: [384, 385, 388, 391, 135], 378: [384, 385, 388, 391, 135], 380: [384, 385, 388, 391, 135], 381: [384, 385, 388, 391, 135], 382: [384, 385, 388, 391, 135], 383: [384, 385, 388, 391, 135], 384: [384, 385, 388, 391, 135], 385: [384, 385, 388, 391, 135], 386: [384, 385, 388, 391, 135], 387: [384, 385, 388, 391, 135], 388: [384, 385, 388, 391, 135], 389: [384, 385, 388, 391, 135], 390: [384, 385, 388, 391, 135], 391: [384, 385, 388, 391, 135], 393: [384, 385, 388, 391, 135], 396: [384, 385, 388, 391, 135], 398: [384, 385, 388, 391, 135], 399: [384, 385, 388, 391, 135], 401: [384, 385, 388, 391, 135], 402: [384, 385, 388, 391, 135], 403: [384, 385, 388, 391, 135], 405: [384, 385, 388, 391, 135], 408: [384, 385, 388, 391, 135], 409: [384, 385, 388, 391, 135], 410: [384, 385, 388, 391, 135], 411: [384, 385, 388, 391, 135], 412: [384, 385, 388, 391, 135], 413: [384, 385, 388, 391, 135], 414: [384, 385, 388, 391, 135], 415: [384, 385, 388, 391, 135], 416: [384, 385, 388, 391, 135], 417: [384, 385, 388, 391, 135], 418: [384, 385, 388, 391, 135], 419: [384, 385, 388, 391, 135], 420: [384, 385, 388, 391, 135], 421: [384, 385, 388, 391, 135], 422: [384, 385, 388, 391, 135], 423: [384, 385, 388, 391, 135], 424: [384, 385, 388, 391, 135], 425: [384, 385, 388, 391, 135], 426: [384, 385, 388, 391, 135], 427: [384, 385, 388, 391, 135], 428: [384, 385, 388, 391, 135], 430: [384, 385, 388, 391, 135], 431: [384, 385, 388, 391, 135], 432: [384, 385, 388, 391, 135], 434: [384, 385, 388, 391, 135], 435: [384, 385, 388, 391, 135], 436: [384, 385, 388, 391, 135], 437: [384, 385, 388, 391, 135], 438: [384, 385, 388, 391, 135], 440: [384, 385, 388, 391, 135], 441: [384, 385, 388, 391, 135], 442: [384, 385, 388, 391, 135], 443: [384, 385, 388, 391, 135], 444: [384, 385, 388, 391, 135], 445: [384, 385, 388, 391, 135], 446: [384, 385, 388, 391, 135], 447: [384, 385, 388, 391, 135], 448: [384, 385, 388, 391, 135], 449: [384, 385, 388, 391, 135], 450: [384, 385, 388, 391, 135], 451: [384, 385, 388, 391, 135], 452: [384, 385, 388, 391, 135], 453: [384, 385, 388, 391, 135], 454: [384, 385, 388, 391, 135], 455: [384, 385, 388, 391, 135], 456: [384, 385, 388, 391, 135], 457: [384, 385, 388, 391, 135], 458: [384, 385, 388, 391, 135], 459: [384, 385, 388, 391, 135], 460: [384, 385, 388, 391, 135], 462: [384, 385, 388, 391, 135], 464: [384, 385, 388, 391, 135], 465: [384, 385, 388, 391, 135], 466: [384, 385, 388, 391, 135], 467: [384, 385, 388, 391, 135], 468: [384, 385, 388, 391, 135], 469: [384, 385, 388, 391, 135], 470: [384, 385, 388, 391, 135], 471: [384, 385, 388, 391, 135], 474: [384, 385, 388, 391, 135], 475: [384, 385, 388, 391, 135], 476: [384, 385, 388, 391, 135], 477: [384, 385, 388, 391, 135], 478: [384, 385, 388, 391, 135], 479: [384, 385, 388, 391, 135], 480: [384, 385, 388, 391, 135], 481: [384, 385, 388, 391, 135], 482: [384, 385, 388, 391, 135], 483: [384, 385, 388, 391, 135], 484: [384, 385, 388, 391, 135], 486: [384, 385, 388, 391, 135], 487: [384, 385, 388, 391, 135], 488: [384, 385, 388, 391, 135], 489: [384, 385, 388, 391, 135], 490: [384, 385, 388, 391, 135], 491: [384, 385, 388, 391, 135], 492: [384, 385, 388, 391, 135], 493: [384, 385, 388, 391, 135], 495: [384, 385, 388, 391, 135], 496: [384, 385, 388, 391, 135], 497: [384, 385, 388, 391, 135], 498: [384, 385, 388, 391, 135], 499: [384, 385, 388, 391, 135], 500: [384, 385, 388, 391, 135], 501: [384, 385, 388, 391, 135], 502: [384, 385, 388, 391, 135], 503: [384, 385, 388, 391, 135], 504: [384, 385, 388, 391, 135], 505: [384, 385, 388, 391, 135], 506: [384, 385, 388, 391, 135], 508: [384, 385, 388, 391, 135], 509: [384, 385, 388, 391, 135], 510: [384, 385, 388, 391, 135], 511: [384, 385, 388, 391, 135], 513: [384, 385, 388, 391, 135], 514: [384, 385, 388, 391, 135], 515: [384, 385, 388, 391, 135], 516: [384, 385, 388, 391, 135], 517: [384, 385, 388, 391, 135], 518: [384, 385, 388, 391, 135], 520: [384, 385, 388, 391, 135], 521: [384, 385, 388, 391, 135], 522: [384, 385, 388, 391, 135], 523: [384, 385, 388, 391, 135], 524: [384, 385, 388, 391, 135], 525: [384, 385, 388, 391, 135], 526: [384, 385, 388, 391, 135], 527: [384, 385, 388, 391, 135], 528: [384, 385, 388, 391, 135], 529: [384, 385, 388, 391, 135], 531: [384, 385, 388, 391, 135], 532: [384, 385, 388, 391, 135], 533: [384, 385, 388, 391, 135], 534: [384, 385, 388, 391, 135], 535: [384, 385, 388, 391, 135], 536: [384, 385, 388, 391, 135], 537: [384, 385, 388, 391, 135], 538: [384, 385, 388, 391, 135], 539: [384, 385, 388, 391, 135], 540: [384, 385, 388, 391, 135], 541: [384, 385, 388, 391, 135], 542: [384, 385, 388, 391, 135], 543: [384, 385, 388, 391, 135], 544: [384, 385, 388, 391, 135], 545: [384, 385, 388, 391, 135], 546: [384, 385, 388, 391, 135], 547: [384, 385, 388, 391, 135], 550: [384, 385, 388, 391, 135], 551: [384, 385, 388, 391, 135], 552: [384, 385, 388, 391, 135], 554: [384, 385, 388, 391, 135], 555: [384, 385, 388, 391, 135], 556: [384, 385, 388, 391, 135], 557: [384, 385, 388, 391, 135], 558: [384, 385, 388, 391, 135], 559: [384, 385, 388, 391, 135], 560: [384, 385, 388, 391, 135], 561: [384, 385, 388, 391, 135], 562: [384, 385, 388, 391, 135], 563: [384, 385, 388, 391, 135], 564: [384, 385, 388, 391, 135], 566: [384, 385, 388, 391, 135], 567: [384, 385, 388, 391, 135], 568: [384, 385, 388, 391, 135], 570: [384, 385, 388, 391, 135], 571: [384, 385, 388, 391, 135], 572: [384, 385, 388, 391, 135], 573: [384, 385, 388, 391, 135], 575: [384, 385, 388, 391, 135], 576: [384, 385, 388, 391, 135], 577: [384, 385, 388, 391, 135], 578: [384, 385, 388, 391, 135], 579: [384, 385, 388, 391, 135], 580: [384, 385, 388, 391, 135], 581: [384, 385, 388, 391, 135], 582: [384, 385, 388, 391, 135], 583: [384, 385, 388, 391, 135], 584: [384, 385, 388, 391, 135], 585: [384, 385, 388, 391, 135], 586: [384, 385, 388, 391, 135], 587: [384, 385, 388, 391, 135], 590: [384, 385, 388, 391, 135], 592: [384, 385, 388, 391, 135], 593: [384, 385, 388, 391, 135], 594: [384, 385, 388, 391, 135], 595: [384, 385, 388, 391, 135], 596: [384, 385, 388, 391, 135], 597: [384, 385, 388, 391, 135], 598: [384, 385, 388, 391, 135], 599: [384, 385, 388, 391, 135], 600: [384, 385, 388, 391, 135], 601: [384, 385, 388, 391, 135], 602: [384, 385, 388, 391, 135], 603: [384, 385, 388, 391, 135], 604: [384, 385, 388, 391, 135], 605: [384, 385, 388, 391, 135], 606: [384, 385, 388, 391, 135], 607: [384, 385, 388, 391, 135], 608: [384, 385, 388, 391, 135], 609: [384, 385, 388, 391, 135], 610: [384, 385, 388, 391, 135]}\n"
     ]
    }
   ],
   "source": [
    "def predict_user_ratings_and_recommendations(item_user_matrix, item_neighborhood, classified_ratings, top_n=5):\n",
    "    \"\"\"\n",
    "    Predict ratings for users based on the majority class label in the item neighborhood.\n",
    "    Also, generate item recommendations for each user.\n",
    "\n",
    "    Parameters:\n",
    "        item_user_matrix (pandas.DataFrame): User-item matrix containing ratings or interactions.\n",
    "        item_neighborhood (dict): Dictionary containing similar items for each item.\n",
    "        classified_ratings (dict): Classified ratings for each item.\n",
    "        top_n (int): Number of top recommendations to generate (default is 5).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing predicted ratings for each user and recommended items.\n",
    "    \"\"\"\n",
    "    user_ratings = {}\n",
    "    user_recommendations = {}\n",
    "\n",
    "    for user_id, user_interactions in item_user_matrix.iterrows():\n",
    "        ratings = {}\n",
    "        recommendations = []\n",
    "\n",
    "        # Iterate over the items interacted by the user\n",
    "        for item_id, interaction in user_interactions.items():\n",
    "            # Check if the item has a classified rating and is in the item neighborhood\n",
    "            if item_id in classified_ratings and item_id in item_neighborhood:\n",
    "                # Get the classified rating for the item\n",
    "                classified_rating = classified_ratings[item_id]\n",
    "                # Add the classified rating to the user's ratings\n",
    "                ratings[item_id] = classified_rating\n",
    "                # Add the item to recommendations\n",
    "                recommendations.extend(item_neighborhood[item_id][:top_n])\n",
    "\n",
    "        # Determine the top recommended items for the user\n",
    "        recommendations = list(set(recommendations))  # Remove duplicates\n",
    "        recommendations = [item_id for item_id in recommendations if item_id not in user_interactions.index]  # Remove items already interacted by the user\n",
    "        user_recommendations[user_id] = recommendations[:top_n]\n",
    "\n",
    "        # Assign the predicted ratings to the user\n",
    "        user_ratings[user_id] = ratings\n",
    "\n",
    "    return user_ratings, user_recommendations\n",
    "\n",
    "# Example usage:\n",
    "predicted_user_ratings, user_recommendations = predict_user_ratings_and_recommendations(item_user_matrix, item_neighborhood, classified_ratings)\n",
    "print(\"Predicted ratings for users:\", predicted_user_ratings)\n",
    "print(\"Recommended items for users:\", user_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate Model Performance\n",
    "\n",
    "- Assess the performance of the ItemKNN classifier using evaluation metrics such as accuracy, precision, recall, F1-score, or area under the ROC curve (AUC).\n",
    "- Compare the performance of different models with varying neighborhood sizes or similarity metrics to identify the optimal configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.14244746479420914\n",
      "Root Mean Squared Error (RMSE): 0.43205576049998556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model_performance(train_matrix, classified_ratings):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) \n",
    "    on the train split.\n",
    "\n",
    "    Parameters:\n",
    "        train_matrix (numpy.ndarray): Item-user matrix from the training data.\n",
    "        classified_ratings (dict): Dictionary containing classified ratings for each item.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing MAE and RMSE\n",
    "    \"\"\"\n",
    "    # Convert train matrix DataFrame to NumPy array\n",
    "    train_matrix_array = train_matrix.to_numpy()\n",
    "\n",
    "    # Flatten the train matrix\n",
    "    actual_ratings = train_matrix_array.flatten()\n",
    "\n",
    "    # Filter out NaN values\n",
    "    valid_indices = ~np.isnan(actual_ratings)\n",
    "    actual_ratings = actual_ratings[valid_indices]\n",
    "\n",
    "    # Convert classified ratings dictionary to numpy array\n",
    "    predicted_ratings = np.array([classified_ratings.get(i, np.nan) for i in range(len(actual_ratings))])\n",
    "\n",
    "    # Filter out NaN values in predicted ratings\n",
    "    valid_predicted_indices = ~np.isnan(predicted_ratings)\n",
    "    actual_ratings = actual_ratings[valid_predicted_indices]\n",
    "    predicted_ratings = predicted_ratings[valid_predicted_indices]\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = np.mean(np.abs(actual_ratings - predicted_ratings))\n",
    "\n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(np.mean((actual_ratings - predicted_ratings) ** 2))\n",
    "\n",
    "    return mae, rmse\n",
    "\n",
    "# Example usage:\n",
    "# Assuming train_matrix and classified_ratings are properly defined\n",
    "mae, rmse = evaluate_model_performance(train_matrix, classified_ratings)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Parameter Tuning\n",
    "\n",
    "Experiment with different parameters such as similarity threshold, neighborhood size, and similarity metric to optimize the performance of your ItemKNN algorithm.\n",
    "Use techniques like cross-validation to tune these parameters and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jaume\\anaconda3\\envs\\SDM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;cosine&#x27;, &#x27;euclidean&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method=&#x27;predict&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: NearestNeighbors</label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=NearestNeighbors(),\n",
       "             param_grid={'metric': ['cosine', 'euclidean'],\n",
       "                         'n_neighbors': [5, 10, 15, 30, 40]},\n",
       "             scoring=make_scorer(cosine_similarity, response_method='predict'))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'cosine', 'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to compute cosine similarity\n",
    "def cosine_similarity(X, Y):\n",
    "    \"\"\"\n",
    "    This function computes the cosine similarity between two vectors X and Y.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): First vector\n",
    "        Y (ndarray): Second vector\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity between X and Y\n",
    "    \"\"\"\n",
    "    return np.dot(X, Y) / (np.linalg.norm(X) * np.linalg.norm(Y))\n",
    "\n",
    "# Define a custom scorer based on cosine similarity\n",
    "cosine_similarity_scorer = make_scorer(cosine_similarity)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 15, 30, 40],\n",
    "    'metric': ['cosine', 'euclidean']\n",
    "}\n",
    "\n",
    "# Initialize NearestNeighbors model\n",
    "knn_model_classification = NearestNeighbors()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn_model_classification, param_grid, cv=5, scoring=cosine_similarity_scorer)\n",
    "\n",
    "# Fit the data to perform hyperparameter tuning\n",
    "grid_search.fit(item_user_matrix)  # item_user_matrix contains item-item similarity matrix\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_classification = grid_search.best_params_\n",
    "\n",
    "print(\"Best parameters:\", best_params_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Deployment\n",
    "\n",
    "- If you want to predict the class labels for new items, repeat steps 4 and 5 using the entire dataset (training + testing) to build the final model.\n",
    "- Use the trained model to predict the class labels for new items based on their nearest neighbors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
