{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # to make jupyter print all outputs, not just the last one\n",
    "from IPython.core.display import HTML # to pretty print pandas df and be able to copy them over (e.g. to ppt slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('cleaned/movielens_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting and importing in parquet leaded to the the conversion of the lists in movielens data in review_data column to numpy arrays. We need to convert them back to lists to use the same approach as Netflix to take samples.\n",
    "\n",
    "*@Jaume maybe for you this is not the case because you have ios.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays to lists in the 'review_data' column\n",
    "df['review_data'] = df['review_data'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count the number of dictionaries per row in the review_data column, replacing NaN with 0\n",
    "df['num_reviews'] = df['review_data'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Step 2: Divide the dataset into strata based on the number of reviews for each movie\n",
    "quintiles = df['num_reviews'].quantile([0, 0.20, 0.40, 0.60, 0.80, 1.0])\n",
    "\n",
    "# Adjust the boundaries to ensure monotonic increase\n",
    "stratum_boundaries = [0, quintiles[0.20], quintiles[0.40], quintiles[0.60], quintiles[0.80], quintiles[1.0]]\n",
    "stratum_labels = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']\n",
    "\n",
    "# Create a new column to categorize movies into strata based on the number of reviews\n",
    "df['review_stratum'] = pd.cut(df['num_reviews'], bins=stratum_boundaries, labels=stratum_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sampled_df = df[df.columns]\n",
    "\n",
    "# Step 1: Count the number of dictionaries per row in the review_data column\n",
    "sampled_df['num_reviews'] = df['review_data'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Step 2: Divide the dataset into strata based on the number of reviews for each movie\n",
    "quintiles = sampled_df['num_reviews'].quantile([0, 0.20, 0.40, 0.60, 0.80, 1.0])\n",
    "# Adjust the boundaries to include fewer movies with a large number of reviews\n",
    "stratum_boundaries = [0, quintiles[0.20], quintiles[0.40], quintiles[0.60], quintiles[0.80], quintiles[1.0]]\n",
    "stratum_labels = ['Q1', 'Q2', 'Q3', 'Q4','Q5']\n",
    "\n",
    "# Create a new column to categorize movies into strata based on the number of reviews\n",
    "sampled_df['review_stratum'] = pd.cut(sampled_df['num_reviews'], bins=stratum_boundaries, labels=stratum_labels)\n",
    "\n",
    "# Step 3: Define sample size per stratum\n",
    "sample_size_per_stratum = 30\n",
    "\n",
    "# Step 4: Within each stratum, apply random sampling techniques to select movies\n",
    "sampled_movies = []\n",
    "\n",
    "# Iterate over each stratum\n",
    "for stratum in sampled_df['review_stratum'].dropna().unique():  # Drop NaN values\n",
    "    # Filter movies in the current stratum\n",
    "    stratum_movies = sampled_df[sampled_df['review_stratum'] == stratum]\n",
    "    \n",
    "    # Apply simple random sampling to select movies within the stratum\n",
    "    sampled_indices = random.sample(list(stratum_movies.index), sample_size_per_stratum)\n",
    "    sampled_movies.extend(sampled_indices)\n",
    "\n",
    "# Step 5: Create the sampled DataFrame\n",
    "sampled_df_movielens = sampled_df.loc[sampled_movies, ['movieId', 'review_data', 'genres', 'year', 'title', 'review_stratum','num_reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6439 reviews in the sampled dataframe.\n",
      "There are 5660 unique users who have reviewed a movie.\n",
      "There are 150 movieIds in the sampled dataset.\n",
      "A unique user places 1 reviews on average in the sampled dataset.\n",
      "A movieId receives 43 reviews on average in the sampled dataset.\n"
     ]
    }
   ],
   "source": [
    "# Extract all user IDs from the 'review_data' column using list comprehension\n",
    "user_ids = [review_entry.get('userId') for row in sampled_df_movielens['review_data'] for review_entry in row if review_entry.get('userId')]\n",
    "\n",
    "# Count the number of unique users and reviews\n",
    "unique_users = set(user_ids)\n",
    "amount_of_reviews = len(user_ids)\n",
    "\n",
    "# Calculate averages\n",
    "avg_reviews_per_unique_user = amount_of_reviews / len(unique_users)\n",
    "avg_reviews_per_movie_id = amount_of_reviews / len(sampled_df_movielens)\n",
    "\n",
    "# Print results\n",
    "print(\"There are {} reviews in the sampled dataframe.\".format(amount_of_reviews))\n",
    "print(\"There are {} unique users who have reviewed a movie.\".format(len(unique_users)))\n",
    "print(\"There are {} movieIds in the sampled dataset.\".format(len(sampled_df_movielens)))\n",
    "print(\"A unique user places {} reviews on average in the sampled dataset.\".format(round(avg_reviews_per_unique_user)))\n",
    "print(\"A movieId receives {} reviews on average in the sampled dataset.\".format(round(avg_reviews_per_movie_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test Results:\n",
      "Stratum: Q5\n",
      "T-statistic: -1.1485336059970532\n",
      "P-value: 0.2507756318586446\n",
      "The difference in means is not statistically significant (fail to reject the null hypothesis)\n",
      "Stratum: Q4\n",
      "T-statistic: 1.0565563376798446\n",
      "P-value: 0.29074414710912544\n",
      "The difference in means is not statistically significant (fail to reject the null hypothesis)\n",
      "Stratum: Q3\n",
      "T-statistic: -1.41383355660149\n",
      "P-value: 0.1574657668091603\n",
      "The difference in means is not statistically significant (fail to reject the null hypothesis)\n",
      "Stratum: Q2\n",
      "T-statistic: nan\n",
      "P-value: nan\n",
      "The difference in means is not statistically significant (fail to reject the null hypothesis)\n",
      "Stratum: Q1\n",
      "T-statistic: nan\n",
      "P-value: nan\n",
      "The difference in means is not statistically significant (fail to reject the null hypothesis)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SJYHa\\Desktop\\venv_ddb\\ddb_pymer4\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Define the strata\n",
    "strata = sampled_df_movielens['review_stratum'].unique()\n",
    "\n",
    "# Perform t-tests for each stratum\n",
    "t_statistics = {}\n",
    "p_values = {}\n",
    "for stratum in strata:\n",
    "    # Extract the 'num_reviews' column for the current stratum\n",
    "    sampled_num_reviews_stratum = sampled_df_movielens[sampled_df_movielens['review_stratum'] == stratum]['num_reviews']\n",
    "    population_num_reviews_stratum = df[df['review_stratum'] == stratum]['num_reviews']\n",
    "    \n",
    "    # Perform the t-test\n",
    "    t_statistic, p_value = ttest_ind(sampled_num_reviews_stratum, population_num_reviews_stratum)\n",
    "    \n",
    "    # Store the results\n",
    "    t_statistics[stratum] = t_statistic\n",
    "    p_values[stratum] = p_value\n",
    "\n",
    "# Print the results\n",
    "print(\"T-test Results:\")\n",
    "for stratum in strata:\n",
    "    print(f\"Stratum: {stratum}\")\n",
    "    print(f\"T-statistic: {t_statistics[stratum]}\")\n",
    "    print(f\"P-value: {p_values[stratum]}\")\n",
    "    alpha = 0.05\n",
    "    if p_values[stratum] < alpha:\n",
    "        print(\"The difference in means is statistically significant (reject the null hypothesis)\")\n",
    "    else:\n",
    "        print(\"The difference in means is not statistically significant (fail to reject the null hypothesis)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in mean betweens sample and df is not significant, meaning the sample is representatitve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df_movielens.to_parquet('cleaned/strat_sample_movielens')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
