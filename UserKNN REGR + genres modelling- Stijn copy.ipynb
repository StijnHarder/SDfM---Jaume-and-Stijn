{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # to make jupyter print all outputs, not just the last one\n",
    "from IPython.core.display import HTML # to pretty print pandas df and be able to copy them over (e.g. to ppt slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_df = pd.read_parquet('cleaned/netflix_parquet')\n",
    "movielens_df = pd.read_parquet('cleaned/movielens_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix_df = netflix_df[netflix_df['review_data'].apply(lambda x: len(x) if x is not None else 0) > 500]\n",
    "netflix_df = netflix_df[netflix_df['review_data'].apply(lambda x: 30 <= len(x) <= 375 if x is not None else False)]\n",
    "movielens_df = movielens_df[movielens_df['review_data'].apply(lambda x: 30 <= len(x) <= 375 if x is not None else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>review_data</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1472</td>\n",
       "      <td>[{'date': 2005-07-19, 'rating': 5.0, 'userId':...</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>428</td>\n",
       "      <td>[{'date': 2005-01-20, 'rating': 4.0, 'userId':...</td>\n",
       "      <td>[Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>[{'date': 2001-05-13, 'rating': 3.0, 'userId':...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>402</td>\n",
       "      <td>[{'date': 2005-05-18, 'rating': 3.0, 'userId':...</td>\n",
       "      <td>[Drama, History, Romance, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>688</td>\n",
       "      <td>[{'date': 2004-05-13, 'rating': 2.0, 'userId':...</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>828</td>\n",
       "      <td>[{'date': 2004-03-27, 'rating': 5.0, 'userId':...</td>\n",
       "      <td>[Documentary, Music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1940</td>\n",
       "      <td>[{'date': 2005-07-11, 'rating': 5.0, 'userId':...</td>\n",
       "      <td>[Drama, Film-Noir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>[{'date': 2005-08-17, 'rating': 3.0, 'userId':...</td>\n",
       "      <td>[Crime, Drama, Film-Noir, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>1611</td>\n",
       "      <td>[{'date': 2003-08-25, 'rating': 4.0, 'userId':...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>1720</td>\n",
       "      <td>[{'date': 2004-06-08, 'rating': 4.0, 'userId':...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                        review_data  \\\n",
       "1471     1472  [{'date': 2005-07-19, 'rating': 5.0, 'userId':...   \n",
       "427       428  [{'date': 2005-01-20, 'rating': 4.0, 'userId':...   \n",
       "145       146  [{'date': 2001-05-13, 'rating': 3.0, 'userId':...   \n",
       "401       402  [{'date': 2005-05-18, 'rating': 3.0, 'userId':...   \n",
       "687       688  [{'date': 2004-05-13, 'rating': 2.0, 'userId':...   \n",
       "827       828  [{'date': 2004-03-27, 'rating': 5.0, 'userId':...   \n",
       "1939     1940  [{'date': 2005-07-11, 'rating': 5.0, 'userId':...   \n",
       "185       186  [{'date': 2005-08-17, 'rating': 3.0, 'userId':...   \n",
       "1610     1611  [{'date': 2003-08-25, 'rating': 4.0, 'userId':...   \n",
       "1719     1720  [{'date': 2004-06-08, 'rating': 4.0, 'userId':...   \n",
       "\n",
       "                                   genres  \n",
       "1471                        [Documentary]  \n",
       "427                              [Family]  \n",
       "145                                  None  \n",
       "401        [Drama, History, Romance, War]  \n",
       "687                         [Documentary]  \n",
       "827                  [Documentary, Music]  \n",
       "1939                   [Drama, Film-Noir]  \n",
       "185   [Crime, Drama, Film-Noir, Thriller]  \n",
       "1610                                 None  \n",
       "1719                                 None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>review_data</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>4736</td>\n",
       "      <td>[{'date': 2003-02-06, 'rating': 1.0, 'userId':...</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>5505</td>\n",
       "      <td>[{'date': 2005-06-27, 'rating': 3.5, 'userId':...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056</th>\n",
       "      <td>7235</td>\n",
       "      <td>[{'date': 2010-12-29, 'rating': 4.5, 'userId':...</td>\n",
       "      <td>[Action, Comedy, Crime, Drama, Horror, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>901</td>\n",
       "      <td>[{'date': 2007-06-15, 'rating': 5.0, 'userId':...</td>\n",
       "      <td>[Comedy, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23737</th>\n",
       "      <td>130636</td>\n",
       "      <td>[{'date': 2016-08-03, 'rating': 3.5, 'userId':...</td>\n",
       "      <td>[Horror, Mystery, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8029</th>\n",
       "      <td>8815</td>\n",
       "      <td>[{'date': 2007-03-08, 'rating': 1.5, 'userId':...</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4644</th>\n",
       "      <td>4769</td>\n",
       "      <td>[{'date': 2003-04-14, 'rating': 3.0, 'userId':...</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>3249</td>\n",
       "      <td>[{'date': 2007-02-03, 'rating': 2.0, 'userId':...</td>\n",
       "      <td>[Drama, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>7019</td>\n",
       "      <td>[{'date': 2004-08-09, 'rating': 0.5, 'userId':...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>27156</td>\n",
       "      <td>[{'date': 2022-01-20, 'rating': 4.0, 'userId':...</td>\n",
       "      <td>[Action, Animation, Drama, Fantasy, Sci-Fi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                        review_data  \\\n",
       "4611      4736  [{'date': 2003-02-06, 'rating': 1.0, 'userId':...   \n",
       "5373      5505  [{'date': 2005-06-27, 'rating': 3.5, 'userId':...   \n",
       "7056      7235  [{'date': 2010-12-29, 'rating': 4.5, 'userId':...   \n",
       "878        901  [{'date': 2007-06-15, 'rating': 5.0, 'userId':...   \n",
       "23737   130636  [{'date': 2016-08-03, 'rating': 3.5, 'userId':...   \n",
       "8029      8815  [{'date': 2007-03-08, 'rating': 1.5, 'userId':...   \n",
       "4644      4769  [{'date': 2003-04-14, 'rating': 3.0, 'userId':...   \n",
       "3147      3249  [{'date': 2007-02-03, 'rating': 2.0, 'userId':...   \n",
       "6842      7019  [{'date': 2004-08-09, 'rating': 0.5, 'userId':...   \n",
       "8997     27156  [{'date': 2022-01-20, 'rating': 4.0, 'userId':...   \n",
       "\n",
       "                                                 genres  \n",
       "4611                           [Comedy, Drama, Romance]  \n",
       "5373                                    [Comedy, Drama]  \n",
       "7056   [Action, Comedy, Crime, Drama, Horror, Thriller]  \n",
       "878                                   [Comedy, Musical]  \n",
       "23737                       [Horror, Mystery, Thriller]  \n",
       "8029                                 [Horror, Thriller]  \n",
       "4644                                      [Documentary]  \n",
       "3147                                  [Drama, Thriller]  \n",
       "6842                                    [Comedy, Drama]  \n",
       "8997        [Action, Animation, Drama, Fantasy, Sci-Fi]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (netflix_df.sample(n=n_rows,random_state=42))[['movieId','review_data','genres']]\n",
    "df\n",
    "df2 = (movielens_df.sample(n=n_rows,random_state=42))[['movieId','review_data','genres']]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289 unique userIds are handled from the Netflix dataset.\n",
      "10 unique movieIds are handled from the Netflix dataset.\n",
      "\n",
      "1627 unique userIds are handled from the Movielens dataset.\n",
      "10 unique movieIds are handled from the Movielens dataset.\n"
     ]
    }
   ],
   "source": [
    "# netflix\n",
    "review_data = df['review_data'].values\n",
    "user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(df['movieId'], review_data)])\n",
    "print(f\"{len(user_ids)} unique userIds are handled from the Netflix dataset.\")\n",
    "print(f\"{len(np.unique(movieIds))} unique movieIds are handled from the Netflix dataset.\")\n",
    "print()\n",
    "\n",
    "# movielens\n",
    "review_data2 = df2['review_data'].values\n",
    "user_ids2 = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data2])\n",
    "ratings2 = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data2])\n",
    "movieIds2 = np.concatenate([[movieId] * len(row) for movieId, row in zip(df['movieId'], review_data2)])\n",
    "print(f\"{len(user_ids2)} unique userIds are handled from the Movielens dataset.\")\n",
    "print(f\"{len(np.unique(movieIds2))} unique movieIds are handled from the Movielens dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train,validation and test split:\n",
    "\n",
    "### Function Explanation\n",
    "\n",
    "`train_val_test_split`\n",
    "\n",
    "1. **Shuffle the Data**:\n",
    "   - The input data is shuffled using `data.sample(frac=1, random_state=42)` to ensure randomness. `random_state=42` ensures reproducibility.\n",
    "\n",
    "2. **Calculate Set Sizes**:\n",
    "   - The sizes of each set (training, validation, and test) are calculated based on the provided ratios and the total number of samples in the data.\n",
    "\n",
    "3. **Split the Data**:\n",
    "   - The shuffled data is split into three sets: training, validation, and test.\n",
    "   - The training data contains the first `num_train` samples.\n",
    "   - The validation data contains the next `num_val` samples, starting from the index immediately following the last training sample.\n",
    "   - The test data contains the remaining samples, starting from the index immediately following the last validation sample.\n",
    "\n",
    "4. **Reset Index**:\n",
    "   - The index of each set is reset to ensure that it starts from 0 and increases incrementally.\n",
    "\n",
    "5. **Return Sets**:\n",
    "   - The function returns the training, validation, and test sets as pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(data, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits the data into training, validation, and test sets, simultaneously ensuring no training data flows into validation or test data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data to be split.\n",
    "    - train_ratio: float, ratio of the training set size to the total data size (default: 0.8).\n",
    "    - val_ratio: float, ratio of the validation set size to the total data size (default: 0.1).\n",
    "    - test_ratio: float, ratio of the test set size to the total data size (default: 0.1).\n",
    "\n",
    "    Returns:\n",
    "    - train_data: pandas DataFrame, training set.\n",
    "    - val_data: pandas DataFrame, validation set.\n",
    "    - test_data: pandas DataFrame, test set.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    data_shuffled = data.sample(frac=1, random_state=42)\n",
    "\n",
    "    # Calculate the sizes of each set\n",
    "    num_samples = len(data_shuffled)\n",
    "    num_train = int(train_ratio * num_samples)\n",
    "    num_val = int(val_ratio * num_samples)\n",
    "    num_test = num_samples - num_train - num_val\n",
    "\n",
    "    # Split the data into train, validation, and test sets\n",
    "    train_data = data_shuffled[:num_train]\n",
    "    # Below is ensured the validation data and the test data starts after the indices which are already in the training data, ensuring that no training data will flow into validation of test data.\n",
    "    val_data = data_shuffled[num_train:num_train+num_val]\n",
    "    test_data = data_shuffled[num_train+num_val:]\n",
    "\n",
    "    # Reset index for each set\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    val_data.reset_index(drop=True, inplace=True)\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up user-item matrix\n",
    "First we will create a user-item matrix which records all the user-item interactions.\n",
    "\n",
    "\n",
    "### `create_user_item_matrix` Function Explanation\n",
    "\n",
    "### Steps:\n",
    "1. **Extract Review Data**:\n",
    "   - Extract the review data from the provided DataFrame, which contains user IDs, ratings, and movie IDs.\n",
    "\n",
    "2. **Create User and Movie IDs Arrays**:\n",
    "   - Extract user IDs, ratings, and movie IDs from the review data and concatenate them into separate arrays.\n",
    "   - Generate dictionaries to map user IDs and movie IDs to unique indices in the user-item matrix.\n",
    "\n",
    "3. **Initialize User-Item Matrix**:\n",
    "   - Determine the dimensions of the user-item matrix based on the number of unique users and movies.\n",
    "   - Initialize an empty user-item matrix filled with NaN values.\n",
    "\n",
    "4. **Populate User-Item Matrix**:\n",
    "   - Iterate through the review data and populate the user-item matrix with ratings.\n",
    "   - Map user and movie IDs to their corresponding indices in the matrix and insert the ratings.\n",
    "\n",
    "5. **Return Results**:\n",
    "   - Return the user-item matrix along with dictionaries mapping user and movie IDs to indices, and arrays containing user and movie IDs.\n",
    "  \n",
    "### Functions Used and Purpose:\n",
    "\n",
    "- **`np.concatenate()`**: Used to concatenate arrays containing user IDs, ratings, and movie IDs extracted from the review data.\n",
    "- **`enumerate()`**: Used to iterate over the unique user IDs and movie IDs and generate indices for mapping.\n",
    "- **`np.unique()`**: Used to find the unique user IDs and movie IDs in the review data.\n",
    "- **`np.full()`**: Used to initialize an empty user-item matrix filled with NaN values.\n",
    "- **`zip()`**: Used to iterate over multiple iterables simultaneously (user IDs, movie IDs, ratings).\n",
    "- **`enumerate()`**: Used to iterate over the indices and elements of an iterable (user IDs, movie IDs) simultaneously.\n",
    "- **Indexing and Slicing**: Used to access and modify elements in arrays and matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(train_test_val_set):\n",
    "    \"\"\"\n",
    "    Creates a user-item matrix from the provided dataset containing review data.\n",
    "\n",
    "    Parameters:\n",
    "    train_test_val_set (DataFrame): DataFrame containing review data with columns 'review_data',\n",
    "                                    which is a list of dictionaries with keys 'userId', 'rating',\n",
    "                                    and 'movieId'.\n",
    "\n",
    "    Returns:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies), the matrix is an NumPy array which contains lists of user-item interactions, meaning a user and their corresponding ratings to the movieIds.    \n",
    "    \n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    \n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    \n",
    "    user_ids (numpy.ndarray): Array containing user IDs corresponding to each rating in the matrix.\n",
    "    \n",
    "    movie_ids (numpy.ndarray): Array containing movie IDs corresponding to each rating in the matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    train_test_val_set = train_test_val_set.drop(['genres'],axis=1)\n",
    "    review_data = train_test_val_set['review_data'].values\n",
    "    user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in review_data])\n",
    "    ratings = np.concatenate([np.array([entry['rating'] for entry in row]) for row in review_data])\n",
    "    movieIds = np.concatenate([[movieId] * len(row) for movieId, row in zip(train_test_val_set['movieId'], review_data)])\n",
    "\n",
    "    # create dictionaries to map user IDs and movie IDs to unique indices to map over\n",
    "    user_id_dict = {user_id: index for index, user_id in enumerate(np.unique(user_ids))}\n",
    "    movie_id_dict = {movie_id: index for index, movie_id in enumerate(np.unique(movieIds))}\n",
    "\n",
    "    # initialize an empty user-item matrix\n",
    "    user_count = len(user_id_dict)\n",
    "    movie_count = len(movie_id_dict)\n",
    "    user_item_matrix = np.full((user_count, movie_count), np.nan)\n",
    "\n",
    "    # populate the user-item matrix with ratings from the dataset\n",
    "    for i, (user_id, movie_id, rating) in enumerate(zip(user_ids, movieIds, ratings)):\n",
    "        user_index = user_id_dict[user_id]\n",
    "        movie_index = movie_id_dict[movie_id]\n",
    "        user_item_matrix[user_index, movie_index] = rating\n",
    "\n",
    "    return user_item_matrix, user_id_dict, movie_id_dict, user_ids, movieIds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous two notebooks about userKNN we only included the similarties of rating patterns, so to compute similarity only the regular user-item matrix was needed. Now we want to include genre preference as well. Before we can include it in the similarity calculation, we first need to initiate a user-genre matrix with 0s and 1s indicating a user has watched a movie with that genre.\n",
    "\n",
    "### Function explanation:\n",
    "\n",
    "`create_user_genre_matrix`\n",
    "\n",
    "1. **Extracting User IDs and Unique Genres**:\n",
    "   - It collects user IDs from the `review_data` column of the DataFrame `df` and gathers unique genres from the `genres` column.\n",
    "\n",
    "2. **Creating Indexing Dictionaries**:\n",
    "   - Two dictionaries are created:\n",
    "     - `genre_to_index`: Maps genres to their respective indices.\n",
    "     - `movieid_to_genres`: Maps movie IDs to their associated genres.\n",
    "\n",
    "3. **Initializing User-Genre Matrix**:\n",
    "   - It initializes a matrix, `user_genre_matrix`, with dimensions `(num_users, num_genres)` to represent users' genre preferences.\n",
    "\n",
    "4. **Mapping User IDs to Indices**:\n",
    "   - A dictionary, `user_id_to_index`, is created to map each user ID to a unique index in the `user_genre_matrix`.\n",
    "\n",
    "5. **Iterating Through Users**:\n",
    "   - The function iterates through each user in the dataset and extracts movie IDs reviewed by that user.\n",
    "\n",
    "6. **Updating User-Genre Matrix**:\n",
    "   - For each user, it finds the genres associated with the reviewed movies and updates the corresponding entries in the `user_genre_matrix` to indicate the user's genre preferences.\n",
    "\n",
    "7. **Returning User-Genre Matrix**:\n",
    "   - Finally, it returns the populated `user_genre_matrix`, which can be used in collaborative filtering recommendation systems to incorporate genre information into the recommendation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_genre_matrix(df):\n",
    "    \"\"\"\n",
    "    Create a user-genre matrix based on movie reviews in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing movie review data.\n",
    "\n",
    "    Returns:\n",
    "    user_genre_matrix (numpy.ndarray): Matrix representing users' genre preferences.\n",
    "    \n",
    "    This function extracts user IDs and unique genres from the DataFrame and constructs a user-genre matrix based on the movies reviewed by each user.\n",
    "    It iterates through each user in the dataset, extracts the movie IDs reviewed by that user, and finds the genres associated with those movie IDs.\n",
    "    Then, it updates the user-genre matrix based on the genre interactions, where each row represents a user and each column represents a genre.\n",
    "    The values in the matrix indicate whether a user has reviewed a movie belonging to a particular genre (1 if yes, 0 if no).\n",
    "    \"\"\"\n",
    "\n",
    "    user_ids = np.concatenate([np.array([entry['userId'] for entry in row]) for row in df['review_data'].values])\n",
    "    unique_genres = set(genre for sublist in df['genres'] if sublist is not None for genre in sublist)\n",
    "    \n",
    "    genre_to_index = {genre: index for index, genre in enumerate(unique_genres)}\n",
    "    movieid_to_genres = dict(zip(df['movieId'], df['genres']))\n",
    "    \n",
    "    num_users = len(np.unique(user_ids))\n",
    "    num_genres = len(unique_genres)\n",
    "    user_genre_matrix = np.zeros((num_users, num_genres))\n",
    "    \n",
    "    user_id_to_index = {user_id: index for index, user_id in enumerate(np.unique(user_ids))}\n",
    "    \n",
    "    for i, user_id in enumerate(np.unique(user_ids)):\n",
    "        user_reviews = df[df['review_data'].apply(lambda x: any(entry['userId'] == user_id for entry in x))]\n",
    "        reviewed_movie_ids = user_reviews['movieId'].values\n",
    "        \n",
    "        user_genres = []\n",
    "        for movie_id in reviewed_movie_ids:\n",
    "            genres = movieid_to_genres.get(movie_id)\n",
    "            if genres is not None:\n",
    "                user_genres.extend(genres)\n",
    "        \n",
    "        for genre in user_genres:\n",
    "            if genre in genre_to_index:\n",
    "                genre_index = genre_to_index[genre]\n",
    "                user_genre_matrix[user_id_to_index[user_id], genre_index] = 1\n",
    "    \n",
    "    return user_genre_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now we will compute the similarity between ratings patterns AND genre preferences of users:\n",
    "\n",
    "### Compute similarity:\n",
    "Regularly, cosine similarity is often used to measure the similarity between users based on their preferences or ratings for items (in this case, movies). Cosine similarity ranges from -1 to 1, where:\n",
    "\n",
    "- 1 indicates perfect similarity,\n",
    "- 0 indicates no similarity, and\n",
    "- -1 indicates perfect dissimilarity.\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Positive Cosine Similarity**: Users are similar in their preferences or ratings for movies.\n",
    "- **Zero Cosine Similarity**: Users have no similarity in their preferences.\n",
    "- **Negative Cosine Similarity**: Users are dissimilar in their preferences, tending towards opposite ratings for movies.\n",
    "\n",
    "### Practical Implication:\n",
    "\n",
    "If one user likes certain types of movies, the other user tends to dislike them, or vice versa. In other words, users with negative cosine similarities have contrasting preferences, making them less suitable for recommending movies to each other.\n",
    "\n",
    "_____ \n",
    "In the function below we will include genre preference as a binary vector when computing the similarity between users. The dot product of row factors of users essentially is added up by one more row vector in terms of genre preference per user. As long as the rows of the shape of the matrix stay the same, we could think of adding more user features to compute user similarity.\n",
    "\n",
    "### Function explanation\n",
    "\n",
    "`calculate_similarity_users_genres`\n",
    "\n",
    "1. **Filling Missing Data**: \n",
    "   - The function fills missing values in the `user_ratings_matrix` and `user_genre_matrix` with zeros. This is necessary to ensure consistency in subsequent calculations.\n",
    "\n",
    "2. **Computing Dot Products**:\n",
    "   - It computes the dot product of each pair of row vectors in the `user_ratings_matrix` to capture the similarity between users based on their ratings for items. This is done considering only values above a specified threshold, indicating the relevance of ratings.\n",
    "   - Additionally, it computes the dot product of `user_genre_matrix` to incorporate user genre preferences. This captures the similarity between users based on their genre preferences.\n",
    "\n",
    "3. **Calculating Norms**:\n",
    "   - The function calculates the norms of each row vector in the `user_ratings_matrix` and `user_genre_matrix`. This represents the magnitude of each user's ratings and genre preferences, respectively.\n",
    "   - For the ratings matrix, it uses the Manhattan norm, which is the sum of absolute distances.\n",
    "\n",
    "4. **Handling Zero Norms**:\n",
    "   - It replaces zero norms with a small value to avoid division by zero in subsequent calculations. If a user has no ratings for any item or no preference for any genre, their norm would be zero. Replacing it with a small value ensures stability in the calculations.\n",
    "\n",
    "5. **Computing Similarity Matrix**:\n",
    "   - Using broadcasting, the function calculates the similarity matrix. It computes the similarity between users based on both their ratings for items and their genre preferences.\n",
    "   - The similarity between users i and j is given by the dot product of their ratings (divided by the product of their norms) plus the dot product of their genre preferences (divided by the product of their genre norms).\n",
    "\n",
    "6. **Setting Diagonal Elements to 0**:\n",
    "   - Finally, the function sets diagonal elements of the similarity matrix to 0 to avoid self-similarity. This ensures that each user's similarity with themselves is not considered in the recommendation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_users_genres(user_ratings_matrix, user_genre_matrix, threshold):\n",
    "    \"\"\"\n",
    "    Calculate user similarity using Manhattan distance-based similarity measure.\n",
    "\n",
    "    Parameters:\n",
    "    user_ratings_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_genre_matrix (numpy.ndarray): Matrix representing users' genre preferences.\n",
    "    threshold (float): Threshold value for considering ratings in the similarity calculation.\n",
    "\n",
    "    Returns:\n",
    "    similarity_matrix (numpy.ndarray): Matrix representing similarity between users based on the Manhattan distance.\n",
    "\n",
    "    The Manhattan distance-based similarity measure is calculated as follows:\n",
    "    1. Compute the dot product of each pair of row vectors in the user_ratings_matrix, considering only values above the threshold.\n",
    "    2. Calculate the norms of each row vector, considering only values above the threshold.\n",
    "    3. Replace zero norms with a small value to avoid division by zero.\n",
    "    4. Compute the dot product of user_genre_matrix to include genre preferences.\n",
    "    5. Calculate the similarity matrix using broadcasting, where the similarity between users i and j is given by the dot product\n",
    "       divided by the product of their norms and genre preferences.\n",
    "    6. Set diagonal elements to 0 to avoid self-similarity.\n",
    "\n",
    "    \"\"\"\n",
    "    # fill in the missing data with 0s\n",
    "    user_ratings_matrix = np.nan_to_num(user_ratings_matrix, nan=0)\n",
    "    \n",
    "    # fill in the missing data with 0s for user_genre_matrix\n",
    "    user_genre_matrix = np.nan_to_num(user_genre_matrix, nan=0)\n",
    "    \n",
    "    # compute dot product of user_ratings_matrix, in other words: similarity between users and genres by perform dot product of each user row vector containing their ratings\n",
    "    dot_products_ratings = np.dot(np.where(user_ratings_matrix >= threshold, user_ratings_matrix, 0), user_ratings_matrix.T)\n",
    "    \n",
    "    # compute dot product of user_genre_matrix, in other words: similarity between users and genres by perform dot product of each user row vector containing their genre preferences\n",
    "    dot_products_genre = np.dot(user_genre_matrix, user_genre_matrix.T)\n",
    "    \n",
    "    # calculate norms of user_ratings_matrix, using the manhatten norm, which is the sum of the absolute distances\n",
    "    norms_ratings = np.sum(np.abs(np.where(user_ratings_matrix >= threshold, user_ratings_matrix, 0)), axis=1)\n",
    "    \n",
    "    # replace zero norms with a small value to avoid division by zero\n",
    "    norms_ratings[norms_ratings == 0] = 1e-8\n",
    "    \n",
    "    # calculate norms of user_genre_matrix\n",
    "    norms_genre = np.sum(user_genre_matrix, axis=1)\n",
    "    \n",
    "    # Replace zero norms with a small value to avoid division by zero\n",
    "    norms_genre[norms_genre == 0] = 1e-8\n",
    "    \n",
    "    # Compute similarity matrix using broadcasting\n",
    "    similarity_matrix = (dot_products_ratings / norms_ratings[:, None]) + (dot_products_genre / norms_genre[:, None])\n",
    "    \n",
    "    # Set diagonal elements to 0 to avoid self-similarity\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform User-Based KNN - rating prediction\n",
    "\n",
    "The top five recommendations of a user are based on the five highest predicted ratings. The highest rating is found by finding the nearest neighbour based on cosine similarity, followed by computing the weighted average of the rating of the nearest neighbors of the specific item. The items with the highest weighted average will be the five recommendations to the user.\n",
    "\n",
    "### Explanation `generate_user_knn_regressor` function:\n",
    "\n",
    "### Function Workflow\n",
    "1. **Validation**: Checks whether the provided user ID exists in the user ID dictionary. If not found, it returns an empty list.\n",
    "\n",
    "2. **Finding Similar Users**:\n",
    "   - Retrieves the index of the user in the user-item matrix using the user ID.\n",
    "   - Computes the similarity scores between the target user and all other users.\n",
    "   - Selects the top-k most similar users based on similarity scores.\n",
    "\n",
    "3. **Finding Rated Movies by Similar Users**:\n",
    "   - Identifies movies that the similar users have rated.\n",
    "\n",
    "4. **Calculating Weighted Average Ratings**:\n",
    "   - For each movie rated by similar users:\n",
    "     - Computes the weighted sum of ratings, where weights are similarity scores between the target user and similar users.\n",
    "     - Accumulates the sum of similarities.\n",
    "     - Calculates the weighted average rating for each movie.\n",
    "\n",
    "5. **Sorting Recommendations**:\n",
    "   - Sorts movies by their weighted average ratings in descending order.\n",
    "\n",
    "6. **Conversion and Return**:\n",
    "   - Converts movie indices back to movie IDs using the movie ID dictionary.\n",
    "   - Returns a list of recommended movie IDs along with their predicted ratings for the given user.\n",
    "\n",
    "### Explanation numpy functions used:\n",
    "\n",
    "1. `np.argsort()`\n",
    "- **Usage**: `np.argsort(array)`\n",
    "- **Explanation**: Returns the indices that would sort an array in ascending order.\n",
    "- **Example**: `np.argsort([30, 10, 20])` returns `[1, 2, 0]`, indicating that the smallest element is at index 1, the second smallest at index 2, and the largest at index 0.\n",
    "\n",
    "2. `np.where()`\n",
    "- **Usage**: `np.where(condition)`\n",
    "- **Explanation**: Returns the indices where a specified condition is true.\n",
    "- **Example**: `np.where([True, False, True])` returns `(array([0, 2]),)`, indicating that the condition is true at indices 0 and 2.\n",
    "\n",
    "3. `np.isnan()`\n",
    "- **Usage**: `np.isnan(array)`\n",
    "- **Explanation**: Returns a boolean array indicating whether each element is NaN (Not a Number).\n",
    "- **Example**: `np.isnan([1, np.nan, 3])` returns `[False, True, False]`, indicating that the second element is NaN.\n",
    "\n",
    "4. `np.zeros_like()`\n",
    "- **Usage**: `np.zeros_like(array)`\n",
    "- **Explanation**: Returns an array of zeros with the same shape and type as the input array.\n",
    "- **Example**: `np.zeros_like([1, 2, 3])` returns `[0, 0, 0]`, creating an array of zeros with the same shape as `[1, 2, 3]`.\n",
    "\n",
    "5. `np.sum()`\n",
    "- **Usage**: `np.sum(array)`\n",
    "- **Explanation**: Computes the sum of array elements over a specified axis or the entire array.\n",
    "- **Example**: `np.sum([1, 2, 3])` returns `6`, summing all elements in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_knn_regressor(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations for a given user using user-based k-nearest neighbors (KNN) collaborative filtering with weighted average.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    recommendations (list): List of tuples containing recommended movie IDs and their predicted ratings for the given user.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # Find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # calculate the similarity scores between the user and the k nearest neighbours by performing dot product of row vectors of each user with target user\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # find the rated movies by filtering NOT nan values\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # intialize 0 matrix before weighted average computation\n",
    "    weighted_avg_ratings = np.zeros_like(user_item_matrix[0])\n",
    "    similarity_sum = 0\n",
    "    \n",
    "    for movie in rated_movies:\n",
    "        # this loop iterates over each movie rated within the k similar users with the target user and computes the weighted sum of similarities to then compute the weighted average\n",
    "        weighted_sum = np.sum(user_item_matrix[similar_users_indices, movie] * user_similarity_matrix[user_index, similar_users_indices])\n",
    "        similarity_sum += np.sum(user_similarity_matrix[user_index, similar_users_indices])\n",
    "        weighted_avg_ratings[movie] = weighted_sum / similarity_sum if similarity_sum != 0 else 0\n",
    "\n",
    "    # the result is sorted descendingly to find out which movies would be the best recommendations\n",
    "    sorted_indices = np.argsort(weighted_avg_ratings)[::-1]\n",
    "\n",
    "    # convert movie indices back to movie IDs and return recommendations\n",
    "    recommendations_regressor = [(list(movie_id_dict.keys())[list(movie_id_dict.values()).index(movie_index)], weighted_avg_ratings[movie_index])\n",
    "                       for movie_index in sorted_indices[:5]]\n",
    "    return recommendations_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See a first batch of recommendations:\n",
    "\n",
    "By using the functions above to recommend movies above the following results are generated for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_netflix, val_data_netflix, test_data_netflix = train_val_test_split(df)\n",
    "train_data_movielens, val_data_movielens, test_data_movielens = train_val_test_split(df2)\n",
    "\n",
    "# set up paramters and threshold for similarity\n",
    "k=1\n",
    "threshold=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Netflix:`\n",
    "\n",
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN regressor Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 1174811:\n",
      "Movie ID: 1720, Predicted Rating: 0.0\n",
      "Movie ID: 1611, Predicted Rating: 0.0\n",
      "Movie ID: 1472, Predicted Rating: 0.0\n",
      "Movie ID: 828, Predicted Rating: 0.0\n",
      "Movie ID: 688, Predicted Rating: 0.0\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_train1, user_id_dict_train1, movie_id_dict_train1, user_ids_train1, movieIds_train1 = create_user_item_matrix(train_data_netflix)\n",
    "# _, user_ratings_matrix_classified_train1 = computing_neutral_scores(user_item_matrix_train1)\n",
    "netflix_user_genre_matrix_train1 = create_user_genre_matrix(train_data_netflix)\n",
    "similarity_matrix_genres_train1 = calculate_similarity_users_genres(user_item_matrix_train1, netflix_user_genre_matrix_train1, threshold)\n",
    "# user_similarity_matrix_manhattan_train1 = calculate_user_similarity_manhattan(user_item_matrix_train1, threshold)\n",
    "\n",
    "# generate recommendations\n",
    "user_id_train1 = user_ids_train1[1]\n",
    "top5_pred_train1 = generate_user_knn_regressor(user_id_train1, user_item_matrix_train1, similarity_matrix_genres_train1, user_id_dict_train1, movie_id_dict_train1, k)\n",
    "\n",
    "# print result\n",
    "print(f\"UserKNN regressor Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id_train1}:\")\n",
    "for movie_id, predicted_rating in top5_pred_train1:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN regressor Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 1998800:\n",
      "Movie ID: 402, Predicted Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_val1, user_id_dict_val1, movie_id_dict_val1, user_ids_val1, movieIds_val1 = create_user_item_matrix(val_data_netflix)\n",
    "netflix_user_genre_matrix_val1 = create_user_genre_matrix(val_data_netflix)\n",
    "# _, user_ratings_matrix_classified_val1 = computing_neutral_scores(user_item_matrix_val1)\n",
    "# user_similarity_matrix_manhattan_val1 = calculate_user_similarity_manhattan(user_item_matrix_val1, threshold)\n",
    "similarity_matrix_genres_val1 = calculate_similarity_users_genres(user_item_matrix_val1, netflix_user_genre_matrix_val1, threshold)\n",
    "\n",
    "# generate recommendations\n",
    "user_id_val1 = user_ids_val1[1]\n",
    "top5_pred_val1 = generate_user_knn_regressor(user_id_val1, user_item_matrix_val1, similarity_matrix_genres_val1, user_id_dict_val1, movie_id_dict_val1, k)\n",
    "\n",
    "# print result\n",
    "print(f\"UserKNN regressor Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id_val1}:\")\n",
    "for movie_id, rating in top5_pred_val1:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Movielens`\n",
    "\n",
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN regressor Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 306139:\n",
      "Movie ID: 7235, Predicted Rating: 2.0\n",
      "Movie ID: 130636, Predicted Rating: 0.0\n",
      "Movie ID: 27156, Predicted Rating: 0.0\n",
      "Movie ID: 8815, Predicted Rating: 0.0\n",
      "Movie ID: 7019, Predicted Rating: 0.0\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_train2, user_id_dict_train2, movie_id_dict_train2, user_ids_train2, movieIds_train2 = create_user_item_matrix(train_data_movielens)\n",
    "movielens_user_genre_matrix_train2 = create_user_genre_matrix(train_data_movielens)\n",
    "# _, user_ratings_matrix_classified_train2 = computing_neutral_scores(user_item_matrix_train2)\n",
    "# user_similarity_matrix_manhattan_train2 = calculate_user_similarity_manhattan(user_item_matrix_train2, threshold)\n",
    "similarity_matrix_genres_train2 = calculate_similarity_users_genres(user_item_matrix_train2, movielens_user_genre_matrix_train2, threshold)\n",
    "\n",
    "# generate recommendations\n",
    "user_id_train2 = user_ids_train2[1]\n",
    "top5_pred_train2 = generate_user_knn_regressor(user_id_train2, user_item_matrix_train2, similarity_matrix_genres_train2, user_id_dict_train2, movie_id_dict_train2, k)\n",
    "\n",
    "# print result\n",
    "print(f\"UserKNN regressor Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id_train2}:\")\n",
    "for movie_id, rating in top5_pred_train2:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserKNN regressor Recommendations: \n",
      "Top 5 recommended movies with predicted ratings for user 39104:\n",
      "Movie ID: 901, Predicted Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_val2, user_id_dict_val2, movie_id_dict_val2, user_ids_val2, movieIds_val2 = create_user_item_matrix(val_data_movielens)\n",
    "movielens_user_genre_matrix_val2 = create_user_genre_matrix(val_data_movielens)\n",
    "# _, user_ratings_matrix_classified_val2 = computing_neutral_scores(user_item_matrix_val2)\n",
    "# user_similarity_matrix_manhattan_val2 = calculate_user_similarity_manhattan(user_item_matrix_val2, threshold)\n",
    "similarity_matrix_genres_val2 = calculate_similarity_users_genres(user_item_matrix_val2, movielens_user_genre_matrix_val2, threshold)\n",
    "\n",
    "# generate recommendations\n",
    "user_id_val2 = user_ids_val2[1]\n",
    "top5_pred_val2 = generate_user_knn_regressor(user_id_val2, user_item_matrix_val2, similarity_matrix_genres_val2, user_id_dict_val2, movie_id_dict_val2, k)\n",
    "\n",
    "# print result\n",
    "print(f\"UserKNN regressor Recommendations: \\nTop 5 recommended movies with predicted ratings for user {user_id_val2}:\")\n",
    "for movie_id, rating in top5_pred_val2:\n",
    "    print(f\"Movie ID: {movie_id}, Predicted Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the movieIds which are recommended are the same, the predicted rating differs somewhat, already indicating a difference between the two userKNN models.\n",
    "\n",
    "## Baseline performance\n",
    "\n",
    "To assess performance, we are going to compare the original ratings matrix with the predicted one after the userKnn model. In order to do so, we will generate a predicted rating matrix with the two functions below. Essentially an array of predicted ratings is generated in contrast with the tuple in the previous function `generate_user_knn_regressor` with the top 5 results. The secon functions will append these in a new matrix. \n",
    "\n",
    "`generate_array_of_pred_ratings`\n",
    "\n",
    "1. **Check User Existence**:\n",
    "   - Ensure that the given `user_id` exists in the `user_id_dict`.\n",
    "\n",
    "2. **Get User Index**:\n",
    "   - Retrieve the index of the user in the user-item matrix based on the `user_id`.\n",
    "\n",
    "3. **Find Similar Users**:\n",
    "   - Calculate the similarity scores between the target user and other users, sort these scores in descending order, and select the top `k` most similar users.\n",
    "\n",
    "4. **Find Rated Movies by Similar Users**:\n",
    "   - Identify the movies that have been rated by the selected similar users.\n",
    "\n",
    "5. **Calculate Weighted Average Ratings**:\n",
    "   - For each movie rated by the similar users, calculate the weighted sum of ratings and the sum of similarities.\n",
    "\n",
    "6. **Calculate Predicted Ratings**:\n",
    "   - Divide the weighted sum of ratings by the sum of similarities to compute the predicted ratings for every movie.\n",
    "\n",
    "7. **Return Predicted Ratings Array**:\n",
    "   - Return the array containing predicted ratings for every movie in `movie_id_dict`.\n",
    "\n",
    "`generate_pred_rating_matrix`\n",
    "\n",
    "1. **Initialize Predicted Ratings Matrix**:\n",
    "   - Initialize a matrix to store predicted ratings for every user and movie.\n",
    "\n",
    "2. **Iterate Over Users**:\n",
    "   - For each user, generate predicted ratings using the `generate_array_of_pred_ratings` function and fill the corresponding row in the predicted ratings matrix.\n",
    "\n",
    "3. **Return Predicted Ratings Matrix**:\n",
    "   - Return the matrix containing predicted ratings for every user and movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_array_of_pred_ratings(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations for a given user using user-based k-nearest neighbors (KNN) collaborative filtering with weighted average.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    predicted_ratings (numpy.ndarray): Array containing predicted ratings for every movie in movie_id_dict.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # Find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # Get similarity scores of the user with other users and sort indices\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # Find movies rated by similar users\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # Calculate weighted average ratings for each movie\n",
    "    weighted_avg_ratings = np.zeros_like(user_item_matrix[0])\n",
    "    similarity_sum = np.zeros_like(user_item_matrix[0])\n",
    "    \n",
    "    for movie in rated_movies:\n",
    "        # Calculate weighted sum of ratings and sum of similarities\n",
    "        weighted_sum = np.sum(user_item_matrix[similar_users_indices, movie] * user_similarity_matrix[user_index, similar_users_indices])\n",
    "        similarity_sum[movie] += np.sum(user_similarity_matrix[user_index, similar_users_indices])\n",
    "        weighted_avg_ratings[movie] += weighted_sum\n",
    "\n",
    "    # Calculate predicted ratings\n",
    "    predicted_ratings_array = np.divide(weighted_avg_ratings, similarity_sum, out=np.zeros_like(weighted_avg_ratings), where=(similarity_sum != 0))\n",
    "\n",
    "    return predicted_ratings_array\n",
    "\n",
    "def generate_pred_rating_matrix(user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates predicted rating matrix for all users.\n",
    "\n",
    "    Parameters:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    predicted_ratings_matrix (numpy.ndarray): Matrix containing predicted ratings for every user and movie.\n",
    "    \"\"\"\n",
    "    num_users = len(user_id_dict)\n",
    "    num_movies = len(movie_id_dict)\n",
    "    predicted_ratings_matrix = np.zeros((num_users, num_movies))\n",
    "\n",
    "    for user_id in user_id_dict:\n",
    "        user_index = user_id_dict[user_id]\n",
    "        predicted_ratings = generate_array_of_pred_ratings(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k)\n",
    "        predicted_ratings_matrix[user_index] = predicted_ratings\n",
    "\n",
    "    return predicted_ratings_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will use RMSE as performance metric, using the function below to compute it:**\n",
    "\n",
    "### Function explanation\n",
    "\n",
    "`compute_rmse`\n",
    "1. **Handle Implicit Ratings**: \n",
    "   - Convert `NaN` values in both `original_ratings` and `predicted_ratings` arrays to 0s. This is done using `np.nan_to_num()` function to ensure that non-rated items are treated as having a rating of 0 for comparison.\n",
    "   \n",
    "2. **Flatten Arrays**:\n",
    "   - Flatten both `original_ratings` and `predicted_ratings` arrays into 1D arrays to facilitate making masks.\n",
    "\n",
    "3. **Remove Unrated Items**:\n",
    "   - Create a mask to filter out entries where the original rating is 0 (unrated items). Only ratings for rated items are considered for RMSE calculation.\n",
    "\n",
    "4. **Compute Squared Differences**:\n",
    "   - Calculate the squared differences between original and predicted ratings for the rated items.\n",
    "\n",
    "5. **Compute Mean Squared Error (MSE)**:\n",
    "   - Compute the mean squared error (MSE) by averaging the squared differences.\n",
    "\n",
    "6. **Compute RMSE**:\n",
    "   - Compute the square root of the mean squared error to obtain the RMSE value, which indicates the average difference between the original and predicted ratings.\n",
    "\n",
    "7. **Return RMSE**:\n",
    "   - Return the computed RMSE value as the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(original_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Computes the Root Mean Square Error (RMSE) between the original ratings and the predicted ratings. MovieIds a user has not interacted with is turned into 0 for now.\n",
    "\n",
    "    Parameters:\n",
    "    original_ratings (numpy.ndarray): Array containing the original ratings.\n",
    "    predicted_ratings (numpy.ndarray): Array containing the predicted ratings.\n",
    "\n",
    "    Returns:\n",
    "    float: The RMSE value.\n",
    "    \n",
    "    \"\"\"\n",
    "    # handle implicit ratings with 0s for now\n",
    "    original_ratings = np.nan_to_num(original_ratings, nan=0, posinf=0, neginf=0)\n",
    "    predicted_ratings = np.nan_to_num(predicted_ratings, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "    # make 1d arrays by flattening them to be able to make masks\n",
    "    original_ratings_flat = original_ratings.flatten()\n",
    "    predicted_ratings_flat = predicted_ratings.flatten()\n",
    "    \n",
    "    # remove entries with no original rating (unrated items)\n",
    "    mask = original_ratings_flat != 0\n",
    "    original_ratings_flat = original_ratings_flat[mask]\n",
    "    predicted_ratings_flat = predicted_ratings_flat[mask]\n",
    "    \n",
    "    # Compute the squared differences\n",
    "    squared_diff = np.square(original_ratings_flat - predicted_ratings_flat)\n",
    "    \n",
    "    # Compute the mean squared error\n",
    "    mse = np.mean(squared_diff)\n",
    "    \n",
    "    # Compute the square root of the mean squared error to get RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Netflix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings_matrix_train1 = generate_pred_rating_matrix(user_item_matrix_train1, similarity_matrix_genres_train1, user_id_dict_train1, movie_id_dict_train1, k=1)\n",
    "predicted_ratings_matrix_val1 = generate_pred_rating_matrix(user_item_matrix_val1, similarity_matrix_genres_val1, user_id_dict_val1, movie_id_dict_val1, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 1.6593534200351532\n",
      "RMSE on validation set: 1.4598450400585696\n"
     ]
    }
   ],
   "source": [
    "train1_rmse = compute_rmse(user_item_matrix_train1, predicted_ratings_matrix_train1)\n",
    "print(\"RMSE on training set:\", train1_rmse)\n",
    "val1_rmse = compute_rmse(user_item_matrix_val1, predicted_ratings_matrix_val1)\n",
    "print(\"RMSE on validation set:\", val1_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Movielens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings_matrix_train2 = generate_pred_rating_matrix(user_item_matrix_train2, similarity_matrix_genres_train2, user_id_dict_train2, movie_id_dict_train2, k=1)\n",
    "predicted_ratings_matrix_val2 = generate_pred_rating_matrix(user_item_matrix_val2, similarity_matrix_genres_val2, user_id_dict_val2, movie_id_dict_val2, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 1.4995171803206377\n",
      "RMSE on validation set: 1.2193039521216908\n"
     ]
    }
   ],
   "source": [
    "train2_rmse = compute_rmse(user_item_matrix_train2, predicted_ratings_matrix_train2)\n",
    "print(\"RMSE on training set:\", train2_rmse)\n",
    "val2_rmse = compute_rmse(user_item_matrix_val2, predicted_ratings_matrix_val2)\n",
    "print(\"RMSE on validation set:\", val2_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Now we have recorded some baseline performance let's find the optimal value for K by loping over different k values while generating the predicted rating matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Netflix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value: 1 | RMSE: 1.6593534200351532\n",
      "K-value: 4 | RMSE: 1.5902267018848553\n",
      "K-value: 10 | RMSE: 1.6083235470793062\n",
      "K-value: 15 | RMSE: 1.6003897186980665\n",
      "\n",
      "Best K-value: 4 | Best RMSE: 1.5902267018848553\n"
     ]
    }
   ],
   "source": [
    "k_list = [1, 4, 10, 15]\n",
    "rmse_list = []\n",
    "best_k_train1 = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for k in k_list:\n",
    "    predicted_item_matrix = generate_pred_rating_matrix(user_item_matrix_train1, similarity_matrix_genres_train1, user_id_dict_train1, movie_id_dict_train1, k=k)\n",
    "    \n",
    "    # Compute Root Mean Square Error (RMSE)\n",
    "    rmse = compute_rmse(user_item_matrix_train1, predicted_item_matrix)\n",
    "    \n",
    "    # Append the RMSE value to the list\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    # Check if current k gives the best RMSE\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_k_train1 = k\n",
    "\n",
    "# Print the result descendingly\n",
    "for i, k_value in enumerate(k_list):\n",
    "    print(f\"K-value: {k_value} | RMSE: {rmse_list[i]}\")\n",
    "\n",
    "print(f\"\\nBest K-value: {best_k_train1} | Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Movielens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value: 1 | RMSE: 1.4995171803206377\n",
      "K-value: 4 | RMSE: 1.4890477827048683\n",
      "K-value: 10 | RMSE: 1.4880920911260074\n",
      "K-value: 15 | RMSE: 1.4657350551873696\n",
      "\n",
      "Best K-value: 15 | Best RMSE: 1.4657350551873696\n"
     ]
    }
   ],
   "source": [
    "k_list = [1, 4, 10, 15]\n",
    "rmse_list = []\n",
    "best_k_train2 = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for k in k_list:\n",
    "    predicted_item_matrix = generate_pred_rating_matrix(user_item_matrix_train2, similarity_matrix_genres_train2, user_id_dict_train2, movie_id_dict_train2, k=k)\n",
    "    \n",
    "    # Compute Root Mean Square Error (RMSE)\n",
    "    rmse = compute_rmse(user_item_matrix_train2, predicted_item_matrix)\n",
    "    \n",
    "    # Append the RMSE value to the list\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    # Check if current k gives the best RMSE\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_k_train2 = k\n",
    "\n",
    "# Print the result descendingly\n",
    "for i, k_value in enumerate(k_list):\n",
    "    print(f\"K-value: {k_value} | RMSE: {rmse_list[i]}\")\n",
    "\n",
    "print(f\"\\nBest K-value: {best_k_train2} | Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final predictions on test set:\n",
    "\n",
    "`Netflix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 1.4820564186528715\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_test1, user_id_dict_test1, movie_id_dict_test1, user_ids_test1, movieIds_test1 = create_user_item_matrix(test_data_netflix)\n",
    "netflix_user_genre_matrix_test1 = create_user_genre_matrix(test_data_netflix)\n",
    "# _, user_ratings_matrix_classified_test1 = computing_neutral_scores(user_item_matrix_test1)\n",
    "# user_similarity_matrix_manhattan_test1 = calculate_user_similarity_manhattan(user_item_matrix_test1, threshold)\n",
    "similarity_matrix_genres_test1 = calculate_similarity_users_genres(user_item_matrix_test1, netflix_user_genre_matrix_test1, threshold)\n",
    "\n",
    "# set up predictions matrix\n",
    "predicted_item_matrix_test1 = generate_pred_rating_matrix(user_item_matrix_test1, similarity_matrix_genres_test1, user_id_dict_test1, movie_id_dict_test1, k=best_k_train1)\n",
    "\n",
    "# compute Root Mean Square Error (RMSE)\n",
    "rmse_test1 = compute_rmse(user_item_matrix_test1, predicted_item_matrix_test1)\n",
    "# print result on test set\n",
    "print(\"RMSE on test set:\", rmse_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Movielens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 1.0886557170871796\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_test2, user_id_dict_test2, movie_id_dict_test2, user_ids_test2, movieIds_test2 = create_user_item_matrix(test_data_movielens)\n",
    "movielens_user_genre_matrix_test2 = create_user_genre_matrix(test_data_movielens)\n",
    "# _, user_ratings_matrix_classified_test2 = computing_neutral_scores(user_item_matrix_test2)\n",
    "# user_similarity_matrix_manhattan_test2 = calculate_user_similarity_manhattan(user_item_matrix_test2, threshold)\n",
    "similarity_matrix_genres_test2 = calculate_similarity_users_genres(user_item_matrix_test2, movielens_user_genre_matrix_test2, threshold)\n",
    "\n",
    "# set up predictions matrix\n",
    "predicted_item_matrix_test2 = generate_pred_rating_matrix(user_item_matrix_test2, similarity_matrix_genres_test2, user_id_dict_test2, movie_id_dict_test2, k=best_k_train2)\n",
    "\n",
    "# compute Root Mean Square Error (RMSE)\n",
    "rmse_test2 = compute_rmse(user_item_matrix_test2, predicted_item_matrix_test2)\n",
    "# print result on test set\n",
    "print(\"RMSE on test set:\", rmse_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit on UserKNN regression\n",
    "\n",
    "Go to UserKNN CLASS modelling-Stijn.ipynb for function explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_knn_classifier_with_movies(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie recommendations for a given user using user-based k-nearest neighbors (KNN) collaborative filtering with neighborhood-based classification.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom recommendations are to be generated.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    recommendations (list): List of tuples containing recommended movie IDs and their predicted ratings for the given user.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    # find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # this line calculates the similarity score between the target and other users and sorts it descendingly\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # the indices of users in the previous line are then used here to find the ratings of those users\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # this line is selecting the ratings of the similar users which are the similar users indices\n",
    "    neighbor_ratings = user_item_matrix[similar_users_indices][:, rated_movies]\n",
    "    # thie line is computing similarity weights\n",
    "    similarity_weights = user_similarity_matrix[user_index, similar_users_indices][:, np.newaxis] # by converting to column vector the matrix multiplication can be performed because the shape is now the same as neighbor_ratings\n",
    "    # this line is performing a dot product of the ratings and the weights to compute the predicted rating\n",
    "    votes = np.dot(neighbor_ratings.T, similarity_weights).flatten()\n",
    "\n",
    "    # Find the top 5 ratings with the maximum votes\n",
    "    top_indices = np.argsort(votes)[-5:][::-1]\n",
    "    top_recommendations = [(list(movie_id_dict.keys())[list(movie_id_dict.values()).index(rated_movies[idx])], votes[idx]) for idx in top_indices]\n",
    "\n",
    "    return top_recommendations\n",
    "\n",
    "def generate_predictions_array(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates movie ratings predictions for a given user using user-based k-nearest neighbors (KNN) collaborative filtering with neighborhood-based classification.\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int): ID of the user for whom ratings are to be predicted.\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    predicted_ratings (numpy.ndarray): Array containing predicted ratings for the given user and all movies in movie_id_dict.\n",
    "    \"\"\"\n",
    "    # Ensure user ID exists in the dictionary\n",
    "    if user_id not in user_id_dict:\n",
    "        print(f\"User with ID {user_id} not found.\")\n",
    "        return np.array([])\n",
    "\n",
    "    # Find the index of the user in the user-item matrix\n",
    "    user_index = user_id_dict[user_id]\n",
    "\n",
    "    # Get similarity scores of the user with other users and sort indices\n",
    "    similar_users_indices = np.argsort(user_similarity_matrix[user_index])[::-1][:k]\n",
    "\n",
    "    # Find movies rated by similar users\n",
    "    rated_movies = np.where(~np.isnan(user_item_matrix[similar_users_indices]))[1]\n",
    "\n",
    "    # Calculate votes from neighbors\n",
    "    neighbor_ratings = user_item_matrix[similar_users_indices][:, rated_movies]\n",
    "    similarity_weights = user_similarity_matrix[user_index, similar_users_indices][:, np.newaxis]\n",
    "    votes = np.dot(neighbor_ratings.T, similarity_weights).flatten()\n",
    "\n",
    "    # Find the predicted ratings for the given user and all movies\n",
    "    predicted_ratings = np.full(len(movie_id_dict), np.nan)  # Initialize with NaN for unrated movies\n",
    "    for movie_id, movie_index in movie_id_dict.items():\n",
    "        if movie_index in rated_movies:\n",
    "            idx = np.where(rated_movies == movie_index)[0][0]\n",
    "            predicted_ratings[movie_index] = votes[idx]\n",
    "\n",
    "    return predicted_ratings\n",
    "\n",
    "def generate_predicted_user_item_matrix(user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k):\n",
    "    \"\"\"\n",
    "    Generates the predicted user-item matrix using user-based k-nearest neighbors (KNN) collaborative filtering with neighborhood-based classification for all users.\n",
    "\n",
    "    Parameters:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "    user_similarity_matrix (numpy.ndarray): Matrix representing cosine similarity between users.\n",
    "    user_id_dict (dict): Dictionary mapping user IDs to unique indices in the user-item matrix.\n",
    "    movie_id_dict (dict): Dictionary mapping movie IDs to unique indices in the user-item matrix.\n",
    "    k (int): Number of nearest neighbors to consider for recommendations.\n",
    "\n",
    "    Returns:\n",
    "    predicted_matrix (numpy.ndarray): Predicted user-item matrix containing ratings for all users and movies.\n",
    "    \"\"\"\n",
    "    num_users = user_item_matrix.shape[0]\n",
    "    num_movies = len(movie_id_dict)\n",
    "    predicted_matrix = np.zeros((num_users, num_movies))\n",
    "\n",
    "    # Iterate over each user\n",
    "    for user_id in user_id_dict:\n",
    "        predicted_ratings = generate_predictions_array(user_id, user_item_matrix, user_similarity_matrix, user_id_dict, movie_id_dict, k)\n",
    "        predicted_matrix[user_id_dict[user_id]] = predicted_ratings\n",
    "\n",
    "    return predicted_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Netflix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings_matrix_train1_class = generate_pred_rating_matrix(user_item_matrix_train1, similarity_matrix_genres_train1, user_id_dict_train1, movie_id_dict_train1, k=1)\n",
    "predicted_ratings_matrix_val1_class = generate_pred_rating_matrix(user_item_matrix_val1, similarity_matrix_genres_val1, user_id_dict_val1, movie_id_dict_val1, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 1.6593534200351532\n",
      "RMSE on validation set: 1.4598450400585696\n"
     ]
    }
   ],
   "source": [
    "train1_rmse_class = compute_rmse(user_item_matrix_train1, predicted_ratings_matrix_train1_class)\n",
    "print(\"RMSE on training set:\", train1_rmse)\n",
    "val1_rmse_class = compute_rmse(user_item_matrix_val1, predicted_ratings_matrix_val1_class)\n",
    "print(\"RMSE on validation set:\", val1_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Movielens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings_matrix_train2_class = generate_pred_rating_matrix(user_item_matrix_train2, similarity_matrix_genres_train2, user_id_dict_train2, movie_id_dict_train2, k=1)\n",
    "predicted_ratings_matrix_val2_class = generate_pred_rating_matrix(user_item_matrix_val2, similarity_matrix_genres_val2, user_id_dict_val2, movie_id_dict_val2, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 1.4995171803206377\n",
      "RMSE on validation set: 1.2193039521216908\n"
     ]
    }
   ],
   "source": [
    "train2_rmse_class = compute_rmse(user_item_matrix_train2, predicted_ratings_matrix_train2_class)\n",
    "print(\"RMSE on training set:\", train2_rmse)\n",
    "val2_rmse_class = compute_rmse(user_item_matrix_val2, predicted_ratings_matrix_val2_class)\n",
    "print(\"RMSE on validation set:\", val2_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning (knn classification)\n",
    "\n",
    "Now we have recorded some baseline performance let's find the optimal value for K by loping over different k values while generating the predicted rating matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Netflix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value: 1 | RMSE: 1.4958319704233833\n",
      "K-value: 4 | RMSE: 1.2760958283885289\n",
      "K-value: 10 | RMSE: 1.205793224704754\n",
      "K-value: 15 | RMSE: 1.2003227023096785\n",
      "\n",
      "Best K-value: 15 | Best RMSE: 1.2003227023096785\n"
     ]
    }
   ],
   "source": [
    "k_list = [1, 4, 10, 15]\n",
    "rmse_list = []\n",
    "best_k_train1_class = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for k in k_list:\n",
    "    predicted_item_matrix = generate_pred_rating_matrix(user_item_matrix_train1, similarity_matrix_genres_train1, user_id_dict_train1, movie_id_dict_train1, k=k)\n",
    "    \n",
    "    # Compute Root Mean Square Error (RMSE)\n",
    "    rmse = compute_rmse(user_item_matrix_train1, predicted_item_matrix)\n",
    "    \n",
    "    # Append the RMSE value to the list\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    # Check if current k gives the best RMSE\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_k_train1_class = k\n",
    "\n",
    "# Print the result descendingly\n",
    "for i, k_value in enumerate(k_list):\n",
    "    print(f\"K-value: {k_value} | RMSE: {rmse_list[i]}\")\n",
    "\n",
    "print(f\"\\nBest K-value: {best_k_train1_class} | Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Movielens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value: 1 | RMSE: 1.3946208857308595\n",
      "K-value: 4 | RMSE: 1.1699329944236059\n",
      "K-value: 10 | RMSE: 1.0826256066618114\n",
      "K-value: 15 | RMSE: 1.0864868970475208\n",
      "\n",
      "Best K-value: 10 | Best RMSE: 1.0826256066618114\n"
     ]
    }
   ],
   "source": [
    "k_list = [1, 4, 10, 15]\n",
    "rmse_list = []\n",
    "best_k_train2_class = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for k in k_list:\n",
    "    predicted_item_matrix = generate_pred_rating_matrix(user_item_matrix_train2, similarity_matrix_genres_train2, user_id_dict_train2, movie_id_dict_train2, k=k)\n",
    "    \n",
    "    # Compute Root Mean Square Error (RMSE)\n",
    "    rmse = compute_rmse(user_item_matrix_train2, predicted_item_matrix)\n",
    "    \n",
    "    # Append the RMSE value to the list\n",
    "    rmse_list.append(rmse)\n",
    "    \n",
    "    # Check if current k gives the best RMSE\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_k_train2_class = k\n",
    "\n",
    "# Print the result descendingly\n",
    "for i, k_value in enumerate(k_list):\n",
    "    print(f\"K-value: {k_value} | RMSE: {rmse_list[i]}\")\n",
    "\n",
    "print(f\"\\nBest K-value: {best_k_train2_class} | Best RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final predictions on test set (knn classification):\n",
    "\n",
    "`Netflix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 1.6469003314573671\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_test1, user_id_dict_test1, movie_id_dict_test1, user_ids_test1, movieIds_test1 = create_user_item_matrix(test_data_netflix)\n",
    "# _, user_ratings_matrix_classified_test1 = computing_neutral_scores(user_item_matrix_test1)\n",
    "similarity_matrix_genres_test1_class = calculate_similarity_users_genres(user_item_matrix_test1, user_item_matrix_test1, threshold)\n",
    "\n",
    "# set up predictions matrix\n",
    "predicted_item_matrix_test1_class = generate_pred_rating_matrix(user_item_matrix_test1, similarity_matrix_genres_test1_class, user_id_dict_test1, movie_id_dict_test1, k=best_k_train1_class)\n",
    "\n",
    "# compute Root Mean Square Error (RMSE)\n",
    "rmse_test1_class = compute_rmse(user_item_matrix_test1, predicted_item_matrix_test1_class)\n",
    "# print result on test set\n",
    "print(\"RMSE on test set:\", rmse_test1_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Movielens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set: 1.1992819268729882\n"
     ]
    }
   ],
   "source": [
    "# set up\n",
    "user_item_matrix_test2, user_id_dict_test2, movie_id_dict_test2, user_ids_test2, movieIds_test2 = create_user_item_matrix(test_data_movielens)\n",
    "# _, user_ratings_matrix_classified_test2 = computing_neutral_scores(user_item_matrix_test2)\n",
    "similarity_matrix_genres_test2_class = calculate_similarity_users_genres(user_item_matrix_test2, user_item_matrix_test2, threshold)\n",
    "\n",
    "# set up predictions matrix\n",
    "predicted_item_matrix_test2_class = generate_pred_rating_matrix(user_item_matrix_test2, similarity_matrix_genres_test2_class, user_id_dict_test2, movie_id_dict_test2, k=best_k_train2_class)\n",
    "\n",
    "# compute Root Mean Square Error (RMSE)\n",
    "rmse_test2_class = compute_rmse(user_item_matrix_test2, predicted_item_matrix_test2_class)\n",
    "# print result on test set\n",
    "print(\"RMSE on test set:\", rmse_test2_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old function to normalize ratings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of ratings in user-item matrix:\n",
    "We might suggest filling the empty values with 0s, but that can create issues with recommendation engines. \n",
    "\n",
    "If we were to fill this NaN with a 0, we would be incorrectly implying they greatly disliked! We are going to center each users ratings around 0 by deducting the row average and then fill in the missing values with 0. This means the missing data is replaced with neutral scores.\n",
    "\n",
    "### `computing_neutral_scores` Function Explanation\n",
    "\n",
    "### Functions Used and Purpose:\n",
    "- **`np.nanmean()`**: Used to calculate the average rating for each user while handling NaN (missing) values.\n",
    "  - **`axis=1`**: Specifies that the calculation is done along the rows (i.e., for each user).\n",
    "- **`np.nan_to_num()`**: Used to fill in missing data (NaN) with zeros while preserving non-NaN values.\n",
    "- **`np.reshape(-1, 1)`**: Used to reshape the array to ensure proper broadcasting during subtraction.\n",
    "- **Indexing and Slicing**: Used to access elements in arrays and matrices.\n",
    "\n",
    "### Steps:\n",
    "1. **Calculate Average Ratings**:\n",
    "   - Use `np.nanmean()` to compute the average rating for each user along the rows of the user-item matrix. This handles missing ratings (NaN) gracefully, computing the mean while ignoring NaN values.\n",
    "\n",
    "2. **Center Ratings Around 0**:\n",
    "   - Subtract the average ratings from each user's ratings in the user-item matrix. This centers each user's ratings around 0, effectively removing the user bias from the ratings.\n",
    "\n",
    "3. **Fill Missing Data with Zeros**:\n",
    "   - Use `np.nan_to_num()` to replace missing data (NaN) with zeros while preserving the existing non-NaN values. This ensures that missing ratings are treated neutrally (i.e., as if the user has not rated the item).\n",
    "\n",
    "4. **Return Normalized User Ratings**:\n",
    "   - Return the resulting normalized user ratings matrix, where missing ratings have been replaced with zeros and each user's ratings are centered around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_neutral_scores(user_item_matrix):\n",
    "    \"\"\"\n",
    "    Compute neutral scores for user-item interactions in a user-item matrix.\n",
    "\n",
    "    Parameters:\n",
    "    user_item_matrix (numpy.ndarray): Matrix representing users' ratings for items (movies).\n",
    "\n",
    "    Returns:\n",
    "    user_ratings_matrix_normed (numpy.ndarray): Matrix representing users' ratings normalized with neutral scores.\n",
    "    \"\"\"\n",
    "    # Calculate the average rating for each user\n",
    "    avg_ratings = np.nanmean(user_item_matrix, axis=1)\n",
    "\n",
    "    # Center each user's ratings around 0\n",
    "    user_ratings_matrix_centered = user_item_matrix - avg_ratings.reshape(-1, 1)\n",
    "\n",
    "    # Fill in the missing data with 0s\n",
    "    user_ratings_matrix_normed = np.nan_to_num(user_ratings_matrix_centered, nan=0)\n",
    "\n",
    "    return user_ratings_matrix_normed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_ddb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
